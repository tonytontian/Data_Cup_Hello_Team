{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Test(Logistic regression, random forest, LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the relevant computational modules\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd #data processing\n",
    "import numpy as np #linear algebra\n",
    "\n",
    "# Models Packages\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Gradient Boosting\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Basic Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# visualization \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "transaction_training = pd.read_csv('../raw_data/transactions_train.csv')\n",
    "payment_training = pd.read_csv('../raw_data/paiements_train.csv')\n",
    "billing_training = pd.read_csv('../raw_data/facturation_train.csv')\n",
    "performance_training = pd.read_csv('../raw_data/performance_train.csv')\n",
    "\n",
    "\n",
    "transaction_test = pd.read_csv('../raw_data/transactions_test.csv')\n",
    "payment_test = pd.read_csv('../raw_data/paiements_test.csv')\n",
    "billing_test = pd.read_csv('../raw_data/facturation_test.csv')\n",
    "performance_test = pd.read_csv('../raw_data/performance_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>TRANSACTION_AMT</th>\n",
       "      <th>TRANSACTION_DTTM</th>\n",
       "      <th>PAYMENT_REVERSAL_XFLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99690111</td>\n",
       "      <td>208.0</td>\n",
       "      <td>2015-04-26 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99690111</td>\n",
       "      <td>176.8</td>\n",
       "      <td>2015-05-28 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99690111</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2015-03-27 04:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99690111</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2015-04-02 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99690111</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2015-11-24 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  TRANSACTION_AMT     TRANSACTION_DTTM PAYMENT_REVERSAL_XFLG\n",
       "0  99690111            208.0  2015-04-26 00:00:00                     Q\n",
       "1  99690111            176.8  2015-05-28 00:00:00                     Q\n",
       "2  99690111            200.0  2015-03-27 04:00:00                     Q\n",
       "3  99690111             80.8  2015-04-02 00:00:00                     Q\n",
       "4  99690111            250.0  2015-11-24 00:00:00                     Q"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payment_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>StatementDate</th>\n",
       "      <th>CurrentTotalBalance</th>\n",
       "      <th>CashBalance</th>\n",
       "      <th>CreditLimit</th>\n",
       "      <th>DelqCycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-05</td>\n",
       "      <td>2015-05-03</td>\n",
       "      <td>8497.84</td>\n",
       "      <td>4293.12</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2014-11</td>\n",
       "      <td>2014-11-03</td>\n",
       "      <td>866.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-06</td>\n",
       "      <td>2015-05-31</td>\n",
       "      <td>10790.95</td>\n",
       "      <td>5224.44</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-10</td>\n",
       "      <td>2015-10-04</td>\n",
       "      <td>12388.46</td>\n",
       "      <td>4786.08</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-11</td>\n",
       "      <td>2015-11-02</td>\n",
       "      <td>12746.50</td>\n",
       "      <td>4818.48</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE PERIODID_MY StatementDate  CurrentTotalBalance  CashBalance  \\\n",
       "0  99690111     2015-05    2015-05-03              8497.84      4293.12   \n",
       "1  99690111     2014-11    2014-11-03               866.00         0.00   \n",
       "2  99690111     2015-06    2015-05-31             10790.95      5224.44   \n",
       "3  99690111     2015-10    2015-10-04             12388.46      4786.08   \n",
       "4  99690111     2015-11    2015-11-02             12746.50      4818.48   \n",
       "\n",
       "   CreditLimit  DelqCycle  \n",
       "0      16200.0          0  \n",
       "1      12000.0          0  \n",
       "2      16200.0          0  \n",
       "3      16200.0          0  \n",
       "4      16200.0          0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billing_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57427180</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29617912</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61632809</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14117855</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE PERIODID_MY  Default\n",
       "0  99690111  2015-12-01        0\n",
       "1  57427180  2012-12-01        0\n",
       "2  29617912  2015-12-01        0\n",
       "3  61632809  2015-12-01        0\n",
       "4  14117855  2013-12-01        0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\futai\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([5.12925010e-04, 2.09659012e-05, 4.88468195e-06, 1.63132045e-06,\n",
       "        7.18226411e-07, 4.80673489e-07, 2.07858806e-07, 1.39191165e-07,\n",
       "        1.28055872e-07, 8.53705811e-08, 5.56764659e-08, 3.52617618e-08,\n",
       "        3.15499974e-08, 1.11352932e-08, 7.42352879e-09, 2.41264686e-08,\n",
       "        7.42352879e-09, 7.42352879e-09, 5.56764659e-09, 1.85588220e-09,\n",
       "        3.71176440e-09, 3.71176440e-09, 1.85588220e-09, 1.85588220e-09,\n",
       "        1.85588220e-09, 0.00000000e+00, 0.00000000e+00, 3.71176440e-09,\n",
       "        0.00000000e+00, 1.85588220e-09]),\n",
       " array([    0.   ,  1843.752,  3687.504,  5531.256,  7375.008,  9218.76 ,\n",
       "        11062.512, 12906.264, 14750.016, 16593.768, 18437.52 , 20281.272,\n",
       "        22125.024, 23968.776, 25812.528, 27656.28 , 29500.032, 31343.784,\n",
       "        33187.536, 35031.288, 36875.04 , 38718.792, 40562.544, 42406.296,\n",
       "        44250.048, 46093.8  , 47937.552, 49781.304, 51625.056, 53468.808,\n",
       "        55312.56 ]),\n",
       " <a list of 30 Patch objects>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Abnormal value detaction\n",
    "plt.hist(np.array(payment_training['TRANSACTION_AMT'].dropna()), normed=True, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11840</th>\n",
       "      <td>32951452</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID_CPTE PERIODID_MY  Default\n",
       "11840  32951452  2014-12-01        0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_training[performance_training['ID_CPTE'] == 32951452]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>StatementDate</th>\n",
       "      <th>CurrentTotalBalance</th>\n",
       "      <th>CashBalance</th>\n",
       "      <th>CreditLimit</th>\n",
       "      <th>DelqCycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21517</th>\n",
       "      <td>23238663</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013-12-12</td>\n",
       "      <td>863.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21518</th>\n",
       "      <td>23238663</td>\n",
       "      <td>2013-11</td>\n",
       "      <td>2013-11-15</td>\n",
       "      <td>358.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21519</th>\n",
       "      <td>23238663</td>\n",
       "      <td>2013-10</td>\n",
       "      <td>2013-10-15</td>\n",
       "      <td>3031.35</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21520</th>\n",
       "      <td>23238663</td>\n",
       "      <td>2013-09</td>\n",
       "      <td>2013-09-13</td>\n",
       "      <td>2249.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21521</th>\n",
       "      <td>23238663</td>\n",
       "      <td>2013-08</td>\n",
       "      <td>2013-08-12</td>\n",
       "      <td>1254.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21522</th>\n",
       "      <td>23238663</td>\n",
       "      <td>2013-07</td>\n",
       "      <td>2013-07-15</td>\n",
       "      <td>461.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21523</th>\n",
       "      <td>23238663</td>\n",
       "      <td>2013-06</td>\n",
       "      <td>2013-06-11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21524</th>\n",
       "      <td>23238663</td>\n",
       "      <td>2013-05</td>\n",
       "      <td>2013-05-13</td>\n",
       "      <td>3156.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21525</th>\n",
       "      <td>23238663</td>\n",
       "      <td>2013-04</td>\n",
       "      <td>2013-04-12</td>\n",
       "      <td>3045.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21526</th>\n",
       "      <td>23238663</td>\n",
       "      <td>2013-03</td>\n",
       "      <td>2013-03-12</td>\n",
       "      <td>2634.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21527</th>\n",
       "      <td>23238663</td>\n",
       "      <td>2013-02</td>\n",
       "      <td>2013-02-10</td>\n",
       "      <td>1958.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21528</th>\n",
       "      <td>23238663</td>\n",
       "      <td>2013-01</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>1365.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21529</th>\n",
       "      <td>23238663</td>\n",
       "      <td>2012-12</td>\n",
       "      <td>2012-12-09</td>\n",
       "      <td>1848.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21530</th>\n",
       "      <td>23238663</td>\n",
       "      <td>2012-11</td>\n",
       "      <td>2012-11-11</td>\n",
       "      <td>1428.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID_CPTE PERIODID_MY StatementDate  CurrentTotalBalance  CashBalance  \\\n",
       "21517  23238663     2013-12    2013-12-12               863.10          0.0   \n",
       "21518  23238663     2013-11    2013-11-15               358.44          0.0   \n",
       "21519  23238663     2013-10    2013-10-15              3031.35         81.0   \n",
       "21520  23238663     2013-09    2013-09-13              2249.14          0.0   \n",
       "21521  23238663     2013-08    2013-08-12              1254.60          0.0   \n",
       "21522  23238663     2013-07    2013-07-15               461.00          0.0   \n",
       "21523  23238663     2013-06    2013-06-11                 0.00          0.0   \n",
       "21524  23238663     2013-05    2013-05-13              3156.00          0.0   \n",
       "21525  23238663     2013-04    2013-04-12              3045.72          0.0   \n",
       "21526  23238663     2013-03    2013-03-12              2634.34          0.0   \n",
       "21527  23238663     2013-02    2013-02-10              1958.10          0.0   \n",
       "21528  23238663     2013-01    2013-01-13              1365.28          0.0   \n",
       "21529  23238663     2012-12    2012-12-09              1848.85          0.0   \n",
       "21530  23238663     2012-11    2012-11-11              1428.61          0.0   \n",
       "\n",
       "       CreditLimit  DelqCycle  \n",
       "21517       8000.0          0  \n",
       "21518       8000.0          0  \n",
       "21519       8000.0          0  \n",
       "21520       8000.0          0  \n",
       "21521       8000.0          0  \n",
       "21522       8000.0          0  \n",
       "21523       8000.0          0  \n",
       "21524       8000.0          0  \n",
       "21525       8000.0          0  \n",
       "21526       8000.0          0  \n",
       "21527       8000.0          0  \n",
       "21528       8000.0          0  \n",
       "21529       8000.0          0  \n",
       "21530       8000.0          0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billing_training[billing_training['ID_CPTE'] == 23238663]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basic scikit-learn wrapper model class\n",
    "class SklearnWrapper:\n",
    "    def __init__(self, clf, seed=0, params=None, seed_bool=True):\n",
    "        if (seed_bool == True):\n",
    "            params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "    \n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create basic xgboost wrapper model class\n",
    "class XgbWrapper:\n",
    "    def __init__(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 250)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(xgb.DMatrix(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create basic lightGBM wrapper model class\n",
    "class LightGbmWrapper:\n",
    "    def __init(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 1550)\n",
    "        self.verbose_eval = params.pop('verbose_eval', 100)\n",
    "        \n",
    "    def train(self, x_train, y_train):\n",
    "        lgtrain = lgb.Dataset(x_train, y_train)\n",
    "        self.lgbm = lgb.train(self.param, lgtrain, num_boost_round=self.nrounds, verbose_eval=self.verbose_eval)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.lgbm.predict(lgb.Dataset(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create out-of-fold predictions \n",
    "# make good use of k-fold CV's result \n",
    "# serving for the staking alogrithm \n",
    "# create a new column generated from model's score\n",
    "\n",
    "def get_oof(clf, x_train, y, x_test):\n",
    "    '''\n",
    "    clf: the classifer, which can be logistic regression, SVM regression, Bayes classifier, etc.\n",
    "    x_train: the training x in training dataset\n",
    "    y: the training y in training dataset\n",
    "    x_test: the testing x in training dataset \n",
    "    '''\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        print('\\nFold {}'.format(i))\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "        \n",
    "        clf.fit(x_tr, y_tr)\n",
    "        \n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "    \n",
    "    m = stats.mode(oof_test_skf, axis=1)\n",
    "    oof_test[:] = m[0][0]\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocess\n",
    "\n",
    "class DataPreprocess:\n",
    "    def __init__(self, label_encoder):\n",
    "        self.lbl = label_encoder\n",
    "    \n",
    "    def convert_date(self, statement_date, period_date):\n",
    "        statement_day = statement_date.split('-')[-1]\n",
    "        period_day = period_date.split('-')[-1]\n",
    "        statement_month = statement_date.split('-')[-2]\n",
    "        period_month = period_date.split('-')[-2]\n",
    "        if int(statement_month) < int(period_month):\n",
    "            tmp = 0\n",
    "        else:\n",
    "            if int(statement_day) > 20:\n",
    "                tmp = 1\n",
    "            else:\n",
    "                tmp = 0\n",
    "        return tmp\n",
    "    \n",
    "    \n",
    "    def initialize_billing(self, billing_df):\n",
    "        tmp = []\n",
    "        for index, row in billing_df.iterrows():\n",
    "            tmp.append(self.convert_date(row['StatementDate'], row['PERIODID_MY']))\n",
    "\n",
    "        billing_df['statement_time'] = tmp\n",
    "        \n",
    "        return billing_df\n",
    "    \n",
    "    def preprocess_transcation(self, transaction_df):\n",
    "        categorical_columns = ['MERCHANT_CATEGORY_XCD', 'MERCHANT_CITY_NAME', 'MERCHANT_COUNTRY_XCD', \n",
    "                               'DECISION_XCD', 'TRANSACTION_CATEGORY_XCD', 'TRANSACTION_TYPE_XCD', 'SICGROUP']\n",
    "        \n",
    "        for col in categorical_columns:\n",
    "            transaction_df[col].fillna('unknown')\n",
    "            transaction_df[col] = self.lbl.fit_transform(transaction_df[col].astype(str))\n",
    "        \n",
    "        transaction_df = transaction_df.groupby(['ID_CPTE', 'MERCHANT_CATEGORY_XCD'])['TRANSACTION_AMT'].sum()\n",
    "        transaction_df = transaction_df.reset_index()\n",
    "        transaction_df = transaction_df.pivot_table('TRANSACTION_AMT', ['ID_CPTE'], 'MERCHANT_CATEGORY_XCD')\n",
    "        transaction_df.columns = ['MERCHANT_CATEGORY_' + str(i) for i in transaction_df.columns]\n",
    "        transaction_df = transaction_df.fillna(0)\n",
    "        \n",
    "        return transaction_df\n",
    "    \n",
    "    def preprocess_payment(self, payment_df):\n",
    "        payment_df = payment_df.dropna()\n",
    "        payment_df['TRANSACTION_DTTM'] = payment_df['TRANSACTION_DTTM'].apply(lambda x: str(x).split(' ')[0][:-3])\n",
    "        payment_df = payment_df.sort_values(['ID_CPTE', 'TRANSACTION_DTTM'])\n",
    "        payment_df['PAYMENT_N_COUNT'] = payment_df['PAYMENT_REVERSAL_XFLG'] == 'N'\n",
    "        \n",
    "        payment_df = payment_df.groupby(['ID_CPTE', 'TRANSACTION_DTTM'])[['TRANSACTION_AMT', 'PAYMENT_N_COUNT']].sum().reset_index()\n",
    "        payment_df = payment_df.groupby('ID_CPTE').tail(12)\n",
    "        \n",
    "        tmp = payment_df.groupby(['ID_CPTE'])['PAYMENT_N_COUNT'].sum().reset_index()\n",
    "        \n",
    "        payment_df['TRANSACTION_DTTM'] = payment_df['TRANSACTION_DTTM'].apply(lambda x: x.split('-')[1])\n",
    "        payment_df = payment_df.pivot_table('TRANSACTION_AMT', ['ID_CPTE'], 'TRANSACTION_DTTM')\n",
    "        payment_df.columns = ['transaction_' + str(i) for i in payment_df.columns + '_month']\n",
    "        payment_df = payment_df.reset_index()\n",
    "        payment_df = payment_df.fillna(0)\n",
    "        \n",
    "        payment_df = payment_df.merge(tmp, on='ID_CPTE')\n",
    "        \n",
    "        return payment_df\n",
    "    \n",
    "    def preprocess_billing(self, billing_df):\n",
    "        billing_df['PERIODID_MY'] = billing_df['PERIODID_MY'].apply(lambda x: x[:-3])\n",
    "        billing_df = billing_df.sort_values(['ID_CPTE', 'PERIODID_MY'])\n",
    "        billing_df = billing_df.reset_index(drop=True)\n",
    "        billing_df = billing_df.groupby('ID_CPTE').tail(12)\n",
    "        billing_df = billing_df.reset_index(drop=True)\n",
    "        billing_df['CreditLeft'] = billing_df['CreditLimit'] - billing_df['CurrentTotalBalance']\n",
    "        \n",
    "        billing_df['PERIODID_MY'] = billing_df['PERIODID_MY'].apply(lambda x: x[-2:])\n",
    "        credit_left = billing_df.pivot_table('CreditLeft', ['ID_CPTE'], 'PERIODID_MY')\n",
    "        credit_left.columns = ['credit_left_' + str(i) for i in credit_left.columns + '_month']\n",
    "        cash_balance = billing_df.pivot_table('CashBalance', ['ID_CPTE'], 'PERIODID_MY')\n",
    "        cash_balance.columns = ['cash_balance_' + str(i) for i in cash_balance.columns + '_month']\n",
    "        \n",
    "        delq_cycle_avg = billing_df.groupby(['ID_CPTE'])['DelqCycle'].mean().reset_index()\n",
    "        delq_cycle_avg = delq_cycle_avg.rename(columns={'DelqCycle': 'AvgDelqCycle'})\n",
    "        \n",
    "        delq_cycle = billing_df.groupby(['ID_CPTE'])['DelqCycle'].max().reset_index()\n",
    "        delq_cycle = delq_cycle.rename(columns={'DelqCycle': 'MaxDelqCycle'})\n",
    "        \n",
    "        late_count = billing_df.groupby(['ID_CPTE'])['statement_time'].sum().reset_index()\n",
    "        late_count = late_count.rename(columns={'statement_time': 'LateCount'})\n",
    "        \n",
    "        credit_left = credit_left.reset_index()\n",
    "        cash_balance = cash_balance.reset_index()\n",
    "        \n",
    "        tmp = credit_left.merge(cash_balance, on='ID_CPTE')\n",
    "        tmp = tmp.merge(delq_cycle, on='ID_CPTE')\n",
    "        tmp = tmp.merge(delq_cycle_avg, on='ID_CPTE')\n",
    "        tmp = tmp.merge(late_count, on='ID_CPTE')\n",
    "        \n",
    "        return tmp\n",
    "    \n",
    "    def merge(self, payment, billing):\n",
    "        merge_df = payment.merge(billing, on='ID_CPTE', how='right')\n",
    "        return merge_df.set_index(['ID_CPTE']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>StatementDate</th>\n",
       "      <th>CurrentTotalBalance</th>\n",
       "      <th>CashBalance</th>\n",
       "      <th>CreditLimit</th>\n",
       "      <th>DelqCycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71424379</td>\n",
       "      <td>2013-11-01</td>\n",
       "      <td>2013-11-04</td>\n",
       "      <td>1444.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71424379</td>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>2014-04-30</td>\n",
       "      <td>785.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71424379</td>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>2014-08-02</td>\n",
       "      <td>1095.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71424379</td>\n",
       "      <td>2014-04-01</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>845.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71424379</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>2013-11-30</td>\n",
       "      <td>1623.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE PERIODID_MY StatementDate  CurrentTotalBalance  CashBalance  \\\n",
       "0  71424379  2013-11-01    2013-11-04              1444.30          0.0   \n",
       "1  71424379  2014-05-01    2014-04-30               785.89          0.0   \n",
       "2  71424379  2014-08-01    2014-08-02              1095.48          0.0   \n",
       "3  71424379  2014-04-01    2014-04-02               845.30          0.0   \n",
       "4  71424379  2013-12-01    2013-11-30              1623.28          0.0   \n",
       "\n",
       "   CreditLimit  DelqCycle  \n",
       "0       3200.0          0  \n",
       "1       3200.0          0  \n",
       "2       3200.0          0  \n",
       "3       3200.0          0  \n",
       "4       3200.0          0  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billing_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = DataPreprocess(label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "billing_training = preprocess.initialize_billing(billing_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\futai\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "processed_payment = preprocess.preprocess_payment(payment_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_billing = preprocess.preprocess_billing(billing_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = preprocess.merge(processed_payment, processed_billing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_col = processed_data.iloc[:, :12].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with missing value in payment\n",
    "for col in transaction_col:\n",
    "    replace_value = processed_data[processed_data[col].notna()][col].mean()\n",
    "    processed_data[col] = processed_data[col].fillna(replace_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.merge(performance_training[['ID_CPTE', 'Default']], on='ID_CPTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.set_index('ID_CPTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_01_month</th>\n",
       "      <th>transaction_02_month</th>\n",
       "      <th>transaction_03_month</th>\n",
       "      <th>transaction_04_month</th>\n",
       "      <th>transaction_05_month</th>\n",
       "      <th>transaction_06_month</th>\n",
       "      <th>transaction_07_month</th>\n",
       "      <th>transaction_08_month</th>\n",
       "      <th>transaction_09_month</th>\n",
       "      <th>transaction_10_month</th>\n",
       "      <th>...</th>\n",
       "      <th>cash_balance_07_month</th>\n",
       "      <th>cash_balance_08_month</th>\n",
       "      <th>cash_balance_09_month</th>\n",
       "      <th>cash_balance_10_month</th>\n",
       "      <th>cash_balance_11_month</th>\n",
       "      <th>cash_balance_12_month</th>\n",
       "      <th>MaxDelqCycle</th>\n",
       "      <th>AvgDelqCycle</th>\n",
       "      <th>LateCount</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10001822</th>\n",
       "      <td>318.00</td>\n",
       "      <td>522.50</td>\n",
       "      <td>374.50</td>\n",
       "      <td>4200.00</td>\n",
       "      <td>262.5</td>\n",
       "      <td>265.00</td>\n",
       "      <td>267.50</td>\n",
       "      <td>300.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>231.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10007972</th>\n",
       "      <td>784.34</td>\n",
       "      <td>168.28</td>\n",
       "      <td>1050.00</td>\n",
       "      <td>559.50</td>\n",
       "      <td>664.0</td>\n",
       "      <td>313.50</td>\n",
       "      <td>843.71</td>\n",
       "      <td>191.9</td>\n",
       "      <td>945.9</td>\n",
       "      <td>701.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012520</th>\n",
       "      <td>0.00</td>\n",
       "      <td>86.10</td>\n",
       "      <td>458.00</td>\n",
       "      <td>1177.31</td>\n",
       "      <td>315.0</td>\n",
       "      <td>525.00</td>\n",
       "      <td>505.00</td>\n",
       "      <td>50.5</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>612.00</td>\n",
       "      <td>...</td>\n",
       "      <td>375.72</td>\n",
       "      <td>477.36</td>\n",
       "      <td>639.0</td>\n",
       "      <td>849.66</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>777.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10025534</th>\n",
       "      <td>131.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>260.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6264.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2080.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10033579</th>\n",
       "      <td>574.55</td>\n",
       "      <td>391.30</td>\n",
       "      <td>412.23</td>\n",
       "      <td>470.53</td>\n",
       "      <td>546.8</td>\n",
       "      <td>419.61</td>\n",
       "      <td>283.92</td>\n",
       "      <td>106.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>219.60</td>\n",
       "      <td>...</td>\n",
       "      <td>20.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          transaction_01_month  transaction_02_month  transaction_03_month  \\\n",
       "ID_CPTE                                                                      \n",
       "10001822                318.00                522.50                374.50   \n",
       "10007972                784.34                168.28               1050.00   \n",
       "10012520                  0.00                 86.10                458.00   \n",
       "10025534                131.30                  0.00                260.00   \n",
       "10033579                574.55                391.30                412.23   \n",
       "\n",
       "          transaction_04_month  transaction_05_month  transaction_06_month  \\\n",
       "ID_CPTE                                                                      \n",
       "10001822               4200.00                 262.5                265.00   \n",
       "10007972                559.50                 664.0                313.50   \n",
       "10012520               1177.31                 315.0                525.00   \n",
       "10025534                  0.00                6264.0                  0.00   \n",
       "10033579                470.53                 546.8                419.61   \n",
       "\n",
       "          transaction_07_month  transaction_08_month  transaction_09_month  \\\n",
       "ID_CPTE                                                                      \n",
       "10001822                267.50                 300.0                 250.0   \n",
       "10007972                843.71                 191.9                 945.9   \n",
       "10012520                505.00                  50.5                1115.0   \n",
       "10025534               2080.00                   0.0                 318.0   \n",
       "10033579                283.92                 106.0                  84.0   \n",
       "\n",
       "          transaction_10_month   ...     cash_balance_07_month  \\\n",
       "ID_CPTE                          ...                             \n",
       "10001822                231.75   ...                      0.00   \n",
       "10007972                701.47   ...                      0.00   \n",
       "10012520                612.00   ...                    375.72   \n",
       "10025534                  0.00   ...                      0.00   \n",
       "10033579                219.60   ...                     20.60   \n",
       "\n",
       "          cash_balance_08_month  cash_balance_09_month  cash_balance_10_month  \\\n",
       "ID_CPTE                                                                         \n",
       "10001822                   0.00                    0.0                   0.00   \n",
       "10007972                   3.09                    0.0                   0.00   \n",
       "10012520                 477.36                  639.0                 849.66   \n",
       "10025534                   0.00                    0.0                   0.00   \n",
       "10033579                   0.00                    0.0                   0.00   \n",
       "\n",
       "          cash_balance_11_month  cash_balance_12_month  MaxDelqCycle  \\\n",
       "ID_CPTE                                                                \n",
       "10001822                  101.0                   0.00             0   \n",
       "10007972                    0.0                   0.00             0   \n",
       "10012520                 1224.0                 777.65             0   \n",
       "10025534                    0.0                   0.00             1   \n",
       "10033579                    0.0                   0.00             1   \n",
       "\n",
       "          AvgDelqCycle  LateCount  Default  \n",
       "ID_CPTE                                     \n",
       "10001822      0.000000          0        0  \n",
       "10007972      0.000000          1        0  \n",
       "10012520      0.000000          0        0  \n",
       "10025534      0.416667         12        1  \n",
       "10033579      0.083333          0        0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>StatementDate</th>\n",
       "      <th>CurrentTotalBalance</th>\n",
       "      <th>CashBalance</th>\n",
       "      <th>CreditLimit</th>\n",
       "      <th>DelqCycle</th>\n",
       "      <th>statement_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>35143533</td>\n",
       "      <td>2012-11</td>\n",
       "      <td>2012-11-24</td>\n",
       "      <td>7541.88</td>\n",
       "      <td>1381.12</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>35143533</td>\n",
       "      <td>2012-12</td>\n",
       "      <td>2012-12-20</td>\n",
       "      <td>53.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>35143533</td>\n",
       "      <td>2013-01</td>\n",
       "      <td>2013-01-20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>35143533</td>\n",
       "      <td>2013-02</td>\n",
       "      <td>2013-02-17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>35143533</td>\n",
       "      <td>2013-03</td>\n",
       "      <td>2013-03-23</td>\n",
       "      <td>745.72</td>\n",
       "      <td>329.60</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>35143533</td>\n",
       "      <td>2013-04</td>\n",
       "      <td>2013-04-22</td>\n",
       "      <td>2831.47</td>\n",
       "      <td>301.92</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>35143533</td>\n",
       "      <td>2013-05</td>\n",
       "      <td>2013-05-19</td>\n",
       "      <td>4157.52</td>\n",
       "      <td>250.92</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>35143533</td>\n",
       "      <td>2013-06</td>\n",
       "      <td>2013-06-23</td>\n",
       "      <td>6199.57</td>\n",
       "      <td>208.08</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>35143533</td>\n",
       "      <td>2013-07</td>\n",
       "      <td>2013-07-20</td>\n",
       "      <td>7001.94</td>\n",
       "      <td>87.72</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>35143533</td>\n",
       "      <td>2013-08</td>\n",
       "      <td>2013-08-20</td>\n",
       "      <td>8375.22</td>\n",
       "      <td>505.00</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>35143533</td>\n",
       "      <td>2013-09</td>\n",
       "      <td>2013-09-21</td>\n",
       "      <td>12490.11</td>\n",
       "      <td>2444.19</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>35143533</td>\n",
       "      <td>2013-10</td>\n",
       "      <td>2013-10-25</td>\n",
       "      <td>12935.77</td>\n",
       "      <td>2985.56</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>35143533</td>\n",
       "      <td>2013-11</td>\n",
       "      <td>2013-11-24</td>\n",
       "      <td>12932.40</td>\n",
       "      <td>2989.35</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>35143533</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013-12-20</td>\n",
       "      <td>12679.30</td>\n",
       "      <td>2837.12</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID_CPTE PERIODID_MY StatementDate  CurrentTotalBalance  CashBalance  \\\n",
       "1012  35143533     2012-11    2012-11-24              7541.88      1381.12   \n",
       "1016  35143533     2012-12    2012-12-20                53.53         0.00   \n",
       "1011  35143533     2013-01    2013-01-20                 0.00         0.00   \n",
       "1014  35143533     2013-02    2013-02-17                 0.00         0.00   \n",
       "1015  35143533     2013-03    2013-03-23               745.72       329.60   \n",
       "1008  35143533     2013-04    2013-04-22              2831.47       301.92   \n",
       "1019  35143533     2013-05    2013-05-19              4157.52       250.92   \n",
       "1009  35143533     2013-06    2013-06-23              6199.57       208.08   \n",
       "1017  35143533     2013-07    2013-07-20              7001.94        87.72   \n",
       "1013  35143533     2013-08    2013-08-20              8375.22       505.00   \n",
       "1020  35143533     2013-09    2013-09-21             12490.11      2444.19   \n",
       "1021  35143533     2013-10    2013-10-25             12935.77      2985.56   \n",
       "1018  35143533     2013-11    2013-11-24             12932.40      2989.35   \n",
       "1010  35143533     2013-12    2013-12-20             12679.30      2837.12   \n",
       "\n",
       "      CreditLimit  DelqCycle  statement_time  \n",
       "1012       7000.0          0               1  \n",
       "1016       7000.0          0               0  \n",
       "1011       7000.0          0               0  \n",
       "1014       7000.0          0               0  \n",
       "1015       7000.0          0               1  \n",
       "1008       7000.0          0               1  \n",
       "1019       7000.0          0               0  \n",
       "1009       7000.0          1               1  \n",
       "1017       7000.0          0               0  \n",
       "1013      12000.0          0               0  \n",
       "1020      12000.0          0               1  \n",
       "1021      12000.0          0               1  \n",
       "1018      12000.0          0               1  \n",
       "1010      12000.0          0               0  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billing_training[billing_training['ID_CPTE'] == 35143533].sort_values(['StatementDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>StatementDate</th>\n",
       "      <th>CurrentTotalBalance</th>\n",
       "      <th>CashBalance</th>\n",
       "      <th>CreditLimit</th>\n",
       "      <th>DelqCycle</th>\n",
       "      <th>statement_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>58512689</td>\n",
       "      <td>2013-11</td>\n",
       "      <td>2013-11-15</td>\n",
       "      <td>2533.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>58512689</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013-12-13</td>\n",
       "      <td>2904.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>58512689</td>\n",
       "      <td>2014-01</td>\n",
       "      <td>2014-01-20</td>\n",
       "      <td>2926.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>58512689</td>\n",
       "      <td>2014-02</td>\n",
       "      <td>2014-02-17</td>\n",
       "      <td>2718.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>58512689</td>\n",
       "      <td>2014-03</td>\n",
       "      <td>2014-03-17</td>\n",
       "      <td>3140.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>58512689</td>\n",
       "      <td>2014-04</td>\n",
       "      <td>2014-04-14</td>\n",
       "      <td>3326.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>58512689</td>\n",
       "      <td>2014-05</td>\n",
       "      <td>2014-05-18</td>\n",
       "      <td>1696.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>58512689</td>\n",
       "      <td>2014-06</td>\n",
       "      <td>2014-06-17</td>\n",
       "      <td>1354.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>58512689</td>\n",
       "      <td>2014-07</td>\n",
       "      <td>2014-07-16</td>\n",
       "      <td>973.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>58512689</td>\n",
       "      <td>2014-08</td>\n",
       "      <td>2014-08-14</td>\n",
       "      <td>788.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>58512689</td>\n",
       "      <td>2014-09</td>\n",
       "      <td>2014-09-15</td>\n",
       "      <td>237.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>58512689</td>\n",
       "      <td>2014-10</td>\n",
       "      <td>2014-10-20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>58512689</td>\n",
       "      <td>2014-11</td>\n",
       "      <td>2014-11-18</td>\n",
       "      <td>781.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>58512689</td>\n",
       "      <td>2014-12</td>\n",
       "      <td>2014-12-14</td>\n",
       "      <td>1462.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID_CPTE PERIODID_MY StatementDate  CurrentTotalBalance  CashBalance  \\\n",
       "113  58512689     2013-11    2013-11-15              2533.40          0.0   \n",
       "112  58512689     2013-12    2013-12-13              2904.72          0.0   \n",
       "117  58512689     2014-01    2014-01-20              2926.35          0.0   \n",
       "120  58512689     2014-02    2014-02-17              2718.92          0.0   \n",
       "114  58512689     2014-03    2014-03-17              3140.00          0.0   \n",
       "125  58512689     2014-04    2014-04-14              3326.96          0.0   \n",
       "123  58512689     2014-05    2014-05-18              1696.00          0.0   \n",
       "115  58512689     2014-06    2014-06-17              1354.68          0.0   \n",
       "119  58512689     2014-07    2014-07-16               973.64          0.0   \n",
       "121  58512689     2014-08    2014-08-14               788.64          0.0   \n",
       "118  58512689     2014-09    2014-09-15               237.12          0.0   \n",
       "122  58512689     2014-10    2014-10-20                 0.00          0.0   \n",
       "116  58512689     2014-11    2014-11-18               781.77          0.0   \n",
       "124  58512689     2014-12    2014-12-14              1462.65          0.0   \n",
       "\n",
       "     CreditLimit  DelqCycle  statement_time  \n",
       "113       8800.0          0               0  \n",
       "112       8800.0          0               0  \n",
       "117       8800.0          0               0  \n",
       "120       8800.0          0               0  \n",
       "114       8800.0          0               0  \n",
       "125       8800.0          0               0  \n",
       "123       8800.0          0               0  \n",
       "115       8800.0          0               0  \n",
       "119       8800.0          0               0  \n",
       "121       8800.0          0               0  \n",
       "118       8800.0          0               0  \n",
       "122       8800.0          0               0  \n",
       "116       8800.0          0               0  \n",
       "124       8800.0          0               0  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billing_training[billing_training['ID_CPTE'] == 58512689].sort_values(['StatementDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>TRANSACTION_AMT</th>\n",
       "      <th>TRANSACTION_DTTM</th>\n",
       "      <th>PAYMENT_REVERSAL_XFLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>61632809</td>\n",
       "      <td>321.00</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>61632809</td>\n",
       "      <td>454.50</td>\n",
       "      <td>2015-01-06 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>61632809</td>\n",
       "      <td>299.25</td>\n",
       "      <td>2015-01-23 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>61632809</td>\n",
       "      <td>345.45</td>\n",
       "      <td>2015-02-07 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>61632809</td>\n",
       "      <td>117.60</td>\n",
       "      <td>2015-02-20 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>61632809</td>\n",
       "      <td>8.56</td>\n",
       "      <td>2015-03-01 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61632809</td>\n",
       "      <td>300.00</td>\n",
       "      <td>2015-03-02 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>61632809</td>\n",
       "      <td>408.00</td>\n",
       "      <td>2015-03-02 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>61632809</td>\n",
       "      <td>50.96</td>\n",
       "      <td>2015-03-04 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>61632809</td>\n",
       "      <td>335.92</td>\n",
       "      <td>2015-03-20 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>61632809</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>2015-03-20 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>61632809</td>\n",
       "      <td>1137.76</td>\n",
       "      <td>2015-04-20 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>61632809</td>\n",
       "      <td>118.56</td>\n",
       "      <td>2015-05-12 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>61632809</td>\n",
       "      <td>318.00</td>\n",
       "      <td>2015-05-29 04:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>61632809</td>\n",
       "      <td>204.00</td>\n",
       "      <td>2015-05-29 04:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>61632809</td>\n",
       "      <td>423.15</td>\n",
       "      <td>2015-07-05 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>61632809</td>\n",
       "      <td>354.90</td>\n",
       "      <td>2015-07-05 20:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>61632809</td>\n",
       "      <td>612.00</td>\n",
       "      <td>2015-07-07 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>61632809</td>\n",
       "      <td>441.91</td>\n",
       "      <td>2015-07-26 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61632809</td>\n",
       "      <td>300.56</td>\n",
       "      <td>2015-07-29 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>61632809</td>\n",
       "      <td>262.50</td>\n",
       "      <td>2015-09-10 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>61632809</td>\n",
       "      <td>303.96</td>\n",
       "      <td>2015-09-15 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>61632809</td>\n",
       "      <td>329.60</td>\n",
       "      <td>2015-09-27 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>61632809</td>\n",
       "      <td>1003.80</td>\n",
       "      <td>2015-09-27 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>61632809</td>\n",
       "      <td>112.20</td>\n",
       "      <td>2015-10-07 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>61632809</td>\n",
       "      <td>47.47</td>\n",
       "      <td>2015-10-12 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>61632809</td>\n",
       "      <td>344.54</td>\n",
       "      <td>2015-11-05 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>61632809</td>\n",
       "      <td>60.00</td>\n",
       "      <td>2015-11-09 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>61632809</td>\n",
       "      <td>42.00</td>\n",
       "      <td>2015-11-16 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>61632809</td>\n",
       "      <td>159.00</td>\n",
       "      <td>2015-11-22 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>61632809</td>\n",
       "      <td>789.70</td>\n",
       "      <td>2015-12-10 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>61632809</td>\n",
       "      <td>182.00</td>\n",
       "      <td>2015-12-17 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID_CPTE  TRANSACTION_AMT     TRANSACTION_DTTM PAYMENT_REVERSAL_XFLG\n",
       "67  61632809           321.00  2015-01-01 00:00:00                     Q\n",
       "56  61632809           454.50  2015-01-06 00:00:00                     Q\n",
       "43  61632809           299.25  2015-01-23 00:00:00                     Q\n",
       "59  61632809           345.45  2015-02-07 00:00:00                     Q\n",
       "49  61632809           117.60  2015-02-20 00:00:00                     Q\n",
       "57  61632809             8.56  2015-03-01 00:00:00                     Q\n",
       "61  61632809           300.00  2015-03-02 00:00:00                     Q\n",
       "58  61632809           408.00  2015-03-02 00:00:00                     Q\n",
       "52  61632809            50.96  2015-03-04 00:00:00                     Q\n",
       "65  61632809           335.92  2015-03-20 00:00:00                     Q\n",
       "63  61632809          1020.00  2015-03-20 00:00:00                     Q\n",
       "42  61632809          1137.76  2015-04-20 00:00:00                     Q\n",
       "71  61632809           118.56  2015-05-12 00:00:00                     Q\n",
       "68  61632809           318.00  2015-05-29 04:00:00                     Q\n",
       "66  61632809           204.00  2015-05-29 04:00:00                     Q\n",
       "69  61632809           423.15  2015-07-05 00:00:00                     Q\n",
       "45  61632809           354.90  2015-07-05 20:00:00                     Q\n",
       "70  61632809           612.00  2015-07-07 00:00:00                     Q\n",
       "51  61632809           441.91  2015-07-26 00:00:00                     Q\n",
       "60  61632809           300.56  2015-07-29 00:00:00                     Q\n",
       "64  61632809           262.50  2015-09-10 00:00:00                     Q\n",
       "72  61632809           303.96  2015-09-15 00:00:00                     Q\n",
       "73  61632809           329.60  2015-09-27 00:00:00                     Q\n",
       "62  61632809          1003.80  2015-09-27 00:00:00                     Q\n",
       "55  61632809           112.20  2015-10-07 00:00:00                     Q\n",
       "54  61632809            47.47  2015-10-12 00:00:00                     Q\n",
       "53  61632809           344.54  2015-11-05 00:00:00                     Q\n",
       "44  61632809            60.00  2015-11-09 00:00:00                     Q\n",
       "48  61632809            42.00  2015-11-16 00:00:00                     Q\n",
       "46  61632809           159.00  2015-11-22 00:00:00                     Q\n",
       "47  61632809           789.70  2015-12-10 00:00:00                     Q\n",
       "50  61632809           182.00  2015-12-17 00:00:00                     Q"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payment_training[payment_training['ID_CPTE'] == 61632809].sort_values(['TRANSACTION_DTTM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>75780289</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>58022132</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>25809739</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>35143533</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>94504449</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>59776762</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>28710728</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>84279471</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>65860216</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>57628717</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID_CPTE PERIODID_MY  Default\n",
       "18   75780289  2012-12-01        1\n",
       "53   58022132  2013-12-01        1\n",
       "56   25809739  2015-12-01        1\n",
       "72   35143533  2013-12-01        1\n",
       "137  94504449  2012-12-01        1\n",
       "208  59776762  2013-12-01        1\n",
       "232  28710728  2016-12-01        1\n",
       "302  84279471  2016-12-01        1\n",
       "320  65860216  2013-12-01        1\n",
       "338  57628717  2013-12-01        1"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_training[performance_training['Default'] == 1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57427180</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29617912</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61632809</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14117855</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23700394</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27881705</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>46100731</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>58512689</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24661392</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE PERIODID_MY  Default\n",
       "0  99690111  2015-12-01        0\n",
       "1  57427180  2012-12-01        0\n",
       "2  29617912  2015-12-01        0\n",
       "3  61632809  2015-12-01        0\n",
       "4  14117855  2013-12-01        0\n",
       "5  23700394  2013-12-01        0\n",
       "6  27881705  2012-12-01        0\n",
       "7  46100731  2012-12-01        0\n",
       "8  58512689  2014-12-01        0\n",
       "9  24661392  2016-12-01        0"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_training[performance_training['Default'] == 0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = processed_data.drop(['MaxDelqCycle'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(processed_data.iloc[:, :-1])\n",
    "y = np.array(processed_data.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\futai\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42, ratio=1)\n",
    "X_res, y_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    " \n",
    "clf = LogisticRegression()\n",
    "rf = RandomForestClassifier(min_samples_split=200, max_depth=20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=200,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_clf = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8112468690369438"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(predict_clf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7920722963618281"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(predict_rf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>credit_left_11_month</th>\n",
       "      <td>0.193770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_12_month</th>\n",
       "      <td>0.104274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_09_month</th>\n",
       "      <td>0.076697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_07_month</th>\n",
       "      <td>0.058398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AvgDelqCycle</th>\n",
       "      <td>0.049819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_06_month</th>\n",
       "      <td>0.040469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_11_month</th>\n",
       "      <td>0.039283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxDelqCycle</th>\n",
       "      <td>0.034331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_02_month</th>\n",
       "      <td>0.033322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_12_month</th>\n",
       "      <td>0.029217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_11_month</th>\n",
       "      <td>0.025679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_12_month</th>\n",
       "      <td>0.025122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_10_month</th>\n",
       "      <td>0.020485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_02_month</th>\n",
       "      <td>0.015638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_04_month</th>\n",
       "      <td>0.015377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_03_month</th>\n",
       "      <td>0.015037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_10_month</th>\n",
       "      <td>0.014547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_08_month</th>\n",
       "      <td>0.014020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_05_month</th>\n",
       "      <td>0.013681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_05_month</th>\n",
       "      <td>0.013111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_08_month</th>\n",
       "      <td>0.013108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_09_month</th>\n",
       "      <td>0.011780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_03_month</th>\n",
       "      <td>0.011655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_09_month</th>\n",
       "      <td>0.011226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_07_month</th>\n",
       "      <td>0.010671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_01_month</th>\n",
       "      <td>0.010412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_04_month</th>\n",
       "      <td>0.010363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_06_month</th>\n",
       "      <td>0.010019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_01_month</th>\n",
       "      <td>0.009247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_05_month</th>\n",
       "      <td>0.009228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_06_month</th>\n",
       "      <td>0.008149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_03_month</th>\n",
       "      <td>0.007753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_04_month</th>\n",
       "      <td>0.007730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_07_month</th>\n",
       "      <td>0.007426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_10_month</th>\n",
       "      <td>0.007285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_08_month</th>\n",
       "      <td>0.006225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_01_month</th>\n",
       "      <td>0.006161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_02_month</th>\n",
       "      <td>0.005138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LateCount</th>\n",
       "      <td>0.004148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAYMENT_N_COUNT</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Importance\n",
       "credit_left_11_month     0.193770\n",
       "credit_left_12_month     0.104274\n",
       "credit_left_09_month     0.076697\n",
       "credit_left_07_month     0.058398\n",
       "AvgDelqCycle             0.049819\n",
       "credit_left_06_month     0.040469\n",
       "transaction_11_month     0.039283\n",
       "MaxDelqCycle             0.034331\n",
       "credit_left_02_month     0.033322\n",
       "transaction_12_month     0.029217\n",
       "cash_balance_11_month    0.025679\n",
       "cash_balance_12_month    0.025122\n",
       "credit_left_10_month     0.020485\n",
       "transaction_02_month     0.015638\n",
       "credit_left_04_month     0.015377\n",
       "credit_left_03_month     0.015037\n",
       "transaction_10_month     0.014547\n",
       "transaction_08_month     0.014020\n",
       "credit_left_05_month     0.013681\n",
       "transaction_05_month     0.013111\n",
       "credit_left_08_month     0.013108\n",
       "cash_balance_09_month    0.011780\n",
       "transaction_03_month     0.011655\n",
       "transaction_09_month     0.011226\n",
       "transaction_07_month     0.010671\n",
       "credit_left_01_month     0.010412\n",
       "transaction_04_month     0.010363\n",
       "transaction_06_month     0.010019\n",
       "transaction_01_month     0.009247\n",
       "cash_balance_05_month    0.009228\n",
       "cash_balance_06_month    0.008149\n",
       "cash_balance_03_month    0.007753\n",
       "cash_balance_04_month    0.007730\n",
       "cash_balance_07_month    0.007426\n",
       "cash_balance_10_month    0.007285\n",
       "cash_balance_08_month    0.006225\n",
       "cash_balance_01_month    0.006161\n",
       "cash_balance_02_month    0.005138\n",
       "LateCount                0.004148\n",
       "PAYMENT_N_COUNT          0.000000"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = rf.feature_importances_\n",
    "importance = pd.DataFrame(importance, index=processed_data.iloc[:, :-1].columns, columns=[\"Importance\"])\n",
    "importance.sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params =  {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    #'max_depth': 15,\n",
    "    'num_leaves': 270,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 2,\n",
    "    'learning_rate': 0.0175,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgtrain = lgb.Dataset(X_train, y_train)\n",
    "lgtest = lgb.Dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.68148\n",
      "[2]\ttraining's binary_logloss: 0.670674\n",
      "[3]\ttraining's binary_logloss: 0.66004\n",
      "[4]\ttraining's binary_logloss: 0.64976\n",
      "[5]\ttraining's binary_logloss: 0.639481\n",
      "[6]\ttraining's binary_logloss: 0.62958\n",
      "[7]\ttraining's binary_logloss: 0.619872\n",
      "[8]\ttraining's binary_logloss: 0.610664\n",
      "[9]\ttraining's binary_logloss: 0.601547\n",
      "[10]\ttraining's binary_logloss: 0.59294\n",
      "[11]\ttraining's binary_logloss: 0.584435\n",
      "[12]\ttraining's binary_logloss: 0.576012\n",
      "[13]\ttraining's binary_logloss: 0.567812\n",
      "[14]\ttraining's binary_logloss: 0.560039\n",
      "[15]\ttraining's binary_logloss: 0.552178\n",
      "[16]\ttraining's binary_logloss: 0.544605\n",
      "[17]\ttraining's binary_logloss: 0.537513\n",
      "[18]\ttraining's binary_logloss: 0.530439\n",
      "[19]\ttraining's binary_logloss: 0.523517\n",
      "[20]\ttraining's binary_logloss: 0.516769\n",
      "[21]\ttraining's binary_logloss: 0.510142\n",
      "[22]\ttraining's binary_logloss: 0.503677\n",
      "[23]\ttraining's binary_logloss: 0.497366\n",
      "[24]\ttraining's binary_logloss: 0.491171\n",
      "[25]\ttraining's binary_logloss: 0.48515\n",
      "[26]\ttraining's binary_logloss: 0.479437\n",
      "[27]\ttraining's binary_logloss: 0.473633\n",
      "[28]\ttraining's binary_logloss: 0.46818\n",
      "[29]\ttraining's binary_logloss: 0.462667\n",
      "[30]\ttraining's binary_logloss: 0.457374\n",
      "[31]\ttraining's binary_logloss: 0.452168\n",
      "[32]\ttraining's binary_logloss: 0.447039\n",
      "[33]\ttraining's binary_logloss: 0.442007\n",
      "[34]\ttraining's binary_logloss: 0.437156\n",
      "[35]\ttraining's binary_logloss: 0.432357\n",
      "[36]\ttraining's binary_logloss: 0.427642\n",
      "[37]\ttraining's binary_logloss: 0.423123\n",
      "[38]\ttraining's binary_logloss: 0.418559\n",
      "[39]\ttraining's binary_logloss: 0.414153\n",
      "[40]\ttraining's binary_logloss: 0.409747\n",
      "[41]\ttraining's binary_logloss: 0.405728\n",
      "[42]\ttraining's binary_logloss: 0.401629\n",
      "[43]\ttraining's binary_logloss: 0.397733\n",
      "[44]\ttraining's binary_logloss: 0.393743\n",
      "[45]\ttraining's binary_logloss: 0.38989\n",
      "[46]\ttraining's binary_logloss: 0.386099\n",
      "[47]\ttraining's binary_logloss: 0.382425\n",
      "[48]\ttraining's binary_logloss: 0.378855\n",
      "[49]\ttraining's binary_logloss: 0.375205\n",
      "[50]\ttraining's binary_logloss: 0.371685\n",
      "[51]\ttraining's binary_logloss: 0.368154\n",
      "[52]\ttraining's binary_logloss: 0.364746\n",
      "[53]\ttraining's binary_logloss: 0.361376\n",
      "[54]\ttraining's binary_logloss: 0.358106\n",
      "[55]\ttraining's binary_logloss: 0.354888\n",
      "[56]\ttraining's binary_logloss: 0.351754\n",
      "[57]\ttraining's binary_logloss: 0.348545\n",
      "[58]\ttraining's binary_logloss: 0.345606\n",
      "[59]\ttraining's binary_logloss: 0.342539\n",
      "[60]\ttraining's binary_logloss: 0.339643\n",
      "[61]\ttraining's binary_logloss: 0.336657\n",
      "[62]\ttraining's binary_logloss: 0.3338\n",
      "[63]\ttraining's binary_logloss: 0.330937\n",
      "[64]\ttraining's binary_logloss: 0.328231\n",
      "[65]\ttraining's binary_logloss: 0.325577\n",
      "[66]\ttraining's binary_logloss: 0.322896\n",
      "[67]\ttraining's binary_logloss: 0.320263\n",
      "[68]\ttraining's binary_logloss: 0.317701\n",
      "[69]\ttraining's binary_logloss: 0.315136\n",
      "[70]\ttraining's binary_logloss: 0.312614\n",
      "[71]\ttraining's binary_logloss: 0.310146\n",
      "[72]\ttraining's binary_logloss: 0.307795\n",
      "[73]\ttraining's binary_logloss: 0.305388\n",
      "[74]\ttraining's binary_logloss: 0.303069\n",
      "[75]\ttraining's binary_logloss: 0.300782\n",
      "[76]\ttraining's binary_logloss: 0.298453\n",
      "[77]\ttraining's binary_logloss: 0.296183\n",
      "[78]\ttraining's binary_logloss: 0.293969\n",
      "[79]\ttraining's binary_logloss: 0.291797\n",
      "[80]\ttraining's binary_logloss: 0.28961\n",
      "[81]\ttraining's binary_logloss: 0.287413\n",
      "[82]\ttraining's binary_logloss: 0.28531\n",
      "[83]\ttraining's binary_logloss: 0.283222\n",
      "[84]\ttraining's binary_logloss: 0.281208\n",
      "[85]\ttraining's binary_logloss: 0.279184\n",
      "[86]\ttraining's binary_logloss: 0.277171\n",
      "[87]\ttraining's binary_logloss: 0.275163\n",
      "[88]\ttraining's binary_logloss: 0.273288\n",
      "[89]\ttraining's binary_logloss: 0.271374\n",
      "[90]\ttraining's binary_logloss: 0.269509\n",
      "[91]\ttraining's binary_logloss: 0.267662\n",
      "[92]\ttraining's binary_logloss: 0.265811\n",
      "[93]\ttraining's binary_logloss: 0.263977\n",
      "[94]\ttraining's binary_logloss: 0.262252\n",
      "[95]\ttraining's binary_logloss: 0.260478\n",
      "[96]\ttraining's binary_logloss: 0.258746\n",
      "[97]\ttraining's binary_logloss: 0.257023\n",
      "[98]\ttraining's binary_logloss: 0.255346\n",
      "[99]\ttraining's binary_logloss: 0.253687\n",
      "[100]\ttraining's binary_logloss: 0.252004\n",
      "[101]\ttraining's binary_logloss: 0.250341\n",
      "[102]\ttraining's binary_logloss: 0.248749\n",
      "[103]\ttraining's binary_logloss: 0.247016\n",
      "[104]\ttraining's binary_logloss: 0.24541\n",
      "[105]\ttraining's binary_logloss: 0.243935\n",
      "[106]\ttraining's binary_logloss: 0.242322\n",
      "[107]\ttraining's binary_logloss: 0.240825\n",
      "[108]\ttraining's binary_logloss: 0.239294\n",
      "[109]\ttraining's binary_logloss: 0.237761\n",
      "[110]\ttraining's binary_logloss: 0.23625\n",
      "[111]\ttraining's binary_logloss: 0.234799\n",
      "[112]\ttraining's binary_logloss: 0.233251\n",
      "[113]\ttraining's binary_logloss: 0.231763\n",
      "[114]\ttraining's binary_logloss: 0.230358\n",
      "[115]\ttraining's binary_logloss: 0.228922\n",
      "[116]\ttraining's binary_logloss: 0.22752\n",
      "[117]\ttraining's binary_logloss: 0.226099\n",
      "[118]\ttraining's binary_logloss: 0.224674\n",
      "[119]\ttraining's binary_logloss: 0.223351\n",
      "[120]\ttraining's binary_logloss: 0.221991\n",
      "[121]\ttraining's binary_logloss: 0.220683\n",
      "[122]\ttraining's binary_logloss: 0.219376\n",
      "[123]\ttraining's binary_logloss: 0.218052\n",
      "[124]\ttraining's binary_logloss: 0.21666\n",
      "[125]\ttraining's binary_logloss: 0.215319\n",
      "[126]\ttraining's binary_logloss: 0.214014\n",
      "[127]\ttraining's binary_logloss: 0.212737\n",
      "[128]\ttraining's binary_logloss: 0.21147\n",
      "[129]\ttraining's binary_logloss: 0.210209\n",
      "[130]\ttraining's binary_logloss: 0.209019\n",
      "[131]\ttraining's binary_logloss: 0.20775\n",
      "[132]\ttraining's binary_logloss: 0.206513\n",
      "[133]\ttraining's binary_logloss: 0.205234\n",
      "[134]\ttraining's binary_logloss: 0.204062\n",
      "[135]\ttraining's binary_logloss: 0.202875\n",
      "[136]\ttraining's binary_logloss: 0.201683\n",
      "[137]\ttraining's binary_logloss: 0.200473\n",
      "[138]\ttraining's binary_logloss: 0.199301\n",
      "[139]\ttraining's binary_logloss: 0.198093\n",
      "[140]\ttraining's binary_logloss: 0.196981\n",
      "[141]\ttraining's binary_logloss: 0.195863\n",
      "[142]\ttraining's binary_logloss: 0.194703\n",
      "[143]\ttraining's binary_logloss: 0.193626\n",
      "[144]\ttraining's binary_logloss: 0.19249\n",
      "[145]\ttraining's binary_logloss: 0.191385\n",
      "[146]\ttraining's binary_logloss: 0.19022\n",
      "[147]\ttraining's binary_logloss: 0.189116\n",
      "[148]\ttraining's binary_logloss: 0.188073\n",
      "[149]\ttraining's binary_logloss: 0.187066\n",
      "[150]\ttraining's binary_logloss: 0.186026\n",
      "[151]\ttraining's binary_logloss: 0.184995\n",
      "[152]\ttraining's binary_logloss: 0.183976\n",
      "[153]\ttraining's binary_logloss: 0.182978\n",
      "[154]\ttraining's binary_logloss: 0.181941\n",
      "[155]\ttraining's binary_logloss: 0.180985\n",
      "[156]\ttraining's binary_logloss: 0.179997\n",
      "[157]\ttraining's binary_logloss: 0.178942\n",
      "[158]\ttraining's binary_logloss: 0.178011\n",
      "[159]\ttraining's binary_logloss: 0.177015\n",
      "[160]\ttraining's binary_logloss: 0.176012\n",
      "[161]\ttraining's binary_logloss: 0.174993\n",
      "[162]\ttraining's binary_logloss: 0.174003\n",
      "[163]\ttraining's binary_logloss: 0.173089\n",
      "[164]\ttraining's binary_logloss: 0.172206\n",
      "[165]\ttraining's binary_logloss: 0.171273\n",
      "[166]\ttraining's binary_logloss: 0.170251\n",
      "[167]\ttraining's binary_logloss: 0.169296\n",
      "[168]\ttraining's binary_logloss: 0.168346\n",
      "[169]\ttraining's binary_logloss: 0.16748\n",
      "[170]\ttraining's binary_logloss: 0.16658\n",
      "[171]\ttraining's binary_logloss: 0.1656\n",
      "[172]\ttraining's binary_logloss: 0.164671\n",
      "[173]\ttraining's binary_logloss: 0.163846\n",
      "[174]\ttraining's binary_logloss: 0.163014\n",
      "[175]\ttraining's binary_logloss: 0.162157\n",
      "[176]\ttraining's binary_logloss: 0.161284\n",
      "[177]\ttraining's binary_logloss: 0.160374\n",
      "[178]\ttraining's binary_logloss: 0.159533\n",
      "[179]\ttraining's binary_logloss: 0.158656\n",
      "[180]\ttraining's binary_logloss: 0.15784\n",
      "[181]\ttraining's binary_logloss: 0.156953\n",
      "[182]\ttraining's binary_logloss: 0.156083\n",
      "[183]\ttraining's binary_logloss: 0.155223\n",
      "[184]\ttraining's binary_logloss: 0.154336\n",
      "[185]\ttraining's binary_logloss: 0.153491\n",
      "[186]\ttraining's binary_logloss: 0.152666\n",
      "[187]\ttraining's binary_logloss: 0.1518\n",
      "[188]\ttraining's binary_logloss: 0.150963\n",
      "[189]\ttraining's binary_logloss: 0.150175\n",
      "[190]\ttraining's binary_logloss: 0.149364\n",
      "[191]\ttraining's binary_logloss: 0.148591\n",
      "[192]\ttraining's binary_logloss: 0.147828\n",
      "[193]\ttraining's binary_logloss: 0.147039\n",
      "[194]\ttraining's binary_logloss: 0.146265\n",
      "[195]\ttraining's binary_logloss: 0.145511\n",
      "[196]\ttraining's binary_logloss: 0.144764\n",
      "[197]\ttraining's binary_logloss: 0.143975\n",
      "[198]\ttraining's binary_logloss: 0.1432\n",
      "[199]\ttraining's binary_logloss: 0.142453\n",
      "[200]\ttraining's binary_logloss: 0.141702\n",
      "[201]\ttraining's binary_logloss: 0.140917\n",
      "[202]\ttraining's binary_logloss: 0.140148\n",
      "[203]\ttraining's binary_logloss: 0.139431\n",
      "[204]\ttraining's binary_logloss: 0.138655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[205]\ttraining's binary_logloss: 0.137888\n",
      "[206]\ttraining's binary_logloss: 0.137106\n",
      "[207]\ttraining's binary_logloss: 0.136362\n",
      "[208]\ttraining's binary_logloss: 0.135622\n",
      "[209]\ttraining's binary_logloss: 0.134914\n",
      "[210]\ttraining's binary_logloss: 0.134156\n",
      "[211]\ttraining's binary_logloss: 0.133387\n",
      "[212]\ttraining's binary_logloss: 0.132675\n",
      "[213]\ttraining's binary_logloss: 0.131935\n",
      "[214]\ttraining's binary_logloss: 0.131248\n",
      "[215]\ttraining's binary_logloss: 0.13054\n",
      "[216]\ttraining's binary_logloss: 0.129859\n",
      "[217]\ttraining's binary_logloss: 0.129197\n",
      "[218]\ttraining's binary_logloss: 0.128469\n",
      "[219]\ttraining's binary_logloss: 0.12776\n",
      "[220]\ttraining's binary_logloss: 0.127061\n",
      "[221]\ttraining's binary_logloss: 0.126393\n",
      "[222]\ttraining's binary_logloss: 0.125669\n",
      "[223]\ttraining's binary_logloss: 0.124992\n",
      "[224]\ttraining's binary_logloss: 0.124286\n",
      "[225]\ttraining's binary_logloss: 0.123594\n",
      "[226]\ttraining's binary_logloss: 0.122962\n",
      "[227]\ttraining's binary_logloss: 0.122219\n",
      "[228]\ttraining's binary_logloss: 0.121557\n",
      "[229]\ttraining's binary_logloss: 0.120891\n",
      "[230]\ttraining's binary_logloss: 0.120278\n",
      "[231]\ttraining's binary_logloss: 0.119657\n",
      "[232]\ttraining's binary_logloss: 0.11896\n",
      "[233]\ttraining's binary_logloss: 0.118376\n",
      "[234]\ttraining's binary_logloss: 0.117799\n",
      "[235]\ttraining's binary_logloss: 0.11721\n",
      "[236]\ttraining's binary_logloss: 0.116609\n",
      "[237]\ttraining's binary_logloss: 0.115963\n",
      "[238]\ttraining's binary_logloss: 0.115338\n",
      "[239]\ttraining's binary_logloss: 0.114723\n",
      "[240]\ttraining's binary_logloss: 0.114122\n",
      "[241]\ttraining's binary_logloss: 0.113521\n",
      "[242]\ttraining's binary_logloss: 0.112911\n",
      "[243]\ttraining's binary_logloss: 0.112325\n",
      "[244]\ttraining's binary_logloss: 0.111687\n",
      "[245]\ttraining's binary_logloss: 0.111129\n",
      "[246]\ttraining's binary_logloss: 0.110536\n",
      "[247]\ttraining's binary_logloss: 0.109965\n",
      "[248]\ttraining's binary_logloss: 0.109409\n",
      "[249]\ttraining's binary_logloss: 0.108818\n",
      "[250]\ttraining's binary_logloss: 0.108226\n",
      "[251]\ttraining's binary_logloss: 0.107662\n",
      "[252]\ttraining's binary_logloss: 0.107083\n",
      "[253]\ttraining's binary_logloss: 0.106516\n",
      "[254]\ttraining's binary_logloss: 0.105921\n",
      "[255]\ttraining's binary_logloss: 0.105386\n",
      "[256]\ttraining's binary_logloss: 0.104811\n",
      "[257]\ttraining's binary_logloss: 0.104261\n",
      "[258]\ttraining's binary_logloss: 0.103723\n",
      "[259]\ttraining's binary_logloss: 0.103167\n",
      "[260]\ttraining's binary_logloss: 0.102626\n",
      "[261]\ttraining's binary_logloss: 0.102102\n",
      "[262]\ttraining's binary_logloss: 0.101551\n",
      "[263]\ttraining's binary_logloss: 0.101004\n",
      "[264]\ttraining's binary_logloss: 0.100485\n",
      "[265]\ttraining's binary_logloss: 0.0999525\n",
      "[266]\ttraining's binary_logloss: 0.0993823\n",
      "[267]\ttraining's binary_logloss: 0.0988568\n",
      "[268]\ttraining's binary_logloss: 0.0982933\n",
      "[269]\ttraining's binary_logloss: 0.0977609\n",
      "[270]\ttraining's binary_logloss: 0.0972617\n",
      "[271]\ttraining's binary_logloss: 0.0967616\n",
      "[272]\ttraining's binary_logloss: 0.096284\n",
      "[273]\ttraining's binary_logloss: 0.0957586\n",
      "[274]\ttraining's binary_logloss: 0.095248\n",
      "[275]\ttraining's binary_logloss: 0.0946976\n",
      "[276]\ttraining's binary_logloss: 0.0941843\n",
      "[277]\ttraining's binary_logloss: 0.09369\n",
      "[278]\ttraining's binary_logloss: 0.0931873\n",
      "[279]\ttraining's binary_logloss: 0.0926936\n",
      "[280]\ttraining's binary_logloss: 0.092236\n",
      "[281]\ttraining's binary_logloss: 0.0917086\n",
      "[282]\ttraining's binary_logloss: 0.0912108\n",
      "[283]\ttraining's binary_logloss: 0.0907371\n",
      "[284]\ttraining's binary_logloss: 0.0902504\n",
      "[285]\ttraining's binary_logloss: 0.0897776\n",
      "[286]\ttraining's binary_logloss: 0.0893077\n",
      "[287]\ttraining's binary_logloss: 0.0888009\n",
      "[288]\ttraining's binary_logloss: 0.0883398\n",
      "[289]\ttraining's binary_logloss: 0.087843\n",
      "[290]\ttraining's binary_logloss: 0.087368\n",
      "[291]\ttraining's binary_logloss: 0.0868766\n",
      "[292]\ttraining's binary_logloss: 0.0863697\n",
      "[293]\ttraining's binary_logloss: 0.0859252\n",
      "[294]\ttraining's binary_logloss: 0.0854552\n",
      "[295]\ttraining's binary_logloss: 0.0850088\n",
      "[296]\ttraining's binary_logloss: 0.0845526\n",
      "[297]\ttraining's binary_logloss: 0.084112\n",
      "[298]\ttraining's binary_logloss: 0.0836705\n",
      "[299]\ttraining's binary_logloss: 0.0832435\n",
      "[300]\ttraining's binary_logloss: 0.0827638\n",
      "[301]\ttraining's binary_logloss: 0.0823448\n",
      "[302]\ttraining's binary_logloss: 0.0818951\n",
      "[303]\ttraining's binary_logloss: 0.0814281\n",
      "[304]\ttraining's binary_logloss: 0.080991\n",
      "[305]\ttraining's binary_logloss: 0.0805718\n",
      "[306]\ttraining's binary_logloss: 0.0801327\n",
      "[307]\ttraining's binary_logloss: 0.0797317\n",
      "[308]\ttraining's binary_logloss: 0.079349\n",
      "[309]\ttraining's binary_logloss: 0.0789404\n",
      "[310]\ttraining's binary_logloss: 0.0785123\n",
      "[311]\ttraining's binary_logloss: 0.0781105\n",
      "[312]\ttraining's binary_logloss: 0.0776761\n",
      "[313]\ttraining's binary_logloss: 0.077272\n",
      "[314]\ttraining's binary_logloss: 0.0768465\n",
      "[315]\ttraining's binary_logloss: 0.0764585\n",
      "[316]\ttraining's binary_logloss: 0.0760955\n",
      "[317]\ttraining's binary_logloss: 0.0756933\n",
      "[318]\ttraining's binary_logloss: 0.0752821\n",
      "[319]\ttraining's binary_logloss: 0.0749085\n",
      "[320]\ttraining's binary_logloss: 0.0745328\n",
      "[321]\ttraining's binary_logloss: 0.0741367\n",
      "[322]\ttraining's binary_logloss: 0.0737458\n",
      "[323]\ttraining's binary_logloss: 0.073333\n",
      "[324]\ttraining's binary_logloss: 0.0729216\n",
      "[325]\ttraining's binary_logloss: 0.0725534\n",
      "[326]\ttraining's binary_logloss: 0.0722059\n",
      "[327]\ttraining's binary_logloss: 0.0718107\n",
      "[328]\ttraining's binary_logloss: 0.0714469\n",
      "[329]\ttraining's binary_logloss: 0.0710741\n",
      "[330]\ttraining's binary_logloss: 0.0706908\n",
      "[331]\ttraining's binary_logloss: 0.0702943\n",
      "[332]\ttraining's binary_logloss: 0.069965\n",
      "[333]\ttraining's binary_logloss: 0.0696201\n",
      "[334]\ttraining's binary_logloss: 0.0692566\n",
      "[335]\ttraining's binary_logloss: 0.0689057\n",
      "[336]\ttraining's binary_logloss: 0.068558\n",
      "[337]\ttraining's binary_logloss: 0.0681981\n",
      "[338]\ttraining's binary_logloss: 0.0678513\n",
      "[339]\ttraining's binary_logloss: 0.0674783\n",
      "[340]\ttraining's binary_logloss: 0.0671315\n",
      "[341]\ttraining's binary_logloss: 0.0667984\n",
      "[342]\ttraining's binary_logloss: 0.0664693\n",
      "[343]\ttraining's binary_logloss: 0.0661032\n",
      "[344]\ttraining's binary_logloss: 0.0657759\n",
      "[345]\ttraining's binary_logloss: 0.0654125\n",
      "[346]\ttraining's binary_logloss: 0.065066\n",
      "[347]\ttraining's binary_logloss: 0.0647413\n",
      "[348]\ttraining's binary_logloss: 0.0644225\n",
      "[349]\ttraining's binary_logloss: 0.0640828\n",
      "[350]\ttraining's binary_logloss: 0.0637513\n",
      "[351]\ttraining's binary_logloss: 0.0634198\n",
      "[352]\ttraining's binary_logloss: 0.0630943\n",
      "[353]\ttraining's binary_logloss: 0.0627576\n",
      "[354]\ttraining's binary_logloss: 0.0624172\n",
      "[355]\ttraining's binary_logloss: 0.0621045\n",
      "[356]\ttraining's binary_logloss: 0.0617556\n",
      "[357]\ttraining's binary_logloss: 0.0614321\n",
      "[358]\ttraining's binary_logloss: 0.0611154\n",
      "[359]\ttraining's binary_logloss: 0.0607778\n",
      "[360]\ttraining's binary_logloss: 0.0604547\n",
      "[361]\ttraining's binary_logloss: 0.0601538\n",
      "[362]\ttraining's binary_logloss: 0.0598591\n",
      "[363]\ttraining's binary_logloss: 0.0595629\n",
      "[364]\ttraining's binary_logloss: 0.0592619\n",
      "[365]\ttraining's binary_logloss: 0.0589456\n",
      "[366]\ttraining's binary_logloss: 0.0586629\n",
      "[367]\ttraining's binary_logloss: 0.058354\n",
      "[368]\ttraining's binary_logloss: 0.0580493\n",
      "[369]\ttraining's binary_logloss: 0.0577556\n",
      "[370]\ttraining's binary_logloss: 0.0574701\n",
      "[371]\ttraining's binary_logloss: 0.0571892\n",
      "[372]\ttraining's binary_logloss: 0.0568863\n",
      "[373]\ttraining's binary_logloss: 0.0565853\n",
      "[374]\ttraining's binary_logloss: 0.0563202\n",
      "[375]\ttraining's binary_logloss: 0.0560642\n",
      "[376]\ttraining's binary_logloss: 0.0557708\n",
      "[377]\ttraining's binary_logloss: 0.0554821\n",
      "[378]\ttraining's binary_logloss: 0.0551912\n",
      "[379]\ttraining's binary_logloss: 0.0549039\n",
      "[380]\ttraining's binary_logloss: 0.0546096\n",
      "[381]\ttraining's binary_logloss: 0.0543058\n",
      "[382]\ttraining's binary_logloss: 0.0540408\n",
      "[383]\ttraining's binary_logloss: 0.0537894\n",
      "[384]\ttraining's binary_logloss: 0.0535254\n",
      "[385]\ttraining's binary_logloss: 0.0532597\n",
      "[386]\ttraining's binary_logloss: 0.0529764\n",
      "[387]\ttraining's binary_logloss: 0.0527259\n",
      "[388]\ttraining's binary_logloss: 0.0524543\n",
      "[389]\ttraining's binary_logloss: 0.0521727\n",
      "[390]\ttraining's binary_logloss: 0.0518796\n",
      "[391]\ttraining's binary_logloss: 0.0516208\n",
      "[392]\ttraining's binary_logloss: 0.05136\n",
      "[393]\ttraining's binary_logloss: 0.0511036\n",
      "[394]\ttraining's binary_logloss: 0.0508531\n",
      "[395]\ttraining's binary_logloss: 0.0505652\n",
      "[396]\ttraining's binary_logloss: 0.05031\n",
      "[397]\ttraining's binary_logloss: 0.050043\n",
      "[398]\ttraining's binary_logloss: 0.0497992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[399]\ttraining's binary_logloss: 0.0495467\n",
      "[400]\ttraining's binary_logloss: 0.0492952\n",
      "[401]\ttraining's binary_logloss: 0.0490298\n",
      "[402]\ttraining's binary_logloss: 0.0487856\n",
      "[403]\ttraining's binary_logloss: 0.0485682\n",
      "[404]\ttraining's binary_logloss: 0.0483242\n",
      "[405]\ttraining's binary_logloss: 0.0480744\n",
      "[406]\ttraining's binary_logloss: 0.0478325\n",
      "[407]\ttraining's binary_logloss: 0.0475933\n",
      "[408]\ttraining's binary_logloss: 0.0473536\n",
      "[409]\ttraining's binary_logloss: 0.0471286\n",
      "[410]\ttraining's binary_logloss: 0.0468885\n",
      "[411]\ttraining's binary_logloss: 0.0466459\n",
      "[412]\ttraining's binary_logloss: 0.0464238\n",
      "[413]\ttraining's binary_logloss: 0.0461957\n",
      "[414]\ttraining's binary_logloss: 0.0459652\n",
      "[415]\ttraining's binary_logloss: 0.0457214\n",
      "[416]\ttraining's binary_logloss: 0.0454857\n",
      "[417]\ttraining's binary_logloss: 0.0452528\n",
      "[418]\ttraining's binary_logloss: 0.0450197\n",
      "[419]\ttraining's binary_logloss: 0.0448007\n",
      "[420]\ttraining's binary_logloss: 0.0445844\n",
      "[421]\ttraining's binary_logloss: 0.0443695\n",
      "[422]\ttraining's binary_logloss: 0.0441507\n",
      "[423]\ttraining's binary_logloss: 0.0439346\n",
      "[424]\ttraining's binary_logloss: 0.0437224\n",
      "[425]\ttraining's binary_logloss: 0.0435059\n",
      "[426]\ttraining's binary_logloss: 0.0432965\n",
      "[427]\ttraining's binary_logloss: 0.0430593\n",
      "[428]\ttraining's binary_logloss: 0.0428457\n",
      "[429]\ttraining's binary_logloss: 0.0426111\n",
      "[430]\ttraining's binary_logloss: 0.0424082\n",
      "[431]\ttraining's binary_logloss: 0.0421917\n",
      "[432]\ttraining's binary_logloss: 0.0419843\n",
      "[433]\ttraining's binary_logloss: 0.0417736\n",
      "[434]\ttraining's binary_logloss: 0.0415767\n",
      "[435]\ttraining's binary_logloss: 0.0413697\n",
      "[436]\ttraining's binary_logloss: 0.0411775\n",
      "[437]\ttraining's binary_logloss: 0.0409708\n",
      "[438]\ttraining's binary_logloss: 0.0407721\n",
      "[439]\ttraining's binary_logloss: 0.0405701\n",
      "[440]\ttraining's binary_logloss: 0.0403681\n",
      "[441]\ttraining's binary_logloss: 0.0401663\n",
      "[442]\ttraining's binary_logloss: 0.039963\n",
      "[443]\ttraining's binary_logloss: 0.039773\n",
      "[444]\ttraining's binary_logloss: 0.0395731\n",
      "[445]\ttraining's binary_logloss: 0.03937\n",
      "[446]\ttraining's binary_logloss: 0.0391687\n",
      "[447]\ttraining's binary_logloss: 0.0389735\n",
      "[448]\ttraining's binary_logloss: 0.0387775\n",
      "[449]\ttraining's binary_logloss: 0.0385628\n",
      "[450]\ttraining's binary_logloss: 0.0383552\n",
      "[451]\ttraining's binary_logloss: 0.0381759\n",
      "[452]\ttraining's binary_logloss: 0.0379891\n",
      "[453]\ttraining's binary_logloss: 0.0377979\n",
      "[454]\ttraining's binary_logloss: 0.0376066\n",
      "[455]\ttraining's binary_logloss: 0.0374232\n",
      "[456]\ttraining's binary_logloss: 0.0372252\n",
      "[457]\ttraining's binary_logloss: 0.0370448\n",
      "[458]\ttraining's binary_logloss: 0.0368747\n",
      "[459]\ttraining's binary_logloss: 0.0366864\n",
      "[460]\ttraining's binary_logloss: 0.0365155\n",
      "[461]\ttraining's binary_logloss: 0.0363481\n",
      "[462]\ttraining's binary_logloss: 0.036184\n",
      "[463]\ttraining's binary_logloss: 0.0359931\n",
      "[464]\ttraining's binary_logloss: 0.0358249\n",
      "[465]\ttraining's binary_logloss: 0.0356332\n",
      "[466]\ttraining's binary_logloss: 0.0354665\n",
      "[467]\ttraining's binary_logloss: 0.035297\n",
      "[468]\ttraining's binary_logloss: 0.035136\n",
      "[469]\ttraining's binary_logloss: 0.034969\n",
      "[470]\ttraining's binary_logloss: 0.034809\n",
      "[471]\ttraining's binary_logloss: 0.0346293\n",
      "[472]\ttraining's binary_logloss: 0.0344667\n",
      "[473]\ttraining's binary_logloss: 0.0342988\n",
      "[474]\ttraining's binary_logloss: 0.0341426\n",
      "[475]\ttraining's binary_logloss: 0.0339898\n",
      "[476]\ttraining's binary_logloss: 0.0338278\n",
      "[477]\ttraining's binary_logloss: 0.0336605\n",
      "[478]\ttraining's binary_logloss: 0.0334973\n",
      "[479]\ttraining's binary_logloss: 0.0333428\n",
      "[480]\ttraining's binary_logloss: 0.0331682\n",
      "[481]\ttraining's binary_logloss: 0.0330224\n",
      "[482]\ttraining's binary_logloss: 0.0328609\n",
      "[483]\ttraining's binary_logloss: 0.0327119\n",
      "[484]\ttraining's binary_logloss: 0.0325621\n",
      "[485]\ttraining's binary_logloss: 0.0324051\n",
      "[486]\ttraining's binary_logloss: 0.0322635\n",
      "[487]\ttraining's binary_logloss: 0.0321152\n",
      "[488]\ttraining's binary_logloss: 0.0319606\n",
      "[489]\ttraining's binary_logloss: 0.0318048\n",
      "[490]\ttraining's binary_logloss: 0.0316654\n",
      "[491]\ttraining's binary_logloss: 0.0315155\n",
      "[492]\ttraining's binary_logloss: 0.0313558\n",
      "[493]\ttraining's binary_logloss: 0.0311993\n",
      "[494]\ttraining's binary_logloss: 0.0310543\n",
      "[495]\ttraining's binary_logloss: 0.0309076\n",
      "[496]\ttraining's binary_logloss: 0.030757\n",
      "[497]\ttraining's binary_logloss: 0.0306136\n",
      "[498]\ttraining's binary_logloss: 0.0304663\n",
      "[499]\ttraining's binary_logloss: 0.0303169\n",
      "[500]\ttraining's binary_logloss: 0.0301719\n",
      "[501]\ttraining's binary_logloss: 0.0300421\n",
      "[502]\ttraining's binary_logloss: 0.0299037\n",
      "[503]\ttraining's binary_logloss: 0.029758\n",
      "[504]\ttraining's binary_logloss: 0.0296194\n",
      "[505]\ttraining's binary_logloss: 0.0294726\n",
      "[506]\ttraining's binary_logloss: 0.0293317\n",
      "[507]\ttraining's binary_logloss: 0.029194\n",
      "[508]\ttraining's binary_logloss: 0.029073\n",
      "[509]\ttraining's binary_logloss: 0.0289309\n",
      "[510]\ttraining's binary_logloss: 0.0287968\n",
      "[511]\ttraining's binary_logloss: 0.0286474\n",
      "[512]\ttraining's binary_logloss: 0.0285004\n",
      "[513]\ttraining's binary_logloss: 0.0283511\n",
      "[514]\ttraining's binary_logloss: 0.0282084\n",
      "[515]\ttraining's binary_logloss: 0.0280705\n",
      "[516]\ttraining's binary_logloss: 0.0279367\n",
      "[517]\ttraining's binary_logloss: 0.0278043\n",
      "[518]\ttraining's binary_logloss: 0.0276731\n",
      "[519]\ttraining's binary_logloss: 0.0275409\n",
      "[520]\ttraining's binary_logloss: 0.0274151\n",
      "[521]\ttraining's binary_logloss: 0.0272868\n",
      "[522]\ttraining's binary_logloss: 0.0271507\n",
      "[523]\ttraining's binary_logloss: 0.0270231\n",
      "[524]\ttraining's binary_logloss: 0.0268823\n",
      "[525]\ttraining's binary_logloss: 0.0267546\n",
      "[526]\ttraining's binary_logloss: 0.0266389\n",
      "[527]\ttraining's binary_logloss: 0.026509\n",
      "[528]\ttraining's binary_logloss: 0.0263783\n",
      "[529]\ttraining's binary_logloss: 0.0262666\n",
      "[530]\ttraining's binary_logloss: 0.0261478\n",
      "[531]\ttraining's binary_logloss: 0.0260275\n",
      "[532]\ttraining's binary_logloss: 0.0259007\n",
      "[533]\ttraining's binary_logloss: 0.0257745\n",
      "[534]\ttraining's binary_logloss: 0.0256501\n",
      "[535]\ttraining's binary_logloss: 0.0255221\n",
      "[536]\ttraining's binary_logloss: 0.0254019\n",
      "[537]\ttraining's binary_logloss: 0.0252873\n",
      "[538]\ttraining's binary_logloss: 0.0251677\n",
      "[539]\ttraining's binary_logloss: 0.0250436\n",
      "[540]\ttraining's binary_logloss: 0.0249247\n",
      "[541]\ttraining's binary_logloss: 0.0248111\n",
      "[542]\ttraining's binary_logloss: 0.0246818\n",
      "[543]\ttraining's binary_logloss: 0.0245697\n",
      "[544]\ttraining's binary_logloss: 0.0244536\n",
      "[545]\ttraining's binary_logloss: 0.0243422\n",
      "[546]\ttraining's binary_logloss: 0.0242316\n",
      "[547]\ttraining's binary_logloss: 0.0241023\n",
      "[548]\ttraining's binary_logloss: 0.0239935\n",
      "[549]\ttraining's binary_logloss: 0.023874\n",
      "[550]\ttraining's binary_logloss: 0.0237612\n",
      "[551]\ttraining's binary_logloss: 0.0236327\n",
      "[552]\ttraining's binary_logloss: 0.0235167\n",
      "[553]\ttraining's binary_logloss: 0.023414\n",
      "[554]\ttraining's binary_logloss: 0.0233028\n",
      "[555]\ttraining's binary_logloss: 0.0231888\n",
      "[556]\ttraining's binary_logloss: 0.0230811\n",
      "[557]\ttraining's binary_logloss: 0.0229735\n",
      "[558]\ttraining's binary_logloss: 0.0228688\n",
      "[559]\ttraining's binary_logloss: 0.0227631\n",
      "[560]\ttraining's binary_logloss: 0.0226514\n",
      "[561]\ttraining's binary_logloss: 0.0225479\n",
      "[562]\ttraining's binary_logloss: 0.0224534\n",
      "[563]\ttraining's binary_logloss: 0.0223462\n",
      "[564]\ttraining's binary_logloss: 0.0222482\n",
      "[565]\ttraining's binary_logloss: 0.0221482\n",
      "[566]\ttraining's binary_logloss: 0.022051\n",
      "[567]\ttraining's binary_logloss: 0.02195\n",
      "[568]\ttraining's binary_logloss: 0.0218546\n",
      "[569]\ttraining's binary_logloss: 0.0217488\n",
      "[570]\ttraining's binary_logloss: 0.0216509\n",
      "[571]\ttraining's binary_logloss: 0.0215476\n",
      "[572]\ttraining's binary_logloss: 0.0214551\n",
      "[573]\ttraining's binary_logloss: 0.0213616\n",
      "[574]\ttraining's binary_logloss: 0.0212602\n",
      "[575]\ttraining's binary_logloss: 0.0211634\n",
      "[576]\ttraining's binary_logloss: 0.0210678\n",
      "[577]\ttraining's binary_logloss: 0.0209711\n",
      "[578]\ttraining's binary_logloss: 0.0208685\n",
      "[579]\ttraining's binary_logloss: 0.0207649\n",
      "[580]\ttraining's binary_logloss: 0.0206745\n",
      "[581]\ttraining's binary_logloss: 0.0205776\n",
      "[582]\ttraining's binary_logloss: 0.0204901\n",
      "[583]\ttraining's binary_logloss: 0.0203994\n",
      "[584]\ttraining's binary_logloss: 0.0203079\n",
      "[585]\ttraining's binary_logloss: 0.0202095\n",
      "[586]\ttraining's binary_logloss: 0.0201197\n",
      "[587]\ttraining's binary_logloss: 0.020016\n",
      "[588]\ttraining's binary_logloss: 0.0199176\n",
      "[589]\ttraining's binary_logloss: 0.0198142\n",
      "[590]\ttraining's binary_logloss: 0.0197146\n",
      "[591]\ttraining's binary_logloss: 0.0196246\n",
      "[592]\ttraining's binary_logloss: 0.0195264\n",
      "[593]\ttraining's binary_logloss: 0.0194436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[594]\ttraining's binary_logloss: 0.0193588\n",
      "[595]\ttraining's binary_logloss: 0.0192676\n",
      "[596]\ttraining's binary_logloss: 0.0191892\n",
      "[597]\ttraining's binary_logloss: 0.0190983\n",
      "[598]\ttraining's binary_logloss: 0.0190122\n",
      "[599]\ttraining's binary_logloss: 0.0189336\n",
      "[600]\ttraining's binary_logloss: 0.0188521\n",
      "[601]\ttraining's binary_logloss: 0.0187715\n",
      "[602]\ttraining's binary_logloss: 0.0186802\n",
      "[603]\ttraining's binary_logloss: 0.0185884\n",
      "[604]\ttraining's binary_logloss: 0.0184991\n",
      "[605]\ttraining's binary_logloss: 0.0184129\n",
      "[606]\ttraining's binary_logloss: 0.0183342\n",
      "[607]\ttraining's binary_logloss: 0.0182519\n",
      "[608]\ttraining's binary_logloss: 0.0181656\n",
      "[609]\ttraining's binary_logloss: 0.0180807\n",
      "[610]\ttraining's binary_logloss: 0.017993\n",
      "[611]\ttraining's binary_logloss: 0.0179118\n",
      "[612]\ttraining's binary_logloss: 0.0178296\n",
      "[613]\ttraining's binary_logloss: 0.0177494\n",
      "[614]\ttraining's binary_logloss: 0.0176727\n",
      "[615]\ttraining's binary_logloss: 0.0175978\n",
      "[616]\ttraining's binary_logloss: 0.0175228\n",
      "[617]\ttraining's binary_logloss: 0.0174349\n",
      "[618]\ttraining's binary_logloss: 0.0173545\n",
      "[619]\ttraining's binary_logloss: 0.017279\n",
      "[620]\ttraining's binary_logloss: 0.017204\n",
      "[621]\ttraining's binary_logloss: 0.0171281\n",
      "[622]\ttraining's binary_logloss: 0.0170505\n",
      "[623]\ttraining's binary_logloss: 0.0169794\n",
      "[624]\ttraining's binary_logloss: 0.0168969\n",
      "[625]\ttraining's binary_logloss: 0.0168239\n",
      "[626]\ttraining's binary_logloss: 0.0167453\n",
      "[627]\ttraining's binary_logloss: 0.0166653\n",
      "[628]\ttraining's binary_logloss: 0.016579\n",
      "[629]\ttraining's binary_logloss: 0.016503\n",
      "[630]\ttraining's binary_logloss: 0.0164299\n",
      "[631]\ttraining's binary_logloss: 0.0163537\n",
      "[632]\ttraining's binary_logloss: 0.0162788\n",
      "[633]\ttraining's binary_logloss: 0.0161981\n",
      "[634]\ttraining's binary_logloss: 0.01612\n",
      "[635]\ttraining's binary_logloss: 0.0160537\n",
      "[636]\ttraining's binary_logloss: 0.0159765\n",
      "[637]\ttraining's binary_logloss: 0.0158926\n",
      "[638]\ttraining's binary_logloss: 0.0158127\n",
      "[639]\ttraining's binary_logloss: 0.0157393\n",
      "[640]\ttraining's binary_logloss: 0.0156715\n",
      "[641]\ttraining's binary_logloss: 0.0156045\n",
      "[642]\ttraining's binary_logloss: 0.0155338\n",
      "[643]\ttraining's binary_logloss: 0.0154624\n",
      "[644]\ttraining's binary_logloss: 0.0153908\n",
      "[645]\ttraining's binary_logloss: 0.0153185\n",
      "[646]\ttraining's binary_logloss: 0.0152505\n",
      "[647]\ttraining's binary_logloss: 0.0151806\n",
      "[648]\ttraining's binary_logloss: 0.0151134\n",
      "[649]\ttraining's binary_logloss: 0.0150391\n",
      "[650]\ttraining's binary_logloss: 0.0149633\n",
      "[651]\ttraining's binary_logloss: 0.0148874\n",
      "[652]\ttraining's binary_logloss: 0.0148153\n",
      "[653]\ttraining's binary_logloss: 0.0147471\n",
      "[654]\ttraining's binary_logloss: 0.0146802\n",
      "[655]\ttraining's binary_logloss: 0.0146109\n",
      "[656]\ttraining's binary_logloss: 0.0145374\n",
      "[657]\ttraining's binary_logloss: 0.0144687\n",
      "[658]\ttraining's binary_logloss: 0.0144015\n",
      "[659]\ttraining's binary_logloss: 0.0143261\n",
      "[660]\ttraining's binary_logloss: 0.0142601\n",
      "[661]\ttraining's binary_logloss: 0.0141912\n",
      "[662]\ttraining's binary_logloss: 0.0141253\n",
      "[663]\ttraining's binary_logloss: 0.0140507\n",
      "[664]\ttraining's binary_logloss: 0.0139856\n",
      "[665]\ttraining's binary_logloss: 0.013916\n",
      "[666]\ttraining's binary_logloss: 0.0138535\n",
      "[667]\ttraining's binary_logloss: 0.0137917\n",
      "[668]\ttraining's binary_logloss: 0.0137299\n",
      "[669]\ttraining's binary_logloss: 0.0136635\n",
      "[670]\ttraining's binary_logloss: 0.0136029\n",
      "[671]\ttraining's binary_logloss: 0.0135429\n",
      "[672]\ttraining's binary_logloss: 0.0134789\n",
      "[673]\ttraining's binary_logloss: 0.0134158\n",
      "[674]\ttraining's binary_logloss: 0.0133559\n",
      "[675]\ttraining's binary_logloss: 0.0132919\n",
      "[676]\ttraining's binary_logloss: 0.0132342\n",
      "[677]\ttraining's binary_logloss: 0.0131672\n",
      "[678]\ttraining's binary_logloss: 0.0131166\n",
      "[679]\ttraining's binary_logloss: 0.0130601\n",
      "[680]\ttraining's binary_logloss: 0.0130035\n",
      "[681]\ttraining's binary_logloss: 0.0129409\n",
      "[682]\ttraining's binary_logloss: 0.0128782\n",
      "[683]\ttraining's binary_logloss: 0.012826\n",
      "[684]\ttraining's binary_logloss: 0.0127653\n",
      "[685]\ttraining's binary_logloss: 0.0127123\n",
      "[686]\ttraining's binary_logloss: 0.0126567\n",
      "[687]\ttraining's binary_logloss: 0.0126066\n",
      "[688]\ttraining's binary_logloss: 0.0125444\n",
      "[689]\ttraining's binary_logloss: 0.0124832\n",
      "[690]\ttraining's binary_logloss: 0.012427\n",
      "[691]\ttraining's binary_logloss: 0.0123747\n",
      "[692]\ttraining's binary_logloss: 0.0123172\n",
      "[693]\ttraining's binary_logloss: 0.0122616\n",
      "[694]\ttraining's binary_logloss: 0.0122049\n",
      "[695]\ttraining's binary_logloss: 0.0121516\n",
      "[696]\ttraining's binary_logloss: 0.0120985\n",
      "[697]\ttraining's binary_logloss: 0.0120469\n",
      "[698]\ttraining's binary_logloss: 0.011992\n",
      "[699]\ttraining's binary_logloss: 0.0119362\n",
      "[700]\ttraining's binary_logloss: 0.0118816\n",
      "[701]\ttraining's binary_logloss: 0.0118293\n",
      "[702]\ttraining's binary_logloss: 0.011775\n",
      "[703]\ttraining's binary_logloss: 0.0117258\n",
      "[704]\ttraining's binary_logloss: 0.0116698\n",
      "[705]\ttraining's binary_logloss: 0.0116073\n",
      "[706]\ttraining's binary_logloss: 0.0115538\n",
      "[707]\ttraining's binary_logloss: 0.0115036\n",
      "[708]\ttraining's binary_logloss: 0.0114487\n",
      "[709]\ttraining's binary_logloss: 0.0113962\n",
      "[710]\ttraining's binary_logloss: 0.0113415\n",
      "[711]\ttraining's binary_logloss: 0.0112907\n",
      "[712]\ttraining's binary_logloss: 0.0112343\n",
      "[713]\ttraining's binary_logloss: 0.0111825\n",
      "[714]\ttraining's binary_logloss: 0.011132\n",
      "[715]\ttraining's binary_logloss: 0.011081\n",
      "[716]\ttraining's binary_logloss: 0.0110276\n",
      "[717]\ttraining's binary_logloss: 0.0109785\n",
      "[718]\ttraining's binary_logloss: 0.010929\n",
      "[719]\ttraining's binary_logloss: 0.0108767\n",
      "[720]\ttraining's binary_logloss: 0.0108305\n",
      "[721]\ttraining's binary_logloss: 0.0107807\n",
      "[722]\ttraining's binary_logloss: 0.0107338\n",
      "[723]\ttraining's binary_logloss: 0.010689\n",
      "[724]\ttraining's binary_logloss: 0.0106366\n",
      "[725]\ttraining's binary_logloss: 0.0105835\n",
      "[726]\ttraining's binary_logloss: 0.010537\n",
      "[727]\ttraining's binary_logloss: 0.0104963\n",
      "[728]\ttraining's binary_logloss: 0.0104506\n",
      "[729]\ttraining's binary_logloss: 0.0103996\n",
      "[730]\ttraining's binary_logloss: 0.0103532\n",
      "[731]\ttraining's binary_logloss: 0.0103082\n",
      "[732]\ttraining's binary_logloss: 0.0102638\n",
      "[733]\ttraining's binary_logloss: 0.0102148\n",
      "[734]\ttraining's binary_logloss: 0.0101664\n",
      "[735]\ttraining's binary_logloss: 0.0101155\n",
      "[736]\ttraining's binary_logloss: 0.010065\n",
      "[737]\ttraining's binary_logloss: 0.0100214\n",
      "[738]\ttraining's binary_logloss: 0.00998145\n",
      "[739]\ttraining's binary_logloss: 0.00992946\n",
      "[740]\ttraining's binary_logloss: 0.00988568\n",
      "[741]\ttraining's binary_logloss: 0.00983869\n",
      "[742]\ttraining's binary_logloss: 0.0097888\n",
      "[743]\ttraining's binary_logloss: 0.00974009\n",
      "[744]\ttraining's binary_logloss: 0.00969797\n",
      "[745]\ttraining's binary_logloss: 0.009655\n",
      "[746]\ttraining's binary_logloss: 0.00961432\n",
      "[747]\ttraining's binary_logloss: 0.00957048\n",
      "[748]\ttraining's binary_logloss: 0.00952945\n",
      "[749]\ttraining's binary_logloss: 0.00948619\n",
      "[750]\ttraining's binary_logloss: 0.0094454\n",
      "[751]\ttraining's binary_logloss: 0.00940666\n",
      "[752]\ttraining's binary_logloss: 0.00936846\n",
      "[753]\ttraining's binary_logloss: 0.00932077\n",
      "[754]\ttraining's binary_logloss: 0.00927985\n",
      "[755]\ttraining's binary_logloss: 0.00923684\n",
      "[756]\ttraining's binary_logloss: 0.00919619\n",
      "[757]\ttraining's binary_logloss: 0.00915496\n",
      "[758]\ttraining's binary_logloss: 0.00911461\n",
      "[759]\ttraining's binary_logloss: 0.0090753\n",
      "[760]\ttraining's binary_logloss: 0.00903524\n",
      "[761]\ttraining's binary_logloss: 0.00899557\n",
      "[762]\ttraining's binary_logloss: 0.00895287\n",
      "[763]\ttraining's binary_logloss: 0.00891433\n",
      "[764]\ttraining's binary_logloss: 0.00887725\n",
      "[765]\ttraining's binary_logloss: 0.00883852\n",
      "[766]\ttraining's binary_logloss: 0.00879936\n",
      "[767]\ttraining's binary_logloss: 0.00876388\n",
      "[768]\ttraining's binary_logloss: 0.00872905\n",
      "[769]\ttraining's binary_logloss: 0.00868848\n",
      "[770]\ttraining's binary_logloss: 0.00864771\n",
      "[771]\ttraining's binary_logloss: 0.00860179\n",
      "[772]\ttraining's binary_logloss: 0.00856187\n",
      "[773]\ttraining's binary_logloss: 0.00852766\n",
      "[774]\ttraining's binary_logloss: 0.0084882\n",
      "[775]\ttraining's binary_logloss: 0.00844813\n",
      "[776]\ttraining's binary_logloss: 0.00840785\n",
      "[777]\ttraining's binary_logloss: 0.00836956\n",
      "[778]\ttraining's binary_logloss: 0.00833282\n",
      "[779]\ttraining's binary_logloss: 0.00829865\n",
      "[780]\ttraining's binary_logloss: 0.00826134\n",
      "[781]\ttraining's binary_logloss: 0.00822296\n",
      "[782]\ttraining's binary_logloss: 0.0081854\n",
      "[783]\ttraining's binary_logloss: 0.00814253\n",
      "[784]\ttraining's binary_logloss: 0.00810371\n",
      "[785]\ttraining's binary_logloss: 0.0080626\n",
      "[786]\ttraining's binary_logloss: 0.00802942\n",
      "[787]\ttraining's binary_logloss: 0.00799611\n",
      "[788]\ttraining's binary_logloss: 0.0079597\n",
      "[789]\ttraining's binary_logloss: 0.00792286\n",
      "[790]\ttraining's binary_logloss: 0.00788659\n",
      "[791]\ttraining's binary_logloss: 0.00785313\n",
      "[792]\ttraining's binary_logloss: 0.00781841\n",
      "[793]\ttraining's binary_logloss: 0.00778451\n",
      "[794]\ttraining's binary_logloss: 0.00774482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[795]\ttraining's binary_logloss: 0.00770688\n",
      "[796]\ttraining's binary_logloss: 0.00767263\n",
      "[797]\ttraining's binary_logloss: 0.00763667\n",
      "[798]\ttraining's binary_logloss: 0.00760667\n",
      "[799]\ttraining's binary_logloss: 0.007576\n",
      "[800]\ttraining's binary_logloss: 0.00754393\n",
      "[801]\ttraining's binary_logloss: 0.0075122\n",
      "[802]\ttraining's binary_logloss: 0.00748191\n",
      "[803]\ttraining's binary_logloss: 0.00744349\n",
      "[804]\ttraining's binary_logloss: 0.00740757\n",
      "[805]\ttraining's binary_logloss: 0.00737312\n",
      "[806]\ttraining's binary_logloss: 0.00733634\n",
      "[807]\ttraining's binary_logloss: 0.00730618\n",
      "[808]\ttraining's binary_logloss: 0.0072727\n",
      "[809]\ttraining's binary_logloss: 0.0072392\n",
      "[810]\ttraining's binary_logloss: 0.00720602\n",
      "[811]\ttraining's binary_logloss: 0.00717338\n",
      "[812]\ttraining's binary_logloss: 0.00714213\n",
      "[813]\ttraining's binary_logloss: 0.00711069\n",
      "[814]\ttraining's binary_logloss: 0.00707701\n",
      "[815]\ttraining's binary_logloss: 0.00704449\n",
      "[816]\ttraining's binary_logloss: 0.0070103\n",
      "[817]\ttraining's binary_logloss: 0.00698084\n",
      "[818]\ttraining's binary_logloss: 0.00695153\n",
      "[819]\ttraining's binary_logloss: 0.00692245\n",
      "[820]\ttraining's binary_logloss: 0.00689327\n",
      "[821]\ttraining's binary_logloss: 0.00686316\n",
      "[822]\ttraining's binary_logloss: 0.00682997\n",
      "[823]\ttraining's binary_logloss: 0.00680074\n",
      "[824]\ttraining's binary_logloss: 0.0067718\n",
      "[825]\ttraining's binary_logloss: 0.0067406\n",
      "[826]\ttraining's binary_logloss: 0.00671167\n",
      "[827]\ttraining's binary_logloss: 0.00668351\n",
      "[828]\ttraining's binary_logloss: 0.0066518\n",
      "[829]\ttraining's binary_logloss: 0.00662143\n",
      "[830]\ttraining's binary_logloss: 0.00659166\n",
      "[831]\ttraining's binary_logloss: 0.00655855\n",
      "[832]\ttraining's binary_logloss: 0.00652862\n",
      "[833]\ttraining's binary_logloss: 0.00649748\n",
      "[834]\ttraining's binary_logloss: 0.00647149\n",
      "[835]\ttraining's binary_logloss: 0.00644291\n",
      "[836]\ttraining's binary_logloss: 0.00641082\n",
      "[837]\ttraining's binary_logloss: 0.00638067\n",
      "[838]\ttraining's binary_logloss: 0.00635312\n",
      "[839]\ttraining's binary_logloss: 0.0063263\n",
      "[840]\ttraining's binary_logloss: 0.00629398\n",
      "[841]\ttraining's binary_logloss: 0.00626739\n",
      "[842]\ttraining's binary_logloss: 0.00623948\n",
      "[843]\ttraining's binary_logloss: 0.00621366\n",
      "[844]\ttraining's binary_logloss: 0.00618364\n",
      "[845]\ttraining's binary_logloss: 0.00615444\n",
      "[846]\ttraining's binary_logloss: 0.00612576\n",
      "[847]\ttraining's binary_logloss: 0.00609829\n",
      "[848]\ttraining's binary_logloss: 0.00606924\n",
      "[849]\ttraining's binary_logloss: 0.00604267\n",
      "[850]\ttraining's binary_logloss: 0.00601367\n",
      "[851]\ttraining's binary_logloss: 0.00598985\n",
      "[852]\ttraining's binary_logloss: 0.0059627\n",
      "[853]\ttraining's binary_logloss: 0.00593449\n",
      "[854]\ttraining's binary_logloss: 0.00590847\n",
      "[855]\ttraining's binary_logloss: 0.00588292\n",
      "[856]\ttraining's binary_logloss: 0.00585758\n",
      "[857]\ttraining's binary_logloss: 0.00583095\n",
      "[858]\ttraining's binary_logloss: 0.00580379\n",
      "[859]\ttraining's binary_logloss: 0.0057776\n",
      "[860]\ttraining's binary_logloss: 0.00575174\n",
      "[861]\ttraining's binary_logloss: 0.00572742\n",
      "[862]\ttraining's binary_logloss: 0.00570151\n",
      "[863]\ttraining's binary_logloss: 0.00567728\n",
      "[864]\ttraining's binary_logloss: 0.0056505\n",
      "[865]\ttraining's binary_logloss: 0.00562782\n",
      "[866]\ttraining's binary_logloss: 0.00560447\n",
      "[867]\ttraining's binary_logloss: 0.00557667\n",
      "[868]\ttraining's binary_logloss: 0.00555281\n",
      "[869]\ttraining's binary_logloss: 0.00552825\n",
      "[870]\ttraining's binary_logloss: 0.00550524\n",
      "[871]\ttraining's binary_logloss: 0.00548206\n",
      "[872]\ttraining's binary_logloss: 0.00545475\n",
      "[873]\ttraining's binary_logloss: 0.00543148\n",
      "[874]\ttraining's binary_logloss: 0.00540864\n",
      "[875]\ttraining's binary_logloss: 0.00538391\n",
      "[876]\ttraining's binary_logloss: 0.00536014\n",
      "[877]\ttraining's binary_logloss: 0.00533615\n",
      "[878]\ttraining's binary_logloss: 0.00530672\n",
      "[879]\ttraining's binary_logloss: 0.0052854\n",
      "[880]\ttraining's binary_logloss: 0.00526246\n",
      "[881]\ttraining's binary_logloss: 0.00523919\n",
      "[882]\ttraining's binary_logloss: 0.00521512\n",
      "[883]\ttraining's binary_logloss: 0.00519039\n",
      "[884]\ttraining's binary_logloss: 0.00516734\n",
      "[885]\ttraining's binary_logloss: 0.0051454\n",
      "[886]\ttraining's binary_logloss: 0.0051204\n",
      "[887]\ttraining's binary_logloss: 0.00509685\n",
      "[888]\ttraining's binary_logloss: 0.00507644\n",
      "[889]\ttraining's binary_logloss: 0.00504772\n",
      "[890]\ttraining's binary_logloss: 0.00502141\n",
      "[891]\ttraining's binary_logloss: 0.00499791\n",
      "[892]\ttraining's binary_logloss: 0.00497386\n",
      "[893]\ttraining's binary_logloss: 0.00495369\n",
      "[894]\ttraining's binary_logloss: 0.00493082\n",
      "[895]\ttraining's binary_logloss: 0.00491063\n",
      "[896]\ttraining's binary_logloss: 0.00488691\n",
      "[897]\ttraining's binary_logloss: 0.00486336\n",
      "[898]\ttraining's binary_logloss: 0.00484026\n",
      "[899]\ttraining's binary_logloss: 0.00481775\n",
      "[900]\ttraining's binary_logloss: 0.00479543\n",
      "[901]\ttraining's binary_logloss: 0.00477549\n",
      "[902]\ttraining's binary_logloss: 0.00474974\n",
      "[903]\ttraining's binary_logloss: 0.00472791\n",
      "[904]\ttraining's binary_logloss: 0.00470743\n",
      "[905]\ttraining's binary_logloss: 0.00468751\n",
      "[906]\ttraining's binary_logloss: 0.00466679\n",
      "[907]\ttraining's binary_logloss: 0.00464093\n",
      "[908]\ttraining's binary_logloss: 0.00461981\n",
      "[909]\ttraining's binary_logloss: 0.00459817\n",
      "[910]\ttraining's binary_logloss: 0.00457548\n",
      "[911]\ttraining's binary_logloss: 0.00455582\n",
      "[912]\ttraining's binary_logloss: 0.00453324\n",
      "[913]\ttraining's binary_logloss: 0.00451311\n",
      "[914]\ttraining's binary_logloss: 0.0044933\n",
      "[915]\ttraining's binary_logloss: 0.0044732\n",
      "[916]\ttraining's binary_logloss: 0.00445505\n",
      "[917]\ttraining's binary_logloss: 0.00443558\n",
      "[918]\ttraining's binary_logloss: 0.00441656\n",
      "[919]\ttraining's binary_logloss: 0.0043964\n",
      "[920]\ttraining's binary_logloss: 0.00437584\n",
      "[921]\ttraining's binary_logloss: 0.00435675\n",
      "[922]\ttraining's binary_logloss: 0.00433773\n",
      "[923]\ttraining's binary_logloss: 0.00431854\n",
      "[924]\ttraining's binary_logloss: 0.00430021\n",
      "[925]\ttraining's binary_logloss: 0.00427935\n",
      "[926]\ttraining's binary_logloss: 0.00426107\n",
      "[927]\ttraining's binary_logloss: 0.00424275\n",
      "[928]\ttraining's binary_logloss: 0.00422104\n",
      "[929]\ttraining's binary_logloss: 0.0042038\n",
      "[930]\ttraining's binary_logloss: 0.00418582\n",
      "[931]\ttraining's binary_logloss: 0.00416542\n",
      "[932]\ttraining's binary_logloss: 0.00414837\n",
      "[933]\ttraining's binary_logloss: 0.00413114\n",
      "[934]\ttraining's binary_logloss: 0.00411096\n",
      "[935]\ttraining's binary_logloss: 0.00409285\n",
      "[936]\ttraining's binary_logloss: 0.0040755\n",
      "[937]\ttraining's binary_logloss: 0.00405484\n",
      "[938]\ttraining's binary_logloss: 0.00403413\n",
      "[939]\ttraining's binary_logloss: 0.0040149\n",
      "[940]\ttraining's binary_logloss: 0.00399295\n",
      "[941]\ttraining's binary_logloss: 0.00397183\n",
      "[942]\ttraining's binary_logloss: 0.00395473\n",
      "[943]\ttraining's binary_logloss: 0.0039365\n",
      "[944]\ttraining's binary_logloss: 0.00391943\n",
      "[945]\ttraining's binary_logloss: 0.00390177\n",
      "[946]\ttraining's binary_logloss: 0.00388295\n",
      "[947]\ttraining's binary_logloss: 0.00386566\n",
      "[948]\ttraining's binary_logloss: 0.00384989\n",
      "[949]\ttraining's binary_logloss: 0.00382949\n",
      "[950]\ttraining's binary_logloss: 0.0038136\n",
      "[951]\ttraining's binary_logloss: 0.00379757\n",
      "[952]\ttraining's binary_logloss: 0.00378057\n",
      "[953]\ttraining's binary_logloss: 0.0037641\n",
      "[954]\ttraining's binary_logloss: 0.00374724\n",
      "[955]\ttraining's binary_logloss: 0.00372991\n",
      "[956]\ttraining's binary_logloss: 0.00371329\n",
      "[957]\ttraining's binary_logloss: 0.00369673\n",
      "[958]\ttraining's binary_logloss: 0.00368134\n",
      "[959]\ttraining's binary_logloss: 0.00366558\n",
      "[960]\ttraining's binary_logloss: 0.00364842\n",
      "[961]\ttraining's binary_logloss: 0.0036304\n",
      "[962]\ttraining's binary_logloss: 0.00361278\n",
      "[963]\ttraining's binary_logloss: 0.00359528\n",
      "[964]\ttraining's binary_logloss: 0.00357932\n",
      "[965]\ttraining's binary_logloss: 0.00356371\n",
      "[966]\ttraining's binary_logloss: 0.00354812\n",
      "[967]\ttraining's binary_logloss: 0.00352801\n",
      "[968]\ttraining's binary_logloss: 0.00350771\n",
      "[969]\ttraining's binary_logloss: 0.00349169\n",
      "[970]\ttraining's binary_logloss: 0.00347385\n",
      "[971]\ttraining's binary_logloss: 0.00345784\n",
      "[972]\ttraining's binary_logloss: 0.00343866\n",
      "[973]\ttraining's binary_logloss: 0.00342181\n",
      "[974]\ttraining's binary_logloss: 0.00340504\n",
      "[975]\ttraining's binary_logloss: 0.00338932\n",
      "[976]\ttraining's binary_logloss: 0.00337532\n",
      "[977]\ttraining's binary_logloss: 0.00335884\n",
      "[978]\ttraining's binary_logloss: 0.00334327\n",
      "[979]\ttraining's binary_logloss: 0.00332793\n",
      "[980]\ttraining's binary_logloss: 0.00331281\n",
      "[981]\ttraining's binary_logloss: 0.00329615\n",
      "[982]\ttraining's binary_logloss: 0.00327892\n",
      "[983]\ttraining's binary_logloss: 0.00326405\n",
      "[984]\ttraining's binary_logloss: 0.00324661\n",
      "[985]\ttraining's binary_logloss: 0.00323329\n",
      "[986]\ttraining's binary_logloss: 0.00321551\n",
      "[987]\ttraining's binary_logloss: 0.00319954\n",
      "[988]\ttraining's binary_logloss: 0.00318625\n",
      "[989]\ttraining's binary_logloss: 0.00317154\n",
      "[990]\ttraining's binary_logloss: 0.00315761\n",
      "[991]\ttraining's binary_logloss: 0.00314526\n",
      "[992]\ttraining's binary_logloss: 0.00313305\n",
      "[993]\ttraining's binary_logloss: 0.00311816\n",
      "[994]\ttraining's binary_logloss: 0.00310472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[995]\ttraining's binary_logloss: 0.0030917\n",
      "[996]\ttraining's binary_logloss: 0.00307582\n",
      "[997]\ttraining's binary_logloss: 0.00305982\n",
      "[998]\ttraining's binary_logloss: 0.00304734\n",
      "[999]\ttraining's binary_logloss: 0.00303402\n",
      "[1000]\ttraining's binary_logloss: 0.00302084\n",
      "[1001]\ttraining's binary_logloss: 0.00300792\n",
      "[1002]\ttraining's binary_logloss: 0.00299515\n",
      "[1003]\ttraining's binary_logloss: 0.00298222\n",
      "[1004]\ttraining's binary_logloss: 0.00296835\n",
      "[1005]\ttraining's binary_logloss: 0.00295525\n",
      "[1006]\ttraining's binary_logloss: 0.00294297\n",
      "[1007]\ttraining's binary_logloss: 0.00292813\n",
      "[1008]\ttraining's binary_logloss: 0.00291201\n",
      "[1009]\ttraining's binary_logloss: 0.00289951\n",
      "[1010]\ttraining's binary_logloss: 0.00288768\n",
      "[1011]\ttraining's binary_logloss: 0.00287513\n",
      "[1012]\ttraining's binary_logloss: 0.00286254\n",
      "[1013]\ttraining's binary_logloss: 0.00284924\n",
      "[1014]\ttraining's binary_logloss: 0.00283557\n",
      "[1015]\ttraining's binary_logloss: 0.00282273\n",
      "[1016]\ttraining's binary_logloss: 0.0028096\n",
      "[1017]\ttraining's binary_logloss: 0.00279817\n",
      "[1018]\ttraining's binary_logloss: 0.00278757\n",
      "[1019]\ttraining's binary_logloss: 0.00277544\n",
      "[1020]\ttraining's binary_logloss: 0.00276142\n",
      "[1021]\ttraining's binary_logloss: 0.00275041\n",
      "[1022]\ttraining's binary_logloss: 0.00273934\n",
      "[1023]\ttraining's binary_logloss: 0.00272686\n",
      "[1024]\ttraining's binary_logloss: 0.00271295\n",
      "[1025]\ttraining's binary_logloss: 0.00270168\n",
      "[1026]\ttraining's binary_logloss: 0.00269056\n",
      "[1027]\ttraining's binary_logloss: 0.00267701\n",
      "[1028]\ttraining's binary_logloss: 0.00266452\n",
      "[1029]\ttraining's binary_logloss: 0.00265034\n",
      "[1030]\ttraining's binary_logloss: 0.0026392\n",
      "[1031]\ttraining's binary_logloss: 0.00262619\n",
      "[1032]\ttraining's binary_logloss: 0.00261433\n",
      "[1033]\ttraining's binary_logloss: 0.00260306\n",
      "[1034]\ttraining's binary_logloss: 0.00258999\n",
      "[1035]\ttraining's binary_logloss: 0.00257846\n",
      "[1036]\ttraining's binary_logloss: 0.00256638\n",
      "[1037]\ttraining's binary_logloss: 0.00255417\n",
      "[1038]\ttraining's binary_logloss: 0.00254225\n",
      "[1039]\ttraining's binary_logloss: 0.00252952\n",
      "[1040]\ttraining's binary_logloss: 0.00251713\n",
      "[1041]\ttraining's binary_logloss: 0.00250416\n",
      "[1042]\ttraining's binary_logloss: 0.00249305\n",
      "[1043]\ttraining's binary_logloss: 0.00248185\n",
      "[1044]\ttraining's binary_logloss: 0.00247125\n",
      "[1045]\ttraining's binary_logloss: 0.00246058\n",
      "[1046]\ttraining's binary_logloss: 0.00245022\n",
      "[1047]\ttraining's binary_logloss: 0.00243921\n",
      "[1048]\ttraining's binary_logloss: 0.00242848\n",
      "[1049]\ttraining's binary_logloss: 0.00241821\n",
      "[1050]\ttraining's binary_logloss: 0.00240739\n",
      "[1051]\ttraining's binary_logloss: 0.00239671\n",
      "[1052]\ttraining's binary_logloss: 0.00238644\n",
      "[1053]\ttraining's binary_logloss: 0.0023761\n",
      "[1054]\ttraining's binary_logloss: 0.00236522\n",
      "[1055]\ttraining's binary_logloss: 0.00235391\n",
      "[1056]\ttraining's binary_logloss: 0.00234434\n",
      "[1057]\ttraining's binary_logloss: 0.00233396\n",
      "[1058]\ttraining's binary_logloss: 0.00232392\n",
      "[1059]\ttraining's binary_logloss: 0.002313\n",
      "[1060]\ttraining's binary_logloss: 0.002302\n",
      "[1061]\ttraining's binary_logloss: 0.00229116\n",
      "[1062]\ttraining's binary_logloss: 0.00228109\n",
      "[1063]\ttraining's binary_logloss: 0.00227032\n",
      "[1064]\ttraining's binary_logloss: 0.00226096\n",
      "[1065]\ttraining's binary_logloss: 0.0022487\n",
      "[1066]\ttraining's binary_logloss: 0.00223906\n",
      "[1067]\ttraining's binary_logloss: 0.00222605\n",
      "[1068]\ttraining's binary_logloss: 0.00221442\n",
      "[1069]\ttraining's binary_logloss: 0.00220311\n",
      "[1070]\ttraining's binary_logloss: 0.00219314\n",
      "[1071]\ttraining's binary_logloss: 0.00218278\n",
      "[1072]\ttraining's binary_logloss: 0.00217251\n",
      "[1073]\ttraining's binary_logloss: 0.00216352\n",
      "[1074]\ttraining's binary_logloss: 0.0021528\n",
      "[1075]\ttraining's binary_logloss: 0.00214197\n",
      "[1076]\ttraining's binary_logloss: 0.00213048\n",
      "[1077]\ttraining's binary_logloss: 0.00212116\n",
      "[1078]\ttraining's binary_logloss: 0.00211063\n",
      "[1079]\ttraining's binary_logloss: 0.00210073\n",
      "[1080]\ttraining's binary_logloss: 0.00209072\n",
      "[1081]\ttraining's binary_logloss: 0.00208239\n",
      "[1082]\ttraining's binary_logloss: 0.00207344\n",
      "[1083]\ttraining's binary_logloss: 0.00206536\n",
      "[1084]\ttraining's binary_logloss: 0.00205479\n",
      "[1085]\ttraining's binary_logloss: 0.0020448\n",
      "[1086]\ttraining's binary_logloss: 0.00203601\n",
      "[1087]\ttraining's binary_logloss: 0.00202642\n",
      "[1088]\ttraining's binary_logloss: 0.00201542\n",
      "[1089]\ttraining's binary_logloss: 0.00200584\n",
      "[1090]\ttraining's binary_logloss: 0.00199625\n",
      "[1091]\ttraining's binary_logloss: 0.0019878\n",
      "[1092]\ttraining's binary_logloss: 0.00197923\n",
      "[1093]\ttraining's binary_logloss: 0.00197009\n",
      "[1094]\ttraining's binary_logloss: 0.00196112\n",
      "[1095]\ttraining's binary_logloss: 0.00195263\n",
      "[1096]\ttraining's binary_logloss: 0.0019435\n",
      "[1097]\ttraining's binary_logloss: 0.00193549\n",
      "[1098]\ttraining's binary_logloss: 0.00192704\n",
      "[1099]\ttraining's binary_logloss: 0.00191733\n",
      "[1100]\ttraining's binary_logloss: 0.00190922\n",
      "[1101]\ttraining's binary_logloss: 0.00190036\n",
      "[1102]\ttraining's binary_logloss: 0.00189144\n",
      "[1103]\ttraining's binary_logloss: 0.00188307\n",
      "[1104]\ttraining's binary_logloss: 0.00187433\n",
      "[1105]\ttraining's binary_logloss: 0.00186418\n",
      "[1106]\ttraining's binary_logloss: 0.00185614\n",
      "[1107]\ttraining's binary_logloss: 0.00184723\n",
      "[1108]\ttraining's binary_logloss: 0.00183898\n",
      "[1109]\ttraining's binary_logloss: 0.0018295\n",
      "[1110]\ttraining's binary_logloss: 0.00182084\n",
      "[1111]\ttraining's binary_logloss: 0.00181143\n",
      "[1112]\ttraining's binary_logloss: 0.00180438\n",
      "[1113]\ttraining's binary_logloss: 0.00179696\n",
      "[1114]\ttraining's binary_logloss: 0.00178852\n",
      "[1115]\ttraining's binary_logloss: 0.00178001\n",
      "[1116]\ttraining's binary_logloss: 0.00177201\n",
      "[1117]\ttraining's binary_logloss: 0.00176519\n",
      "[1118]\ttraining's binary_logloss: 0.00175786\n",
      "[1119]\ttraining's binary_logloss: 0.00175006\n",
      "[1120]\ttraining's binary_logloss: 0.00174264\n",
      "[1121]\ttraining's binary_logloss: 0.00173444\n",
      "[1122]\ttraining's binary_logloss: 0.0017274\n",
      "[1123]\ttraining's binary_logloss: 0.00172062\n",
      "[1124]\ttraining's binary_logloss: 0.00171302\n",
      "[1125]\ttraining's binary_logloss: 0.00170493\n",
      "[1126]\ttraining's binary_logloss: 0.00169691\n",
      "[1127]\ttraining's binary_logloss: 0.00168918\n",
      "[1128]\ttraining's binary_logloss: 0.0016809\n",
      "[1129]\ttraining's binary_logloss: 0.00167196\n",
      "[1130]\ttraining's binary_logloss: 0.00166411\n",
      "[1131]\ttraining's binary_logloss: 0.00165626\n",
      "[1132]\ttraining's binary_logloss: 0.00164836\n",
      "[1133]\ttraining's binary_logloss: 0.00163968\n",
      "[1134]\ttraining's binary_logloss: 0.0016332\n",
      "[1135]\ttraining's binary_logloss: 0.00162585\n",
      "[1136]\ttraining's binary_logloss: 0.00161869\n",
      "[1137]\ttraining's binary_logloss: 0.00161052\n",
      "[1138]\ttraining's binary_logloss: 0.0016036\n",
      "[1139]\ttraining's binary_logloss: 0.00159505\n",
      "[1140]\ttraining's binary_logloss: 0.00158911\n",
      "[1141]\ttraining's binary_logloss: 0.001582\n",
      "[1142]\ttraining's binary_logloss: 0.00157452\n",
      "[1143]\ttraining's binary_logloss: 0.00156813\n",
      "[1144]\ttraining's binary_logloss: 0.00156148\n",
      "[1145]\ttraining's binary_logloss: 0.00155407\n",
      "[1146]\ttraining's binary_logloss: 0.00154748\n",
      "[1147]\ttraining's binary_logloss: 0.00154075\n",
      "[1148]\ttraining's binary_logloss: 0.00153361\n",
      "[1149]\ttraining's binary_logloss: 0.00152677\n",
      "[1150]\ttraining's binary_logloss: 0.00152022\n",
      "[1151]\ttraining's binary_logloss: 0.00151388\n",
      "[1152]\ttraining's binary_logloss: 0.00150709\n",
      "[1153]\ttraining's binary_logloss: 0.00150003\n",
      "[1154]\ttraining's binary_logloss: 0.00149361\n",
      "[1155]\ttraining's binary_logloss: 0.00148698\n",
      "[1156]\ttraining's binary_logloss: 0.00148038\n",
      "[1157]\ttraining's binary_logloss: 0.00147329\n",
      "[1158]\ttraining's binary_logloss: 0.00146697\n",
      "[1159]\ttraining's binary_logloss: 0.0014603\n",
      "[1160]\ttraining's binary_logloss: 0.00145308\n",
      "[1161]\ttraining's binary_logloss: 0.0014453\n",
      "[1162]\ttraining's binary_logloss: 0.00143856\n",
      "[1163]\ttraining's binary_logloss: 0.0014323\n",
      "[1164]\ttraining's binary_logloss: 0.00142664\n",
      "[1165]\ttraining's binary_logloss: 0.0014184\n",
      "[1166]\ttraining's binary_logloss: 0.00141257\n",
      "[1167]\ttraining's binary_logloss: 0.00140633\n",
      "[1168]\ttraining's binary_logloss: 0.00139954\n",
      "[1169]\ttraining's binary_logloss: 0.00139329\n",
      "[1170]\ttraining's binary_logloss: 0.00138734\n",
      "[1171]\ttraining's binary_logloss: 0.00138043\n",
      "[1172]\ttraining's binary_logloss: 0.0013742\n",
      "[1173]\ttraining's binary_logloss: 0.00136626\n",
      "[1174]\ttraining's binary_logloss: 0.00136076\n",
      "[1175]\ttraining's binary_logloss: 0.00135489\n",
      "[1176]\ttraining's binary_logloss: 0.00134859\n",
      "[1177]\ttraining's binary_logloss: 0.00134278\n",
      "[1178]\ttraining's binary_logloss: 0.0013371\n",
      "[1179]\ttraining's binary_logloss: 0.00133086\n",
      "[1180]\ttraining's binary_logloss: 0.00132474\n",
      "[1181]\ttraining's binary_logloss: 0.00131911\n",
      "[1182]\ttraining's binary_logloss: 0.00131368\n",
      "[1183]\ttraining's binary_logloss: 0.0013079\n",
      "[1184]\ttraining's binary_logloss: 0.00130222\n",
      "[1185]\ttraining's binary_logloss: 0.00129536\n",
      "[1186]\ttraining's binary_logloss: 0.00128786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1187]\ttraining's binary_logloss: 0.00128252\n",
      "[1188]\ttraining's binary_logloss: 0.00127707\n",
      "[1189]\ttraining's binary_logloss: 0.00127115\n",
      "[1190]\ttraining's binary_logloss: 0.00126573\n",
      "[1191]\ttraining's binary_logloss: 0.00126042\n",
      "[1192]\ttraining's binary_logloss: 0.00125482\n",
      "[1193]\ttraining's binary_logloss: 0.00125015\n",
      "[1194]\ttraining's binary_logloss: 0.00124402\n",
      "[1195]\ttraining's binary_logloss: 0.00123863\n",
      "[1196]\ttraining's binary_logloss: 0.00123293\n",
      "[1197]\ttraining's binary_logloss: 0.00122688\n",
      "[1198]\ttraining's binary_logloss: 0.00122197\n",
      "[1199]\ttraining's binary_logloss: 0.0012175\n",
      "[1200]\ttraining's binary_logloss: 0.00121239\n",
      "[1201]\ttraining's binary_logloss: 0.0012067\n",
      "[1202]\ttraining's binary_logloss: 0.00120212\n",
      "[1203]\ttraining's binary_logloss: 0.00119686\n",
      "[1204]\ttraining's binary_logloss: 0.00119173\n",
      "[1205]\ttraining's binary_logloss: 0.00118667\n",
      "[1206]\ttraining's binary_logloss: 0.00118157\n",
      "[1207]\ttraining's binary_logloss: 0.00117586\n",
      "[1208]\ttraining's binary_logloss: 0.00117122\n",
      "[1209]\ttraining's binary_logloss: 0.00116601\n",
      "[1210]\ttraining's binary_logloss: 0.0011615\n",
      "[1211]\ttraining's binary_logloss: 0.00115646\n",
      "[1212]\ttraining's binary_logloss: 0.00115096\n",
      "[1213]\ttraining's binary_logloss: 0.00114498\n",
      "[1214]\ttraining's binary_logloss: 0.0011405\n",
      "[1215]\ttraining's binary_logloss: 0.0011357\n",
      "[1216]\ttraining's binary_logloss: 0.00113009\n",
      "[1217]\ttraining's binary_logloss: 0.00112479\n",
      "[1218]\ttraining's binary_logloss: 0.00111933\n",
      "[1219]\ttraining's binary_logloss: 0.00111426\n",
      "[1220]\ttraining's binary_logloss: 0.00110889\n",
      "[1221]\ttraining's binary_logloss: 0.00110325\n",
      "[1222]\ttraining's binary_logloss: 0.00109837\n",
      "[1223]\ttraining's binary_logloss: 0.00109387\n",
      "[1224]\ttraining's binary_logloss: 0.00108837\n",
      "[1225]\ttraining's binary_logloss: 0.00108278\n",
      "[1226]\ttraining's binary_logloss: 0.00107689\n",
      "[1227]\ttraining's binary_logloss: 0.00107119\n",
      "[1228]\ttraining's binary_logloss: 0.00106539\n",
      "[1229]\ttraining's binary_logloss: 0.00105945\n",
      "[1230]\ttraining's binary_logloss: 0.00105411\n",
      "[1231]\ttraining's binary_logloss: 0.00104924\n",
      "[1232]\ttraining's binary_logloss: 0.00104353\n",
      "[1233]\ttraining's binary_logloss: 0.00103885\n",
      "[1234]\ttraining's binary_logloss: 0.00103415\n",
      "[1235]\ttraining's binary_logloss: 0.00103014\n",
      "[1236]\ttraining's binary_logloss: 0.00102568\n",
      "[1237]\ttraining's binary_logloss: 0.00102046\n",
      "[1238]\ttraining's binary_logloss: 0.00101607\n",
      "[1239]\ttraining's binary_logloss: 0.00101169\n",
      "[1240]\ttraining's binary_logloss: 0.00100686\n",
      "[1241]\ttraining's binary_logloss: 0.00100261\n",
      "[1242]\ttraining's binary_logloss: 0.000998326\n",
      "[1243]\ttraining's binary_logloss: 0.000994478\n",
      "[1244]\ttraining's binary_logloss: 0.000990146\n",
      "[1245]\ttraining's binary_logloss: 0.00098594\n",
      "[1246]\ttraining's binary_logloss: 0.000981618\n",
      "[1247]\ttraining's binary_logloss: 0.000976521\n",
      "[1248]\ttraining's binary_logloss: 0.000972225\n",
      "[1249]\ttraining's binary_logloss: 0.00096755\n",
      "[1250]\ttraining's binary_logloss: 0.000963421\n",
      "[1251]\ttraining's binary_logloss: 0.000958173\n",
      "[1252]\ttraining's binary_logloss: 0.000952861\n",
      "[1253]\ttraining's binary_logloss: 0.0009486\n",
      "[1254]\ttraining's binary_logloss: 0.000944124\n",
      "[1255]\ttraining's binary_logloss: 0.00094044\n",
      "[1256]\ttraining's binary_logloss: 0.000936266\n",
      "[1257]\ttraining's binary_logloss: 0.000932154\n",
      "[1258]\ttraining's binary_logloss: 0.000927386\n",
      "[1259]\ttraining's binary_logloss: 0.000923195\n",
      "[1260]\ttraining's binary_logloss: 0.000918933\n",
      "[1261]\ttraining's binary_logloss: 0.000914947\n",
      "[1262]\ttraining's binary_logloss: 0.000911149\n",
      "[1263]\ttraining's binary_logloss: 0.000907313\n",
      "[1264]\ttraining's binary_logloss: 0.000903769\n",
      "[1265]\ttraining's binary_logloss: 0.000900072\n",
      "[1266]\ttraining's binary_logloss: 0.000895933\n",
      "[1267]\ttraining's binary_logloss: 0.000892289\n",
      "[1268]\ttraining's binary_logloss: 0.000888015\n",
      "[1269]\ttraining's binary_logloss: 0.000883802\n",
      "[1270]\ttraining's binary_logloss: 0.000879957\n",
      "[1271]\ttraining's binary_logloss: 0.000874914\n",
      "[1272]\ttraining's binary_logloss: 0.000870397\n",
      "[1273]\ttraining's binary_logloss: 0.000865975\n",
      "[1274]\ttraining's binary_logloss: 0.000862086\n",
      "[1275]\ttraining's binary_logloss: 0.000857507\n",
      "[1276]\ttraining's binary_logloss: 0.000853683\n",
      "[1277]\ttraining's binary_logloss: 0.00084986\n",
      "[1278]\ttraining's binary_logloss: 0.000845572\n",
      "[1279]\ttraining's binary_logloss: 0.000842094\n",
      "[1280]\ttraining's binary_logloss: 0.000837409\n",
      "[1281]\ttraining's binary_logloss: 0.000833979\n",
      "[1282]\ttraining's binary_logloss: 0.000830745\n",
      "[1283]\ttraining's binary_logloss: 0.000827121\n",
      "[1284]\ttraining's binary_logloss: 0.000823922\n",
      "[1285]\ttraining's binary_logloss: 0.000820168\n",
      "[1286]\ttraining's binary_logloss: 0.000816543\n",
      "[1287]\ttraining's binary_logloss: 0.000813213\n",
      "[1288]\ttraining's binary_logloss: 0.000809617\n",
      "[1289]\ttraining's binary_logloss: 0.000805381\n",
      "[1290]\ttraining's binary_logloss: 0.000800134\n",
      "[1291]\ttraining's binary_logloss: 0.000796035\n",
      "[1292]\ttraining's binary_logloss: 0.00079236\n",
      "[1293]\ttraining's binary_logloss: 0.00078893\n",
      "[1294]\ttraining's binary_logloss: 0.000784952\n",
      "[1295]\ttraining's binary_logloss: 0.000780965\n",
      "[1296]\ttraining's binary_logloss: 0.000777167\n",
      "[1297]\ttraining's binary_logloss: 0.000773936\n",
      "[1298]\ttraining's binary_logloss: 0.000770851\n",
      "[1299]\ttraining's binary_logloss: 0.000767342\n",
      "[1300]\ttraining's binary_logloss: 0.000764131\n",
      "[1301]\ttraining's binary_logloss: 0.000760658\n",
      "[1302]\ttraining's binary_logloss: 0.0007572\n",
      "[1303]\ttraining's binary_logloss: 0.000753757\n",
      "[1304]\ttraining's binary_logloss: 0.000750791\n",
      "[1305]\ttraining's binary_logloss: 0.000747842\n",
      "[1306]\ttraining's binary_logloss: 0.000744363\n",
      "[1307]\ttraining's binary_logloss: 0.000741348\n",
      "[1308]\ttraining's binary_logloss: 0.000738017\n",
      "[1309]\ttraining's binary_logloss: 0.000734736\n",
      "[1310]\ttraining's binary_logloss: 0.000731696\n",
      "[1311]\ttraining's binary_logloss: 0.000728787\n",
      "[1312]\ttraining's binary_logloss: 0.000725506\n",
      "[1313]\ttraining's binary_logloss: 0.000722249\n",
      "[1314]\ttraining's binary_logloss: 0.000718936\n",
      "[1315]\ttraining's binary_logloss: 0.000715826\n",
      "[1316]\ttraining's binary_logloss: 0.000712406\n",
      "[1317]\ttraining's binary_logloss: 0.000709148\n",
      "[1318]\ttraining's binary_logloss: 0.000705937\n",
      "[1319]\ttraining's binary_logloss: 0.000702625\n",
      "[1320]\ttraining's binary_logloss: 0.00069927\n",
      "[1321]\ttraining's binary_logloss: 0.000695845\n",
      "[1322]\ttraining's binary_logloss: 0.000693047\n",
      "[1323]\ttraining's binary_logloss: 0.000690275\n",
      "[1324]\ttraining's binary_logloss: 0.000686988\n",
      "[1325]\ttraining's binary_logloss: 0.000683651\n",
      "[1326]\ttraining's binary_logloss: 0.000680516\n",
      "[1327]\ttraining's binary_logloss: 0.000677701\n",
      "[1328]\ttraining's binary_logloss: 0.000674861\n",
      "[1329]\ttraining's binary_logloss: 0.000671425\n",
      "[1330]\ttraining's binary_logloss: 0.000668512\n",
      "[1331]\ttraining's binary_logloss: 0.000664903\n",
      "[1332]\ttraining's binary_logloss: 0.00066193\n",
      "[1333]\ttraining's binary_logloss: 0.000659103\n",
      "[1334]\ttraining's binary_logloss: 0.000656029\n",
      "[1335]\ttraining's binary_logloss: 0.000653537\n",
      "[1336]\ttraining's binary_logloss: 0.000650661\n",
      "[1337]\ttraining's binary_logloss: 0.000647451\n",
      "[1338]\ttraining's binary_logloss: 0.000644458\n",
      "[1339]\ttraining's binary_logloss: 0.000641556\n",
      "[1340]\ttraining's binary_logloss: 0.000638978\n",
      "[1341]\ttraining's binary_logloss: 0.000635674\n",
      "[1342]\ttraining's binary_logloss: 0.000632626\n",
      "[1343]\ttraining's binary_logloss: 0.000629834\n",
      "[1344]\ttraining's binary_logloss: 0.000627365\n",
      "[1345]\ttraining's binary_logloss: 0.000624383\n",
      "[1346]\ttraining's binary_logloss: 0.000621258\n",
      "[1347]\ttraining's binary_logloss: 0.000618466\n",
      "[1348]\ttraining's binary_logloss: 0.000614854\n",
      "[1349]\ttraining's binary_logloss: 0.000612435\n",
      "[1350]\ttraining's binary_logloss: 0.000609847\n",
      "[1351]\ttraining's binary_logloss: 0.000606835\n",
      "[1352]\ttraining's binary_logloss: 0.000604018\n",
      "[1353]\ttraining's binary_logloss: 0.000601232\n",
      "[1354]\ttraining's binary_logloss: 0.000598351\n",
      "[1355]\ttraining's binary_logloss: 0.000595476\n",
      "[1356]\ttraining's binary_logloss: 0.000592794\n",
      "[1357]\ttraining's binary_logloss: 0.000590378\n",
      "[1358]\ttraining's binary_logloss: 0.000587732\n",
      "[1359]\ttraining's binary_logloss: 0.000585122\n",
      "[1360]\ttraining's binary_logloss: 0.00058241\n",
      "[1361]\ttraining's binary_logloss: 0.000579835\n",
      "[1362]\ttraining's binary_logloss: 0.000577072\n",
      "[1363]\ttraining's binary_logloss: 0.000574726\n",
      "[1364]\ttraining's binary_logloss: 0.000572294\n",
      "[1365]\ttraining's binary_logloss: 0.000569993\n",
      "[1366]\ttraining's binary_logloss: 0.00056708\n",
      "[1367]\ttraining's binary_logloss: 0.000564592\n",
      "[1368]\ttraining's binary_logloss: 0.000562028\n",
      "[1369]\ttraining's binary_logloss: 0.000559595\n",
      "[1370]\ttraining's binary_logloss: 0.000556651\n",
      "[1371]\ttraining's binary_logloss: 0.000554001\n",
      "[1372]\ttraining's binary_logloss: 0.000551363\n",
      "[1373]\ttraining's binary_logloss: 0.00054893\n",
      "[1374]\ttraining's binary_logloss: 0.000546648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1375]\ttraining's binary_logloss: 0.000544048\n",
      "[1376]\ttraining's binary_logloss: 0.000541364\n",
      "[1377]\ttraining's binary_logloss: 0.000538699\n",
      "[1378]\ttraining's binary_logloss: 0.000536437\n",
      "[1379]\ttraining's binary_logloss: 0.000533459\n",
      "[1380]\ttraining's binary_logloss: 0.000531091\n",
      "[1381]\ttraining's binary_logloss: 0.000528925\n",
      "[1382]\ttraining's binary_logloss: 0.000526779\n",
      "[1383]\ttraining's binary_logloss: 0.000524704\n",
      "[1384]\ttraining's binary_logloss: 0.000522177\n",
      "[1385]\ttraining's binary_logloss: 0.00051983\n",
      "[1386]\ttraining's binary_logloss: 0.000517157\n",
      "[1387]\ttraining's binary_logloss: 0.000514924\n",
      "[1388]\ttraining's binary_logloss: 0.000512359\n",
      "[1389]\ttraining's binary_logloss: 0.000510093\n",
      "[1390]\ttraining's binary_logloss: 0.000507848\n",
      "[1391]\ttraining's binary_logloss: 0.000505519\n",
      "[1392]\ttraining's binary_logloss: 0.000503257\n",
      "[1393]\ttraining's binary_logloss: 0.000500882\n",
      "[1394]\ttraining's binary_logloss: 0.000498748\n",
      "[1395]\ttraining's binary_logloss: 0.000496091\n",
      "[1396]\ttraining's binary_logloss: 0.000493784\n",
      "[1397]\ttraining's binary_logloss: 0.000491648\n",
      "[1398]\ttraining's binary_logloss: 0.00048962\n",
      "[1399]\ttraining's binary_logloss: 0.00048775\n",
      "[1400]\ttraining's binary_logloss: 0.000485774\n",
      "[1401]\ttraining's binary_logloss: 0.000483603\n",
      "[1402]\ttraining's binary_logloss: 0.000481386\n",
      "[1403]\ttraining's binary_logloss: 0.000479355\n",
      "[1404]\ttraining's binary_logloss: 0.000477154\n",
      "[1405]\ttraining's binary_logloss: 0.00047492\n",
      "[1406]\ttraining's binary_logloss: 0.000472576\n",
      "[1407]\ttraining's binary_logloss: 0.000470566\n",
      "[1408]\ttraining's binary_logloss: 0.000468227\n",
      "[1409]\ttraining's binary_logloss: 0.000466262\n",
      "[1410]\ttraining's binary_logloss: 0.000463817\n",
      "[1411]\ttraining's binary_logloss: 0.000461872\n",
      "[1412]\ttraining's binary_logloss: 0.000459805\n",
      "[1413]\ttraining's binary_logloss: 0.000457515\n",
      "[1414]\ttraining's binary_logloss: 0.000455446\n",
      "[1415]\ttraining's binary_logloss: 0.000452931\n",
      "[1416]\ttraining's binary_logloss: 0.000450511\n",
      "[1417]\ttraining's binary_logloss: 0.000448563\n",
      "[1418]\ttraining's binary_logloss: 0.000446167\n",
      "[1419]\ttraining's binary_logloss: 0.000444258\n",
      "[1420]\ttraining's binary_logloss: 0.000441709\n",
      "[1421]\ttraining's binary_logloss: 0.000439803\n",
      "[1422]\ttraining's binary_logloss: 0.000437696\n",
      "[1423]\ttraining's binary_logloss: 0.000435319\n",
      "[1424]\ttraining's binary_logloss: 0.000433318\n",
      "[1425]\ttraining's binary_logloss: 0.000431343\n",
      "[1426]\ttraining's binary_logloss: 0.000429421\n",
      "[1427]\ttraining's binary_logloss: 0.000427747\n",
      "[1428]\ttraining's binary_logloss: 0.000425872\n",
      "[1429]\ttraining's binary_logloss: 0.000424289\n",
      "[1430]\ttraining's binary_logloss: 0.00042189\n",
      "[1431]\ttraining's binary_logloss: 0.00042001\n",
      "[1432]\ttraining's binary_logloss: 0.000418058\n",
      "[1433]\ttraining's binary_logloss: 0.000416089\n",
      "[1434]\ttraining's binary_logloss: 0.000414116\n",
      "[1435]\ttraining's binary_logloss: 0.000412088\n",
      "[1436]\ttraining's binary_logloss: 0.000410109\n",
      "[1437]\ttraining's binary_logloss: 0.000407823\n",
      "[1438]\ttraining's binary_logloss: 0.000405734\n",
      "[1439]\ttraining's binary_logloss: 0.000403616\n",
      "[1440]\ttraining's binary_logloss: 0.000401841\n",
      "[1441]\ttraining's binary_logloss: 0.000400198\n",
      "[1442]\ttraining's binary_logloss: 0.000398018\n",
      "[1443]\ttraining's binary_logloss: 0.000396486\n",
      "[1444]\ttraining's binary_logloss: 0.000394272\n",
      "[1445]\ttraining's binary_logloss: 0.000392343\n",
      "[1446]\ttraining's binary_logloss: 0.000390575\n",
      "[1447]\ttraining's binary_logloss: 0.000388884\n",
      "[1448]\ttraining's binary_logloss: 0.00038711\n",
      "[1449]\ttraining's binary_logloss: 0.000385544\n",
      "[1450]\ttraining's binary_logloss: 0.000383697\n",
      "[1451]\ttraining's binary_logloss: 0.000381859\n",
      "[1452]\ttraining's binary_logloss: 0.000380292\n",
      "[1453]\ttraining's binary_logloss: 0.000378754\n",
      "[1454]\ttraining's binary_logloss: 0.000377012\n",
      "[1455]\ttraining's binary_logloss: 0.000375355\n",
      "[1456]\ttraining's binary_logloss: 0.000373636\n",
      "[1457]\ttraining's binary_logloss: 0.000372077\n",
      "[1458]\ttraining's binary_logloss: 0.000370506\n",
      "[1459]\ttraining's binary_logloss: 0.000368952\n",
      "[1460]\ttraining's binary_logloss: 0.000367437\n",
      "[1461]\ttraining's binary_logloss: 0.000365658\n",
      "[1462]\ttraining's binary_logloss: 0.000363636\n",
      "[1463]\ttraining's binary_logloss: 0.000361222\n",
      "[1464]\ttraining's binary_logloss: 0.000359174\n",
      "[1465]\ttraining's binary_logloss: 0.000357312\n",
      "[1466]\ttraining's binary_logloss: 0.0003559\n",
      "[1467]\ttraining's binary_logloss: 0.000354231\n",
      "[1468]\ttraining's binary_logloss: 0.000352401\n",
      "[1469]\ttraining's binary_logloss: 0.000350967\n",
      "[1470]\ttraining's binary_logloss: 0.000349494\n",
      "[1471]\ttraining's binary_logloss: 0.000347741\n",
      "[1472]\ttraining's binary_logloss: 0.000346181\n",
      "[1473]\ttraining's binary_logloss: 0.00034446\n",
      "[1474]\ttraining's binary_logloss: 0.000342994\n",
      "[1475]\ttraining's binary_logloss: 0.000341293\n",
      "[1476]\ttraining's binary_logloss: 0.000339532\n",
      "[1477]\ttraining's binary_logloss: 0.000338181\n",
      "[1478]\ttraining's binary_logloss: 0.000336659\n",
      "[1479]\ttraining's binary_logloss: 0.000335117\n",
      "[1480]\ttraining's binary_logloss: 0.000333427\n",
      "[1481]\ttraining's binary_logloss: 0.000332007\n",
      "[1482]\ttraining's binary_logloss: 0.000330408\n",
      "[1483]\ttraining's binary_logloss: 0.000329031\n",
      "[1484]\ttraining's binary_logloss: 0.00032712\n",
      "[1485]\ttraining's binary_logloss: 0.000325532\n",
      "[1486]\ttraining's binary_logloss: 0.000324077\n",
      "[1487]\ttraining's binary_logloss: 0.000322811\n",
      "[1488]\ttraining's binary_logloss: 0.00032136\n",
      "[1489]\ttraining's binary_logloss: 0.000319854\n",
      "[1490]\ttraining's binary_logloss: 0.000318546\n",
      "[1491]\ttraining's binary_logloss: 0.000317071\n",
      "[1492]\ttraining's binary_logloss: 0.000315646\n",
      "[1493]\ttraining's binary_logloss: 0.000314449\n",
      "[1494]\ttraining's binary_logloss: 0.000313042\n",
      "[1495]\ttraining's binary_logloss: 0.000311704\n",
      "[1496]\ttraining's binary_logloss: 0.000310045\n",
      "[1497]\ttraining's binary_logloss: 0.000308648\n",
      "[1498]\ttraining's binary_logloss: 0.000307069\n",
      "[1499]\ttraining's binary_logloss: 0.000305545\n",
      "[1500]\ttraining's binary_logloss: 0.000304227\n",
      "[1501]\ttraining's binary_logloss: 0.000302932\n",
      "[1502]\ttraining's binary_logloss: 0.000301666\n",
      "[1503]\ttraining's binary_logloss: 0.000300423\n",
      "[1504]\ttraining's binary_logloss: 0.000298926\n",
      "[1505]\ttraining's binary_logloss: 0.000297754\n",
      "[1506]\ttraining's binary_logloss: 0.00029658\n",
      "[1507]\ttraining's binary_logloss: 0.000295471\n",
      "[1508]\ttraining's binary_logloss: 0.000294234\n",
      "[1509]\ttraining's binary_logloss: 0.000292997\n",
      "[1510]\ttraining's binary_logloss: 0.000291785\n",
      "[1511]\ttraining's binary_logloss: 0.000290414\n",
      "[1512]\ttraining's binary_logloss: 0.000289194\n",
      "[1513]\ttraining's binary_logloss: 0.000287787\n",
      "[1514]\ttraining's binary_logloss: 0.000286551\n",
      "[1515]\ttraining's binary_logloss: 0.000285356\n",
      "[1516]\ttraining's binary_logloss: 0.000283793\n",
      "[1517]\ttraining's binary_logloss: 0.000282355\n",
      "[1518]\ttraining's binary_logloss: 0.000281282\n",
      "[1519]\ttraining's binary_logloss: 0.000280266\n",
      "[1520]\ttraining's binary_logloss: 0.000279138\n",
      "[1521]\ttraining's binary_logloss: 0.000277885\n",
      "[1522]\ttraining's binary_logloss: 0.00027665\n",
      "[1523]\ttraining's binary_logloss: 0.000275532\n",
      "[1524]\ttraining's binary_logloss: 0.000274284\n",
      "[1525]\ttraining's binary_logloss: 0.00027298\n",
      "[1526]\ttraining's binary_logloss: 0.000271624\n",
      "[1527]\ttraining's binary_logloss: 0.00027049\n",
      "[1528]\ttraining's binary_logloss: 0.000269293\n",
      "[1529]\ttraining's binary_logloss: 0.000267826\n",
      "[1530]\ttraining's binary_logloss: 0.000266567\n",
      "[1531]\ttraining's binary_logloss: 0.00026526\n",
      "[1532]\ttraining's binary_logloss: 0.000263966\n",
      "[1533]\ttraining's binary_logloss: 0.000262765\n",
      "[1534]\ttraining's binary_logloss: 0.000261436\n",
      "[1535]\ttraining's binary_logloss: 0.000260428\n",
      "[1536]\ttraining's binary_logloss: 0.000259412\n",
      "[1537]\ttraining's binary_logloss: 0.000258198\n",
      "[1538]\ttraining's binary_logloss: 0.000257047\n",
      "[1539]\ttraining's binary_logloss: 0.000255843\n",
      "[1540]\ttraining's binary_logloss: 0.000254438\n",
      "[1541]\ttraining's binary_logloss: 0.000253264\n",
      "[1542]\ttraining's binary_logloss: 0.000251856\n",
      "[1543]\ttraining's binary_logloss: 0.000250743\n",
      "[1544]\ttraining's binary_logloss: 0.000249682\n",
      "[1545]\ttraining's binary_logloss: 0.000248475\n",
      "[1546]\ttraining's binary_logloss: 0.000247281\n",
      "[1547]\ttraining's binary_logloss: 0.000246027\n",
      "[1548]\ttraining's binary_logloss: 0.000244813\n",
      "[1549]\ttraining's binary_logloss: 0.000243581\n",
      "[1550]\ttraining's binary_logloss: 0.000242475\n",
      "[1551]\ttraining's binary_logloss: 0.000241394\n",
      "[1552]\ttraining's binary_logloss: 0.000240348\n",
      "[1553]\ttraining's binary_logloss: 0.000239278\n",
      "[1554]\ttraining's binary_logloss: 0.000238417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1555]\ttraining's binary_logloss: 0.000237183\n",
      "[1556]\ttraining's binary_logloss: 0.000235952\n",
      "[1557]\ttraining's binary_logloss: 0.000234932\n",
      "[1558]\ttraining's binary_logloss: 0.000233894\n",
      "[1559]\ttraining's binary_logloss: 0.0002329\n",
      "[1560]\ttraining's binary_logloss: 0.000231818\n",
      "[1561]\ttraining's binary_logloss: 0.00023071\n",
      "[1562]\ttraining's binary_logloss: 0.000229741\n",
      "[1563]\ttraining's binary_logloss: 0.000228818\n",
      "[1564]\ttraining's binary_logloss: 0.000227656\n",
      "[1565]\ttraining's binary_logloss: 0.000226498\n",
      "[1566]\ttraining's binary_logloss: 0.000225624\n",
      "[1567]\ttraining's binary_logloss: 0.000224755\n",
      "[1568]\ttraining's binary_logloss: 0.000223797\n",
      "[1569]\ttraining's binary_logloss: 0.000222843\n",
      "[1570]\ttraining's binary_logloss: 0.000221862\n",
      "[1571]\ttraining's binary_logloss: 0.000220928\n",
      "[1572]\ttraining's binary_logloss: 0.000220072\n",
      "[1573]\ttraining's binary_logloss: 0.000218744\n",
      "[1574]\ttraining's binary_logloss: 0.000217807\n",
      "[1575]\ttraining's binary_logloss: 0.000216863\n",
      "[1576]\ttraining's binary_logloss: 0.000215954\n",
      "[1577]\ttraining's binary_logloss: 0.000215056\n",
      "[1578]\ttraining's binary_logloss: 0.000214205\n",
      "[1579]\ttraining's binary_logloss: 0.000213194\n",
      "[1580]\ttraining's binary_logloss: 0.00021199\n",
      "[1581]\ttraining's binary_logloss: 0.000210874\n",
      "[1582]\ttraining's binary_logloss: 0.000209991\n",
      "[1583]\ttraining's binary_logloss: 0.000209178\n",
      "[1584]\ttraining's binary_logloss: 0.000208319\n",
      "[1585]\ttraining's binary_logloss: 0.000207429\n",
      "[1586]\ttraining's binary_logloss: 0.000206634\n",
      "[1587]\ttraining's binary_logloss: 0.000205703\n",
      "[1588]\ttraining's binary_logloss: 0.000204859\n",
      "[1589]\ttraining's binary_logloss: 0.00020365\n",
      "[1590]\ttraining's binary_logloss: 0.000202858\n",
      "[1591]\ttraining's binary_logloss: 0.000201986\n",
      "[1592]\ttraining's binary_logloss: 0.000201227\n",
      "[1593]\ttraining's binary_logloss: 0.000200271\n",
      "[1594]\ttraining's binary_logloss: 0.000199388\n",
      "[1595]\ttraining's binary_logloss: 0.000198495\n",
      "[1596]\ttraining's binary_logloss: 0.000197777\n",
      "[1597]\ttraining's binary_logloss: 0.000196741\n",
      "[1598]\ttraining's binary_logloss: 0.000195828\n",
      "[1599]\ttraining's binary_logloss: 0.000194916\n",
      "[1600]\ttraining's binary_logloss: 0.000194107\n",
      "[1601]\ttraining's binary_logloss: 0.000193149\n",
      "[1602]\ttraining's binary_logloss: 0.000192185\n",
      "[1603]\ttraining's binary_logloss: 0.000191165\n",
      "[1604]\ttraining's binary_logloss: 0.000190336\n",
      "[1605]\ttraining's binary_logloss: 0.000189487\n",
      "[1606]\ttraining's binary_logloss: 0.000188633\n",
      "[1607]\ttraining's binary_logloss: 0.000187876\n",
      "[1608]\ttraining's binary_logloss: 0.000186901\n",
      "[1609]\ttraining's binary_logloss: 0.000186175\n",
      "[1610]\ttraining's binary_logloss: 0.000185424\n",
      "[1611]\ttraining's binary_logloss: 0.000184543\n",
      "[1612]\ttraining's binary_logloss: 0.000183739\n",
      "[1613]\ttraining's binary_logloss: 0.000182881\n",
      "[1614]\ttraining's binary_logloss: 0.000182019\n",
      "[1615]\ttraining's binary_logloss: 0.000181379\n",
      "[1616]\ttraining's binary_logloss: 0.00018051\n",
      "[1617]\ttraining's binary_logloss: 0.000179742\n",
      "[1618]\ttraining's binary_logloss: 0.000179098\n",
      "[1619]\ttraining's binary_logloss: 0.000178163\n",
      "[1620]\ttraining's binary_logloss: 0.000177362\n",
      "[1621]\ttraining's binary_logloss: 0.000176562\n",
      "[1622]\ttraining's binary_logloss: 0.000175871\n",
      "[1623]\ttraining's binary_logloss: 0.000175028\n",
      "[1624]\ttraining's binary_logloss: 0.000174238\n",
      "[1625]\ttraining's binary_logloss: 0.000173548\n",
      "[1626]\ttraining's binary_logloss: 0.000172836\n",
      "[1627]\ttraining's binary_logloss: 0.00017217\n",
      "[1628]\ttraining's binary_logloss: 0.000171576\n",
      "[1629]\ttraining's binary_logloss: 0.000170804\n",
      "[1630]\ttraining's binary_logloss: 0.000170177\n",
      "[1631]\ttraining's binary_logloss: 0.000169549\n",
      "[1632]\ttraining's binary_logloss: 0.000168658\n",
      "[1633]\ttraining's binary_logloss: 0.000167829\n",
      "[1634]\ttraining's binary_logloss: 0.000167162\n",
      "[1635]\ttraining's binary_logloss: 0.000166479\n",
      "[1636]\ttraining's binary_logloss: 0.00016591\n",
      "[1637]\ttraining's binary_logloss: 0.000165239\n",
      "[1638]\ttraining's binary_logloss: 0.000164534\n",
      "[1639]\ttraining's binary_logloss: 0.000163902\n",
      "[1640]\ttraining's binary_logloss: 0.00016316\n",
      "[1641]\ttraining's binary_logloss: 0.00016243\n",
      "[1642]\ttraining's binary_logloss: 0.000161685\n",
      "[1643]\ttraining's binary_logloss: 0.000160805\n",
      "[1644]\ttraining's binary_logloss: 0.000159987\n",
      "[1645]\ttraining's binary_logloss: 0.000159316\n",
      "[1646]\ttraining's binary_logloss: 0.000158637\n",
      "[1647]\ttraining's binary_logloss: 0.000157953\n",
      "[1648]\ttraining's binary_logloss: 0.000157389\n",
      "[1649]\ttraining's binary_logloss: 0.000156813\n",
      "[1650]\ttraining's binary_logloss: 0.000156049\n",
      "[1651]\ttraining's binary_logloss: 0.000155406\n",
      "[1652]\ttraining's binary_logloss: 0.000154727\n",
      "[1653]\ttraining's binary_logloss: 0.000153988\n",
      "[1654]\ttraining's binary_logloss: 0.00015337\n",
      "[1655]\ttraining's binary_logloss: 0.000152767\n",
      "[1656]\ttraining's binary_logloss: 0.000152119\n",
      "[1657]\ttraining's binary_logloss: 0.000151431\n",
      "[1658]\ttraining's binary_logloss: 0.00015076\n",
      "[1659]\ttraining's binary_logloss: 0.000150125\n",
      "[1660]\ttraining's binary_logloss: 0.000149349\n",
      "[1661]\ttraining's binary_logloss: 0.000148748\n",
      "[1662]\ttraining's binary_logloss: 0.000148162\n",
      "[1663]\ttraining's binary_logloss: 0.000147365\n",
      "[1664]\ttraining's binary_logloss: 0.00014667\n",
      "[1665]\ttraining's binary_logloss: 0.000146008\n",
      "[1666]\ttraining's binary_logloss: 0.000145356\n",
      "[1667]\ttraining's binary_logloss: 0.000144833\n",
      "[1668]\ttraining's binary_logloss: 0.000144106\n",
      "[1669]\ttraining's binary_logloss: 0.000143436\n",
      "[1670]\ttraining's binary_logloss: 0.000142851\n",
      "[1671]\ttraining's binary_logloss: 0.000142271\n",
      "[1672]\ttraining's binary_logloss: 0.00014168\n",
      "[1673]\ttraining's binary_logloss: 0.000141062\n",
      "[1674]\ttraining's binary_logloss: 0.000140445\n",
      "[1675]\ttraining's binary_logloss: 0.000139867\n",
      "[1676]\ttraining's binary_logloss: 0.000139245\n",
      "[1677]\ttraining's binary_logloss: 0.000138627\n",
      "[1678]\ttraining's binary_logloss: 0.000138049\n",
      "[1679]\ttraining's binary_logloss: 0.000137468\n",
      "[1680]\ttraining's binary_logloss: 0.000136744\n",
      "[1681]\ttraining's binary_logloss: 0.000136127\n",
      "[1682]\ttraining's binary_logloss: 0.000135469\n",
      "[1683]\ttraining's binary_logloss: 0.000134933\n",
      "[1684]\ttraining's binary_logloss: 0.000134369\n",
      "[1685]\ttraining's binary_logloss: 0.000133764\n",
      "[1686]\ttraining's binary_logloss: 0.00013316\n",
      "[1687]\ttraining's binary_logloss: 0.000132611\n",
      "[1688]\ttraining's binary_logloss: 0.000132083\n",
      "[1689]\ttraining's binary_logloss: 0.000131417\n",
      "[1690]\ttraining's binary_logloss: 0.000130832\n",
      "[1691]\ttraining's binary_logloss: 0.000130181\n",
      "[1692]\ttraining's binary_logloss: 0.000129655\n",
      "[1693]\ttraining's binary_logloss: 0.000129115\n",
      "[1694]\ttraining's binary_logloss: 0.000128566\n",
      "[1695]\ttraining's binary_logloss: 0.000127946\n",
      "[1696]\ttraining's binary_logloss: 0.00012738\n",
      "[1697]\ttraining's binary_logloss: 0.000126805\n",
      "[1698]\ttraining's binary_logloss: 0.000126277\n",
      "[1699]\ttraining's binary_logloss: 0.000125748\n",
      "[1700]\ttraining's binary_logloss: 0.000125273\n",
      "[1701]\ttraining's binary_logloss: 0.000124584\n",
      "[1702]\ttraining's binary_logloss: 0.000124087\n",
      "[1703]\ttraining's binary_logloss: 0.000123606\n",
      "[1704]\ttraining's binary_logloss: 0.000123131\n",
      "[1705]\ttraining's binary_logloss: 0.000122581\n",
      "[1706]\ttraining's binary_logloss: 0.000122065\n",
      "[1707]\ttraining's binary_logloss: 0.000121494\n",
      "[1708]\ttraining's binary_logloss: 0.000120906\n",
      "[1709]\ttraining's binary_logloss: 0.000120406\n",
      "[1710]\ttraining's binary_logloss: 0.00011987\n",
      "[1711]\ttraining's binary_logloss: 0.000119372\n",
      "[1712]\ttraining's binary_logloss: 0.000118786\n",
      "[1713]\ttraining's binary_logloss: 0.000118221\n",
      "[1714]\ttraining's binary_logloss: 0.000117732\n",
      "[1715]\ttraining's binary_logloss: 0.000117183\n",
      "[1716]\ttraining's binary_logloss: 0.00011669\n",
      "[1717]\ttraining's binary_logloss: 0.000116206\n",
      "[1718]\ttraining's binary_logloss: 0.000115752\n",
      "[1719]\ttraining's binary_logloss: 0.000115203\n",
      "[1720]\ttraining's binary_logloss: 0.000114704\n",
      "[1721]\ttraining's binary_logloss: 0.000114122\n",
      "[1722]\ttraining's binary_logloss: 0.000113652\n",
      "[1723]\ttraining's binary_logloss: 0.000113162\n",
      "[1724]\ttraining's binary_logloss: 0.000112675\n",
      "[1725]\ttraining's binary_logloss: 0.000112251\n",
      "[1726]\ttraining's binary_logloss: 0.000111779\n",
      "[1727]\ttraining's binary_logloss: 0.000111356\n",
      "[1728]\ttraining's binary_logloss: 0.000110926\n",
      "[1729]\ttraining's binary_logloss: 0.000110445\n",
      "[1730]\ttraining's binary_logloss: 0.000109974\n",
      "[1731]\ttraining's binary_logloss: 0.000109488\n",
      "[1732]\ttraining's binary_logloss: 0.00010901\n",
      "[1733]\ttraining's binary_logloss: 0.000108566\n",
      "[1734]\ttraining's binary_logloss: 0.000108145\n",
      "[1735]\ttraining's binary_logloss: 0.000107661\n",
      "[1736]\ttraining's binary_logloss: 0.000107134\n",
      "[1737]\ttraining's binary_logloss: 0.000106651\n",
      "[1738]\ttraining's binary_logloss: 0.000106211\n",
      "[1739]\ttraining's binary_logloss: 0.000105806\n",
      "[1740]\ttraining's binary_logloss: 0.000105409\n",
      "[1741]\ttraining's binary_logloss: 0.000104974\n",
      "[1742]\ttraining's binary_logloss: 0.000104546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1743]\ttraining's binary_logloss: 0.000104106\n",
      "[1744]\ttraining's binary_logloss: 0.000103661\n",
      "[1745]\ttraining's binary_logloss: 0.000103216\n",
      "[1746]\ttraining's binary_logloss: 0.000102811\n",
      "[1747]\ttraining's binary_logloss: 0.00010241\n",
      "[1748]\ttraining's binary_logloss: 0.000101941\n",
      "[1749]\ttraining's binary_logloss: 0.000101537\n",
      "[1750]\ttraining's binary_logloss: 0.000101117\n",
      "[1751]\ttraining's binary_logloss: 0.00010077\n",
      "[1752]\ttraining's binary_logloss: 0.000100368\n",
      "[1753]\ttraining's binary_logloss: 9.99566e-05\n",
      "[1754]\ttraining's binary_logloss: 9.95633e-05\n",
      "[1755]\ttraining's binary_logloss: 9.91463e-05\n",
      "[1756]\ttraining's binary_logloss: 9.87198e-05\n",
      "[1757]\ttraining's binary_logloss: 9.82956e-05\n",
      "[1758]\ttraining's binary_logloss: 9.78316e-05\n",
      "[1759]\ttraining's binary_logloss: 9.74421e-05\n",
      "[1760]\ttraining's binary_logloss: 9.70827e-05\n",
      "[1761]\ttraining's binary_logloss: 9.67152e-05\n",
      "[1762]\ttraining's binary_logloss: 9.62585e-05\n",
      "[1763]\ttraining's binary_logloss: 9.58661e-05\n",
      "[1764]\ttraining's binary_logloss: 9.54213e-05\n",
      "[1765]\ttraining's binary_logloss: 9.49931e-05\n",
      "[1766]\ttraining's binary_logloss: 9.46289e-05\n",
      "[1767]\ttraining's binary_logloss: 9.41595e-05\n",
      "[1768]\ttraining's binary_logloss: 9.37928e-05\n",
      "[1769]\ttraining's binary_logloss: 9.34383e-05\n",
      "[1770]\ttraining's binary_logloss: 9.30776e-05\n",
      "[1771]\ttraining's binary_logloss: 9.26723e-05\n",
      "[1772]\ttraining's binary_logloss: 9.22416e-05\n",
      "[1773]\ttraining's binary_logloss: 9.18505e-05\n",
      "[1774]\ttraining's binary_logloss: 9.14919e-05\n",
      "[1775]\ttraining's binary_logloss: 9.11247e-05\n",
      "[1776]\ttraining's binary_logloss: 9.07357e-05\n",
      "[1777]\ttraining's binary_logloss: 9.03633e-05\n",
      "[1778]\ttraining's binary_logloss: 9.00033e-05\n",
      "[1779]\ttraining's binary_logloss: 8.96431e-05\n",
      "[1780]\ttraining's binary_logloss: 8.93126e-05\n",
      "[1781]\ttraining's binary_logloss: 8.89614e-05\n",
      "[1782]\ttraining's binary_logloss: 8.85757e-05\n",
      "[1783]\ttraining's binary_logloss: 8.8196e-05\n",
      "[1784]\ttraining's binary_logloss: 8.78014e-05\n",
      "[1785]\ttraining's binary_logloss: 8.74758e-05\n",
      "[1786]\ttraining's binary_logloss: 8.70943e-05\n",
      "[1787]\ttraining's binary_logloss: 8.67238e-05\n",
      "[1788]\ttraining's binary_logloss: 8.63708e-05\n",
      "[1789]\ttraining's binary_logloss: 8.60121e-05\n",
      "[1790]\ttraining's binary_logloss: 8.56388e-05\n",
      "[1791]\ttraining's binary_logloss: 8.53136e-05\n",
      "[1792]\ttraining's binary_logloss: 8.49028e-05\n",
      "[1793]\ttraining's binary_logloss: 8.44634e-05\n",
      "[1794]\ttraining's binary_logloss: 8.40463e-05\n",
      "[1795]\ttraining's binary_logloss: 8.37066e-05\n",
      "[1796]\ttraining's binary_logloss: 8.32906e-05\n",
      "[1797]\ttraining's binary_logloss: 8.28479e-05\n",
      "[1798]\ttraining's binary_logloss: 8.24514e-05\n",
      "[1799]\ttraining's binary_logloss: 8.2161e-05\n",
      "[1800]\ttraining's binary_logloss: 8.18455e-05\n",
      "[1801]\ttraining's binary_logloss: 8.14796e-05\n",
      "[1802]\ttraining's binary_logloss: 8.11729e-05\n",
      "[1803]\ttraining's binary_logloss: 8.08567e-05\n",
      "[1804]\ttraining's binary_logloss: 8.05675e-05\n",
      "[1805]\ttraining's binary_logloss: 8.01677e-05\n",
      "[1806]\ttraining's binary_logloss: 7.98172e-05\n",
      "[1807]\ttraining's binary_logloss: 7.94832e-05\n",
      "[1808]\ttraining's binary_logloss: 7.91508e-05\n",
      "[1809]\ttraining's binary_logloss: 7.8841e-05\n",
      "[1810]\ttraining's binary_logloss: 7.85081e-05\n",
      "[1811]\ttraining's binary_logloss: 7.81794e-05\n",
      "[1812]\ttraining's binary_logloss: 7.78872e-05\n",
      "[1813]\ttraining's binary_logloss: 7.75589e-05\n",
      "[1814]\ttraining's binary_logloss: 7.72129e-05\n",
      "[1815]\ttraining's binary_logloss: 7.68812e-05\n",
      "[1816]\ttraining's binary_logloss: 7.65837e-05\n",
      "[1817]\ttraining's binary_logloss: 7.6313e-05\n",
      "[1818]\ttraining's binary_logloss: 7.60198e-05\n",
      "[1819]\ttraining's binary_logloss: 7.57084e-05\n",
      "[1820]\ttraining's binary_logloss: 7.53851e-05\n",
      "[1821]\ttraining's binary_logloss: 7.50699e-05\n",
      "[1822]\ttraining's binary_logloss: 7.47433e-05\n",
      "[1823]\ttraining's binary_logloss: 7.44698e-05\n",
      "[1824]\ttraining's binary_logloss: 7.41721e-05\n",
      "[1825]\ttraining's binary_logloss: 7.39048e-05\n",
      "[1826]\ttraining's binary_logloss: 7.36122e-05\n",
      "[1827]\ttraining's binary_logloss: 7.33113e-05\n",
      "[1828]\ttraining's binary_logloss: 7.30205e-05\n",
      "[1829]\ttraining's binary_logloss: 7.26269e-05\n",
      "[1830]\ttraining's binary_logloss: 7.23584e-05\n",
      "[1831]\ttraining's binary_logloss: 7.20806e-05\n",
      "[1832]\ttraining's binary_logloss: 7.17975e-05\n",
      "[1833]\ttraining's binary_logloss: 7.14996e-05\n",
      "[1834]\ttraining's binary_logloss: 7.12199e-05\n",
      "[1835]\ttraining's binary_logloss: 7.0907e-05\n",
      "[1836]\ttraining's binary_logloss: 7.05885e-05\n",
      "[1837]\ttraining's binary_logloss: 7.03258e-05\n",
      "[1838]\ttraining's binary_logloss: 7.0015e-05\n",
      "[1839]\ttraining's binary_logloss: 6.97592e-05\n",
      "[1840]\ttraining's binary_logloss: 6.94703e-05\n",
      "[1841]\ttraining's binary_logloss: 6.92248e-05\n",
      "[1842]\ttraining's binary_logloss: 6.89669e-05\n",
      "[1843]\ttraining's binary_logloss: 6.87255e-05\n",
      "[1844]\ttraining's binary_logloss: 6.84675e-05\n",
      "[1845]\ttraining's binary_logloss: 6.81625e-05\n",
      "[1846]\ttraining's binary_logloss: 6.79152e-05\n",
      "[1847]\ttraining's binary_logloss: 6.76136e-05\n",
      "[1848]\ttraining's binary_logloss: 6.73329e-05\n",
      "[1849]\ttraining's binary_logloss: 6.70516e-05\n",
      "[1850]\ttraining's binary_logloss: 6.67737e-05\n",
      "[1851]\ttraining's binary_logloss: 6.65174e-05\n",
      "[1852]\ttraining's binary_logloss: 6.62766e-05\n",
      "[1853]\ttraining's binary_logloss: 6.60277e-05\n",
      "[1854]\ttraining's binary_logloss: 6.57523e-05\n",
      "[1855]\ttraining's binary_logloss: 6.54896e-05\n",
      "[1856]\ttraining's binary_logloss: 6.51976e-05\n",
      "[1857]\ttraining's binary_logloss: 6.49278e-05\n",
      "[1858]\ttraining's binary_logloss: 6.46837e-05\n",
      "[1859]\ttraining's binary_logloss: 6.44315e-05\n",
      "[1860]\ttraining's binary_logloss: 6.41968e-05\n",
      "[1861]\ttraining's binary_logloss: 6.39596e-05\n",
      "[1862]\ttraining's binary_logloss: 6.37087e-05\n",
      "[1863]\ttraining's binary_logloss: 6.34719e-05\n",
      "[1864]\ttraining's binary_logloss: 6.32104e-05\n",
      "[1865]\ttraining's binary_logloss: 6.29644e-05\n",
      "[1866]\ttraining's binary_logloss: 6.27444e-05\n",
      "[1867]\ttraining's binary_logloss: 6.24945e-05\n",
      "[1868]\ttraining's binary_logloss: 6.22493e-05\n",
      "[1869]\ttraining's binary_logloss: 6.20031e-05\n",
      "[1870]\ttraining's binary_logloss: 6.17566e-05\n",
      "[1871]\ttraining's binary_logloss: 6.14842e-05\n",
      "[1872]\ttraining's binary_logloss: 6.12341e-05\n",
      "[1873]\ttraining's binary_logloss: 6.09894e-05\n",
      "[1874]\ttraining's binary_logloss: 6.07589e-05\n",
      "[1875]\ttraining's binary_logloss: 6.05318e-05\n",
      "[1876]\ttraining's binary_logloss: 6.03084e-05\n",
      "[1877]\ttraining's binary_logloss: 6.00413e-05\n",
      "[1878]\ttraining's binary_logloss: 5.98308e-05\n",
      "[1879]\ttraining's binary_logloss: 5.96066e-05\n",
      "[1880]\ttraining's binary_logloss: 5.93734e-05\n",
      "[1881]\ttraining's binary_logloss: 5.91164e-05\n",
      "[1882]\ttraining's binary_logloss: 5.88891e-05\n",
      "[1883]\ttraining's binary_logloss: 5.86513e-05\n",
      "[1884]\ttraining's binary_logloss: 5.84384e-05\n",
      "[1885]\ttraining's binary_logloss: 5.822e-05\n",
      "[1886]\ttraining's binary_logloss: 5.80054e-05\n",
      "[1887]\ttraining's binary_logloss: 5.7775e-05\n",
      "[1888]\ttraining's binary_logloss: 5.75255e-05\n",
      "[1889]\ttraining's binary_logloss: 5.72832e-05\n",
      "[1890]\ttraining's binary_logloss: 5.70764e-05\n",
      "[1891]\ttraining's binary_logloss: 5.68607e-05\n",
      "[1892]\ttraining's binary_logloss: 5.66528e-05\n",
      "[1893]\ttraining's binary_logloss: 5.64254e-05\n",
      "[1894]\ttraining's binary_logloss: 5.61827e-05\n",
      "[1895]\ttraining's binary_logloss: 5.59785e-05\n",
      "[1896]\ttraining's binary_logloss: 5.57726e-05\n",
      "[1897]\ttraining's binary_logloss: 5.55504e-05\n",
      "[1898]\ttraining's binary_logloss: 5.53502e-05\n",
      "[1899]\ttraining's binary_logloss: 5.51518e-05\n",
      "[1900]\ttraining's binary_logloss: 5.49609e-05\n",
      "[1901]\ttraining's binary_logloss: 5.47477e-05\n",
      "[1902]\ttraining's binary_logloss: 5.45329e-05\n",
      "[1903]\ttraining's binary_logloss: 5.43336e-05\n",
      "[1904]\ttraining's binary_logloss: 5.41286e-05\n",
      "[1905]\ttraining's binary_logloss: 5.39209e-05\n",
      "[1906]\ttraining's binary_logloss: 5.37394e-05\n",
      "[1907]\ttraining's binary_logloss: 5.3528e-05\n",
      "[1908]\ttraining's binary_logloss: 5.33452e-05\n",
      "[1909]\ttraining's binary_logloss: 5.31229e-05\n",
      "[1910]\ttraining's binary_logloss: 5.29171e-05\n",
      "[1911]\ttraining's binary_logloss: 5.26857e-05\n",
      "[1912]\ttraining's binary_logloss: 5.24808e-05\n",
      "[1913]\ttraining's binary_logloss: 5.22542e-05\n",
      "[1914]\ttraining's binary_logloss: 5.20711e-05\n",
      "[1915]\ttraining's binary_logloss: 5.18766e-05\n",
      "[1916]\ttraining's binary_logloss: 5.16901e-05\n",
      "[1917]\ttraining's binary_logloss: 5.14891e-05\n",
      "[1918]\ttraining's binary_logloss: 5.13113e-05\n",
      "[1919]\ttraining's binary_logloss: 5.11144e-05\n",
      "[1920]\ttraining's binary_logloss: 5.09301e-05\n",
      "[1921]\ttraining's binary_logloss: 5.07211e-05\n",
      "[1922]\ttraining's binary_logloss: 5.0537e-05\n",
      "[1923]\ttraining's binary_logloss: 5.03598e-05\n",
      "[1924]\ttraining's binary_logloss: 5.0183e-05\n",
      "[1925]\ttraining's binary_logloss: 4.99927e-05\n",
      "[1926]\ttraining's binary_logloss: 4.97963e-05\n",
      "[1927]\ttraining's binary_logloss: 4.96014e-05\n",
      "[1928]\ttraining's binary_logloss: 4.9412e-05\n",
      "[1929]\ttraining's binary_logloss: 4.92263e-05\n",
      "[1930]\ttraining's binary_logloss: 4.90286e-05\n",
      "[1931]\ttraining's binary_logloss: 4.88422e-05\n",
      "[1932]\ttraining's binary_logloss: 4.86589e-05\n",
      "[1933]\ttraining's binary_logloss: 4.85008e-05\n",
      "[1934]\ttraining's binary_logloss: 4.83381e-05\n",
      "[1935]\ttraining's binary_logloss: 4.81594e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1936]\ttraining's binary_logloss: 4.79931e-05\n",
      "[1937]\ttraining's binary_logloss: 4.78078e-05\n",
      "[1938]\ttraining's binary_logloss: 4.76106e-05\n",
      "[1939]\ttraining's binary_logloss: 4.74359e-05\n",
      "[1940]\ttraining's binary_logloss: 4.72632e-05\n",
      "[1941]\ttraining's binary_logloss: 4.7099e-05\n",
      "[1942]\ttraining's binary_logloss: 4.69425e-05\n",
      "[1943]\ttraining's binary_logloss: 4.67615e-05\n",
      "[1944]\ttraining's binary_logloss: 4.65937e-05\n",
      "[1945]\ttraining's binary_logloss: 4.64248e-05\n",
      "[1946]\ttraining's binary_logloss: 4.62582e-05\n",
      "[1947]\ttraining's binary_logloss: 4.60822e-05\n",
      "[1948]\ttraining's binary_logloss: 4.58805e-05\n",
      "[1949]\ttraining's binary_logloss: 4.57202e-05\n",
      "[1950]\ttraining's binary_logloss: 4.55479e-05\n",
      "[1951]\ttraining's binary_logloss: 4.53909e-05\n",
      "[1952]\ttraining's binary_logloss: 4.52144e-05\n",
      "[1953]\ttraining's binary_logloss: 4.50477e-05\n",
      "[1954]\ttraining's binary_logloss: 4.48905e-05\n",
      "[1955]\ttraining's binary_logloss: 4.4718e-05\n",
      "[1956]\ttraining's binary_logloss: 4.45491e-05\n",
      "[1957]\ttraining's binary_logloss: 4.43801e-05\n",
      "[1958]\ttraining's binary_logloss: 4.42126e-05\n",
      "[1959]\ttraining's binary_logloss: 4.40316e-05\n",
      "[1960]\ttraining's binary_logloss: 4.38646e-05\n",
      "[1961]\ttraining's binary_logloss: 4.37085e-05\n",
      "[1962]\ttraining's binary_logloss: 4.35391e-05\n",
      "[1963]\ttraining's binary_logloss: 4.33615e-05\n",
      "[1964]\ttraining's binary_logloss: 4.32035e-05\n",
      "[1965]\ttraining's binary_logloss: 4.30582e-05\n",
      "[1966]\ttraining's binary_logloss: 4.29072e-05\n",
      "[1967]\ttraining's binary_logloss: 4.2754e-05\n",
      "[1968]\ttraining's binary_logloss: 4.25985e-05\n",
      "[1969]\ttraining's binary_logloss: 4.24459e-05\n",
      "[1970]\ttraining's binary_logloss: 4.23014e-05\n",
      "[1971]\ttraining's binary_logloss: 4.21479e-05\n",
      "[1972]\ttraining's binary_logloss: 4.19923e-05\n",
      "[1973]\ttraining's binary_logloss: 4.18511e-05\n",
      "[1974]\ttraining's binary_logloss: 4.17048e-05\n",
      "[1975]\ttraining's binary_logloss: 4.15553e-05\n",
      "[1976]\ttraining's binary_logloss: 4.14085e-05\n",
      "[1977]\ttraining's binary_logloss: 4.12333e-05\n",
      "[1978]\ttraining's binary_logloss: 4.10685e-05\n",
      "[1979]\ttraining's binary_logloss: 4.09331e-05\n",
      "[1980]\ttraining's binary_logloss: 4.07962e-05\n",
      "[1981]\ttraining's binary_logloss: 4.0653e-05\n",
      "[1982]\ttraining's binary_logloss: 4.04946e-05\n",
      "[1983]\ttraining's binary_logloss: 4.03281e-05\n",
      "[1984]\ttraining's binary_logloss: 4.01741e-05\n",
      "[1985]\ttraining's binary_logloss: 4.00385e-05\n",
      "[1986]\ttraining's binary_logloss: 3.98684e-05\n",
      "[1987]\ttraining's binary_logloss: 3.97362e-05\n",
      "[1988]\ttraining's binary_logloss: 3.95975e-05\n",
      "[1989]\ttraining's binary_logloss: 3.94595e-05\n",
      "[1990]\ttraining's binary_logloss: 3.9332e-05\n",
      "[1991]\ttraining's binary_logloss: 3.9187e-05\n",
      "[1992]\ttraining's binary_logloss: 3.90063e-05\n",
      "[1993]\ttraining's binary_logloss: 3.88731e-05\n",
      "[1994]\ttraining's binary_logloss: 3.87438e-05\n",
      "[1995]\ttraining's binary_logloss: 3.85628e-05\n",
      "[1996]\ttraining's binary_logloss: 3.84209e-05\n",
      "[1997]\ttraining's binary_logloss: 3.82872e-05\n",
      "[1998]\ttraining's binary_logloss: 3.81538e-05\n",
      "[1999]\ttraining's binary_logloss: 3.80293e-05\n",
      "[2000]\ttraining's binary_logloss: 3.79183e-05\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = lgb.train(\n",
    "    lgbm_params,\n",
    "    lgtrain,\n",
    "    valid_sets=lgtrain,\n",
    "    num_boost_round=2000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lgb = lgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lgb = np.array([0 if i < 0.5 else 1 for i in predict_lgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7909786641929499"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(predict_lgb, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search, tune parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameters to search\n",
    "gridParams = {\n",
    "    'learning_rate': [0.0125, 0.0175, 0.0225],\n",
    "    'n_estimators': [40],\n",
    "    'num_leaves': [170, 220, 270, 320],\n",
    "    #'max_depth': [15, 25, 35],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'feature_fraction': [0.4, 0.5, 0.6]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classifier to use. Note that parameters have to be input manually\n",
    "# not as a dict!\n",
    "mdl = lgb.LGBMClassifier(boosting_type= 'gbdt', objective = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(mdl, gridParams, verbose=0, cv=5, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "        n_jobs=-1, num_leaves=31, objective='binary', random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=0),\n",
       "       fit_params=None, iid=True, n_jobs=2,\n",
       "       param_grid={'learning_rate': [0.0125, 0.0175, 0.0225], 'n_estimators': [40], 'num_leaves': [170, 220, 270, 320], 'boosting_type': ['gbdt'], 'objective': ['binary'], 'feature_fraction': [0.4, 0.5, 0.6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'gbdt', 'feature_fraction': 0.5, 'learning_rate': 0.0225, 'n_estimators': 40, 'num_leaves': 320, 'objective': 'binary'}\n",
      "0.8844150432336702\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters found\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using parameters already set above, replace in the best from the grid search\n",
    "\n",
    "# params['max_bin'] = grid.best_params_['max_bin']\n",
    "lgbm_params['feature_fraction'] = grid.best_params_['feature_fraction']\n",
    "lgbm_params['learning_rate'] = grid.best_params_['learning_rate']\n",
    "lgbm_params['num_leaves'] = grid.best_params_['num_leaves']\n",
    "#lgbm_params['max_depth'] = grid.best_params_['max_depth']\n",
    "#lgbm_params['reg_alpha'] = grid.best_params_['reg_alpha']\n",
    "#lgbm_params['reg_lambda'] = grid.best_params_['reg_lambda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with params: \n",
      "{'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'binary_logloss', 'num_leaves': 320, 'feature_fraction': 0.5, 'bagging_fraction': 0.75, 'bagging_freq': 2, 'learning_rate': 0.0225, 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "print('Fitting with params: ')\n",
    "print(lgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgtrain = lgb.Dataset(X_train, y_train)\n",
    "lgtest = lgb.Dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.680222\n",
      "[2]\ttraining's binary_logloss: 0.665389\n",
      "[3]\ttraining's binary_logloss: 0.653191\n",
      "[4]\ttraining's binary_logloss: 0.639386\n",
      "[5]\ttraining's binary_logloss: 0.62627\n",
      "[6]\ttraining's binary_logloss: 0.615549\n",
      "[7]\ttraining's binary_logloss: 0.604853\n",
      "[8]\ttraining's binary_logloss: 0.59271\n",
      "[9]\ttraining's binary_logloss: 0.583045\n",
      "[10]\ttraining's binary_logloss: 0.571847\n",
      "[11]\ttraining's binary_logloss: 0.562659\n",
      "[12]\ttraining's binary_logloss: 0.552023\n",
      "[13]\ttraining's binary_logloss: 0.543252\n",
      "[14]\ttraining's binary_logloss: 0.5332\n",
      "[15]\ttraining's binary_logloss: 0.525082\n",
      "[16]\ttraining's binary_logloss: 0.516985\n",
      "[17]\ttraining's binary_logloss: 0.507895\n",
      "[18]\ttraining's binary_logloss: 0.500583\n",
      "[19]\ttraining's binary_logloss: 0.492051\n",
      "[20]\ttraining's binary_logloss: 0.485031\n",
      "[21]\ttraining's binary_logloss: 0.476843\n",
      "[22]\ttraining's binary_logloss: 0.470439\n",
      "[23]\ttraining's binary_logloss: 0.463842\n",
      "[24]\ttraining's binary_logloss: 0.457568\n",
      "[25]\ttraining's binary_logloss: 0.450124\n",
      "[26]\ttraining's binary_logloss: 0.442863\n",
      "[27]\ttraining's binary_logloss: 0.436866\n",
      "[28]\ttraining's binary_logloss: 0.430031\n",
      "[29]\ttraining's binary_logloss: 0.423316\n",
      "[30]\ttraining's binary_logloss: 0.417821\n",
      "[31]\ttraining's binary_logloss: 0.412454\n",
      "[32]\ttraining's binary_logloss: 0.407226\n",
      "[33]\ttraining's binary_logloss: 0.402097\n",
      "[34]\ttraining's binary_logloss: 0.396021\n",
      "[35]\ttraining's binary_logloss: 0.390113\n",
      "[36]\ttraining's binary_logloss: 0.384373\n",
      "[37]\ttraining's binary_logloss: 0.378835\n",
      "[38]\ttraining's binary_logloss: 0.373457\n",
      "[39]\ttraining's binary_logloss: 0.369036\n",
      "[40]\ttraining's binary_logloss: 0.363843\n",
      "[41]\ttraining's binary_logloss: 0.358683\n",
      "[42]\ttraining's binary_logloss: 0.354539\n",
      "[43]\ttraining's binary_logloss: 0.350432\n",
      "[44]\ttraining's binary_logloss: 0.346455\n",
      "[45]\ttraining's binary_logloss: 0.342591\n",
      "[46]\ttraining's binary_logloss: 0.338\n",
      "[47]\ttraining's binary_logloss: 0.333452\n",
      "[48]\ttraining's binary_logloss: 0.329652\n",
      "[49]\ttraining's binary_logloss: 0.325324\n",
      "[50]\ttraining's binary_logloss: 0.321838\n",
      "[51]\ttraining's binary_logloss: 0.317738\n",
      "[52]\ttraining's binary_logloss: 0.313594\n",
      "[53]\ttraining's binary_logloss: 0.310179\n",
      "[54]\ttraining's binary_logloss: 0.306219\n",
      "[55]\ttraining's binary_logloss: 0.302281\n",
      "[56]\ttraining's binary_logloss: 0.299129\n",
      "[57]\ttraining's binary_logloss: 0.295446\n",
      "[58]\ttraining's binary_logloss: 0.292324\n",
      "[59]\ttraining's binary_logloss: 0.289192\n",
      "[60]\ttraining's binary_logloss: 0.286263\n",
      "[61]\ttraining's binary_logloss: 0.282729\n",
      "[62]\ttraining's binary_logloss: 0.279313\n",
      "[63]\ttraining's binary_logloss: 0.276339\n",
      "[64]\ttraining's binary_logloss: 0.273098\n",
      "[65]\ttraining's binary_logloss: 0.269809\n",
      "[66]\ttraining's binary_logloss: 0.26716\n",
      "[67]\ttraining's binary_logloss: 0.264516\n",
      "[68]\ttraining's binary_logloss: 0.261425\n",
      "[69]\ttraining's binary_logloss: 0.258397\n",
      "[70]\ttraining's binary_logloss: 0.255847\n",
      "[71]\ttraining's binary_logloss: 0.252974\n",
      "[72]\ttraining's binary_logloss: 0.250494\n",
      "[73]\ttraining's binary_logloss: 0.247654\n",
      "[74]\ttraining's binary_logloss: 0.244912\n",
      "[75]\ttraining's binary_logloss: 0.242179\n",
      "[76]\ttraining's binary_logloss: 0.239927\n",
      "[77]\ttraining's binary_logloss: 0.237654\n",
      "[78]\ttraining's binary_logloss: 0.235416\n",
      "[79]\ttraining's binary_logloss: 0.232839\n",
      "[80]\ttraining's binary_logloss: 0.230254\n",
      "[81]\ttraining's binary_logloss: 0.228116\n",
      "[82]\ttraining's binary_logloss: 0.22595\n",
      "[83]\ttraining's binary_logloss: 0.223745\n",
      "[84]\ttraining's binary_logloss: 0.221405\n",
      "[85]\ttraining's binary_logloss: 0.219366\n",
      "[86]\ttraining's binary_logloss: 0.216977\n",
      "[87]\ttraining's binary_logloss: 0.215062\n",
      "[88]\ttraining's binary_logloss: 0.213134\n",
      "[89]\ttraining's binary_logloss: 0.210799\n",
      "[90]\ttraining's binary_logloss: 0.20891\n",
      "[91]\ttraining's binary_logloss: 0.206936\n",
      "[92]\ttraining's binary_logloss: 0.205073\n",
      "[93]\ttraining's binary_logloss: 0.203222\n",
      "[94]\ttraining's binary_logloss: 0.201399\n",
      "[95]\ttraining's binary_logloss: 0.199616\n",
      "[96]\ttraining's binary_logloss: 0.197558\n",
      "[97]\ttraining's binary_logloss: 0.195517\n",
      "[98]\ttraining's binary_logloss: 0.193481\n",
      "[99]\ttraining's binary_logloss: 0.19181\n",
      "[100]\ttraining's binary_logloss: 0.18985\n",
      "[101]\ttraining's binary_logloss: 0.188184\n",
      "[102]\ttraining's binary_logloss: 0.186243\n",
      "[103]\ttraining's binary_logloss: 0.1846\n",
      "[104]\ttraining's binary_logloss: 0.183001\n",
      "[105]\ttraining's binary_logloss: 0.181409\n",
      "[106]\ttraining's binary_logloss: 0.17958\n",
      "[107]\ttraining's binary_logloss: 0.177852\n",
      "[108]\ttraining's binary_logloss: 0.176298\n",
      "[109]\ttraining's binary_logloss: 0.174731\n",
      "[110]\ttraining's binary_logloss: 0.173066\n",
      "[111]\ttraining's binary_logloss: 0.17138\n",
      "[112]\ttraining's binary_logloss: 0.169681\n",
      "[113]\ttraining's binary_logloss: 0.168056\n",
      "[114]\ttraining's binary_logloss: 0.166574\n",
      "[115]\ttraining's binary_logloss: 0.16505\n",
      "[116]\ttraining's binary_logloss: 0.163439\n",
      "[117]\ttraining's binary_logloss: 0.161835\n",
      "[118]\ttraining's binary_logloss: 0.16045\n",
      "[119]\ttraining's binary_logloss: 0.158915\n",
      "[120]\ttraining's binary_logloss: 0.157535\n",
      "[121]\ttraining's binary_logloss: 0.15603\n",
      "[122]\ttraining's binary_logloss: 0.154673\n",
      "[123]\ttraining's binary_logloss: 0.153211\n",
      "[124]\ttraining's binary_logloss: 0.151833\n",
      "[125]\ttraining's binary_logloss: 0.150388\n",
      "[126]\ttraining's binary_logloss: 0.149049\n",
      "[127]\ttraining's binary_logloss: 0.147708\n",
      "[128]\ttraining's binary_logloss: 0.146473\n",
      "[129]\ttraining's binary_logloss: 0.145248\n",
      "[130]\ttraining's binary_logloss: 0.143848\n",
      "[131]\ttraining's binary_logloss: 0.142619\n",
      "[132]\ttraining's binary_logloss: 0.141392\n",
      "[133]\ttraining's binary_logloss: 0.140198\n",
      "[134]\ttraining's binary_logloss: 0.139015\n",
      "[135]\ttraining's binary_logloss: 0.137765\n",
      "[136]\ttraining's binary_logloss: 0.136486\n",
      "[137]\ttraining's binary_logloss: 0.135285\n",
      "[138]\ttraining's binary_logloss: 0.134101\n",
      "[139]\ttraining's binary_logloss: 0.132783\n",
      "[140]\ttraining's binary_logloss: 0.131557\n",
      "[141]\ttraining's binary_logloss: 0.130466\n",
      "[142]\ttraining's binary_logloss: 0.129237\n",
      "[143]\ttraining's binary_logloss: 0.128172\n",
      "[144]\ttraining's binary_logloss: 0.127111\n",
      "[145]\ttraining's binary_logloss: 0.125993\n",
      "[146]\ttraining's binary_logloss: 0.124816\n",
      "[147]\ttraining's binary_logloss: 0.123631\n",
      "[148]\ttraining's binary_logloss: 0.122634\n",
      "[149]\ttraining's binary_logloss: 0.121626\n",
      "[150]\ttraining's binary_logloss: 0.120608\n",
      "[151]\ttraining's binary_logloss: 0.119482\n",
      "[152]\ttraining's binary_logloss: 0.118381\n",
      "[153]\ttraining's binary_logloss: 0.117389\n",
      "[154]\ttraining's binary_logloss: 0.116389\n",
      "[155]\ttraining's binary_logloss: 0.11542\n",
      "[156]\ttraining's binary_logloss: 0.114442\n",
      "[157]\ttraining's binary_logloss: 0.11352\n",
      "[158]\ttraining's binary_logloss: 0.112498\n",
      "[159]\ttraining's binary_logloss: 0.111524\n",
      "[160]\ttraining's binary_logloss: 0.110578\n",
      "[161]\ttraining's binary_logloss: 0.10956\n",
      "[162]\ttraining's binary_logloss: 0.108621\n",
      "[163]\ttraining's binary_logloss: 0.107724\n",
      "[164]\ttraining's binary_logloss: 0.106785\n",
      "[165]\ttraining's binary_logloss: 0.105888\n",
      "[166]\ttraining's binary_logloss: 0.10498\n",
      "[167]\ttraining's binary_logloss: 0.104073\n",
      "[168]\ttraining's binary_logloss: 0.10323\n",
      "[169]\ttraining's binary_logloss: 0.102326\n",
      "[170]\ttraining's binary_logloss: 0.101388\n",
      "[171]\ttraining's binary_logloss: 0.100495\n",
      "[172]\ttraining's binary_logloss: 0.0996294\n",
      "[173]\ttraining's binary_logloss: 0.0987357\n",
      "[174]\ttraining's binary_logloss: 0.0978636\n",
      "[175]\ttraining's binary_logloss: 0.0970149\n",
      "[176]\ttraining's binary_logloss: 0.0962237\n",
      "[177]\ttraining's binary_logloss: 0.0953594\n",
      "[178]\ttraining's binary_logloss: 0.0945412\n",
      "[179]\ttraining's binary_logloss: 0.0937402\n",
      "[180]\ttraining's binary_logloss: 0.0928828\n",
      "[181]\ttraining's binary_logloss: 0.092026\n",
      "[182]\ttraining's binary_logloss: 0.0912394\n",
      "[183]\ttraining's binary_logloss: 0.0904406\n",
      "[184]\ttraining's binary_logloss: 0.0896833\n",
      "[185]\ttraining's binary_logloss: 0.0889474\n",
      "[186]\ttraining's binary_logloss: 0.0881854\n",
      "[187]\ttraining's binary_logloss: 0.087443\n",
      "[188]\ttraining's binary_logloss: 0.0867075\n",
      "[189]\ttraining's binary_logloss: 0.0859807\n",
      "[190]\ttraining's binary_logloss: 0.0852889\n",
      "[191]\ttraining's binary_logloss: 0.0845113\n",
      "[192]\ttraining's binary_logloss: 0.0837996\n",
      "[193]\ttraining's binary_logloss: 0.0830889\n",
      "[194]\ttraining's binary_logloss: 0.0823895\n",
      "[195]\ttraining's binary_logloss: 0.0817079\n",
      "[196]\ttraining's binary_logloss: 0.0810216\n",
      "[197]\ttraining's binary_logloss: 0.0803372\n",
      "[198]\ttraining's binary_logloss: 0.0796561\n",
      "[199]\ttraining's binary_logloss: 0.0789705\n",
      "[200]\ttraining's binary_logloss: 0.0782787\n",
      "[201]\ttraining's binary_logloss: 0.0776109\n",
      "[202]\ttraining's binary_logloss: 0.0769876\n",
      "[203]\ttraining's binary_logloss: 0.0763521\n",
      "[204]\ttraining's binary_logloss: 0.0757012\n",
      "[205]\ttraining's binary_logloss: 0.0750365\n",
      "[206]\ttraining's binary_logloss: 0.0744222\n",
      "[207]\ttraining's binary_logloss: 0.0737757\n",
      "[208]\ttraining's binary_logloss: 0.0731274\n",
      "[209]\ttraining's binary_logloss: 0.0724873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[210]\ttraining's binary_logloss: 0.0718775\n",
      "[211]\ttraining's binary_logloss: 0.0712573\n",
      "[212]\ttraining's binary_logloss: 0.0706457\n",
      "[213]\ttraining's binary_logloss: 0.0700746\n",
      "[214]\ttraining's binary_logloss: 0.0694923\n",
      "[215]\ttraining's binary_logloss: 0.0689093\n",
      "[216]\ttraining's binary_logloss: 0.0683074\n",
      "[217]\ttraining's binary_logloss: 0.0677445\n",
      "[218]\ttraining's binary_logloss: 0.0671402\n",
      "[219]\ttraining's binary_logloss: 0.0665853\n",
      "[220]\ttraining's binary_logloss: 0.0660362\n",
      "[221]\ttraining's binary_logloss: 0.0654867\n",
      "[222]\ttraining's binary_logloss: 0.0649203\n",
      "[223]\ttraining's binary_logloss: 0.0643821\n",
      "[224]\ttraining's binary_logloss: 0.0638353\n",
      "[225]\ttraining's binary_logloss: 0.0633037\n",
      "[226]\ttraining's binary_logloss: 0.0627686\n",
      "[227]\ttraining's binary_logloss: 0.062247\n",
      "[228]\ttraining's binary_logloss: 0.0616928\n",
      "[229]\ttraining's binary_logloss: 0.0611645\n",
      "[230]\ttraining's binary_logloss: 0.060674\n",
      "[231]\ttraining's binary_logloss: 0.060146\n",
      "[232]\ttraining's binary_logloss: 0.0596419\n",
      "[233]\ttraining's binary_logloss: 0.0591329\n",
      "[234]\ttraining's binary_logloss: 0.0586578\n",
      "[235]\ttraining's binary_logloss: 0.0581926\n",
      "[236]\ttraining's binary_logloss: 0.0576935\n",
      "[237]\ttraining's binary_logloss: 0.0571812\n",
      "[238]\ttraining's binary_logloss: 0.0567206\n",
      "[239]\ttraining's binary_logloss: 0.0562546\n",
      "[240]\ttraining's binary_logloss: 0.0558056\n",
      "[241]\ttraining's binary_logloss: 0.0553591\n",
      "[242]\ttraining's binary_logloss: 0.0548927\n",
      "[243]\ttraining's binary_logloss: 0.0544449\n",
      "[244]\ttraining's binary_logloss: 0.0539824\n",
      "[245]\ttraining's binary_logloss: 0.0535405\n",
      "[246]\ttraining's binary_logloss: 0.053092\n",
      "[247]\ttraining's binary_logloss: 0.0526487\n",
      "[248]\ttraining's binary_logloss: 0.052204\n",
      "[249]\ttraining's binary_logloss: 0.0517845\n",
      "[250]\ttraining's binary_logloss: 0.0513661\n",
      "[251]\ttraining's binary_logloss: 0.0509722\n",
      "[252]\ttraining's binary_logloss: 0.0505274\n",
      "[253]\ttraining's binary_logloss: 0.0500858\n",
      "[254]\ttraining's binary_logloss: 0.0496857\n",
      "[255]\ttraining's binary_logloss: 0.0492794\n",
      "[256]\ttraining's binary_logloss: 0.0488712\n",
      "[257]\ttraining's binary_logloss: 0.0484738\n",
      "[258]\ttraining's binary_logloss: 0.0480591\n",
      "[259]\ttraining's binary_logloss: 0.0476827\n",
      "[260]\ttraining's binary_logloss: 0.0472827\n",
      "[261]\ttraining's binary_logloss: 0.0469102\n",
      "[262]\ttraining's binary_logloss: 0.0465381\n",
      "[263]\ttraining's binary_logloss: 0.0461619\n",
      "[264]\ttraining's binary_logloss: 0.0457931\n",
      "[265]\ttraining's binary_logloss: 0.0454302\n",
      "[266]\ttraining's binary_logloss: 0.0450816\n",
      "[267]\ttraining's binary_logloss: 0.0447059\n",
      "[268]\ttraining's binary_logloss: 0.0443118\n",
      "[269]\ttraining's binary_logloss: 0.0439762\n",
      "[270]\ttraining's binary_logloss: 0.0436226\n",
      "[271]\ttraining's binary_logloss: 0.0432669\n",
      "[272]\ttraining's binary_logloss: 0.0429001\n",
      "[273]\ttraining's binary_logloss: 0.0425413\n",
      "[274]\ttraining's binary_logloss: 0.0421744\n",
      "[275]\ttraining's binary_logloss: 0.0418465\n",
      "[276]\ttraining's binary_logloss: 0.0415034\n",
      "[277]\ttraining's binary_logloss: 0.0411432\n",
      "[278]\ttraining's binary_logloss: 0.0408113\n",
      "[279]\ttraining's binary_logloss: 0.0405188\n",
      "[280]\ttraining's binary_logloss: 0.0402111\n",
      "[281]\ttraining's binary_logloss: 0.0399052\n",
      "[282]\ttraining's binary_logloss: 0.0395824\n",
      "[283]\ttraining's binary_logloss: 0.0392569\n",
      "[284]\ttraining's binary_logloss: 0.0389149\n",
      "[285]\ttraining's binary_logloss: 0.038617\n",
      "[286]\ttraining's binary_logloss: 0.0383037\n",
      "[287]\ttraining's binary_logloss: 0.0379702\n",
      "[288]\ttraining's binary_logloss: 0.037656\n",
      "[289]\ttraining's binary_logloss: 0.0373662\n",
      "[290]\ttraining's binary_logloss: 0.0370525\n",
      "[291]\ttraining's binary_logloss: 0.0367385\n",
      "[292]\ttraining's binary_logloss: 0.0364464\n",
      "[293]\ttraining's binary_logloss: 0.0361371\n",
      "[294]\ttraining's binary_logloss: 0.0358559\n",
      "[295]\ttraining's binary_logloss: 0.0355284\n",
      "[296]\ttraining's binary_logloss: 0.0352235\n",
      "[297]\ttraining's binary_logloss: 0.034946\n",
      "[298]\ttraining's binary_logloss: 0.0346744\n",
      "[299]\ttraining's binary_logloss: 0.0344141\n",
      "[300]\ttraining's binary_logloss: 0.0341223\n",
      "[301]\ttraining's binary_logloss: 0.0338338\n",
      "[302]\ttraining's binary_logloss: 0.0335595\n",
      "[303]\ttraining's binary_logloss: 0.033282\n",
      "[304]\ttraining's binary_logloss: 0.0330139\n",
      "[305]\ttraining's binary_logloss: 0.0327439\n",
      "[306]\ttraining's binary_logloss: 0.0324765\n",
      "[307]\ttraining's binary_logloss: 0.0321917\n",
      "[308]\ttraining's binary_logloss: 0.0319131\n",
      "[309]\ttraining's binary_logloss: 0.0316567\n",
      "[310]\ttraining's binary_logloss: 0.0314051\n",
      "[311]\ttraining's binary_logloss: 0.031133\n",
      "[312]\ttraining's binary_logloss: 0.030862\n",
      "[313]\ttraining's binary_logloss: 0.030608\n",
      "[314]\ttraining's binary_logloss: 0.030382\n",
      "[315]\ttraining's binary_logloss: 0.0301456\n",
      "[316]\ttraining's binary_logloss: 0.0298864\n",
      "[317]\ttraining's binary_logloss: 0.0296352\n",
      "[318]\ttraining's binary_logloss: 0.0293912\n",
      "[319]\ttraining's binary_logloss: 0.0291764\n",
      "[320]\ttraining's binary_logloss: 0.0289415\n",
      "[321]\ttraining's binary_logloss: 0.0287321\n",
      "[322]\ttraining's binary_logloss: 0.0285198\n",
      "[323]\ttraining's binary_logloss: 0.0282825\n",
      "[324]\ttraining's binary_logloss: 0.0280454\n",
      "[325]\ttraining's binary_logloss: 0.0278348\n",
      "[326]\ttraining's binary_logloss: 0.0276282\n",
      "[327]\ttraining's binary_logloss: 0.0274064\n",
      "[328]\ttraining's binary_logloss: 0.027178\n",
      "[329]\ttraining's binary_logloss: 0.0269663\n",
      "[330]\ttraining's binary_logloss: 0.0267317\n",
      "[331]\ttraining's binary_logloss: 0.0265166\n",
      "[332]\ttraining's binary_logloss: 0.0263091\n",
      "[333]\ttraining's binary_logloss: 0.0260861\n",
      "[334]\ttraining's binary_logloss: 0.0258715\n",
      "[335]\ttraining's binary_logloss: 0.025651\n",
      "[336]\ttraining's binary_logloss: 0.025426\n",
      "[337]\ttraining's binary_logloss: 0.0252183\n",
      "[338]\ttraining's binary_logloss: 0.0250017\n",
      "[339]\ttraining's binary_logloss: 0.0247903\n",
      "[340]\ttraining's binary_logloss: 0.0245898\n",
      "[341]\ttraining's binary_logloss: 0.0243914\n",
      "[342]\ttraining's binary_logloss: 0.0242077\n",
      "[343]\ttraining's binary_logloss: 0.0240187\n",
      "[344]\ttraining's binary_logloss: 0.0238253\n",
      "[345]\ttraining's binary_logloss: 0.0236364\n",
      "[346]\ttraining's binary_logloss: 0.0234341\n",
      "[347]\ttraining's binary_logloss: 0.0232563\n",
      "[348]\ttraining's binary_logloss: 0.0230729\n",
      "[349]\ttraining's binary_logloss: 0.0228832\n",
      "[350]\ttraining's binary_logloss: 0.0226982\n",
      "[351]\ttraining's binary_logloss: 0.0225075\n",
      "[352]\ttraining's binary_logloss: 0.022324\n",
      "[353]\ttraining's binary_logloss: 0.0221345\n",
      "[354]\ttraining's binary_logloss: 0.0219515\n",
      "[355]\ttraining's binary_logloss: 0.0217733\n",
      "[356]\ttraining's binary_logloss: 0.0216092\n",
      "[357]\ttraining's binary_logloss: 0.0214223\n",
      "[358]\ttraining's binary_logloss: 0.0212504\n",
      "[359]\ttraining's binary_logloss: 0.0210655\n",
      "[360]\ttraining's binary_logloss: 0.0209005\n",
      "[361]\ttraining's binary_logloss: 0.0207346\n",
      "[362]\ttraining's binary_logloss: 0.020561\n",
      "[363]\ttraining's binary_logloss: 0.0203921\n",
      "[364]\ttraining's binary_logloss: 0.0202248\n",
      "[365]\ttraining's binary_logloss: 0.0200559\n",
      "[366]\ttraining's binary_logloss: 0.0199136\n",
      "[367]\ttraining's binary_logloss: 0.0197524\n",
      "[368]\ttraining's binary_logloss: 0.0196051\n",
      "[369]\ttraining's binary_logloss: 0.0194403\n",
      "[370]\ttraining's binary_logloss: 0.0192774\n",
      "[371]\ttraining's binary_logloss: 0.0191292\n",
      "[372]\ttraining's binary_logloss: 0.0189735\n",
      "[373]\ttraining's binary_logloss: 0.0188269\n",
      "[374]\ttraining's binary_logloss: 0.0186661\n",
      "[375]\ttraining's binary_logloss: 0.0185115\n",
      "[376]\ttraining's binary_logloss: 0.018353\n",
      "[377]\ttraining's binary_logloss: 0.0182142\n",
      "[378]\ttraining's binary_logloss: 0.0180639\n",
      "[379]\ttraining's binary_logloss: 0.0179162\n",
      "[380]\ttraining's binary_logloss: 0.0177819\n",
      "[381]\ttraining's binary_logloss: 0.0176316\n",
      "[382]\ttraining's binary_logloss: 0.0174905\n",
      "[383]\ttraining's binary_logloss: 0.0173412\n",
      "[384]\ttraining's binary_logloss: 0.017194\n",
      "[385]\ttraining's binary_logloss: 0.0170561\n",
      "[386]\ttraining's binary_logloss: 0.0169135\n",
      "[387]\ttraining's binary_logloss: 0.0167759\n",
      "[388]\ttraining's binary_logloss: 0.0166436\n",
      "[389]\ttraining's binary_logloss: 0.0165042\n",
      "[390]\ttraining's binary_logloss: 0.0163716\n",
      "[391]\ttraining's binary_logloss: 0.016234\n",
      "[392]\ttraining's binary_logloss: 0.0160974\n",
      "[393]\ttraining's binary_logloss: 0.015975\n",
      "[394]\ttraining's binary_logloss: 0.0158432\n",
      "[395]\ttraining's binary_logloss: 0.0157229\n",
      "[396]\ttraining's binary_logloss: 0.0155963\n",
      "[397]\ttraining's binary_logloss: 0.0154822\n",
      "[398]\ttraining's binary_logloss: 0.0153512\n",
      "[399]\ttraining's binary_logloss: 0.0152372\n",
      "[400]\ttraining's binary_logloss: 0.0151112\n",
      "[401]\ttraining's binary_logloss: 0.0149924\n",
      "[402]\ttraining's binary_logloss: 0.0148698\n",
      "[403]\ttraining's binary_logloss: 0.014747\n",
      "[404]\ttraining's binary_logloss: 0.0146206\n",
      "[405]\ttraining's binary_logloss: 0.0144991\n",
      "[406]\ttraining's binary_logloss: 0.0143859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[407]\ttraining's binary_logloss: 0.0142639\n",
      "[408]\ttraining's binary_logloss: 0.0141573\n",
      "[409]\ttraining's binary_logloss: 0.0140331\n",
      "[410]\ttraining's binary_logloss: 0.0139167\n",
      "[411]\ttraining's binary_logloss: 0.013798\n",
      "[412]\ttraining's binary_logloss: 0.013688\n",
      "[413]\ttraining's binary_logloss: 0.0135787\n",
      "[414]\ttraining's binary_logloss: 0.0134703\n",
      "[415]\ttraining's binary_logloss: 0.0133609\n",
      "[416]\ttraining's binary_logloss: 0.0132512\n",
      "[417]\ttraining's binary_logloss: 0.013148\n",
      "[418]\ttraining's binary_logloss: 0.0130366\n",
      "[419]\ttraining's binary_logloss: 0.0129306\n",
      "[420]\ttraining's binary_logloss: 0.0128261\n",
      "[421]\ttraining's binary_logloss: 0.0127246\n",
      "[422]\ttraining's binary_logloss: 0.0126299\n",
      "[423]\ttraining's binary_logloss: 0.0125329\n",
      "[424]\ttraining's binary_logloss: 0.0124376\n",
      "[425]\ttraining's binary_logloss: 0.0123354\n",
      "[426]\ttraining's binary_logloss: 0.0122491\n",
      "[427]\ttraining's binary_logloss: 0.0121527\n",
      "[428]\ttraining's binary_logloss: 0.0120527\n",
      "[429]\ttraining's binary_logloss: 0.0119477\n",
      "[430]\ttraining's binary_logloss: 0.0118515\n",
      "[431]\ttraining's binary_logloss: 0.0117582\n",
      "[432]\ttraining's binary_logloss: 0.0116659\n",
      "[433]\ttraining's binary_logloss: 0.0115649\n",
      "[434]\ttraining's binary_logloss: 0.0114687\n",
      "[435]\ttraining's binary_logloss: 0.0113724\n",
      "[436]\ttraining's binary_logloss: 0.0112798\n",
      "[437]\ttraining's binary_logloss: 0.0111875\n",
      "[438]\ttraining's binary_logloss: 0.0111013\n",
      "[439]\ttraining's binary_logloss: 0.01101\n",
      "[440]\ttraining's binary_logloss: 0.0109208\n",
      "[441]\ttraining's binary_logloss: 0.0108396\n",
      "[442]\ttraining's binary_logloss: 0.0107578\n",
      "[443]\ttraining's binary_logloss: 0.0106789\n",
      "[444]\ttraining's binary_logloss: 0.0105905\n",
      "[445]\ttraining's binary_logloss: 0.010511\n",
      "[446]\ttraining's binary_logloss: 0.0104321\n",
      "[447]\ttraining's binary_logloss: 0.0103527\n",
      "[448]\ttraining's binary_logloss: 0.0102767\n",
      "[449]\ttraining's binary_logloss: 0.0101921\n",
      "[450]\ttraining's binary_logloss: 0.010107\n",
      "[451]\ttraining's binary_logloss: 0.0100257\n",
      "[452]\ttraining's binary_logloss: 0.00994741\n",
      "[453]\ttraining's binary_logloss: 0.00986475\n",
      "[454]\ttraining's binary_logloss: 0.00978731\n",
      "[455]\ttraining's binary_logloss: 0.00970769\n",
      "[456]\ttraining's binary_logloss: 0.00962948\n",
      "[457]\ttraining's binary_logloss: 0.00955181\n",
      "[458]\ttraining's binary_logloss: 0.00947826\n",
      "[459]\ttraining's binary_logloss: 0.00940775\n",
      "[460]\ttraining's binary_logloss: 0.00933288\n",
      "[461]\ttraining's binary_logloss: 0.00926603\n",
      "[462]\ttraining's binary_logloss: 0.00919398\n",
      "[463]\ttraining's binary_logloss: 0.00912698\n",
      "[464]\ttraining's binary_logloss: 0.00905713\n",
      "[465]\ttraining's binary_logloss: 0.00899197\n",
      "[466]\ttraining's binary_logloss: 0.00891997\n",
      "[467]\ttraining's binary_logloss: 0.00884594\n",
      "[468]\ttraining's binary_logloss: 0.00877518\n",
      "[469]\ttraining's binary_logloss: 0.00870208\n",
      "[470]\ttraining's binary_logloss: 0.00862725\n",
      "[471]\ttraining's binary_logloss: 0.00856134\n",
      "[472]\ttraining's binary_logloss: 0.00848943\n",
      "[473]\ttraining's binary_logloss: 0.0084242\n",
      "[474]\ttraining's binary_logloss: 0.00835432\n",
      "[475]\ttraining's binary_logloss: 0.00828648\n",
      "[476]\ttraining's binary_logloss: 0.00821892\n",
      "[477]\ttraining's binary_logloss: 0.00815447\n",
      "[478]\ttraining's binary_logloss: 0.00808909\n",
      "[479]\ttraining's binary_logloss: 0.00802759\n",
      "[480]\ttraining's binary_logloss: 0.00797184\n",
      "[481]\ttraining's binary_logloss: 0.00790573\n",
      "[482]\ttraining's binary_logloss: 0.00783988\n",
      "[483]\ttraining's binary_logloss: 0.00778448\n",
      "[484]\ttraining's binary_logloss: 0.00772241\n",
      "[485]\ttraining's binary_logloss: 0.00765803\n",
      "[486]\ttraining's binary_logloss: 0.00759661\n",
      "[487]\ttraining's binary_logloss: 0.00753877\n",
      "[488]\ttraining's binary_logloss: 0.0074768\n",
      "[489]\ttraining's binary_logloss: 0.00741559\n",
      "[490]\ttraining's binary_logloss: 0.00735604\n",
      "[491]\ttraining's binary_logloss: 0.00729501\n",
      "[492]\ttraining's binary_logloss: 0.00723731\n",
      "[493]\ttraining's binary_logloss: 0.00718093\n",
      "[494]\ttraining's binary_logloss: 0.00712794\n",
      "[495]\ttraining's binary_logloss: 0.00707347\n",
      "[496]\ttraining's binary_logloss: 0.00701735\n",
      "[497]\ttraining's binary_logloss: 0.0069622\n",
      "[498]\ttraining's binary_logloss: 0.00690865\n",
      "[499]\ttraining's binary_logloss: 0.00685084\n",
      "[500]\ttraining's binary_logloss: 0.00679287\n",
      "[501]\ttraining's binary_logloss: 0.00674308\n",
      "[502]\ttraining's binary_logloss: 0.00668582\n",
      "[503]\ttraining's binary_logloss: 0.00663332\n",
      "[504]\ttraining's binary_logloss: 0.00658206\n",
      "[505]\ttraining's binary_logloss: 0.00653104\n",
      "[506]\ttraining's binary_logloss: 0.00648054\n",
      "[507]\ttraining's binary_logloss: 0.00642796\n",
      "[508]\ttraining's binary_logloss: 0.00637618\n",
      "[509]\ttraining's binary_logloss: 0.00632459\n",
      "[510]\ttraining's binary_logloss: 0.00627287\n",
      "[511]\ttraining's binary_logloss: 0.00622077\n",
      "[512]\ttraining's binary_logloss: 0.00617174\n",
      "[513]\ttraining's binary_logloss: 0.006127\n",
      "[514]\ttraining's binary_logloss: 0.00608111\n",
      "[515]\ttraining's binary_logloss: 0.00603267\n",
      "[516]\ttraining's binary_logloss: 0.00598272\n",
      "[517]\ttraining's binary_logloss: 0.00593633\n",
      "[518]\ttraining's binary_logloss: 0.00588906\n",
      "[519]\ttraining's binary_logloss: 0.00584512\n",
      "[520]\ttraining's binary_logloss: 0.00579932\n",
      "[521]\ttraining's binary_logloss: 0.00575665\n",
      "[522]\ttraining's binary_logloss: 0.00571205\n",
      "[523]\ttraining's binary_logloss: 0.00566551\n",
      "[524]\ttraining's binary_logloss: 0.00562038\n",
      "[525]\ttraining's binary_logloss: 0.00557926\n",
      "[526]\ttraining's binary_logloss: 0.00553161\n",
      "[527]\ttraining's binary_logloss: 0.00548546\n",
      "[528]\ttraining's binary_logloss: 0.00544294\n",
      "[529]\ttraining's binary_logloss: 0.00539937\n",
      "[530]\ttraining's binary_logloss: 0.00535696\n",
      "[531]\ttraining's binary_logloss: 0.00531375\n",
      "[532]\ttraining's binary_logloss: 0.00527048\n",
      "[533]\ttraining's binary_logloss: 0.00522886\n",
      "[534]\ttraining's binary_logloss: 0.00518942\n",
      "[535]\ttraining's binary_logloss: 0.00514654\n",
      "[536]\ttraining's binary_logloss: 0.00510462\n",
      "[537]\ttraining's binary_logloss: 0.00506074\n",
      "[538]\ttraining's binary_logloss: 0.00501978\n",
      "[539]\ttraining's binary_logloss: 0.00497849\n",
      "[540]\ttraining's binary_logloss: 0.00494098\n",
      "[541]\ttraining's binary_logloss: 0.00490356\n",
      "[542]\ttraining's binary_logloss: 0.00486279\n",
      "[543]\ttraining's binary_logloss: 0.00482352\n",
      "[544]\ttraining's binary_logloss: 0.0047861\n",
      "[545]\ttraining's binary_logloss: 0.00475004\n",
      "[546]\ttraining's binary_logloss: 0.00471113\n",
      "[547]\ttraining's binary_logloss: 0.00467382\n",
      "[548]\ttraining's binary_logloss: 0.0046391\n",
      "[549]\ttraining's binary_logloss: 0.00460383\n",
      "[550]\ttraining's binary_logloss: 0.00456689\n",
      "[551]\ttraining's binary_logloss: 0.00452877\n",
      "[552]\ttraining's binary_logloss: 0.00449356\n",
      "[553]\ttraining's binary_logloss: 0.00445817\n",
      "[554]\ttraining's binary_logloss: 0.00442387\n",
      "[555]\ttraining's binary_logloss: 0.00438959\n",
      "[556]\ttraining's binary_logloss: 0.00435404\n",
      "[557]\ttraining's binary_logloss: 0.00431921\n",
      "[558]\ttraining's binary_logloss: 0.00428663\n",
      "[559]\ttraining's binary_logloss: 0.00425618\n",
      "[560]\ttraining's binary_logloss: 0.00422215\n",
      "[561]\ttraining's binary_logloss: 0.00418948\n",
      "[562]\ttraining's binary_logloss: 0.00415716\n",
      "[563]\ttraining's binary_logloss: 0.00412402\n",
      "[564]\ttraining's binary_logloss: 0.0040908\n",
      "[565]\ttraining's binary_logloss: 0.00405725\n",
      "[566]\ttraining's binary_logloss: 0.00402385\n",
      "[567]\ttraining's binary_logloss: 0.00399371\n",
      "[568]\ttraining's binary_logloss: 0.00396273\n",
      "[569]\ttraining's binary_logloss: 0.00393109\n",
      "[570]\ttraining's binary_logloss: 0.00390102\n",
      "[571]\ttraining's binary_logloss: 0.00387364\n",
      "[572]\ttraining's binary_logloss: 0.00384651\n",
      "[573]\ttraining's binary_logloss: 0.00382086\n",
      "[574]\ttraining's binary_logloss: 0.0037891\n",
      "[575]\ttraining's binary_logloss: 0.00376111\n",
      "[576]\ttraining's binary_logloss: 0.00373028\n",
      "[577]\ttraining's binary_logloss: 0.00370032\n",
      "[578]\ttraining's binary_logloss: 0.00367095\n",
      "[579]\ttraining's binary_logloss: 0.00364245\n",
      "[580]\ttraining's binary_logloss: 0.00361393\n",
      "[581]\ttraining's binary_logloss: 0.00358688\n",
      "[582]\ttraining's binary_logloss: 0.00355818\n",
      "[583]\ttraining's binary_logloss: 0.00353245\n",
      "[584]\ttraining's binary_logloss: 0.00350468\n",
      "[585]\ttraining's binary_logloss: 0.00347792\n",
      "[586]\ttraining's binary_logloss: 0.00345192\n",
      "[587]\ttraining's binary_logloss: 0.00342412\n",
      "[588]\ttraining's binary_logloss: 0.00339715\n",
      "[589]\ttraining's binary_logloss: 0.00336933\n",
      "[590]\ttraining's binary_logloss: 0.00334325\n",
      "[591]\ttraining's binary_logloss: 0.00331721\n",
      "[592]\ttraining's binary_logloss: 0.00329134\n",
      "[593]\ttraining's binary_logloss: 0.00326562\n",
      "[594]\ttraining's binary_logloss: 0.00324085\n",
      "[595]\ttraining's binary_logloss: 0.0032169\n",
      "[596]\ttraining's binary_logloss: 0.00319151\n",
      "[597]\ttraining's binary_logloss: 0.00316546\n",
      "[598]\ttraining's binary_logloss: 0.0031397\n",
      "[599]\ttraining's binary_logloss: 0.00311609\n",
      "[600]\ttraining's binary_logloss: 0.00309428\n",
      "[601]\ttraining's binary_logloss: 0.00306765\n",
      "[602]\ttraining's binary_logloss: 0.00304358\n",
      "[603]\ttraining's binary_logloss: 0.00301926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[604]\ttraining's binary_logloss: 0.00299644\n",
      "[605]\ttraining's binary_logloss: 0.00297256\n",
      "[606]\ttraining's binary_logloss: 0.00294822\n",
      "[607]\ttraining's binary_logloss: 0.00292443\n",
      "[608]\ttraining's binary_logloss: 0.0029017\n",
      "[609]\ttraining's binary_logloss: 0.00288082\n",
      "[610]\ttraining's binary_logloss: 0.0028574\n",
      "[611]\ttraining's binary_logloss: 0.00283461\n",
      "[612]\ttraining's binary_logloss: 0.00281261\n",
      "[613]\ttraining's binary_logloss: 0.00279116\n",
      "[614]\ttraining's binary_logloss: 0.00276892\n",
      "[615]\ttraining's binary_logloss: 0.00274794\n",
      "[616]\ttraining's binary_logloss: 0.00272591\n",
      "[617]\ttraining's binary_logloss: 0.00270472\n",
      "[618]\ttraining's binary_logloss: 0.00268229\n",
      "[619]\ttraining's binary_logloss: 0.00266158\n",
      "[620]\ttraining's binary_logloss: 0.00264038\n",
      "[621]\ttraining's binary_logloss: 0.00261928\n",
      "[622]\ttraining's binary_logloss: 0.00259988\n",
      "[623]\ttraining's binary_logloss: 0.00257971\n",
      "[624]\ttraining's binary_logloss: 0.00255949\n",
      "[625]\ttraining's binary_logloss: 0.00254063\n",
      "[626]\ttraining's binary_logloss: 0.00252184\n",
      "[627]\ttraining's binary_logloss: 0.00250281\n",
      "[628]\ttraining's binary_logloss: 0.00248461\n",
      "[629]\ttraining's binary_logloss: 0.00246441\n",
      "[630]\ttraining's binary_logloss: 0.0024452\n",
      "[631]\ttraining's binary_logloss: 0.00242476\n",
      "[632]\ttraining's binary_logloss: 0.00240603\n",
      "[633]\ttraining's binary_logloss: 0.00238747\n",
      "[634]\ttraining's binary_logloss: 0.00236905\n",
      "[635]\ttraining's binary_logloss: 0.00235091\n",
      "[636]\ttraining's binary_logloss: 0.00233317\n",
      "[637]\ttraining's binary_logloss: 0.00231435\n",
      "[638]\ttraining's binary_logloss: 0.00229616\n",
      "[639]\ttraining's binary_logloss: 0.00227771\n",
      "[640]\ttraining's binary_logloss: 0.00226004\n",
      "[641]\ttraining's binary_logloss: 0.00224241\n",
      "[642]\ttraining's binary_logloss: 0.00222582\n",
      "[643]\ttraining's binary_logloss: 0.0022077\n",
      "[644]\ttraining's binary_logloss: 0.00218994\n",
      "[645]\ttraining's binary_logloss: 0.00217255\n",
      "[646]\ttraining's binary_logloss: 0.00215473\n",
      "[647]\ttraining's binary_logloss: 0.00213709\n",
      "[648]\ttraining's binary_logloss: 0.00212058\n",
      "[649]\ttraining's binary_logloss: 0.00210411\n",
      "[650]\ttraining's binary_logloss: 0.00208651\n",
      "[651]\ttraining's binary_logloss: 0.00206919\n",
      "[652]\ttraining's binary_logloss: 0.00205418\n",
      "[653]\ttraining's binary_logloss: 0.0020374\n",
      "[654]\ttraining's binary_logloss: 0.00202224\n",
      "[655]\ttraining's binary_logloss: 0.00200532\n",
      "[656]\ttraining's binary_logloss: 0.00198903\n",
      "[657]\ttraining's binary_logloss: 0.00197374\n",
      "[658]\ttraining's binary_logloss: 0.00195791\n",
      "[659]\ttraining's binary_logloss: 0.00194182\n",
      "[660]\ttraining's binary_logloss: 0.00192587\n",
      "[661]\ttraining's binary_logloss: 0.00191004\n",
      "[662]\ttraining's binary_logloss: 0.00189457\n",
      "[663]\ttraining's binary_logloss: 0.00187956\n",
      "[664]\ttraining's binary_logloss: 0.00186545\n",
      "[665]\ttraining's binary_logloss: 0.00185061\n",
      "[666]\ttraining's binary_logloss: 0.00183567\n",
      "[667]\ttraining's binary_logloss: 0.00182104\n",
      "[668]\ttraining's binary_logloss: 0.00180665\n",
      "[669]\ttraining's binary_logloss: 0.00179201\n",
      "[670]\ttraining's binary_logloss: 0.0017792\n",
      "[671]\ttraining's binary_logloss: 0.00176656\n",
      "[672]\ttraining's binary_logloss: 0.00175385\n",
      "[673]\ttraining's binary_logloss: 0.00174096\n",
      "[674]\ttraining's binary_logloss: 0.00172668\n",
      "[675]\ttraining's binary_logloss: 0.00171353\n",
      "[676]\ttraining's binary_logloss: 0.00170006\n",
      "[677]\ttraining's binary_logloss: 0.00168729\n",
      "[678]\ttraining's binary_logloss: 0.0016747\n",
      "[679]\ttraining's binary_logloss: 0.00166179\n",
      "[680]\ttraining's binary_logloss: 0.00164895\n",
      "[681]\ttraining's binary_logloss: 0.00163582\n",
      "[682]\ttraining's binary_logloss: 0.0016233\n",
      "[683]\ttraining's binary_logloss: 0.00161075\n",
      "[684]\ttraining's binary_logloss: 0.00159844\n",
      "[685]\ttraining's binary_logloss: 0.00158619\n",
      "[686]\ttraining's binary_logloss: 0.00157377\n",
      "[687]\ttraining's binary_logloss: 0.00156146\n",
      "[688]\ttraining's binary_logloss: 0.00154931\n",
      "[689]\ttraining's binary_logloss: 0.00153709\n",
      "[690]\ttraining's binary_logloss: 0.00152544\n",
      "[691]\ttraining's binary_logloss: 0.00151305\n",
      "[692]\ttraining's binary_logloss: 0.00149977\n",
      "[693]\ttraining's binary_logloss: 0.00148815\n",
      "[694]\ttraining's binary_logloss: 0.00147699\n",
      "[695]\ttraining's binary_logloss: 0.00146678\n",
      "[696]\ttraining's binary_logloss: 0.00145617\n",
      "[697]\ttraining's binary_logloss: 0.00144367\n",
      "[698]\ttraining's binary_logloss: 0.00143247\n",
      "[699]\ttraining's binary_logloss: 0.00142147\n",
      "[700]\ttraining's binary_logloss: 0.00140977\n",
      "[701]\ttraining's binary_logloss: 0.00139751\n",
      "[702]\ttraining's binary_logloss: 0.00138635\n",
      "[703]\ttraining's binary_logloss: 0.00137483\n",
      "[704]\ttraining's binary_logloss: 0.00136413\n",
      "[705]\ttraining's binary_logloss: 0.00135286\n",
      "[706]\ttraining's binary_logloss: 0.0013424\n",
      "[707]\ttraining's binary_logloss: 0.0013316\n",
      "[708]\ttraining's binary_logloss: 0.00132091\n",
      "[709]\ttraining's binary_logloss: 0.00131195\n",
      "[710]\ttraining's binary_logloss: 0.00130125\n",
      "[711]\ttraining's binary_logloss: 0.00129114\n",
      "[712]\ttraining's binary_logloss: 0.00128078\n",
      "[713]\ttraining's binary_logloss: 0.00127009\n",
      "[714]\ttraining's binary_logloss: 0.00126105\n",
      "[715]\ttraining's binary_logloss: 0.00125066\n",
      "[716]\ttraining's binary_logloss: 0.00124086\n",
      "[717]\ttraining's binary_logloss: 0.00123028\n",
      "[718]\ttraining's binary_logloss: 0.00122004\n",
      "[719]\ttraining's binary_logloss: 0.0012109\n",
      "[720]\ttraining's binary_logloss: 0.00120115\n",
      "[721]\ttraining's binary_logloss: 0.00119106\n",
      "[722]\ttraining's binary_logloss: 0.0011815\n",
      "[723]\ttraining's binary_logloss: 0.0011717\n",
      "[724]\ttraining's binary_logloss: 0.00116229\n",
      "[725]\ttraining's binary_logloss: 0.00115284\n",
      "[726]\ttraining's binary_logloss: 0.00114389\n",
      "[727]\ttraining's binary_logloss: 0.00113531\n",
      "[728]\ttraining's binary_logloss: 0.00112603\n",
      "[729]\ttraining's binary_logloss: 0.00111745\n",
      "[730]\ttraining's binary_logloss: 0.00110916\n",
      "[731]\ttraining's binary_logloss: 0.00110099\n",
      "[732]\ttraining's binary_logloss: 0.00109198\n",
      "[733]\ttraining's binary_logloss: 0.00108294\n",
      "[734]\ttraining's binary_logloss: 0.00107449\n",
      "[735]\ttraining's binary_logloss: 0.00106643\n",
      "[736]\ttraining's binary_logloss: 0.00105853\n",
      "[737]\ttraining's binary_logloss: 0.00105001\n",
      "[738]\ttraining's binary_logloss: 0.00104202\n",
      "[739]\ttraining's binary_logloss: 0.00103432\n",
      "[740]\ttraining's binary_logloss: 0.00102605\n",
      "[741]\ttraining's binary_logloss: 0.00101822\n",
      "[742]\ttraining's binary_logloss: 0.00101009\n",
      "[743]\ttraining's binary_logloss: 0.00100224\n",
      "[744]\ttraining's binary_logloss: 0.000994029\n",
      "[745]\ttraining's binary_logloss: 0.000985923\n",
      "[746]\ttraining's binary_logloss: 0.000978976\n",
      "[747]\ttraining's binary_logloss: 0.000972001\n",
      "[748]\ttraining's binary_logloss: 0.000965211\n",
      "[749]\ttraining's binary_logloss: 0.000958108\n",
      "[750]\ttraining's binary_logloss: 0.000950666\n",
      "[751]\ttraining's binary_logloss: 0.000943709\n",
      "[752]\ttraining's binary_logloss: 0.000937318\n",
      "[753]\ttraining's binary_logloss: 0.000929515\n",
      "[754]\ttraining's binary_logloss: 0.000921668\n",
      "[755]\ttraining's binary_logloss: 0.000914354\n",
      "[756]\ttraining's binary_logloss: 0.000907198\n",
      "[757]\ttraining's binary_logloss: 0.000900276\n",
      "[758]\ttraining's binary_logloss: 0.00089378\n",
      "[759]\ttraining's binary_logloss: 0.000887107\n",
      "[760]\ttraining's binary_logloss: 0.000880171\n",
      "[761]\ttraining's binary_logloss: 0.000872751\n",
      "[762]\ttraining's binary_logloss: 0.000865381\n",
      "[763]\ttraining's binary_logloss: 0.000858845\n",
      "[764]\ttraining's binary_logloss: 0.00085236\n",
      "[765]\ttraining's binary_logloss: 0.000845514\n",
      "[766]\ttraining's binary_logloss: 0.00083906\n",
      "[767]\ttraining's binary_logloss: 0.000832549\n",
      "[768]\ttraining's binary_logloss: 0.000825869\n",
      "[769]\ttraining's binary_logloss: 0.000820465\n",
      "[770]\ttraining's binary_logloss: 0.00081404\n",
      "[771]\ttraining's binary_logloss: 0.000807294\n",
      "[772]\ttraining's binary_logloss: 0.000800979\n",
      "[773]\ttraining's binary_logloss: 0.000795322\n",
      "[774]\ttraining's binary_logloss: 0.000789099\n",
      "[775]\ttraining's binary_logloss: 0.000782887\n",
      "[776]\ttraining's binary_logloss: 0.000777277\n",
      "[777]\ttraining's binary_logloss: 0.000771069\n",
      "[778]\ttraining's binary_logloss: 0.000764946\n",
      "[779]\ttraining's binary_logloss: 0.000759581\n",
      "[780]\ttraining's binary_logloss: 0.000754427\n",
      "[781]\ttraining's binary_logloss: 0.000748701\n",
      "[782]\ttraining's binary_logloss: 0.000743121\n",
      "[783]\ttraining's binary_logloss: 0.000737235\n",
      "[784]\ttraining's binary_logloss: 0.000731845\n",
      "[785]\ttraining's binary_logloss: 0.000726076\n",
      "[786]\ttraining's binary_logloss: 0.000720054\n",
      "[787]\ttraining's binary_logloss: 0.000713907\n",
      "[788]\ttraining's binary_logloss: 0.000708407\n",
      "[789]\ttraining's binary_logloss: 0.000703062\n",
      "[790]\ttraining's binary_logloss: 0.000697496\n",
      "[791]\ttraining's binary_logloss: 0.000692131\n",
      "[792]\ttraining's binary_logloss: 0.000686933\n",
      "[793]\ttraining's binary_logloss: 0.000681557\n",
      "[794]\ttraining's binary_logloss: 0.000676122\n",
      "[795]\ttraining's binary_logloss: 0.000670592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[796]\ttraining's binary_logloss: 0.000665436\n",
      "[797]\ttraining's binary_logloss: 0.000660075\n",
      "[798]\ttraining's binary_logloss: 0.00065479\n",
      "[799]\ttraining's binary_logloss: 0.000649751\n",
      "[800]\ttraining's binary_logloss: 0.000644324\n",
      "[801]\ttraining's binary_logloss: 0.00063918\n",
      "[802]\ttraining's binary_logloss: 0.000633717\n",
      "[803]\ttraining's binary_logloss: 0.000628787\n",
      "[804]\ttraining's binary_logloss: 0.00062438\n",
      "[805]\ttraining's binary_logloss: 0.000619466\n",
      "[806]\ttraining's binary_logloss: 0.000614507\n",
      "[807]\ttraining's binary_logloss: 0.000609592\n",
      "[808]\ttraining's binary_logloss: 0.000605237\n",
      "[809]\ttraining's binary_logloss: 0.000600439\n",
      "[810]\ttraining's binary_logloss: 0.000595942\n",
      "[811]\ttraining's binary_logloss: 0.000591371\n",
      "[812]\ttraining's binary_logloss: 0.000587394\n",
      "[813]\ttraining's binary_logloss: 0.000582484\n",
      "[814]\ttraining's binary_logloss: 0.000578136\n",
      "[815]\ttraining's binary_logloss: 0.000573411\n",
      "[816]\ttraining's binary_logloss: 0.000568867\n",
      "[817]\ttraining's binary_logloss: 0.000564542\n",
      "[818]\ttraining's binary_logloss: 0.0005606\n",
      "[819]\ttraining's binary_logloss: 0.000556298\n",
      "[820]\ttraining's binary_logloss: 0.000552264\n",
      "[821]\ttraining's binary_logloss: 0.000547744\n",
      "[822]\ttraining's binary_logloss: 0.000543334\n",
      "[823]\ttraining's binary_logloss: 0.000539112\n",
      "[824]\ttraining's binary_logloss: 0.000535085\n",
      "[825]\ttraining's binary_logloss: 0.000530733\n",
      "[826]\ttraining's binary_logloss: 0.000526531\n",
      "[827]\ttraining's binary_logloss: 0.000522138\n",
      "[828]\ttraining's binary_logloss: 0.00051821\n",
      "[829]\ttraining's binary_logloss: 0.000514734\n",
      "[830]\ttraining's binary_logloss: 0.000510627\n",
      "[831]\ttraining's binary_logloss: 0.000506388\n",
      "[832]\ttraining's binary_logloss: 0.000502854\n",
      "[833]\ttraining's binary_logloss: 0.000499202\n",
      "[834]\ttraining's binary_logloss: 0.000495591\n",
      "[835]\ttraining's binary_logloss: 0.000491393\n",
      "[836]\ttraining's binary_logloss: 0.000487444\n",
      "[837]\ttraining's binary_logloss: 0.00048377\n",
      "[838]\ttraining's binary_logloss: 0.000479997\n",
      "[839]\ttraining's binary_logloss: 0.000475975\n",
      "[840]\ttraining's binary_logloss: 0.000472316\n",
      "[841]\ttraining's binary_logloss: 0.000468375\n",
      "[842]\ttraining's binary_logloss: 0.000464332\n",
      "[843]\ttraining's binary_logloss: 0.000460688\n",
      "[844]\ttraining's binary_logloss: 0.000457162\n",
      "[845]\ttraining's binary_logloss: 0.000453708\n",
      "[846]\ttraining's binary_logloss: 0.00045013\n",
      "[847]\ttraining's binary_logloss: 0.000446671\n",
      "[848]\ttraining's binary_logloss: 0.00044291\n",
      "[849]\ttraining's binary_logloss: 0.000439203\n",
      "[850]\ttraining's binary_logloss: 0.000436024\n",
      "[851]\ttraining's binary_logloss: 0.000432385\n",
      "[852]\ttraining's binary_logloss: 0.000429031\n",
      "[853]\ttraining's binary_logloss: 0.000425483\n",
      "[854]\ttraining's binary_logloss: 0.000422669\n",
      "[855]\ttraining's binary_logloss: 0.000419355\n",
      "[856]\ttraining's binary_logloss: 0.000415986\n",
      "[857]\ttraining's binary_logloss: 0.000412632\n",
      "[858]\ttraining's binary_logloss: 0.000409252\n",
      "[859]\ttraining's binary_logloss: 0.000406175\n",
      "[860]\ttraining's binary_logloss: 0.000403178\n",
      "[861]\ttraining's binary_logloss: 0.000399875\n",
      "[862]\ttraining's binary_logloss: 0.000396982\n",
      "[863]\ttraining's binary_logloss: 0.000393883\n",
      "[864]\ttraining's binary_logloss: 0.000390697\n",
      "[865]\ttraining's binary_logloss: 0.000387479\n",
      "[866]\ttraining's binary_logloss: 0.000384445\n",
      "[867]\ttraining's binary_logloss: 0.000381607\n",
      "[868]\ttraining's binary_logloss: 0.000378848\n",
      "[869]\ttraining's binary_logloss: 0.000376154\n",
      "[870]\ttraining's binary_logloss: 0.000373166\n",
      "[871]\ttraining's binary_logloss: 0.000370477\n",
      "[872]\ttraining's binary_logloss: 0.000367433\n",
      "[873]\ttraining's binary_logloss: 0.00036485\n",
      "[874]\ttraining's binary_logloss: 0.000361996\n",
      "[875]\ttraining's binary_logloss: 0.000359266\n",
      "[876]\ttraining's binary_logloss: 0.000356395\n",
      "[877]\ttraining's binary_logloss: 0.000353373\n",
      "[878]\ttraining's binary_logloss: 0.000350489\n",
      "[879]\ttraining's binary_logloss: 0.000347999\n",
      "[880]\ttraining's binary_logloss: 0.0003451\n",
      "[881]\ttraining's binary_logloss: 0.000342358\n",
      "[882]\ttraining's binary_logloss: 0.000339693\n",
      "[883]\ttraining's binary_logloss: 0.000336905\n",
      "[884]\ttraining's binary_logloss: 0.000334112\n",
      "[885]\ttraining's binary_logloss: 0.000331483\n",
      "[886]\ttraining's binary_logloss: 0.000329074\n",
      "[887]\ttraining's binary_logloss: 0.000326443\n",
      "[888]\ttraining's binary_logloss: 0.000323903\n",
      "[889]\ttraining's binary_logloss: 0.000321559\n",
      "[890]\ttraining's binary_logloss: 0.000319246\n",
      "[891]\ttraining's binary_logloss: 0.000316832\n",
      "[892]\ttraining's binary_logloss: 0.000314387\n",
      "[893]\ttraining's binary_logloss: 0.000311928\n",
      "[894]\ttraining's binary_logloss: 0.000309521\n",
      "[895]\ttraining's binary_logloss: 0.000307083\n",
      "[896]\ttraining's binary_logloss: 0.000304744\n",
      "[897]\ttraining's binary_logloss: 0.000302272\n",
      "[898]\ttraining's binary_logloss: 0.000299779\n",
      "[899]\ttraining's binary_logloss: 0.000297359\n",
      "[900]\ttraining's binary_logloss: 0.000294994\n",
      "[901]\ttraining's binary_logloss: 0.000292697\n",
      "[902]\ttraining's binary_logloss: 0.000290274\n",
      "[903]\ttraining's binary_logloss: 0.000288115\n",
      "[904]\ttraining's binary_logloss: 0.000285963\n",
      "[905]\ttraining's binary_logloss: 0.000283717\n",
      "[906]\ttraining's binary_logloss: 0.0002814\n",
      "[907]\ttraining's binary_logloss: 0.000279117\n",
      "[908]\ttraining's binary_logloss: 0.000277027\n",
      "[909]\ttraining's binary_logloss: 0.000274746\n",
      "[910]\ttraining's binary_logloss: 0.000272598\n",
      "[911]\ttraining's binary_logloss: 0.000270779\n",
      "[912]\ttraining's binary_logloss: 0.00026891\n",
      "[913]\ttraining's binary_logloss: 0.000266815\n",
      "[914]\ttraining's binary_logloss: 0.000264861\n",
      "[915]\ttraining's binary_logloss: 0.000262747\n",
      "[916]\ttraining's binary_logloss: 0.000260994\n",
      "[917]\ttraining's binary_logloss: 0.000258943\n",
      "[918]\ttraining's binary_logloss: 0.000257017\n",
      "[919]\ttraining's binary_logloss: 0.0002552\n",
      "[920]\ttraining's binary_logloss: 0.000253255\n",
      "[921]\ttraining's binary_logloss: 0.000251312\n",
      "[922]\ttraining's binary_logloss: 0.000249361\n",
      "[923]\ttraining's binary_logloss: 0.000247456\n",
      "[924]\ttraining's binary_logloss: 0.000245578\n",
      "[925]\ttraining's binary_logloss: 0.000243854\n",
      "[926]\ttraining's binary_logloss: 0.000242178\n",
      "[927]\ttraining's binary_logloss: 0.000240527\n",
      "[928]\ttraining's binary_logloss: 0.000238795\n",
      "[929]\ttraining's binary_logloss: 0.000236968\n",
      "[930]\ttraining's binary_logloss: 0.000235187\n",
      "[931]\ttraining's binary_logloss: 0.000233486\n",
      "[932]\ttraining's binary_logloss: 0.000231696\n",
      "[933]\ttraining's binary_logloss: 0.000230057\n",
      "[934]\ttraining's binary_logloss: 0.000228378\n",
      "[935]\ttraining's binary_logloss: 0.000226716\n",
      "[936]\ttraining's binary_logloss: 0.000224917\n",
      "[937]\ttraining's binary_logloss: 0.000223279\n",
      "[938]\ttraining's binary_logloss: 0.000221831\n",
      "[939]\ttraining's binary_logloss: 0.000220189\n",
      "[940]\ttraining's binary_logloss: 0.000218656\n",
      "[941]\ttraining's binary_logloss: 0.000217024\n",
      "[942]\ttraining's binary_logloss: 0.0002155\n",
      "[943]\ttraining's binary_logloss: 0.000214124\n",
      "[944]\ttraining's binary_logloss: 0.000212688\n",
      "[945]\ttraining's binary_logloss: 0.000211168\n",
      "[946]\ttraining's binary_logloss: 0.000209649\n",
      "[947]\ttraining's binary_logloss: 0.00020797\n",
      "[948]\ttraining's binary_logloss: 0.000206442\n",
      "[949]\ttraining's binary_logloss: 0.000204962\n",
      "[950]\ttraining's binary_logloss: 0.000203535\n",
      "[951]\ttraining's binary_logloss: 0.000202\n",
      "[952]\ttraining's binary_logloss: 0.000200361\n",
      "[953]\ttraining's binary_logloss: 0.000198931\n",
      "[954]\ttraining's binary_logloss: 0.000197549\n",
      "[955]\ttraining's binary_logloss: 0.000195953\n",
      "[956]\ttraining's binary_logloss: 0.000194446\n",
      "[957]\ttraining's binary_logloss: 0.000193004\n",
      "[958]\ttraining's binary_logloss: 0.000191445\n",
      "[959]\ttraining's binary_logloss: 0.000189957\n",
      "[960]\ttraining's binary_logloss: 0.000188592\n",
      "[961]\ttraining's binary_logloss: 0.00018728\n",
      "[962]\ttraining's binary_logloss: 0.000185855\n",
      "[963]\ttraining's binary_logloss: 0.000184461\n",
      "[964]\ttraining's binary_logloss: 0.000182907\n",
      "[965]\ttraining's binary_logloss: 0.000181507\n",
      "[966]\ttraining's binary_logloss: 0.00018009\n",
      "[967]\ttraining's binary_logloss: 0.000178794\n",
      "[968]\ttraining's binary_logloss: 0.000177439\n",
      "[969]\ttraining's binary_logloss: 0.000176101\n",
      "[970]\ttraining's binary_logloss: 0.000174738\n",
      "[971]\ttraining's binary_logloss: 0.000173478\n",
      "[972]\ttraining's binary_logloss: 0.000172178\n",
      "[973]\ttraining's binary_logloss: 0.000170793\n",
      "[974]\ttraining's binary_logloss: 0.000169726\n",
      "[975]\ttraining's binary_logloss: 0.00016857\n",
      "[976]\ttraining's binary_logloss: 0.000167174\n",
      "[977]\ttraining's binary_logloss: 0.000166089\n",
      "[978]\ttraining's binary_logloss: 0.000164957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[979]\ttraining's binary_logloss: 0.000163644\n",
      "[980]\ttraining's binary_logloss: 0.00016237\n",
      "[981]\ttraining's binary_logloss: 0.000161089\n",
      "[982]\ttraining's binary_logloss: 0.000160084\n",
      "[983]\ttraining's binary_logloss: 0.00015887\n",
      "[984]\ttraining's binary_logloss: 0.000157668\n",
      "[985]\ttraining's binary_logloss: 0.000156381\n",
      "[986]\ttraining's binary_logloss: 0.000155366\n",
      "[987]\ttraining's binary_logloss: 0.000154374\n",
      "[988]\ttraining's binary_logloss: 0.000153286\n",
      "[989]\ttraining's binary_logloss: 0.000152041\n",
      "[990]\ttraining's binary_logloss: 0.000151092\n",
      "[991]\ttraining's binary_logloss: 0.000150107\n",
      "[992]\ttraining's binary_logloss: 0.000148887\n",
      "[993]\ttraining's binary_logloss: 0.000147745\n",
      "[994]\ttraining's binary_logloss: 0.000146639\n",
      "[995]\ttraining's binary_logloss: 0.000145609\n",
      "[996]\ttraining's binary_logloss: 0.000144471\n",
      "[997]\ttraining's binary_logloss: 0.000143481\n",
      "[998]\ttraining's binary_logloss: 0.000142394\n",
      "[999]\ttraining's binary_logloss: 0.000141364\n",
      "[1000]\ttraining's binary_logloss: 0.000140278\n",
      "[1001]\ttraining's binary_logloss: 0.000139199\n",
      "[1002]\ttraining's binary_logloss: 0.000138104\n",
      "[1003]\ttraining's binary_logloss: 0.000137033\n",
      "[1004]\ttraining's binary_logloss: 0.000135978\n",
      "[1005]\ttraining's binary_logloss: 0.000134939\n",
      "[1006]\ttraining's binary_logloss: 0.000133974\n",
      "[1007]\ttraining's binary_logloss: 0.000132898\n",
      "[1008]\ttraining's binary_logloss: 0.000131971\n",
      "[1009]\ttraining's binary_logloss: 0.000131091\n",
      "[1010]\ttraining's binary_logloss: 0.000130253\n",
      "[1011]\ttraining's binary_logloss: 0.000129278\n",
      "[1012]\ttraining's binary_logloss: 0.00012824\n",
      "[1013]\ttraining's binary_logloss: 0.000127274\n",
      "[1014]\ttraining's binary_logloss: 0.000126302\n",
      "[1015]\ttraining's binary_logloss: 0.000125426\n",
      "[1016]\ttraining's binary_logloss: 0.000124542\n",
      "[1017]\ttraining's binary_logloss: 0.000123692\n",
      "[1018]\ttraining's binary_logloss: 0.000122885\n",
      "[1019]\ttraining's binary_logloss: 0.00012192\n",
      "[1020]\ttraining's binary_logloss: 0.000120888\n",
      "[1021]\ttraining's binary_logloss: 0.000119971\n",
      "[1022]\ttraining's binary_logloss: 0.000119288\n",
      "[1023]\ttraining's binary_logloss: 0.000118444\n",
      "[1024]\ttraining's binary_logloss: 0.000117705\n",
      "[1025]\ttraining's binary_logloss: 0.000116891\n",
      "[1026]\ttraining's binary_logloss: 0.000116142\n",
      "[1027]\ttraining's binary_logloss: 0.000115299\n",
      "[1028]\ttraining's binary_logloss: 0.000114466\n",
      "[1029]\ttraining's binary_logloss: 0.000113683\n",
      "[1030]\ttraining's binary_logloss: 0.000112981\n",
      "[1031]\ttraining's binary_logloss: 0.000112185\n",
      "[1032]\ttraining's binary_logloss: 0.000111412\n",
      "[1033]\ttraining's binary_logloss: 0.000110684\n",
      "[1034]\ttraining's binary_logloss: 0.000110013\n",
      "[1035]\ttraining's binary_logloss: 0.000109251\n",
      "[1036]\ttraining's binary_logloss: 0.000108506\n",
      "[1037]\ttraining's binary_logloss: 0.000107752\n",
      "[1038]\ttraining's binary_logloss: 0.000107167\n",
      "[1039]\ttraining's binary_logloss: 0.000106546\n",
      "[1040]\ttraining's binary_logloss: 0.000105779\n",
      "[1041]\ttraining's binary_logloss: 0.000104887\n",
      "[1042]\ttraining's binary_logloss: 0.000104304\n",
      "[1043]\ttraining's binary_logloss: 0.000103447\n",
      "[1044]\ttraining's binary_logloss: 0.000102635\n",
      "[1045]\ttraining's binary_logloss: 0.000101992\n",
      "[1046]\ttraining's binary_logloss: 0.000101402\n",
      "[1047]\ttraining's binary_logloss: 0.000100619\n",
      "[1048]\ttraining's binary_logloss: 9.99402e-05\n",
      "[1049]\ttraining's binary_logloss: 9.93777e-05\n",
      "[1050]\ttraining's binary_logloss: 9.87908e-05\n",
      "[1051]\ttraining's binary_logloss: 9.82413e-05\n",
      "[1052]\ttraining's binary_logloss: 9.74749e-05\n",
      "[1053]\ttraining's binary_logloss: 9.66629e-05\n",
      "[1054]\ttraining's binary_logloss: 9.59186e-05\n",
      "[1055]\ttraining's binary_logloss: 9.52483e-05\n",
      "[1056]\ttraining's binary_logloss: 9.45499e-05\n",
      "[1057]\ttraining's binary_logloss: 9.39565e-05\n",
      "[1058]\ttraining's binary_logloss: 9.31427e-05\n",
      "[1059]\ttraining's binary_logloss: 9.25067e-05\n",
      "[1060]\ttraining's binary_logloss: 9.17922e-05\n",
      "[1061]\ttraining's binary_logloss: 9.1131e-05\n",
      "[1062]\ttraining's binary_logloss: 9.04007e-05\n",
      "[1063]\ttraining's binary_logloss: 8.97412e-05\n",
      "[1064]\ttraining's binary_logloss: 8.92121e-05\n",
      "[1065]\ttraining's binary_logloss: 8.8552e-05\n",
      "[1066]\ttraining's binary_logloss: 8.78754e-05\n",
      "[1067]\ttraining's binary_logloss: 8.71968e-05\n",
      "[1068]\ttraining's binary_logloss: 8.66236e-05\n",
      "[1069]\ttraining's binary_logloss: 8.59517e-05\n",
      "[1070]\ttraining's binary_logloss: 8.52893e-05\n",
      "[1071]\ttraining's binary_logloss: 8.46676e-05\n",
      "[1072]\ttraining's binary_logloss: 8.39503e-05\n",
      "[1073]\ttraining's binary_logloss: 8.32341e-05\n",
      "[1074]\ttraining's binary_logloss: 8.2606e-05\n",
      "[1075]\ttraining's binary_logloss: 8.19406e-05\n",
      "[1076]\ttraining's binary_logloss: 8.12243e-05\n",
      "[1077]\ttraining's binary_logloss: 8.05778e-05\n",
      "[1078]\ttraining's binary_logloss: 7.99291e-05\n",
      "[1079]\ttraining's binary_logloss: 7.92497e-05\n",
      "[1080]\ttraining's binary_logloss: 7.86694e-05\n",
      "[1081]\ttraining's binary_logloss: 7.7988e-05\n",
      "[1082]\ttraining's binary_logloss: 7.73068e-05\n",
      "[1083]\ttraining's binary_logloss: 7.67067e-05\n",
      "[1084]\ttraining's binary_logloss: 7.61313e-05\n",
      "[1085]\ttraining's binary_logloss: 7.54849e-05\n",
      "[1086]\ttraining's binary_logloss: 7.48132e-05\n",
      "[1087]\ttraining's binary_logloss: 7.42267e-05\n",
      "[1088]\ttraining's binary_logloss: 7.36208e-05\n",
      "[1089]\ttraining's binary_logloss: 7.3005e-05\n",
      "[1090]\ttraining's binary_logloss: 7.24844e-05\n",
      "[1091]\ttraining's binary_logloss: 7.18612e-05\n",
      "[1092]\ttraining's binary_logloss: 7.13284e-05\n",
      "[1093]\ttraining's binary_logloss: 7.07154e-05\n",
      "[1094]\ttraining's binary_logloss: 7.0138e-05\n",
      "[1095]\ttraining's binary_logloss: 6.9548e-05\n",
      "[1096]\ttraining's binary_logloss: 6.90337e-05\n",
      "[1097]\ttraining's binary_logloss: 6.84832e-05\n",
      "[1098]\ttraining's binary_logloss: 6.79789e-05\n",
      "[1099]\ttraining's binary_logloss: 6.74705e-05\n",
      "[1100]\ttraining's binary_logloss: 6.69375e-05\n",
      "[1101]\ttraining's binary_logloss: 6.64494e-05\n",
      "[1102]\ttraining's binary_logloss: 6.5941e-05\n",
      "[1103]\ttraining's binary_logloss: 6.54606e-05\n",
      "[1104]\ttraining's binary_logloss: 6.49232e-05\n",
      "[1105]\ttraining's binary_logloss: 6.44568e-05\n",
      "[1106]\ttraining's binary_logloss: 6.39153e-05\n",
      "[1107]\ttraining's binary_logloss: 6.34338e-05\n",
      "[1108]\ttraining's binary_logloss: 6.29428e-05\n",
      "[1109]\ttraining's binary_logloss: 6.24528e-05\n",
      "[1110]\ttraining's binary_logloss: 6.19389e-05\n",
      "[1111]\ttraining's binary_logloss: 6.14372e-05\n",
      "[1112]\ttraining's binary_logloss: 6.09947e-05\n",
      "[1113]\ttraining's binary_logloss: 6.05625e-05\n",
      "[1114]\ttraining's binary_logloss: 6.00877e-05\n",
      "[1115]\ttraining's binary_logloss: 5.9625e-05\n",
      "[1116]\ttraining's binary_logloss: 5.9157e-05\n",
      "[1117]\ttraining's binary_logloss: 5.86779e-05\n",
      "[1118]\ttraining's binary_logloss: 5.82361e-05\n",
      "[1119]\ttraining's binary_logloss: 5.78212e-05\n",
      "[1120]\ttraining's binary_logloss: 5.74242e-05\n",
      "[1121]\ttraining's binary_logloss: 5.69706e-05\n",
      "[1122]\ttraining's binary_logloss: 5.6559e-05\n",
      "[1123]\ttraining's binary_logloss: 5.61478e-05\n",
      "[1124]\ttraining's binary_logloss: 5.57277e-05\n",
      "[1125]\ttraining's binary_logloss: 5.52793e-05\n",
      "[1126]\ttraining's binary_logloss: 5.48532e-05\n",
      "[1127]\ttraining's binary_logloss: 5.4438e-05\n",
      "[1128]\ttraining's binary_logloss: 5.39994e-05\n",
      "[1129]\ttraining's binary_logloss: 5.35934e-05\n",
      "[1130]\ttraining's binary_logloss: 5.3221e-05\n",
      "[1131]\ttraining's binary_logloss: 5.28143e-05\n",
      "[1132]\ttraining's binary_logloss: 5.2453e-05\n",
      "[1133]\ttraining's binary_logloss: 5.20346e-05\n",
      "[1134]\ttraining's binary_logloss: 5.1666e-05\n",
      "[1135]\ttraining's binary_logloss: 5.12903e-05\n",
      "[1136]\ttraining's binary_logloss: 5.08979e-05\n",
      "[1137]\ttraining's binary_logloss: 5.05225e-05\n",
      "[1138]\ttraining's binary_logloss: 5.01622e-05\n",
      "[1139]\ttraining's binary_logloss: 4.97815e-05\n",
      "[1140]\ttraining's binary_logloss: 4.94395e-05\n",
      "[1141]\ttraining's binary_logloss: 4.90738e-05\n",
      "[1142]\ttraining's binary_logloss: 4.87131e-05\n",
      "[1143]\ttraining's binary_logloss: 4.83437e-05\n",
      "[1144]\ttraining's binary_logloss: 4.7976e-05\n",
      "[1145]\ttraining's binary_logloss: 4.7596e-05\n",
      "[1146]\ttraining's binary_logloss: 4.72851e-05\n",
      "[1147]\ttraining's binary_logloss: 4.69456e-05\n",
      "[1148]\ttraining's binary_logloss: 4.6619e-05\n",
      "[1149]\ttraining's binary_logloss: 4.62834e-05\n",
      "[1150]\ttraining's binary_logloss: 4.59604e-05\n",
      "[1151]\ttraining's binary_logloss: 4.56315e-05\n",
      "[1152]\ttraining's binary_logloss: 4.53187e-05\n",
      "[1153]\ttraining's binary_logloss: 4.50186e-05\n",
      "[1154]\ttraining's binary_logloss: 4.46949e-05\n",
      "[1155]\ttraining's binary_logloss: 4.43828e-05\n",
      "[1156]\ttraining's binary_logloss: 4.40823e-05\n",
      "[1157]\ttraining's binary_logloss: 4.3753e-05\n",
      "[1158]\ttraining's binary_logloss: 4.34428e-05\n",
      "[1159]\ttraining's binary_logloss: 4.31148e-05\n",
      "[1160]\ttraining's binary_logloss: 4.28125e-05\n",
      "[1161]\ttraining's binary_logloss: 4.25361e-05\n",
      "[1162]\ttraining's binary_logloss: 4.22572e-05\n",
      "[1163]\ttraining's binary_logloss: 4.19562e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1164]\ttraining's binary_logloss: 4.16505e-05\n",
      "[1165]\ttraining's binary_logloss: 4.13743e-05\n",
      "[1166]\ttraining's binary_logloss: 4.10963e-05\n",
      "[1167]\ttraining's binary_logloss: 4.08226e-05\n",
      "[1168]\ttraining's binary_logloss: 4.05317e-05\n",
      "[1169]\ttraining's binary_logloss: 4.02618e-05\n",
      "[1170]\ttraining's binary_logloss: 3.99749e-05\n",
      "[1171]\ttraining's binary_logloss: 3.97036e-05\n",
      "[1172]\ttraining's binary_logloss: 3.94376e-05\n",
      "[1173]\ttraining's binary_logloss: 3.91676e-05\n",
      "[1174]\ttraining's binary_logloss: 3.89108e-05\n",
      "[1175]\ttraining's binary_logloss: 3.86341e-05\n",
      "[1176]\ttraining's binary_logloss: 3.83648e-05\n",
      "[1177]\ttraining's binary_logloss: 3.81288e-05\n",
      "[1178]\ttraining's binary_logloss: 3.78801e-05\n",
      "[1179]\ttraining's binary_logloss: 3.76234e-05\n",
      "[1180]\ttraining's binary_logloss: 3.73545e-05\n",
      "[1181]\ttraining's binary_logloss: 3.71047e-05\n",
      "[1182]\ttraining's binary_logloss: 3.68688e-05\n",
      "[1183]\ttraining's binary_logloss: 3.66272e-05\n",
      "[1184]\ttraining's binary_logloss: 3.63637e-05\n",
      "[1185]\ttraining's binary_logloss: 3.61201e-05\n",
      "[1186]\ttraining's binary_logloss: 3.5876e-05\n",
      "[1187]\ttraining's binary_logloss: 3.56508e-05\n",
      "[1188]\ttraining's binary_logloss: 3.54237e-05\n",
      "[1189]\ttraining's binary_logloss: 3.51822e-05\n",
      "[1190]\ttraining's binary_logloss: 3.49472e-05\n",
      "[1191]\ttraining's binary_logloss: 3.47117e-05\n",
      "[1192]\ttraining's binary_logloss: 3.44909e-05\n",
      "[1193]\ttraining's binary_logloss: 3.42836e-05\n",
      "[1194]\ttraining's binary_logloss: 3.40663e-05\n",
      "[1195]\ttraining's binary_logloss: 3.38461e-05\n",
      "[1196]\ttraining's binary_logloss: 3.36271e-05\n",
      "[1197]\ttraining's binary_logloss: 3.34196e-05\n",
      "[1198]\ttraining's binary_logloss: 3.32065e-05\n",
      "[1199]\ttraining's binary_logloss: 3.29954e-05\n",
      "[1200]\ttraining's binary_logloss: 3.27886e-05\n",
      "[1201]\ttraining's binary_logloss: 3.25962e-05\n",
      "[1202]\ttraining's binary_logloss: 3.23912e-05\n",
      "[1203]\ttraining's binary_logloss: 3.22001e-05\n",
      "[1204]\ttraining's binary_logloss: 3.20101e-05\n",
      "[1205]\ttraining's binary_logloss: 3.18089e-05\n",
      "[1206]\ttraining's binary_logloss: 3.16083e-05\n",
      "[1207]\ttraining's binary_logloss: 3.14105e-05\n",
      "[1208]\ttraining's binary_logloss: 3.1214e-05\n",
      "[1209]\ttraining's binary_logloss: 3.10223e-05\n",
      "[1210]\ttraining's binary_logloss: 3.08396e-05\n",
      "[1211]\ttraining's binary_logloss: 3.06545e-05\n",
      "[1212]\ttraining's binary_logloss: 3.04702e-05\n",
      "[1213]\ttraining's binary_logloss: 3.02958e-05\n",
      "[1214]\ttraining's binary_logloss: 3.01192e-05\n",
      "[1215]\ttraining's binary_logloss: 2.99462e-05\n",
      "[1216]\ttraining's binary_logloss: 2.97637e-05\n",
      "[1217]\ttraining's binary_logloss: 2.95872e-05\n",
      "[1218]\ttraining's binary_logloss: 2.94039e-05\n",
      "[1219]\ttraining's binary_logloss: 2.92331e-05\n",
      "[1220]\ttraining's binary_logloss: 2.90623e-05\n",
      "[1221]\ttraining's binary_logloss: 2.88933e-05\n",
      "[1222]\ttraining's binary_logloss: 2.87284e-05\n",
      "[1223]\ttraining's binary_logloss: 2.8561e-05\n",
      "[1224]\ttraining's binary_logloss: 2.83936e-05\n",
      "[1225]\ttraining's binary_logloss: 2.82257e-05\n",
      "[1226]\ttraining's binary_logloss: 2.80766e-05\n",
      "[1227]\ttraining's binary_logloss: 2.79171e-05\n",
      "[1228]\ttraining's binary_logloss: 2.77594e-05\n",
      "[1229]\ttraining's binary_logloss: 2.76022e-05\n",
      "[1230]\ttraining's binary_logloss: 2.74403e-05\n",
      "[1231]\ttraining's binary_logloss: 2.72812e-05\n",
      "[1232]\ttraining's binary_logloss: 2.71343e-05\n",
      "[1233]\ttraining's binary_logloss: 2.69807e-05\n",
      "[1234]\ttraining's binary_logloss: 2.68239e-05\n",
      "[1235]\ttraining's binary_logloss: 2.66876e-05\n",
      "[1236]\ttraining's binary_logloss: 2.65518e-05\n",
      "[1237]\ttraining's binary_logloss: 2.64087e-05\n",
      "[1238]\ttraining's binary_logloss: 2.62584e-05\n",
      "[1239]\ttraining's binary_logloss: 2.6112e-05\n",
      "[1240]\ttraining's binary_logloss: 2.59584e-05\n",
      "[1241]\ttraining's binary_logloss: 2.58125e-05\n",
      "[1242]\ttraining's binary_logloss: 2.56712e-05\n",
      "[1243]\ttraining's binary_logloss: 2.55385e-05\n",
      "[1244]\ttraining's binary_logloss: 2.54013e-05\n",
      "[1245]\ttraining's binary_logloss: 2.52685e-05\n",
      "[1246]\ttraining's binary_logloss: 2.51352e-05\n",
      "[1247]\ttraining's binary_logloss: 2.50004e-05\n",
      "[1248]\ttraining's binary_logloss: 2.48608e-05\n",
      "[1249]\ttraining's binary_logloss: 2.47287e-05\n",
      "[1250]\ttraining's binary_logloss: 2.4598e-05\n",
      "[1251]\ttraining's binary_logloss: 2.44708e-05\n",
      "[1252]\ttraining's binary_logloss: 2.43439e-05\n",
      "[1253]\ttraining's binary_logloss: 2.42199e-05\n",
      "[1254]\ttraining's binary_logloss: 2.41049e-05\n",
      "[1255]\ttraining's binary_logloss: 2.39817e-05\n",
      "[1256]\ttraining's binary_logloss: 2.38617e-05\n",
      "[1257]\ttraining's binary_logloss: 2.37355e-05\n",
      "[1258]\ttraining's binary_logloss: 2.36101e-05\n",
      "[1259]\ttraining's binary_logloss: 2.34888e-05\n",
      "[1260]\ttraining's binary_logloss: 2.33702e-05\n",
      "[1261]\ttraining's binary_logloss: 2.32552e-05\n",
      "[1262]\ttraining's binary_logloss: 2.31414e-05\n",
      "[1263]\ttraining's binary_logloss: 2.30157e-05\n",
      "[1264]\ttraining's binary_logloss: 2.28976e-05\n",
      "[1265]\ttraining's binary_logloss: 2.2766e-05\n",
      "[1266]\ttraining's binary_logloss: 2.26494e-05\n",
      "[1267]\ttraining's binary_logloss: 2.25387e-05\n",
      "[1268]\ttraining's binary_logloss: 2.24253e-05\n",
      "[1269]\ttraining's binary_logloss: 2.23098e-05\n",
      "[1270]\ttraining's binary_logloss: 2.22044e-05\n",
      "[1271]\ttraining's binary_logloss: 2.20947e-05\n",
      "[1272]\ttraining's binary_logloss: 2.19858e-05\n",
      "[1273]\ttraining's binary_logloss: 2.18875e-05\n",
      "[1274]\ttraining's binary_logloss: 2.17842e-05\n",
      "[1275]\ttraining's binary_logloss: 2.16757e-05\n",
      "[1276]\ttraining's binary_logloss: 2.1573e-05\n",
      "[1277]\ttraining's binary_logloss: 2.14724e-05\n",
      "[1278]\ttraining's binary_logloss: 2.13613e-05\n",
      "[1279]\ttraining's binary_logloss: 2.12574e-05\n",
      "[1280]\ttraining's binary_logloss: 2.11617e-05\n",
      "[1281]\ttraining's binary_logloss: 2.10606e-05\n",
      "[1282]\ttraining's binary_logloss: 2.0957e-05\n",
      "[1283]\ttraining's binary_logloss: 2.08634e-05\n",
      "[1284]\ttraining's binary_logloss: 2.07604e-05\n",
      "[1285]\ttraining's binary_logloss: 2.06674e-05\n",
      "[1286]\ttraining's binary_logloss: 2.05772e-05\n",
      "[1287]\ttraining's binary_logloss: 2.04733e-05\n",
      "[1288]\ttraining's binary_logloss: 2.03855e-05\n",
      "[1289]\ttraining's binary_logloss: 2.02933e-05\n",
      "[1290]\ttraining's binary_logloss: 2.02091e-05\n",
      "[1291]\ttraining's binary_logloss: 2.01142e-05\n",
      "[1292]\ttraining's binary_logloss: 2.00315e-05\n",
      "[1293]\ttraining's binary_logloss: 1.99423e-05\n",
      "[1294]\ttraining's binary_logloss: 1.9856e-05\n",
      "[1295]\ttraining's binary_logloss: 1.97659e-05\n",
      "[1296]\ttraining's binary_logloss: 1.96697e-05\n",
      "[1297]\ttraining's binary_logloss: 1.95924e-05\n",
      "[1298]\ttraining's binary_logloss: 1.95056e-05\n",
      "[1299]\ttraining's binary_logloss: 1.94249e-05\n",
      "[1300]\ttraining's binary_logloss: 1.93382e-05\n",
      "[1301]\ttraining's binary_logloss: 1.92559e-05\n",
      "[1302]\ttraining's binary_logloss: 1.91701e-05\n",
      "[1303]\ttraining's binary_logloss: 1.90876e-05\n",
      "[1304]\ttraining's binary_logloss: 1.90029e-05\n",
      "[1305]\ttraining's binary_logloss: 1.89239e-05\n",
      "[1306]\ttraining's binary_logloss: 1.88508e-05\n",
      "[1307]\ttraining's binary_logloss: 1.87665e-05\n",
      "[1308]\ttraining's binary_logloss: 1.86883e-05\n",
      "[1309]\ttraining's binary_logloss: 1.86108e-05\n",
      "[1310]\ttraining's binary_logloss: 1.85327e-05\n",
      "[1311]\ttraining's binary_logloss: 1.84568e-05\n",
      "[1312]\ttraining's binary_logloss: 1.83705e-05\n",
      "[1313]\ttraining's binary_logloss: 1.82926e-05\n",
      "[1314]\ttraining's binary_logloss: 1.82225e-05\n",
      "[1315]\ttraining's binary_logloss: 1.81447e-05\n",
      "[1316]\ttraining's binary_logloss: 1.80673e-05\n",
      "[1317]\ttraining's binary_logloss: 1.79949e-05\n",
      "[1318]\ttraining's binary_logloss: 1.79188e-05\n",
      "[1319]\ttraining's binary_logloss: 1.78471e-05\n",
      "[1320]\ttraining's binary_logloss: 1.7777e-05\n",
      "[1321]\ttraining's binary_logloss: 1.77051e-05\n",
      "[1322]\ttraining's binary_logloss: 1.7637e-05\n",
      "[1323]\ttraining's binary_logloss: 1.75622e-05\n",
      "[1324]\ttraining's binary_logloss: 1.74957e-05\n",
      "[1325]\ttraining's binary_logloss: 1.74316e-05\n",
      "[1326]\ttraining's binary_logloss: 1.73651e-05\n",
      "[1327]\ttraining's binary_logloss: 1.72979e-05\n",
      "[1328]\ttraining's binary_logloss: 1.72323e-05\n",
      "[1329]\ttraining's binary_logloss: 1.71631e-05\n",
      "[1330]\ttraining's binary_logloss: 1.70984e-05\n",
      "[1331]\ttraining's binary_logloss: 1.70318e-05\n",
      "[1332]\ttraining's binary_logloss: 1.69628e-05\n",
      "[1333]\ttraining's binary_logloss: 1.68973e-05\n",
      "[1334]\ttraining's binary_logloss: 1.68325e-05\n",
      "[1335]\ttraining's binary_logloss: 1.67683e-05\n",
      "[1336]\ttraining's binary_logloss: 1.66981e-05\n",
      "[1337]\ttraining's binary_logloss: 1.66362e-05\n",
      "[1338]\ttraining's binary_logloss: 1.65791e-05\n",
      "[1339]\ttraining's binary_logloss: 1.65187e-05\n",
      "[1340]\ttraining's binary_logloss: 1.64577e-05\n",
      "[1341]\ttraining's binary_logloss: 1.63935e-05\n",
      "[1342]\ttraining's binary_logloss: 1.63355e-05\n",
      "[1343]\ttraining's binary_logloss: 1.62722e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1344]\ttraining's binary_logloss: 1.62183e-05\n",
      "[1345]\ttraining's binary_logloss: 1.6161e-05\n",
      "[1346]\ttraining's binary_logloss: 1.61064e-05\n",
      "[1347]\ttraining's binary_logloss: 1.605e-05\n",
      "[1348]\ttraining's binary_logloss: 1.59934e-05\n",
      "[1349]\ttraining's binary_logloss: 1.59328e-05\n",
      "[1350]\ttraining's binary_logloss: 1.58742e-05\n",
      "[1351]\ttraining's binary_logloss: 1.58222e-05\n",
      "[1352]\ttraining's binary_logloss: 1.57637e-05\n",
      "[1353]\ttraining's binary_logloss: 1.57048e-05\n",
      "[1354]\ttraining's binary_logloss: 1.56482e-05\n",
      "[1355]\ttraining's binary_logloss: 1.55935e-05\n",
      "[1356]\ttraining's binary_logloss: 1.55417e-05\n",
      "[1357]\ttraining's binary_logloss: 1.54888e-05\n",
      "[1358]\ttraining's binary_logloss: 1.54332e-05\n",
      "[1359]\ttraining's binary_logloss: 1.53762e-05\n",
      "[1360]\ttraining's binary_logloss: 1.53159e-05\n",
      "[1361]\ttraining's binary_logloss: 1.52665e-05\n",
      "[1362]\ttraining's binary_logloss: 1.52178e-05\n",
      "[1363]\ttraining's binary_logloss: 1.51688e-05\n",
      "[1364]\ttraining's binary_logloss: 1.51197e-05\n",
      "[1365]\ttraining's binary_logloss: 1.50705e-05\n",
      "[1366]\ttraining's binary_logloss: 1.50219e-05\n",
      "[1367]\ttraining's binary_logloss: 1.49734e-05\n",
      "[1368]\ttraining's binary_logloss: 1.49189e-05\n",
      "[1369]\ttraining's binary_logloss: 1.48617e-05\n",
      "[1370]\ttraining's binary_logloss: 1.48146e-05\n",
      "[1371]\ttraining's binary_logloss: 1.47644e-05\n",
      "[1372]\ttraining's binary_logloss: 1.47107e-05\n",
      "[1373]\ttraining's binary_logloss: 1.46607e-05\n",
      "[1374]\ttraining's binary_logloss: 1.46148e-05\n",
      "[1375]\ttraining's binary_logloss: 1.45734e-05\n",
      "[1376]\ttraining's binary_logloss: 1.45312e-05\n",
      "[1377]\ttraining's binary_logloss: 1.44846e-05\n",
      "[1378]\ttraining's binary_logloss: 1.44388e-05\n",
      "[1379]\ttraining's binary_logloss: 1.43874e-05\n",
      "[1380]\ttraining's binary_logloss: 1.43405e-05\n",
      "[1381]\ttraining's binary_logloss: 1.42999e-05\n",
      "[1382]\ttraining's binary_logloss: 1.42559e-05\n",
      "[1383]\ttraining's binary_logloss: 1.42097e-05\n",
      "[1384]\ttraining's binary_logloss: 1.4161e-05\n",
      "[1385]\ttraining's binary_logloss: 1.4116e-05\n",
      "[1386]\ttraining's binary_logloss: 1.40719e-05\n",
      "[1387]\ttraining's binary_logloss: 1.40281e-05\n",
      "[1388]\ttraining's binary_logloss: 1.39906e-05\n",
      "[1389]\ttraining's binary_logloss: 1.39444e-05\n",
      "[1390]\ttraining's binary_logloss: 1.39046e-05\n",
      "[1391]\ttraining's binary_logloss: 1.38599e-05\n",
      "[1392]\ttraining's binary_logloss: 1.38123e-05\n",
      "[1393]\ttraining's binary_logloss: 1.37677e-05\n",
      "[1394]\ttraining's binary_logloss: 1.37244e-05\n",
      "[1395]\ttraining's binary_logloss: 1.36811e-05\n",
      "[1396]\ttraining's binary_logloss: 1.36341e-05\n",
      "[1397]\ttraining's binary_logloss: 1.35948e-05\n",
      "[1398]\ttraining's binary_logloss: 1.35552e-05\n",
      "[1399]\ttraining's binary_logloss: 1.3517e-05\n",
      "[1400]\ttraining's binary_logloss: 1.34772e-05\n",
      "[1401]\ttraining's binary_logloss: 1.34377e-05\n",
      "[1402]\ttraining's binary_logloss: 1.34005e-05\n",
      "[1403]\ttraining's binary_logloss: 1.33606e-05\n",
      "[1404]\ttraining's binary_logloss: 1.33214e-05\n",
      "[1405]\ttraining's binary_logloss: 1.32806e-05\n",
      "[1406]\ttraining's binary_logloss: 1.3243e-05\n",
      "[1407]\ttraining's binary_logloss: 1.32016e-05\n",
      "[1408]\ttraining's binary_logloss: 1.3162e-05\n",
      "[1409]\ttraining's binary_logloss: 1.31228e-05\n",
      "[1410]\ttraining's binary_logloss: 1.30869e-05\n",
      "[1411]\ttraining's binary_logloss: 1.30484e-05\n",
      "[1412]\ttraining's binary_logloss: 1.30114e-05\n",
      "[1413]\ttraining's binary_logloss: 1.29734e-05\n",
      "[1414]\ttraining's binary_logloss: 1.2934e-05\n",
      "[1415]\ttraining's binary_logloss: 1.28926e-05\n",
      "[1416]\ttraining's binary_logloss: 1.28537e-05\n",
      "[1417]\ttraining's binary_logloss: 1.28151e-05\n",
      "[1418]\ttraining's binary_logloss: 1.27791e-05\n",
      "[1419]\ttraining's binary_logloss: 1.27419e-05\n",
      "[1420]\ttraining's binary_logloss: 1.2705e-05\n",
      "[1421]\ttraining's binary_logloss: 1.26722e-05\n",
      "[1422]\ttraining's binary_logloss: 1.26354e-05\n",
      "[1423]\ttraining's binary_logloss: 1.26014e-05\n",
      "[1424]\ttraining's binary_logloss: 1.25652e-05\n",
      "[1425]\ttraining's binary_logloss: 1.25301e-05\n",
      "[1426]\ttraining's binary_logloss: 1.24968e-05\n",
      "[1427]\ttraining's binary_logloss: 1.2464e-05\n",
      "[1428]\ttraining's binary_logloss: 1.24294e-05\n",
      "[1429]\ttraining's binary_logloss: 1.23963e-05\n",
      "[1430]\ttraining's binary_logloss: 1.23596e-05\n",
      "[1431]\ttraining's binary_logloss: 1.2325e-05\n",
      "[1432]\ttraining's binary_logloss: 1.229e-05\n",
      "[1433]\ttraining's binary_logloss: 1.22525e-05\n",
      "[1434]\ttraining's binary_logloss: 1.22209e-05\n",
      "[1435]\ttraining's binary_logloss: 1.21859e-05\n",
      "[1436]\ttraining's binary_logloss: 1.21502e-05\n",
      "[1437]\ttraining's binary_logloss: 1.21177e-05\n",
      "[1438]\ttraining's binary_logloss: 1.20857e-05\n",
      "[1439]\ttraining's binary_logloss: 1.2055e-05\n",
      "[1440]\ttraining's binary_logloss: 1.202e-05\n",
      "[1441]\ttraining's binary_logloss: 1.19894e-05\n",
      "[1442]\ttraining's binary_logloss: 1.19603e-05\n",
      "[1443]\ttraining's binary_logloss: 1.19265e-05\n",
      "[1444]\ttraining's binary_logloss: 1.18948e-05\n",
      "[1445]\ttraining's binary_logloss: 1.18635e-05\n",
      "[1446]\ttraining's binary_logloss: 1.18333e-05\n",
      "[1447]\ttraining's binary_logloss: 1.1802e-05\n",
      "[1448]\ttraining's binary_logloss: 1.17665e-05\n",
      "[1449]\ttraining's binary_logloss: 1.17387e-05\n",
      "[1450]\ttraining's binary_logloss: 1.17082e-05\n",
      "[1451]\ttraining's binary_logloss: 1.16815e-05\n",
      "[1452]\ttraining's binary_logloss: 1.16547e-05\n",
      "[1453]\ttraining's binary_logloss: 1.16247e-05\n",
      "[1454]\ttraining's binary_logloss: 1.1593e-05\n",
      "[1455]\ttraining's binary_logloss: 1.15608e-05\n",
      "[1456]\ttraining's binary_logloss: 1.15326e-05\n",
      "[1457]\ttraining's binary_logloss: 1.15066e-05\n",
      "[1458]\ttraining's binary_logloss: 1.14765e-05\n",
      "[1459]\ttraining's binary_logloss: 1.14457e-05\n",
      "[1460]\ttraining's binary_logloss: 1.14191e-05\n",
      "[1461]\ttraining's binary_logloss: 1.13906e-05\n",
      "[1462]\ttraining's binary_logloss: 1.13586e-05\n",
      "[1463]\ttraining's binary_logloss: 1.13275e-05\n",
      "[1464]\ttraining's binary_logloss: 1.12933e-05\n",
      "[1465]\ttraining's binary_logloss: 1.12666e-05\n",
      "[1466]\ttraining's binary_logloss: 1.12392e-05\n",
      "[1467]\ttraining's binary_logloss: 1.12118e-05\n",
      "[1468]\ttraining's binary_logloss: 1.11832e-05\n",
      "[1469]\ttraining's binary_logloss: 1.11551e-05\n",
      "[1470]\ttraining's binary_logloss: 1.11271e-05\n",
      "[1471]\ttraining's binary_logloss: 1.10981e-05\n",
      "[1472]\ttraining's binary_logloss: 1.10736e-05\n",
      "[1473]\ttraining's binary_logloss: 1.10449e-05\n",
      "[1474]\ttraining's binary_logloss: 1.10184e-05\n",
      "[1475]\ttraining's binary_logloss: 1.09931e-05\n",
      "[1476]\ttraining's binary_logloss: 1.09644e-05\n",
      "[1477]\ttraining's binary_logloss: 1.09343e-05\n",
      "[1478]\ttraining's binary_logloss: 1.09084e-05\n",
      "[1479]\ttraining's binary_logloss: 1.08803e-05\n",
      "[1480]\ttraining's binary_logloss: 1.08546e-05\n",
      "[1481]\ttraining's binary_logloss: 1.08294e-05\n",
      "[1482]\ttraining's binary_logloss: 1.08037e-05\n",
      "[1483]\ttraining's binary_logloss: 1.07775e-05\n",
      "[1484]\ttraining's binary_logloss: 1.07524e-05\n",
      "[1485]\ttraining's binary_logloss: 1.07272e-05\n",
      "[1486]\ttraining's binary_logloss: 1.07016e-05\n",
      "[1487]\ttraining's binary_logloss: 1.06768e-05\n",
      "[1488]\ttraining's binary_logloss: 1.06519e-05\n",
      "[1489]\ttraining's binary_logloss: 1.06264e-05\n",
      "[1490]\ttraining's binary_logloss: 1.06024e-05\n",
      "[1491]\ttraining's binary_logloss: 1.05792e-05\n",
      "[1492]\ttraining's binary_logloss: 1.05523e-05\n",
      "[1493]\ttraining's binary_logloss: 1.05294e-05\n",
      "[1494]\ttraining's binary_logloss: 1.05048e-05\n",
      "[1495]\ttraining's binary_logloss: 1.04808e-05\n",
      "[1496]\ttraining's binary_logloss: 1.04563e-05\n",
      "[1497]\ttraining's binary_logloss: 1.0432e-05\n",
      "[1498]\ttraining's binary_logloss: 1.04079e-05\n",
      "[1499]\ttraining's binary_logloss: 1.03835e-05\n",
      "[1500]\ttraining's binary_logloss: 1.0362e-05\n",
      "[1501]\ttraining's binary_logloss: 1.0335e-05\n",
      "[1502]\ttraining's binary_logloss: 1.03106e-05\n",
      "[1503]\ttraining's binary_logloss: 1.02872e-05\n",
      "[1504]\ttraining's binary_logloss: 1.02636e-05\n",
      "[1505]\ttraining's binary_logloss: 1.02396e-05\n",
      "[1506]\ttraining's binary_logloss: 1.02181e-05\n",
      "[1507]\ttraining's binary_logloss: 1.01966e-05\n",
      "[1508]\ttraining's binary_logloss: 1.01741e-05\n",
      "[1509]\ttraining's binary_logloss: 1.01521e-05\n",
      "[1510]\ttraining's binary_logloss: 1.01288e-05\n",
      "[1511]\ttraining's binary_logloss: 1.0106e-05\n",
      "[1512]\ttraining's binary_logloss: 1.00832e-05\n",
      "[1513]\ttraining's binary_logloss: 1.00618e-05\n",
      "[1514]\ttraining's binary_logloss: 1.00403e-05\n",
      "[1515]\ttraining's binary_logloss: 1.00176e-05\n",
      "[1516]\ttraining's binary_logloss: 9.99919e-06\n",
      "[1517]\ttraining's binary_logloss: 9.97574e-06\n",
      "[1518]\ttraining's binary_logloss: 9.95281e-06\n",
      "[1519]\ttraining's binary_logloss: 9.9291e-06\n",
      "[1520]\ttraining's binary_logloss: 9.90533e-06\n",
      "[1521]\ttraining's binary_logloss: 9.88469e-06\n",
      "[1522]\ttraining's binary_logloss: 9.86357e-06\n",
      "[1523]\ttraining's binary_logloss: 9.84037e-06\n",
      "[1524]\ttraining's binary_logloss: 9.82054e-06\n",
      "[1525]\ttraining's binary_logloss: 9.79536e-06\n",
      "[1526]\ttraining's binary_logloss: 9.77456e-06\n",
      "[1527]\ttraining's binary_logloss: 9.75455e-06\n",
      "[1528]\ttraining's binary_logloss: 9.73511e-06\n",
      "[1529]\ttraining's binary_logloss: 9.71586e-06\n",
      "[1530]\ttraining's binary_logloss: 9.69467e-06\n",
      "[1531]\ttraining's binary_logloss: 9.67402e-06\n",
      "[1532]\ttraining's binary_logloss: 9.6536e-06\n",
      "[1533]\ttraining's binary_logloss: 9.63375e-06\n",
      "[1534]\ttraining's binary_logloss: 9.61467e-06\n",
      "[1535]\ttraining's binary_logloss: 9.59409e-06\n",
      "[1536]\ttraining's binary_logloss: 9.57502e-06\n",
      "[1537]\ttraining's binary_logloss: 9.55519e-06\n",
      "[1538]\ttraining's binary_logloss: 9.53333e-06\n",
      "[1539]\ttraining's binary_logloss: 9.5152e-06\n",
      "[1540]\ttraining's binary_logloss: 9.49633e-06\n",
      "[1541]\ttraining's binary_logloss: 9.47706e-06\n",
      "[1542]\ttraining's binary_logloss: 9.45786e-06\n",
      "[1543]\ttraining's binary_logloss: 9.43997e-06\n",
      "[1544]\ttraining's binary_logloss: 9.42425e-06\n",
      "[1545]\ttraining's binary_logloss: 9.40438e-06\n",
      "[1546]\ttraining's binary_logloss: 9.38648e-06\n",
      "[1547]\ttraining's binary_logloss: 9.36729e-06\n",
      "[1548]\ttraining's binary_logloss: 9.3458e-06\n",
      "[1549]\ttraining's binary_logloss: 9.32727e-06\n",
      "[1550]\ttraining's binary_logloss: 9.31044e-06\n",
      "[1551]\ttraining's binary_logloss: 9.29338e-06\n",
      "[1552]\ttraining's binary_logloss: 9.2766e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1553]\ttraining's binary_logloss: 9.25781e-06\n",
      "[1554]\ttraining's binary_logloss: 9.23756e-06\n",
      "[1555]\ttraining's binary_logloss: 9.22115e-06\n",
      "[1556]\ttraining's binary_logloss: 9.20403e-06\n",
      "[1557]\ttraining's binary_logloss: 9.18673e-06\n",
      "[1558]\ttraining's binary_logloss: 9.16882e-06\n",
      "[1559]\ttraining's binary_logloss: 9.15068e-06\n",
      "[1560]\ttraining's binary_logloss: 9.13266e-06\n",
      "[1561]\ttraining's binary_logloss: 9.11568e-06\n",
      "[1562]\ttraining's binary_logloss: 9.0989e-06\n",
      "[1563]\ttraining's binary_logloss: 9.07901e-06\n",
      "[1564]\ttraining's binary_logloss: 9.06201e-06\n",
      "[1565]\ttraining's binary_logloss: 9.0431e-06\n",
      "[1566]\ttraining's binary_logloss: 9.02718e-06\n",
      "[1567]\ttraining's binary_logloss: 9.01013e-06\n",
      "[1568]\ttraining's binary_logloss: 8.99377e-06\n",
      "[1569]\ttraining's binary_logloss: 8.97788e-06\n",
      "[1570]\ttraining's binary_logloss: 8.96065e-06\n",
      "[1571]\ttraining's binary_logloss: 8.94516e-06\n",
      "[1572]\ttraining's binary_logloss: 8.92878e-06\n",
      "[1573]\ttraining's binary_logloss: 8.91231e-06\n",
      "[1574]\ttraining's binary_logloss: 8.89579e-06\n",
      "[1575]\ttraining's binary_logloss: 8.87838e-06\n",
      "[1576]\ttraining's binary_logloss: 8.86119e-06\n",
      "[1577]\ttraining's binary_logloss: 8.8417e-06\n",
      "[1578]\ttraining's binary_logloss: 8.82436e-06\n",
      "[1579]\ttraining's binary_logloss: 8.80796e-06\n",
      "[1580]\ttraining's binary_logloss: 8.79146e-06\n",
      "[1581]\ttraining's binary_logloss: 8.77473e-06\n",
      "[1582]\ttraining's binary_logloss: 8.75805e-06\n",
      "[1583]\ttraining's binary_logloss: 8.74204e-06\n",
      "[1584]\ttraining's binary_logloss: 8.72629e-06\n",
      "[1585]\ttraining's binary_logloss: 8.70906e-06\n",
      "[1586]\ttraining's binary_logloss: 8.69291e-06\n",
      "[1587]\ttraining's binary_logloss: 8.67688e-06\n",
      "[1588]\ttraining's binary_logloss: 8.66008e-06\n",
      "[1589]\ttraining's binary_logloss: 8.64476e-06\n",
      "[1590]\ttraining's binary_logloss: 8.6274e-06\n",
      "[1591]\ttraining's binary_logloss: 8.61129e-06\n",
      "[1592]\ttraining's binary_logloss: 8.59635e-06\n",
      "[1593]\ttraining's binary_logloss: 8.57887e-06\n",
      "[1594]\ttraining's binary_logloss: 8.56329e-06\n",
      "[1595]\ttraining's binary_logloss: 8.54776e-06\n",
      "[1596]\ttraining's binary_logloss: 8.53266e-06\n",
      "[1597]\ttraining's binary_logloss: 8.51767e-06\n",
      "[1598]\ttraining's binary_logloss: 8.50286e-06\n",
      "[1599]\ttraining's binary_logloss: 8.48759e-06\n",
      "[1600]\ttraining's binary_logloss: 8.47329e-06\n",
      "[1601]\ttraining's binary_logloss: 8.45901e-06\n",
      "[1602]\ttraining's binary_logloss: 8.44413e-06\n",
      "[1603]\ttraining's binary_logloss: 8.42858e-06\n",
      "[1604]\ttraining's binary_logloss: 8.41495e-06\n",
      "[1605]\ttraining's binary_logloss: 8.3989e-06\n",
      "[1606]\ttraining's binary_logloss: 8.38431e-06\n",
      "[1607]\ttraining's binary_logloss: 8.36922e-06\n",
      "[1608]\ttraining's binary_logloss: 8.3538e-06\n",
      "[1609]\ttraining's binary_logloss: 8.33946e-06\n",
      "[1610]\ttraining's binary_logloss: 8.32557e-06\n",
      "[1611]\ttraining's binary_logloss: 8.31118e-06\n",
      "[1612]\ttraining's binary_logloss: 8.29704e-06\n",
      "[1613]\ttraining's binary_logloss: 8.28307e-06\n",
      "[1614]\ttraining's binary_logloss: 8.26919e-06\n",
      "[1615]\ttraining's binary_logloss: 8.255e-06\n",
      "[1616]\ttraining's binary_logloss: 8.24058e-06\n",
      "[1617]\ttraining's binary_logloss: 8.22654e-06\n",
      "[1618]\ttraining's binary_logloss: 8.2132e-06\n",
      "[1619]\ttraining's binary_logloss: 8.19988e-06\n",
      "[1620]\ttraining's binary_logloss: 8.18653e-06\n",
      "[1621]\ttraining's binary_logloss: 8.17288e-06\n",
      "[1622]\ttraining's binary_logloss: 8.16093e-06\n",
      "[1623]\ttraining's binary_logloss: 8.14721e-06\n",
      "[1624]\ttraining's binary_logloss: 8.13373e-06\n",
      "[1625]\ttraining's binary_logloss: 8.12e-06\n",
      "[1626]\ttraining's binary_logloss: 8.10788e-06\n",
      "[1627]\ttraining's binary_logloss: 8.09299e-06\n",
      "[1628]\ttraining's binary_logloss: 8.07988e-06\n",
      "[1629]\ttraining's binary_logloss: 8.06503e-06\n",
      "[1630]\ttraining's binary_logloss: 8.0521e-06\n",
      "[1631]\ttraining's binary_logloss: 8.03819e-06\n",
      "[1632]\ttraining's binary_logloss: 8.02355e-06\n",
      "[1633]\ttraining's binary_logloss: 8.0118e-06\n",
      "[1634]\ttraining's binary_logloss: 7.99962e-06\n",
      "[1635]\ttraining's binary_logloss: 7.98537e-06\n",
      "[1636]\ttraining's binary_logloss: 7.97348e-06\n",
      "[1637]\ttraining's binary_logloss: 7.96072e-06\n",
      "[1638]\ttraining's binary_logloss: 7.94632e-06\n",
      "[1639]\ttraining's binary_logloss: 7.93308e-06\n",
      "[1640]\ttraining's binary_logloss: 7.91992e-06\n",
      "[1641]\ttraining's binary_logloss: 7.90675e-06\n",
      "[1642]\ttraining's binary_logloss: 7.89344e-06\n",
      "[1643]\ttraining's binary_logloss: 7.88213e-06\n",
      "[1644]\ttraining's binary_logloss: 7.86946e-06\n",
      "[1645]\ttraining's binary_logloss: 7.8572e-06\n",
      "[1646]\ttraining's binary_logloss: 7.8439e-06\n",
      "[1647]\ttraining's binary_logloss: 7.83208e-06\n",
      "[1648]\ttraining's binary_logloss: 7.81895e-06\n",
      "[1649]\ttraining's binary_logloss: 7.80534e-06\n",
      "[1650]\ttraining's binary_logloss: 7.79326e-06\n",
      "[1651]\ttraining's binary_logloss: 7.77937e-06\n",
      "[1652]\ttraining's binary_logloss: 7.76536e-06\n",
      "[1653]\ttraining's binary_logloss: 7.75412e-06\n",
      "[1654]\ttraining's binary_logloss: 7.74121e-06\n",
      "[1655]\ttraining's binary_logloss: 7.72886e-06\n",
      "[1656]\ttraining's binary_logloss: 7.71651e-06\n",
      "[1657]\ttraining's binary_logloss: 7.70433e-06\n",
      "[1658]\ttraining's binary_logloss: 7.69141e-06\n",
      "[1659]\ttraining's binary_logloss: 7.67797e-06\n",
      "[1660]\ttraining's binary_logloss: 7.66671e-06\n",
      "[1661]\ttraining's binary_logloss: 7.65476e-06\n",
      "[1662]\ttraining's binary_logloss: 7.64304e-06\n",
      "[1663]\ttraining's binary_logloss: 7.63077e-06\n",
      "[1664]\ttraining's binary_logloss: 7.61962e-06\n",
      "[1665]\ttraining's binary_logloss: 7.60814e-06\n",
      "[1666]\ttraining's binary_logloss: 7.59588e-06\n",
      "[1667]\ttraining's binary_logloss: 7.5838e-06\n",
      "[1668]\ttraining's binary_logloss: 7.57164e-06\n",
      "[1669]\ttraining's binary_logloss: 7.56149e-06\n",
      "[1670]\ttraining's binary_logloss: 7.54928e-06\n",
      "[1671]\ttraining's binary_logloss: 7.53736e-06\n",
      "[1672]\ttraining's binary_logloss: 7.52447e-06\n",
      "[1673]\ttraining's binary_logloss: 7.513e-06\n",
      "[1674]\ttraining's binary_logloss: 7.50343e-06\n",
      "[1675]\ttraining's binary_logloss: 7.49158e-06\n",
      "[1676]\ttraining's binary_logloss: 7.48048e-06\n",
      "[1677]\ttraining's binary_logloss: 7.46936e-06\n",
      "[1678]\ttraining's binary_logloss: 7.45792e-06\n",
      "[1679]\ttraining's binary_logloss: 7.4472e-06\n",
      "[1680]\ttraining's binary_logloss: 7.43644e-06\n",
      "[1681]\ttraining's binary_logloss: 7.4252e-06\n",
      "[1682]\ttraining's binary_logloss: 7.4122e-06\n",
      "[1683]\ttraining's binary_logloss: 7.40159e-06\n",
      "[1684]\ttraining's binary_logloss: 7.39083e-06\n",
      "[1685]\ttraining's binary_logloss: 7.38094e-06\n",
      "[1686]\ttraining's binary_logloss: 7.36909e-06\n",
      "[1687]\ttraining's binary_logloss: 7.35807e-06\n",
      "[1688]\ttraining's binary_logloss: 7.34752e-06\n",
      "[1689]\ttraining's binary_logloss: 7.33719e-06\n",
      "[1690]\ttraining's binary_logloss: 7.32672e-06\n",
      "[1691]\ttraining's binary_logloss: 7.31469e-06\n",
      "[1692]\ttraining's binary_logloss: 7.303e-06\n",
      "[1693]\ttraining's binary_logloss: 7.2916e-06\n",
      "[1694]\ttraining's binary_logloss: 7.28127e-06\n",
      "[1695]\ttraining's binary_logloss: 7.26931e-06\n",
      "[1696]\ttraining's binary_logloss: 7.25872e-06\n",
      "[1697]\ttraining's binary_logloss: 7.24913e-06\n",
      "[1698]\ttraining's binary_logloss: 7.2373e-06\n",
      "[1699]\ttraining's binary_logloss: 7.22752e-06\n",
      "[1700]\ttraining's binary_logloss: 7.21647e-06\n",
      "[1701]\ttraining's binary_logloss: 7.20297e-06\n",
      "[1702]\ttraining's binary_logloss: 7.19237e-06\n",
      "[1703]\ttraining's binary_logloss: 7.18318e-06\n",
      "[1704]\ttraining's binary_logloss: 7.17382e-06\n",
      "[1705]\ttraining's binary_logloss: 7.16347e-06\n",
      "[1706]\ttraining's binary_logloss: 7.15342e-06\n",
      "[1707]\ttraining's binary_logloss: 7.14289e-06\n",
      "[1708]\ttraining's binary_logloss: 7.13269e-06\n",
      "[1709]\ttraining's binary_logloss: 7.12199e-06\n",
      "[1710]\ttraining's binary_logloss: 7.1124e-06\n",
      "[1711]\ttraining's binary_logloss: 7.10249e-06\n",
      "[1712]\ttraining's binary_logloss: 7.09169e-06\n",
      "[1713]\ttraining's binary_logloss: 7.08122e-06\n",
      "[1714]\ttraining's binary_logloss: 7.07058e-06\n",
      "[1715]\ttraining's binary_logloss: 7.05996e-06\n",
      "[1716]\ttraining's binary_logloss: 7.04942e-06\n",
      "[1717]\ttraining's binary_logloss: 7.0395e-06\n",
      "[1718]\ttraining's binary_logloss: 7.02977e-06\n",
      "[1719]\ttraining's binary_logloss: 7.01974e-06\n",
      "[1720]\ttraining's binary_logloss: 7.00971e-06\n",
      "[1721]\ttraining's binary_logloss: 6.99914e-06\n",
      "[1722]\ttraining's binary_logloss: 6.98951e-06\n",
      "[1723]\ttraining's binary_logloss: 6.97997e-06\n",
      "[1724]\ttraining's binary_logloss: 6.96952e-06\n",
      "[1725]\ttraining's binary_logloss: 6.96014e-06\n",
      "[1726]\ttraining's binary_logloss: 6.9508e-06\n",
      "[1727]\ttraining's binary_logloss: 6.94008e-06\n",
      "[1728]\ttraining's binary_logloss: 6.93092e-06\n",
      "[1729]\ttraining's binary_logloss: 6.92127e-06\n",
      "[1730]\ttraining's binary_logloss: 6.91187e-06\n",
      "[1731]\ttraining's binary_logloss: 6.90268e-06\n",
      "[1732]\ttraining's binary_logloss: 6.89239e-06\n",
      "[1733]\ttraining's binary_logloss: 6.88345e-06\n",
      "[1734]\ttraining's binary_logloss: 6.8739e-06\n",
      "[1735]\ttraining's binary_logloss: 6.86487e-06\n",
      "[1736]\ttraining's binary_logloss: 6.85616e-06\n",
      "[1737]\ttraining's binary_logloss: 6.84685e-06\n",
      "[1738]\ttraining's binary_logloss: 6.83805e-06\n",
      "[1739]\ttraining's binary_logloss: 6.82827e-06\n",
      "[1740]\ttraining's binary_logloss: 6.8193e-06\n",
      "[1741]\ttraining's binary_logloss: 6.81079e-06\n",
      "[1742]\ttraining's binary_logloss: 6.80147e-06\n",
      "[1743]\ttraining's binary_logloss: 6.79158e-06\n",
      "[1744]\ttraining's binary_logloss: 6.78321e-06\n",
      "[1745]\ttraining's binary_logloss: 6.77417e-06\n",
      "[1746]\ttraining's binary_logloss: 6.76477e-06\n",
      "[1747]\ttraining's binary_logloss: 6.75567e-06\n",
      "[1748]\ttraining's binary_logloss: 6.74736e-06\n",
      "[1749]\ttraining's binary_logloss: 6.73847e-06\n",
      "[1750]\ttraining's binary_logloss: 6.73035e-06\n",
      "[1751]\ttraining's binary_logloss: 6.72054e-06\n",
      "[1752]\ttraining's binary_logloss: 6.7118e-06\n",
      "[1753]\ttraining's binary_logloss: 6.70276e-06\n",
      "[1754]\ttraining's binary_logloss: 6.69366e-06\n",
      "[1755]\ttraining's binary_logloss: 6.686e-06\n",
      "[1756]\ttraining's binary_logloss: 6.6769e-06\n",
      "[1757]\ttraining's binary_logloss: 6.66747e-06\n",
      "[1758]\ttraining's binary_logloss: 6.65871e-06\n",
      "[1759]\ttraining's binary_logloss: 6.64827e-06\n",
      "[1760]\ttraining's binary_logloss: 6.63855e-06\n",
      "[1761]\ttraining's binary_logloss: 6.63049e-06\n",
      "[1762]\ttraining's binary_logloss: 6.62162e-06\n",
      "[1763]\ttraining's binary_logloss: 6.6128e-06\n",
      "[1764]\ttraining's binary_logloss: 6.60458e-06\n",
      "[1765]\ttraining's binary_logloss: 6.59592e-06\n",
      "[1766]\ttraining's binary_logloss: 6.58789e-06\n",
      "[1767]\ttraining's binary_logloss: 6.57897e-06\n",
      "[1768]\ttraining's binary_logloss: 6.56972e-06\n",
      "[1769]\ttraining's binary_logloss: 6.56191e-06\n",
      "[1770]\ttraining's binary_logloss: 6.55289e-06\n",
      "[1771]\ttraining's binary_logloss: 6.54412e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1772]\ttraining's binary_logloss: 6.53492e-06\n",
      "[1773]\ttraining's binary_logloss: 6.52657e-06\n",
      "[1774]\ttraining's binary_logloss: 6.51756e-06\n",
      "[1775]\ttraining's binary_logloss: 6.50965e-06\n",
      "[1776]\ttraining's binary_logloss: 6.50126e-06\n",
      "[1777]\ttraining's binary_logloss: 6.49219e-06\n",
      "[1778]\ttraining's binary_logloss: 6.48339e-06\n",
      "[1779]\ttraining's binary_logloss: 6.47467e-06\n",
      "[1780]\ttraining's binary_logloss: 6.46675e-06\n",
      "[1781]\ttraining's binary_logloss: 6.45843e-06\n",
      "[1782]\ttraining's binary_logloss: 6.44942e-06\n",
      "[1783]\ttraining's binary_logloss: 6.44213e-06\n",
      "[1784]\ttraining's binary_logloss: 6.43393e-06\n",
      "[1785]\ttraining's binary_logloss: 6.42529e-06\n",
      "[1786]\ttraining's binary_logloss: 6.41752e-06\n",
      "[1787]\ttraining's binary_logloss: 6.40996e-06\n",
      "[1788]\ttraining's binary_logloss: 6.40191e-06\n",
      "[1789]\ttraining's binary_logloss: 6.39398e-06\n",
      "[1790]\ttraining's binary_logloss: 6.38634e-06\n",
      "[1791]\ttraining's binary_logloss: 6.37877e-06\n",
      "[1792]\ttraining's binary_logloss: 6.37166e-06\n",
      "[1793]\ttraining's binary_logloss: 6.36367e-06\n",
      "[1794]\ttraining's binary_logloss: 6.35627e-06\n",
      "[1795]\ttraining's binary_logloss: 6.34901e-06\n",
      "[1796]\ttraining's binary_logloss: 6.34119e-06\n",
      "[1797]\ttraining's binary_logloss: 6.33371e-06\n",
      "[1798]\ttraining's binary_logloss: 6.32558e-06\n",
      "[1799]\ttraining's binary_logloss: 6.31841e-06\n",
      "[1800]\ttraining's binary_logloss: 6.3106e-06\n",
      "[1801]\ttraining's binary_logloss: 6.30273e-06\n",
      "[1802]\ttraining's binary_logloss: 6.29586e-06\n",
      "[1803]\ttraining's binary_logloss: 6.28893e-06\n",
      "[1804]\ttraining's binary_logloss: 6.28086e-06\n",
      "[1805]\ttraining's binary_logloss: 6.27356e-06\n",
      "[1806]\ttraining's binary_logloss: 6.26594e-06\n",
      "[1807]\ttraining's binary_logloss: 6.25857e-06\n",
      "[1808]\ttraining's binary_logloss: 6.25149e-06\n",
      "[1809]\ttraining's binary_logloss: 6.24366e-06\n",
      "[1810]\ttraining's binary_logloss: 6.23697e-06\n",
      "[1811]\ttraining's binary_logloss: 6.22941e-06\n",
      "[1812]\ttraining's binary_logloss: 6.22163e-06\n",
      "[1813]\ttraining's binary_logloss: 6.21404e-06\n",
      "[1814]\ttraining's binary_logloss: 6.20617e-06\n",
      "[1815]\ttraining's binary_logloss: 6.19948e-06\n",
      "[1816]\ttraining's binary_logloss: 6.1928e-06\n",
      "[1817]\ttraining's binary_logloss: 6.18511e-06\n",
      "[1818]\ttraining's binary_logloss: 6.17809e-06\n",
      "[1819]\ttraining's binary_logloss: 6.17128e-06\n",
      "[1820]\ttraining's binary_logloss: 6.16402e-06\n",
      "[1821]\ttraining's binary_logloss: 6.15629e-06\n",
      "[1822]\ttraining's binary_logloss: 6.14891e-06\n",
      "[1823]\ttraining's binary_logloss: 6.14081e-06\n",
      "[1824]\ttraining's binary_logloss: 6.13206e-06\n",
      "[1825]\ttraining's binary_logloss: 6.12567e-06\n",
      "[1826]\ttraining's binary_logloss: 6.11864e-06\n",
      "[1827]\ttraining's binary_logloss: 6.11194e-06\n",
      "[1828]\ttraining's binary_logloss: 6.1052e-06\n",
      "[1829]\ttraining's binary_logloss: 6.09847e-06\n",
      "[1830]\ttraining's binary_logloss: 6.09142e-06\n",
      "[1831]\ttraining's binary_logloss: 6.08313e-06\n",
      "[1832]\ttraining's binary_logloss: 6.07543e-06\n",
      "[1833]\ttraining's binary_logloss: 6.06813e-06\n",
      "[1834]\ttraining's binary_logloss: 6.06068e-06\n",
      "[1835]\ttraining's binary_logloss: 6.0532e-06\n",
      "[1836]\ttraining's binary_logloss: 6.04658e-06\n",
      "[1837]\ttraining's binary_logloss: 6.04005e-06\n",
      "[1838]\ttraining's binary_logloss: 6.03357e-06\n",
      "[1839]\ttraining's binary_logloss: 6.02803e-06\n",
      "[1840]\ttraining's binary_logloss: 6.02171e-06\n",
      "[1841]\ttraining's binary_logloss: 6.01517e-06\n",
      "[1842]\ttraining's binary_logloss: 6.00818e-06\n",
      "[1843]\ttraining's binary_logloss: 6.00124e-06\n",
      "[1844]\ttraining's binary_logloss: 5.99385e-06\n",
      "[1845]\ttraining's binary_logloss: 5.98694e-06\n",
      "[1846]\ttraining's binary_logloss: 5.97983e-06\n",
      "[1847]\ttraining's binary_logloss: 5.97246e-06\n",
      "[1848]\ttraining's binary_logloss: 5.96568e-06\n",
      "[1849]\ttraining's binary_logloss: 5.95912e-06\n",
      "[1850]\ttraining's binary_logloss: 5.9521e-06\n",
      "[1851]\ttraining's binary_logloss: 5.94505e-06\n",
      "[1852]\ttraining's binary_logloss: 5.93807e-06\n",
      "[1853]\ttraining's binary_logloss: 5.93068e-06\n",
      "[1854]\ttraining's binary_logloss: 5.92497e-06\n",
      "[1855]\ttraining's binary_logloss: 5.91778e-06\n",
      "[1856]\ttraining's binary_logloss: 5.91069e-06\n",
      "[1857]\ttraining's binary_logloss: 5.90501e-06\n",
      "[1858]\ttraining's binary_logloss: 5.89868e-06\n",
      "[1859]\ttraining's binary_logloss: 5.89222e-06\n",
      "[1860]\ttraining's binary_logloss: 5.88608e-06\n",
      "[1861]\ttraining's binary_logloss: 5.87977e-06\n",
      "[1862]\ttraining's binary_logloss: 5.87368e-06\n",
      "[1863]\ttraining's binary_logloss: 5.86763e-06\n",
      "[1864]\ttraining's binary_logloss: 5.86009e-06\n",
      "[1865]\ttraining's binary_logloss: 5.85279e-06\n",
      "[1866]\ttraining's binary_logloss: 5.84584e-06\n",
      "[1867]\ttraining's binary_logloss: 5.84014e-06\n",
      "[1868]\ttraining's binary_logloss: 5.83429e-06\n",
      "[1869]\ttraining's binary_logloss: 5.82973e-06\n",
      "[1870]\ttraining's binary_logloss: 5.82377e-06\n",
      "[1871]\ttraining's binary_logloss: 5.8178e-06\n",
      "[1872]\ttraining's binary_logloss: 5.8117e-06\n",
      "[1873]\ttraining's binary_logloss: 5.80606e-06\n",
      "[1874]\ttraining's binary_logloss: 5.79977e-06\n",
      "[1875]\ttraining's binary_logloss: 5.79383e-06\n",
      "[1876]\ttraining's binary_logloss: 5.78809e-06\n",
      "[1877]\ttraining's binary_logloss: 5.78136e-06\n",
      "[1878]\ttraining's binary_logloss: 5.77477e-06\n",
      "[1879]\ttraining's binary_logloss: 5.76862e-06\n",
      "[1880]\ttraining's binary_logloss: 5.76285e-06\n",
      "[1881]\ttraining's binary_logloss: 5.7554e-06\n",
      "[1882]\ttraining's binary_logloss: 5.74978e-06\n",
      "[1883]\ttraining's binary_logloss: 5.74227e-06\n",
      "[1884]\ttraining's binary_logloss: 5.73585e-06\n",
      "[1885]\ttraining's binary_logloss: 5.72867e-06\n",
      "[1886]\ttraining's binary_logloss: 5.72316e-06\n",
      "[1887]\ttraining's binary_logloss: 5.717e-06\n",
      "[1888]\ttraining's binary_logloss: 5.71101e-06\n",
      "[1889]\ttraining's binary_logloss: 5.7045e-06\n",
      "[1890]\ttraining's binary_logloss: 5.69837e-06\n",
      "[1891]\ttraining's binary_logloss: 5.69291e-06\n",
      "[1892]\ttraining's binary_logloss: 5.68698e-06\n",
      "[1893]\ttraining's binary_logloss: 5.68081e-06\n",
      "[1894]\ttraining's binary_logloss: 5.67493e-06\n",
      "[1895]\ttraining's binary_logloss: 5.66876e-06\n",
      "[1896]\ttraining's binary_logloss: 5.66263e-06\n",
      "[1897]\ttraining's binary_logloss: 5.6569e-06\n",
      "[1898]\ttraining's binary_logloss: 5.65103e-06\n",
      "[1899]\ttraining's binary_logloss: 5.64546e-06\n",
      "[1900]\ttraining's binary_logloss: 5.63915e-06\n",
      "[1901]\ttraining's binary_logloss: 5.6333e-06\n",
      "[1902]\ttraining's binary_logloss: 5.62708e-06\n",
      "[1903]\ttraining's binary_logloss: 5.62099e-06\n",
      "[1904]\ttraining's binary_logloss: 5.61492e-06\n",
      "[1905]\ttraining's binary_logloss: 5.60894e-06\n",
      "[1906]\ttraining's binary_logloss: 5.60416e-06\n",
      "[1907]\ttraining's binary_logloss: 5.59853e-06\n",
      "[1908]\ttraining's binary_logloss: 5.59154e-06\n",
      "[1909]\ttraining's binary_logloss: 5.58521e-06\n",
      "[1910]\ttraining's binary_logloss: 5.57955e-06\n",
      "[1911]\ttraining's binary_logloss: 5.57364e-06\n",
      "[1912]\ttraining's binary_logloss: 5.56714e-06\n",
      "[1913]\ttraining's binary_logloss: 5.56112e-06\n",
      "[1914]\ttraining's binary_logloss: 5.55574e-06\n",
      "[1915]\ttraining's binary_logloss: 5.54948e-06\n",
      "[1916]\ttraining's binary_logloss: 5.54262e-06\n",
      "[1917]\ttraining's binary_logloss: 5.53732e-06\n",
      "[1918]\ttraining's binary_logloss: 5.5321e-06\n",
      "[1919]\ttraining's binary_logloss: 5.52662e-06\n",
      "[1920]\ttraining's binary_logloss: 5.52104e-06\n",
      "[1921]\ttraining's binary_logloss: 5.51658e-06\n",
      "[1922]\ttraining's binary_logloss: 5.51155e-06\n",
      "[1923]\ttraining's binary_logloss: 5.50561e-06\n",
      "[1924]\ttraining's binary_logloss: 5.50007e-06\n",
      "[1925]\ttraining's binary_logloss: 5.49511e-06\n",
      "[1926]\ttraining's binary_logloss: 5.48919e-06\n",
      "[1927]\ttraining's binary_logloss: 5.48303e-06\n",
      "[1928]\ttraining's binary_logloss: 5.47692e-06\n",
      "[1929]\ttraining's binary_logloss: 5.47107e-06\n",
      "[1930]\ttraining's binary_logloss: 5.46635e-06\n",
      "[1931]\ttraining's binary_logloss: 5.46079e-06\n",
      "[1932]\ttraining's binary_logloss: 5.45536e-06\n",
      "[1933]\ttraining's binary_logloss: 5.44939e-06\n",
      "[1934]\ttraining's binary_logloss: 5.44458e-06\n",
      "[1935]\ttraining's binary_logloss: 5.43872e-06\n",
      "[1936]\ttraining's binary_logloss: 5.43237e-06\n",
      "[1937]\ttraining's binary_logloss: 5.42692e-06\n",
      "[1938]\ttraining's binary_logloss: 5.42104e-06\n",
      "[1939]\ttraining's binary_logloss: 5.41502e-06\n",
      "[1940]\ttraining's binary_logloss: 5.40914e-06\n",
      "[1941]\ttraining's binary_logloss: 5.40276e-06\n",
      "[1942]\ttraining's binary_logloss: 5.39721e-06\n",
      "[1943]\ttraining's binary_logloss: 5.39156e-06\n",
      "[1944]\ttraining's binary_logloss: 5.3865e-06\n",
      "[1945]\ttraining's binary_logloss: 5.38112e-06\n",
      "[1946]\ttraining's binary_logloss: 5.37558e-06\n",
      "[1947]\ttraining's binary_logloss: 5.37032e-06\n",
      "[1948]\ttraining's binary_logloss: 5.36499e-06\n",
      "[1949]\ttraining's binary_logloss: 5.35959e-06\n",
      "[1950]\ttraining's binary_logloss: 5.35458e-06\n",
      "[1951]\ttraining's binary_logloss: 5.34946e-06\n",
      "[1952]\ttraining's binary_logloss: 5.34433e-06\n",
      "[1953]\ttraining's binary_logloss: 5.33969e-06\n",
      "[1954]\ttraining's binary_logloss: 5.33394e-06\n",
      "[1955]\ttraining's binary_logloss: 5.32884e-06\n",
      "[1956]\ttraining's binary_logloss: 5.32343e-06\n",
      "[1957]\ttraining's binary_logloss: 5.31797e-06\n",
      "[1958]\ttraining's binary_logloss: 5.31248e-06\n",
      "[1959]\ttraining's binary_logloss: 5.30677e-06\n",
      "[1960]\ttraining's binary_logloss: 5.30158e-06\n",
      "[1961]\ttraining's binary_logloss: 5.29594e-06\n",
      "[1962]\ttraining's binary_logloss: 5.2902e-06\n",
      "[1963]\ttraining's binary_logloss: 5.2857e-06\n",
      "[1964]\ttraining's binary_logloss: 5.28045e-06\n",
      "[1965]\ttraining's binary_logloss: 5.27492e-06\n",
      "[1966]\ttraining's binary_logloss: 5.27036e-06\n",
      "[1967]\ttraining's binary_logloss: 5.26526e-06\n",
      "[1968]\ttraining's binary_logloss: 5.26072e-06\n",
      "[1969]\ttraining's binary_logloss: 5.25524e-06\n",
      "[1970]\ttraining's binary_logloss: 5.25051e-06\n",
      "[1971]\ttraining's binary_logloss: 5.24557e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1972]\ttraining's binary_logloss: 5.24024e-06\n",
      "[1973]\ttraining's binary_logloss: 5.23445e-06\n",
      "[1974]\ttraining's binary_logloss: 5.2301e-06\n",
      "[1975]\ttraining's binary_logloss: 5.22441e-06\n",
      "[1976]\ttraining's binary_logloss: 5.21882e-06\n",
      "[1977]\ttraining's binary_logloss: 5.2137e-06\n",
      "[1978]\ttraining's binary_logloss: 5.2088e-06\n",
      "[1979]\ttraining's binary_logloss: 5.20424e-06\n",
      "[1980]\ttraining's binary_logloss: 5.19881e-06\n",
      "[1981]\ttraining's binary_logloss: 5.19479e-06\n",
      "[1982]\ttraining's binary_logloss: 5.18965e-06\n",
      "[1983]\ttraining's binary_logloss: 5.18484e-06\n",
      "[1984]\ttraining's binary_logloss: 5.18018e-06\n",
      "[1985]\ttraining's binary_logloss: 5.17597e-06\n",
      "[1986]\ttraining's binary_logloss: 5.17166e-06\n",
      "[1987]\ttraining's binary_logloss: 5.16702e-06\n",
      "[1988]\ttraining's binary_logloss: 5.16228e-06\n",
      "[1989]\ttraining's binary_logloss: 5.15773e-06\n",
      "[1990]\ttraining's binary_logloss: 5.15253e-06\n",
      "[1991]\ttraining's binary_logloss: 5.1477e-06\n",
      "[1992]\ttraining's binary_logloss: 5.14276e-06\n",
      "[1993]\ttraining's binary_logloss: 5.13758e-06\n",
      "[1994]\ttraining's binary_logloss: 5.13204e-06\n",
      "[1995]\ttraining's binary_logloss: 5.12742e-06\n",
      "[1996]\ttraining's binary_logloss: 5.12294e-06\n",
      "[1997]\ttraining's binary_logloss: 5.11821e-06\n",
      "[1998]\ttraining's binary_logloss: 5.11321e-06\n",
      "[1999]\ttraining's binary_logloss: 5.10806e-06\n",
      "[2000]\ttraining's binary_logloss: 5.10318e-06\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = lgb.train(\n",
    "    lgbm_params,\n",
    "    lgtrain,\n",
    "    valid_sets=lgtrain,\n",
    "    num_boost_round=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9227782792854905"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_lgb = lgb_clf.predict(X_test)\n",
    "predict_lgb = np.array([0 if i < 0.6 else 1 for i in predict_lgb])\n",
    "roc_auc_score(predict_lgb, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf, 'random_forest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.679963\n",
      "[2]\ttraining's binary_logloss: 0.66497\n",
      "[3]\ttraining's binary_logloss: 0.652721\n",
      "[4]\ttraining's binary_logloss: 0.638789\n",
      "[5]\ttraining's binary_logloss: 0.625434\n",
      "[6]\ttraining's binary_logloss: 0.61472\n",
      "[7]\ttraining's binary_logloss: 0.603808\n",
      "[8]\ttraining's binary_logloss: 0.591721\n",
      "[9]\ttraining's binary_logloss: 0.581847\n",
      "[10]\ttraining's binary_logloss: 0.57042\n",
      "[11]\ttraining's binary_logloss: 0.561189\n",
      "[12]\ttraining's binary_logloss: 0.550441\n",
      "[13]\ttraining's binary_logloss: 0.541623\n",
      "[14]\ttraining's binary_logloss: 0.53153\n",
      "[15]\ttraining's binary_logloss: 0.52316\n",
      "[16]\ttraining's binary_logloss: 0.515254\n",
      "[17]\ttraining's binary_logloss: 0.505888\n",
      "[18]\ttraining's binary_logloss: 0.498422\n",
      "[19]\ttraining's binary_logloss: 0.489725\n",
      "[20]\ttraining's binary_logloss: 0.482526\n",
      "[21]\ttraining's binary_logloss: 0.47419\n",
      "[22]\ttraining's binary_logloss: 0.467509\n",
      "[23]\ttraining's binary_logloss: 0.460875\n",
      "[24]\ttraining's binary_logloss: 0.454472\n",
      "[25]\ttraining's binary_logloss: 0.446948\n",
      "[26]\ttraining's binary_logloss: 0.439619\n",
      "[27]\ttraining's binary_logloss: 0.433498\n",
      "[28]\ttraining's binary_logloss: 0.426549\n",
      "[29]\ttraining's binary_logloss: 0.419785\n",
      "[30]\ttraining's binary_logloss: 0.414263\n",
      "[31]\ttraining's binary_logloss: 0.408809\n",
      "[32]\ttraining's binary_logloss: 0.40361\n",
      "[33]\ttraining's binary_logloss: 0.398344\n",
      "[34]\ttraining's binary_logloss: 0.392252\n",
      "[35]\ttraining's binary_logloss: 0.386275\n",
      "[36]\ttraining's binary_logloss: 0.380373\n",
      "[37]\ttraining's binary_logloss: 0.374821\n",
      "[38]\ttraining's binary_logloss: 0.369349\n",
      "[39]\ttraining's binary_logloss: 0.3649\n",
      "[40]\ttraining's binary_logloss: 0.359667\n",
      "[41]\ttraining's binary_logloss: 0.354524\n",
      "[42]\ttraining's binary_logloss: 0.350275\n",
      "[43]\ttraining's binary_logloss: 0.346366\n",
      "[44]\ttraining's binary_logloss: 0.342267\n",
      "[45]\ttraining's binary_logloss: 0.338377\n",
      "[46]\ttraining's binary_logloss: 0.333706\n",
      "[47]\ttraining's binary_logloss: 0.329126\n",
      "[48]\ttraining's binary_logloss: 0.325375\n",
      "[49]\ttraining's binary_logloss: 0.321066\n",
      "[50]\ttraining's binary_logloss: 0.317551\n",
      "[51]\ttraining's binary_logloss: 0.313404\n",
      "[52]\ttraining's binary_logloss: 0.309235\n",
      "[53]\ttraining's binary_logloss: 0.305869\n",
      "[54]\ttraining's binary_logloss: 0.301895\n",
      "[55]\ttraining's binary_logloss: 0.298002\n",
      "[56]\ttraining's binary_logloss: 0.294753\n",
      "[57]\ttraining's binary_logloss: 0.291059\n",
      "[58]\ttraining's binary_logloss: 0.28797\n",
      "[59]\ttraining's binary_logloss: 0.284929\n",
      "[60]\ttraining's binary_logloss: 0.282025\n",
      "[61]\ttraining's binary_logloss: 0.278468\n",
      "[62]\ttraining's binary_logloss: 0.274933\n",
      "[63]\ttraining's binary_logloss: 0.272195\n",
      "[64]\ttraining's binary_logloss: 0.268885\n",
      "[65]\ttraining's binary_logloss: 0.265655\n",
      "[66]\ttraining's binary_logloss: 0.262983\n",
      "[67]\ttraining's binary_logloss: 0.260381\n",
      "[68]\ttraining's binary_logloss: 0.257138\n",
      "[69]\ttraining's binary_logloss: 0.253977\n",
      "[70]\ttraining's binary_logloss: 0.251412\n",
      "[71]\ttraining's binary_logloss: 0.248524\n",
      "[72]\ttraining's binary_logloss: 0.246123\n",
      "[73]\ttraining's binary_logloss: 0.243222\n",
      "[74]\ttraining's binary_logloss: 0.240436\n",
      "[75]\ttraining's binary_logloss: 0.237646\n",
      "[76]\ttraining's binary_logloss: 0.235419\n",
      "[77]\ttraining's binary_logloss: 0.233128\n",
      "[78]\ttraining's binary_logloss: 0.230896\n",
      "[79]\ttraining's binary_logloss: 0.228234\n",
      "[80]\ttraining's binary_logloss: 0.225676\n",
      "[81]\ttraining's binary_logloss: 0.223547\n",
      "[82]\ttraining's binary_logloss: 0.221389\n",
      "[83]\ttraining's binary_logloss: 0.219321\n",
      "[84]\ttraining's binary_logloss: 0.216957\n",
      "[85]\ttraining's binary_logloss: 0.214964\n",
      "[86]\ttraining's binary_logloss: 0.2126\n",
      "[87]\ttraining's binary_logloss: 0.210673\n",
      "[88]\ttraining's binary_logloss: 0.208848\n",
      "[89]\ttraining's binary_logloss: 0.206566\n",
      "[90]\ttraining's binary_logloss: 0.204684\n",
      "[91]\ttraining's binary_logloss: 0.202782\n",
      "[92]\ttraining's binary_logloss: 0.200945\n",
      "[93]\ttraining's binary_logloss: 0.199153\n",
      "[94]\ttraining's binary_logloss: 0.197372\n",
      "[95]\ttraining's binary_logloss: 0.195579\n",
      "[96]\ttraining's binary_logloss: 0.193489\n",
      "[97]\ttraining's binary_logloss: 0.191461\n",
      "[98]\ttraining's binary_logloss: 0.189404\n",
      "[99]\ttraining's binary_logloss: 0.187745\n",
      "[100]\ttraining's binary_logloss: 0.18577\n",
      "[101]\ttraining's binary_logloss: 0.184144\n",
      "[102]\ttraining's binary_logloss: 0.182228\n",
      "[103]\ttraining's binary_logloss: 0.180646\n",
      "[104]\ttraining's binary_logloss: 0.179066\n",
      "[105]\ttraining's binary_logloss: 0.177547\n",
      "[106]\ttraining's binary_logloss: 0.175685\n",
      "[107]\ttraining's binary_logloss: 0.173863\n",
      "[108]\ttraining's binary_logloss: 0.172411\n",
      "[109]\ttraining's binary_logloss: 0.170898\n",
      "[110]\ttraining's binary_logloss: 0.169154\n",
      "[111]\ttraining's binary_logloss: 0.167372\n",
      "[112]\ttraining's binary_logloss: 0.16566\n",
      "[113]\ttraining's binary_logloss: 0.164063\n",
      "[114]\ttraining's binary_logloss: 0.162583\n",
      "[115]\ttraining's binary_logloss: 0.161207\n",
      "[116]\ttraining's binary_logloss: 0.159556\n",
      "[117]\ttraining's binary_logloss: 0.157945\n",
      "[118]\ttraining's binary_logloss: 0.156649\n",
      "[119]\ttraining's binary_logloss: 0.155091\n",
      "[120]\ttraining's binary_logloss: 0.153802\n",
      "[121]\ttraining's binary_logloss: 0.152265\n",
      "[122]\ttraining's binary_logloss: 0.151015\n",
      "[123]\ttraining's binary_logloss: 0.149507\n",
      "[124]\ttraining's binary_logloss: 0.148255\n",
      "[125]\ttraining's binary_logloss: 0.146797\n",
      "[126]\ttraining's binary_logloss: 0.14555\n",
      "[127]\ttraining's binary_logloss: 0.144185\n",
      "[128]\ttraining's binary_logloss: 0.142939\n",
      "[129]\ttraining's binary_logloss: 0.141812\n",
      "[130]\ttraining's binary_logloss: 0.140409\n",
      "[131]\ttraining's binary_logloss: 0.139231\n",
      "[132]\ttraining's binary_logloss: 0.138025\n",
      "[133]\ttraining's binary_logloss: 0.136891\n",
      "[134]\ttraining's binary_logloss: 0.135781\n",
      "[135]\ttraining's binary_logloss: 0.13452\n",
      "[136]\ttraining's binary_logloss: 0.133225\n",
      "[137]\ttraining's binary_logloss: 0.132128\n",
      "[138]\ttraining's binary_logloss: 0.130994\n",
      "[139]\ttraining's binary_logloss: 0.129713\n",
      "[140]\ttraining's binary_logloss: 0.128477\n",
      "[141]\ttraining's binary_logloss: 0.127455\n",
      "[142]\ttraining's binary_logloss: 0.126277\n",
      "[143]\ttraining's binary_logloss: 0.125246\n",
      "[144]\ttraining's binary_logloss: 0.124189\n",
      "[145]\ttraining's binary_logloss: 0.123137\n",
      "[146]\ttraining's binary_logloss: 0.121966\n",
      "[147]\ttraining's binary_logloss: 0.120761\n",
      "[148]\ttraining's binary_logloss: 0.119799\n",
      "[149]\ttraining's binary_logloss: 0.118851\n",
      "[150]\ttraining's binary_logloss: 0.117906\n",
      "[151]\ttraining's binary_logloss: 0.116812\n",
      "[152]\ttraining's binary_logloss: 0.115737\n",
      "[153]\ttraining's binary_logloss: 0.114804\n",
      "[154]\ttraining's binary_logloss: 0.113885\n",
      "[155]\ttraining's binary_logloss: 0.112927\n",
      "[156]\ttraining's binary_logloss: 0.112013\n",
      "[157]\ttraining's binary_logloss: 0.111113\n",
      "[158]\ttraining's binary_logloss: 0.11007\n",
      "[159]\ttraining's binary_logloss: 0.109017\n",
      "[160]\ttraining's binary_logloss: 0.108137\n",
      "[161]\ttraining's binary_logloss: 0.10711\n",
      "[162]\ttraining's binary_logloss: 0.106263\n",
      "[163]\ttraining's binary_logloss: 0.105385\n",
      "[164]\ttraining's binary_logloss: 0.1044\n",
      "[165]\ttraining's binary_logloss: 0.103551\n",
      "[166]\ttraining's binary_logloss: 0.102634\n",
      "[167]\ttraining's binary_logloss: 0.101702\n",
      "[168]\ttraining's binary_logloss: 0.10087\n",
      "[169]\ttraining's binary_logloss: 0.0999508\n",
      "[170]\ttraining's binary_logloss: 0.0990197\n",
      "[171]\ttraining's binary_logloss: 0.098245\n",
      "[172]\ttraining's binary_logloss: 0.0975026\n",
      "[173]\ttraining's binary_logloss: 0.0966415\n",
      "[174]\ttraining's binary_logloss: 0.0957594\n",
      "[175]\ttraining's binary_logloss: 0.0949628\n",
      "[176]\ttraining's binary_logloss: 0.0942145\n",
      "[177]\ttraining's binary_logloss: 0.0933526\n",
      "[178]\ttraining's binary_logloss: 0.092574\n",
      "[179]\ttraining's binary_logloss: 0.0918334\n",
      "[180]\ttraining's binary_logloss: 0.0909988\n",
      "[181]\ttraining's binary_logloss: 0.0901212\n",
      "[182]\ttraining's binary_logloss: 0.0892825\n",
      "[183]\ttraining's binary_logloss: 0.0884927\n",
      "[184]\ttraining's binary_logloss: 0.0877016\n",
      "[185]\ttraining's binary_logloss: 0.0870071\n",
      "[186]\ttraining's binary_logloss: 0.0862312\n",
      "[187]\ttraining's binary_logloss: 0.0855052\n",
      "[188]\ttraining's binary_logloss: 0.0847689\n",
      "[189]\ttraining's binary_logloss: 0.0840466\n",
      "[190]\ttraining's binary_logloss: 0.0834341\n",
      "[191]\ttraining's binary_logloss: 0.0826686\n",
      "[192]\ttraining's binary_logloss: 0.0819852\n",
      "[193]\ttraining's binary_logloss: 0.0812484\n",
      "[194]\ttraining's binary_logloss: 0.0805737\n",
      "[195]\ttraining's binary_logloss: 0.0798818\n",
      "[196]\ttraining's binary_logloss: 0.0791462\n",
      "[197]\ttraining's binary_logloss: 0.0785112\n",
      "[198]\ttraining's binary_logloss: 0.0778671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[199]\ttraining's binary_logloss: 0.0772638\n",
      "[200]\ttraining's binary_logloss: 0.0766379\n",
      "[201]\ttraining's binary_logloss: 0.0759774\n",
      "[202]\ttraining's binary_logloss: 0.0753103\n",
      "[203]\ttraining's binary_logloss: 0.0747256\n",
      "[204]\ttraining's binary_logloss: 0.0741488\n",
      "[205]\ttraining's binary_logloss: 0.0734999\n",
      "[206]\ttraining's binary_logloss: 0.0729097\n",
      "[207]\ttraining's binary_logloss: 0.07227\n",
      "[208]\ttraining's binary_logloss: 0.0715998\n",
      "[209]\ttraining's binary_logloss: 0.0709609\n",
      "[210]\ttraining's binary_logloss: 0.0703132\n",
      "[211]\ttraining's binary_logloss: 0.0697548\n",
      "[212]\ttraining's binary_logloss: 0.0691784\n",
      "[213]\ttraining's binary_logloss: 0.0685933\n",
      "[214]\ttraining's binary_logloss: 0.0680614\n",
      "[215]\ttraining's binary_logloss: 0.0674941\n",
      "[216]\ttraining's binary_logloss: 0.0669178\n",
      "[217]\ttraining's binary_logloss: 0.066328\n",
      "[218]\ttraining's binary_logloss: 0.0658082\n",
      "[219]\ttraining's binary_logloss: 0.0653198\n",
      "[220]\ttraining's binary_logloss: 0.0647656\n",
      "[221]\ttraining's binary_logloss: 0.0642212\n",
      "[222]\ttraining's binary_logloss: 0.0636756\n",
      "[223]\ttraining's binary_logloss: 0.0631491\n",
      "[224]\ttraining's binary_logloss: 0.062638\n",
      "[225]\ttraining's binary_logloss: 0.0621118\n",
      "[226]\ttraining's binary_logloss: 0.0616183\n",
      "[227]\ttraining's binary_logloss: 0.0611019\n",
      "[228]\ttraining's binary_logloss: 0.0606229\n",
      "[229]\ttraining's binary_logloss: 0.0600992\n",
      "[230]\ttraining's binary_logloss: 0.0596143\n",
      "[231]\ttraining's binary_logloss: 0.0591266\n",
      "[232]\ttraining's binary_logloss: 0.0586705\n",
      "[233]\ttraining's binary_logloss: 0.0581841\n",
      "[234]\ttraining's binary_logloss: 0.0577083\n",
      "[235]\ttraining's binary_logloss: 0.0572214\n",
      "[236]\ttraining's binary_logloss: 0.056758\n",
      "[237]\ttraining's binary_logloss: 0.0562983\n",
      "[238]\ttraining's binary_logloss: 0.0558459\n",
      "[239]\ttraining's binary_logloss: 0.0553963\n",
      "[240]\ttraining's binary_logloss: 0.0549271\n",
      "[241]\ttraining's binary_logloss: 0.0544738\n",
      "[242]\ttraining's binary_logloss: 0.0540053\n",
      "[243]\ttraining's binary_logloss: 0.0535628\n",
      "[244]\ttraining's binary_logloss: 0.0531533\n",
      "[245]\ttraining's binary_logloss: 0.0527112\n",
      "[246]\ttraining's binary_logloss: 0.0522844\n",
      "[247]\ttraining's binary_logloss: 0.0518874\n",
      "[248]\ttraining's binary_logloss: 0.0514647\n",
      "[249]\ttraining's binary_logloss: 0.0510556\n",
      "[250]\ttraining's binary_logloss: 0.0506682\n",
      "[251]\ttraining's binary_logloss: 0.0502696\n",
      "[252]\ttraining's binary_logloss: 0.0498742\n",
      "[253]\ttraining's binary_logloss: 0.0494613\n",
      "[254]\ttraining's binary_logloss: 0.0490746\n",
      "[255]\ttraining's binary_logloss: 0.048682\n",
      "[256]\ttraining's binary_logloss: 0.0482955\n",
      "[257]\ttraining's binary_logloss: 0.0479037\n",
      "[258]\ttraining's binary_logloss: 0.0475096\n",
      "[259]\ttraining's binary_logloss: 0.0471576\n",
      "[260]\ttraining's binary_logloss: 0.0467778\n",
      "[261]\ttraining's binary_logloss: 0.0464054\n",
      "[262]\ttraining's binary_logloss: 0.0460471\n",
      "[263]\ttraining's binary_logloss: 0.045672\n",
      "[264]\ttraining's binary_logloss: 0.045319\n",
      "[265]\ttraining's binary_logloss: 0.0449705\n",
      "[266]\ttraining's binary_logloss: 0.0446228\n",
      "[267]\ttraining's binary_logloss: 0.044261\n",
      "[268]\ttraining's binary_logloss: 0.0438791\n",
      "[269]\ttraining's binary_logloss: 0.0435181\n",
      "[270]\ttraining's binary_logloss: 0.0431746\n",
      "[271]\ttraining's binary_logloss: 0.0428168\n",
      "[272]\ttraining's binary_logloss: 0.0424875\n",
      "[273]\ttraining's binary_logloss: 0.0421553\n",
      "[274]\ttraining's binary_logloss: 0.0418083\n",
      "[275]\ttraining's binary_logloss: 0.041475\n",
      "[276]\ttraining's binary_logloss: 0.0411459\n",
      "[277]\ttraining's binary_logloss: 0.0408344\n",
      "[278]\ttraining's binary_logloss: 0.040494\n",
      "[279]\ttraining's binary_logloss: 0.0401883\n",
      "[280]\ttraining's binary_logloss: 0.0398791\n",
      "[281]\ttraining's binary_logloss: 0.0395616\n",
      "[282]\ttraining's binary_logloss: 0.0392493\n",
      "[283]\ttraining's binary_logloss: 0.0389341\n",
      "[284]\ttraining's binary_logloss: 0.0386259\n",
      "[285]\ttraining's binary_logloss: 0.038319\n",
      "[286]\ttraining's binary_logloss: 0.0380191\n",
      "[287]\ttraining's binary_logloss: 0.0377088\n",
      "[288]\ttraining's binary_logloss: 0.0374307\n",
      "[289]\ttraining's binary_logloss: 0.0371431\n",
      "[290]\ttraining's binary_logloss: 0.0368473\n",
      "[291]\ttraining's binary_logloss: 0.0365469\n",
      "[292]\ttraining's binary_logloss: 0.036274\n",
      "[293]\ttraining's binary_logloss: 0.0359971\n",
      "[294]\ttraining's binary_logloss: 0.0357139\n",
      "[295]\ttraining's binary_logloss: 0.0354357\n",
      "[296]\ttraining's binary_logloss: 0.0351663\n",
      "[297]\ttraining's binary_logloss: 0.0348798\n",
      "[298]\ttraining's binary_logloss: 0.0346154\n",
      "[299]\ttraining's binary_logloss: 0.0343329\n",
      "[300]\ttraining's binary_logloss: 0.0340559\n",
      "[301]\ttraining's binary_logloss: 0.0337888\n",
      "[302]\ttraining's binary_logloss: 0.0335231\n",
      "[303]\ttraining's binary_logloss: 0.0332643\n",
      "[304]\ttraining's binary_logloss: 0.0330167\n",
      "[305]\ttraining's binary_logloss: 0.0327656\n",
      "[306]\ttraining's binary_logloss: 0.0325011\n",
      "[307]\ttraining's binary_logloss: 0.0322418\n",
      "[308]\ttraining's binary_logloss: 0.031996\n",
      "[309]\ttraining's binary_logloss: 0.0317577\n",
      "[310]\ttraining's binary_logloss: 0.0315155\n",
      "[311]\ttraining's binary_logloss: 0.0312587\n",
      "[312]\ttraining's binary_logloss: 0.0310052\n",
      "[313]\ttraining's binary_logloss: 0.0307574\n",
      "[314]\ttraining's binary_logloss: 0.0305268\n",
      "[315]\ttraining's binary_logloss: 0.030294\n",
      "[316]\ttraining's binary_logloss: 0.0300643\n",
      "[317]\ttraining's binary_logloss: 0.0298353\n",
      "[318]\ttraining's binary_logloss: 0.0296069\n",
      "[319]\ttraining's binary_logloss: 0.0293748\n",
      "[320]\ttraining's binary_logloss: 0.029155\n",
      "[321]\ttraining's binary_logloss: 0.0289416\n",
      "[322]\ttraining's binary_logloss: 0.0287221\n",
      "[323]\ttraining's binary_logloss: 0.0284949\n",
      "[324]\ttraining's binary_logloss: 0.0282682\n",
      "[325]\ttraining's binary_logloss: 0.0280631\n",
      "[326]\ttraining's binary_logloss: 0.0278447\n",
      "[327]\ttraining's binary_logloss: 0.0276368\n",
      "[328]\ttraining's binary_logloss: 0.027427\n",
      "[329]\ttraining's binary_logloss: 0.0272156\n",
      "[330]\ttraining's binary_logloss: 0.027004\n",
      "[331]\ttraining's binary_logloss: 0.0267961\n",
      "[332]\ttraining's binary_logloss: 0.0265897\n",
      "[333]\ttraining's binary_logloss: 0.0263855\n",
      "[334]\ttraining's binary_logloss: 0.0261838\n",
      "[335]\ttraining's binary_logloss: 0.025981\n",
      "[336]\ttraining's binary_logloss: 0.0257806\n",
      "[337]\ttraining's binary_logloss: 0.0255857\n",
      "[338]\ttraining's binary_logloss: 0.0253861\n",
      "[339]\ttraining's binary_logloss: 0.0251884\n",
      "[340]\ttraining's binary_logloss: 0.0249973\n",
      "[341]\ttraining's binary_logloss: 0.0248062\n",
      "[342]\ttraining's binary_logloss: 0.0246153\n",
      "[343]\ttraining's binary_logloss: 0.0244462\n",
      "[344]\ttraining's binary_logloss: 0.0242738\n",
      "[345]\ttraining's binary_logloss: 0.0240907\n",
      "[346]\ttraining's binary_logloss: 0.0239012\n",
      "[347]\ttraining's binary_logloss: 0.02373\n",
      "[348]\ttraining's binary_logloss: 0.0235527\n",
      "[349]\ttraining's binary_logloss: 0.0233665\n",
      "[350]\ttraining's binary_logloss: 0.0231985\n",
      "[351]\ttraining's binary_logloss: 0.0230255\n",
      "[352]\ttraining's binary_logloss: 0.0228425\n",
      "[353]\ttraining's binary_logloss: 0.0226706\n",
      "[354]\ttraining's binary_logloss: 0.0224954\n",
      "[355]\ttraining's binary_logloss: 0.022318\n",
      "[356]\ttraining's binary_logloss: 0.0221549\n",
      "[357]\ttraining's binary_logloss: 0.0219782\n",
      "[358]\ttraining's binary_logloss: 0.021806\n",
      "[359]\ttraining's binary_logloss: 0.0216314\n",
      "[360]\ttraining's binary_logloss: 0.0214707\n",
      "[361]\ttraining's binary_logloss: 0.0213098\n",
      "[362]\ttraining's binary_logloss: 0.0211541\n",
      "[363]\ttraining's binary_logloss: 0.020992\n",
      "[364]\ttraining's binary_logloss: 0.0208415\n",
      "[365]\ttraining's binary_logloss: 0.02068\n",
      "[366]\ttraining's binary_logloss: 0.0205189\n",
      "[367]\ttraining's binary_logloss: 0.0203626\n",
      "[368]\ttraining's binary_logloss: 0.0202103\n",
      "[369]\ttraining's binary_logloss: 0.0200436\n",
      "[370]\ttraining's binary_logloss: 0.0198875\n",
      "[371]\ttraining's binary_logloss: 0.0197482\n",
      "[372]\ttraining's binary_logloss: 0.0195942\n",
      "[373]\ttraining's binary_logloss: 0.0194506\n",
      "[374]\ttraining's binary_logloss: 0.0193044\n",
      "[375]\ttraining's binary_logloss: 0.019162\n",
      "[376]\ttraining's binary_logloss: 0.0190129\n",
      "[377]\ttraining's binary_logloss: 0.0188638\n",
      "[378]\ttraining's binary_logloss: 0.0187253\n",
      "[379]\ttraining's binary_logloss: 0.0185813\n",
      "[380]\ttraining's binary_logloss: 0.0184323\n",
      "[381]\ttraining's binary_logloss: 0.0182838\n",
      "[382]\ttraining's binary_logloss: 0.0181414\n",
      "[383]\ttraining's binary_logloss: 0.0180054\n",
      "[384]\ttraining's binary_logloss: 0.0178645\n",
      "[385]\ttraining's binary_logloss: 0.0177298\n",
      "[386]\ttraining's binary_logloss: 0.0175903\n",
      "[387]\ttraining's binary_logloss: 0.0174592\n",
      "[388]\ttraining's binary_logloss: 0.0173305\n",
      "[389]\ttraining's binary_logloss: 0.0171948\n",
      "[390]\ttraining's binary_logloss: 0.0170689\n",
      "[391]\ttraining's binary_logloss: 0.016942\n",
      "[392]\ttraining's binary_logloss: 0.0168076\n",
      "[393]\ttraining's binary_logloss: 0.0166851\n",
      "[394]\ttraining's binary_logloss: 0.0165552\n",
      "[395]\ttraining's binary_logloss: 0.0164301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[396]\ttraining's binary_logloss: 0.0163086\n",
      "[397]\ttraining's binary_logloss: 0.0161884\n",
      "[398]\ttraining's binary_logloss: 0.0160625\n",
      "[399]\ttraining's binary_logloss: 0.0159455\n",
      "[400]\ttraining's binary_logloss: 0.0158206\n",
      "[401]\ttraining's binary_logloss: 0.0157\n",
      "[402]\ttraining's binary_logloss: 0.0155789\n",
      "[403]\ttraining's binary_logloss: 0.0154607\n",
      "[404]\ttraining's binary_logloss: 0.0153426\n",
      "[405]\ttraining's binary_logloss: 0.0152259\n",
      "[406]\ttraining's binary_logloss: 0.0151091\n",
      "[407]\ttraining's binary_logloss: 0.0149929\n",
      "[408]\ttraining's binary_logloss: 0.0148796\n",
      "[409]\ttraining's binary_logloss: 0.0147623\n",
      "[410]\ttraining's binary_logloss: 0.0146502\n",
      "[411]\ttraining's binary_logloss: 0.0145413\n",
      "[412]\ttraining's binary_logloss: 0.0144362\n",
      "[413]\ttraining's binary_logloss: 0.0143286\n",
      "[414]\ttraining's binary_logloss: 0.0142198\n",
      "[415]\ttraining's binary_logloss: 0.0141239\n",
      "[416]\ttraining's binary_logloss: 0.0140186\n",
      "[417]\ttraining's binary_logloss: 0.0139128\n",
      "[418]\ttraining's binary_logloss: 0.0138017\n",
      "[419]\ttraining's binary_logloss: 0.0137046\n",
      "[420]\ttraining's binary_logloss: 0.0136069\n",
      "[421]\ttraining's binary_logloss: 0.0135029\n",
      "[422]\ttraining's binary_logloss: 0.0134028\n",
      "[423]\ttraining's binary_logloss: 0.0132999\n",
      "[424]\ttraining's binary_logloss: 0.0131975\n",
      "[425]\ttraining's binary_logloss: 0.0130979\n",
      "[426]\ttraining's binary_logloss: 0.0129995\n",
      "[427]\ttraining's binary_logloss: 0.012904\n",
      "[428]\ttraining's binary_logloss: 0.0128033\n",
      "[429]\ttraining's binary_logloss: 0.0127136\n",
      "[430]\ttraining's binary_logloss: 0.0126146\n",
      "[431]\ttraining's binary_logloss: 0.0125212\n",
      "[432]\ttraining's binary_logloss: 0.0124241\n",
      "[433]\ttraining's binary_logloss: 0.0123305\n",
      "[434]\ttraining's binary_logloss: 0.0122348\n",
      "[435]\ttraining's binary_logloss: 0.0121236\n",
      "[436]\ttraining's binary_logloss: 0.012016\n",
      "[437]\ttraining's binary_logloss: 0.011919\n",
      "[438]\ttraining's binary_logloss: 0.0118206\n",
      "[439]\ttraining's binary_logloss: 0.0117187\n",
      "[440]\ttraining's binary_logloss: 0.0116259\n",
      "[441]\ttraining's binary_logloss: 0.0115359\n",
      "[442]\ttraining's binary_logloss: 0.0114464\n",
      "[443]\ttraining's binary_logloss: 0.0113553\n",
      "[444]\ttraining's binary_logloss: 0.011261\n",
      "[445]\ttraining's binary_logloss: 0.0111769\n",
      "[446]\ttraining's binary_logloss: 0.0110875\n",
      "[447]\ttraining's binary_logloss: 0.0109997\n",
      "[448]\ttraining's binary_logloss: 0.0109131\n",
      "[449]\ttraining's binary_logloss: 0.0108244\n",
      "[450]\ttraining's binary_logloss: 0.0107454\n",
      "[451]\ttraining's binary_logloss: 0.0106594\n",
      "[452]\ttraining's binary_logloss: 0.0105764\n",
      "[453]\ttraining's binary_logloss: 0.010495\n",
      "[454]\ttraining's binary_logloss: 0.010414\n",
      "[455]\ttraining's binary_logloss: 0.0103356\n",
      "[456]\ttraining's binary_logloss: 0.010256\n",
      "[457]\ttraining's binary_logloss: 0.0101826\n",
      "[458]\ttraining's binary_logloss: 0.0101069\n",
      "[459]\ttraining's binary_logloss: 0.0100338\n",
      "[460]\ttraining's binary_logloss: 0.00995369\n",
      "[461]\ttraining's binary_logloss: 0.00987729\n",
      "[462]\ttraining's binary_logloss: 0.00979927\n",
      "[463]\ttraining's binary_logloss: 0.00972719\n",
      "[464]\ttraining's binary_logloss: 0.00965655\n",
      "[465]\ttraining's binary_logloss: 0.00958958\n",
      "[466]\ttraining's binary_logloss: 0.00951833\n",
      "[467]\ttraining's binary_logloss: 0.00944965\n",
      "[468]\ttraining's binary_logloss: 0.0093761\n",
      "[469]\ttraining's binary_logloss: 0.00930542\n",
      "[470]\ttraining's binary_logloss: 0.00923198\n",
      "[471]\ttraining's binary_logloss: 0.00916088\n",
      "[472]\ttraining's binary_logloss: 0.00908771\n",
      "[473]\ttraining's binary_logloss: 0.00901988\n",
      "[474]\ttraining's binary_logloss: 0.00895402\n",
      "[475]\ttraining's binary_logloss: 0.00888605\n",
      "[476]\ttraining's binary_logloss: 0.00881833\n",
      "[477]\ttraining's binary_logloss: 0.00875457\n",
      "[478]\ttraining's binary_logloss: 0.00868633\n",
      "[479]\ttraining's binary_logloss: 0.00862282\n",
      "[480]\ttraining's binary_logloss: 0.0085609\n",
      "[481]\ttraining's binary_logloss: 0.00849696\n",
      "[482]\ttraining's binary_logloss: 0.00843481\n",
      "[483]\ttraining's binary_logloss: 0.00837361\n",
      "[484]\ttraining's binary_logloss: 0.00830722\n",
      "[485]\ttraining's binary_logloss: 0.00824393\n",
      "[486]\ttraining's binary_logloss: 0.0081838\n",
      "[487]\ttraining's binary_logloss: 0.00812343\n",
      "[488]\ttraining's binary_logloss: 0.00806065\n",
      "[489]\ttraining's binary_logloss: 0.00799721\n",
      "[490]\ttraining's binary_logloss: 0.00793789\n",
      "[491]\ttraining's binary_logloss: 0.00787337\n",
      "[492]\ttraining's binary_logloss: 0.00781241\n",
      "[493]\ttraining's binary_logloss: 0.00775038\n",
      "[494]\ttraining's binary_logloss: 0.00769436\n",
      "[495]\ttraining's binary_logloss: 0.00763446\n",
      "[496]\ttraining's binary_logloss: 0.00757692\n",
      "[497]\ttraining's binary_logloss: 0.0075195\n",
      "[498]\ttraining's binary_logloss: 0.00746318\n",
      "[499]\ttraining's binary_logloss: 0.00740737\n",
      "[500]\ttraining's binary_logloss: 0.00735041\n",
      "[501]\ttraining's binary_logloss: 0.00729884\n",
      "[502]\ttraining's binary_logloss: 0.00724389\n",
      "[503]\ttraining's binary_logloss: 0.00719009\n",
      "[504]\ttraining's binary_logloss: 0.00713717\n",
      "[505]\ttraining's binary_logloss: 0.00708024\n",
      "[506]\ttraining's binary_logloss: 0.00702735\n",
      "[507]\ttraining's binary_logloss: 0.00697376\n",
      "[508]\ttraining's binary_logloss: 0.00692056\n",
      "[509]\ttraining's binary_logloss: 0.00686662\n",
      "[510]\ttraining's binary_logloss: 0.00681365\n",
      "[511]\ttraining's binary_logloss: 0.00676248\n",
      "[512]\ttraining's binary_logloss: 0.00671352\n",
      "[513]\ttraining's binary_logloss: 0.00665958\n",
      "[514]\ttraining's binary_logloss: 0.0066081\n",
      "[515]\ttraining's binary_logloss: 0.00656117\n",
      "[516]\ttraining's binary_logloss: 0.00651347\n",
      "[517]\ttraining's binary_logloss: 0.00646572\n",
      "[518]\ttraining's binary_logloss: 0.00641729\n",
      "[519]\ttraining's binary_logloss: 0.00637126\n",
      "[520]\ttraining's binary_logloss: 0.00632733\n",
      "[521]\ttraining's binary_logloss: 0.00628047\n",
      "[522]\ttraining's binary_logloss: 0.00623394\n",
      "[523]\ttraining's binary_logloss: 0.00618545\n",
      "[524]\ttraining's binary_logloss: 0.00614251\n",
      "[525]\ttraining's binary_logloss: 0.00609624\n",
      "[526]\ttraining's binary_logloss: 0.00605199\n",
      "[527]\ttraining's binary_logloss: 0.00600674\n",
      "[528]\ttraining's binary_logloss: 0.00595805\n",
      "[529]\ttraining's binary_logloss: 0.00591459\n",
      "[530]\ttraining's binary_logloss: 0.00587135\n",
      "[531]\ttraining's binary_logloss: 0.0058292\n",
      "[532]\ttraining's binary_logloss: 0.00578771\n",
      "[533]\ttraining's binary_logloss: 0.00574617\n",
      "[534]\ttraining's binary_logloss: 0.00570553\n",
      "[535]\ttraining's binary_logloss: 0.00566361\n",
      "[536]\ttraining's binary_logloss: 0.00562273\n",
      "[537]\ttraining's binary_logloss: 0.00558305\n",
      "[538]\ttraining's binary_logloss: 0.00554141\n",
      "[539]\ttraining's binary_logloss: 0.0055018\n",
      "[540]\ttraining's binary_logloss: 0.00546259\n",
      "[541]\ttraining's binary_logloss: 0.00542238\n",
      "[542]\ttraining's binary_logloss: 0.00538263\n",
      "[543]\ttraining's binary_logloss: 0.00534271\n",
      "[544]\ttraining's binary_logloss: 0.00530291\n",
      "[545]\ttraining's binary_logloss: 0.0052648\n",
      "[546]\ttraining's binary_logloss: 0.00522638\n",
      "[547]\ttraining's binary_logloss: 0.00518853\n",
      "[548]\ttraining's binary_logloss: 0.00515006\n",
      "[549]\ttraining's binary_logloss: 0.00511013\n",
      "[550]\ttraining's binary_logloss: 0.00507613\n",
      "[551]\ttraining's binary_logloss: 0.0050393\n",
      "[552]\ttraining's binary_logloss: 0.00500306\n",
      "[553]\ttraining's binary_logloss: 0.00496487\n",
      "[554]\ttraining's binary_logloss: 0.00492896\n",
      "[555]\ttraining's binary_logloss: 0.00489539\n",
      "[556]\ttraining's binary_logloss: 0.00486115\n",
      "[557]\ttraining's binary_logloss: 0.00482578\n",
      "[558]\ttraining's binary_logloss: 0.00479116\n",
      "[559]\ttraining's binary_logloss: 0.00475699\n",
      "[560]\ttraining's binary_logloss: 0.00472517\n",
      "[561]\ttraining's binary_logloss: 0.00468991\n",
      "[562]\ttraining's binary_logloss: 0.00465603\n",
      "[563]\ttraining's binary_logloss: 0.0046219\n",
      "[564]\ttraining's binary_logloss: 0.00458762\n",
      "[565]\ttraining's binary_logloss: 0.00455125\n",
      "[566]\ttraining's binary_logloss: 0.00451594\n",
      "[567]\ttraining's binary_logloss: 0.00448456\n",
      "[568]\ttraining's binary_logloss: 0.00445117\n",
      "[569]\ttraining's binary_logloss: 0.00441999\n",
      "[570]\ttraining's binary_logloss: 0.00439001\n",
      "[571]\ttraining's binary_logloss: 0.00435911\n",
      "[572]\ttraining's binary_logloss: 0.00432921\n",
      "[573]\ttraining's binary_logloss: 0.00429818\n",
      "[574]\ttraining's binary_logloss: 0.00426774\n",
      "[575]\ttraining's binary_logloss: 0.00423699\n",
      "[576]\ttraining's binary_logloss: 0.00420747\n",
      "[577]\ttraining's binary_logloss: 0.00417603\n",
      "[578]\ttraining's binary_logloss: 0.00414608\n",
      "[579]\ttraining's binary_logloss: 0.00411793\n",
      "[580]\ttraining's binary_logloss: 0.00409056\n",
      "[581]\ttraining's binary_logloss: 0.00406136\n",
      "[582]\ttraining's binary_logloss: 0.00403054\n",
      "[583]\ttraining's binary_logloss: 0.004\n",
      "[584]\ttraining's binary_logloss: 0.00397183\n",
      "[585]\ttraining's binary_logloss: 0.00394187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[586]\ttraining's binary_logloss: 0.00391371\n",
      "[587]\ttraining's binary_logloss: 0.00388607\n",
      "[588]\ttraining's binary_logloss: 0.00385704\n",
      "[589]\ttraining's binary_logloss: 0.00382918\n",
      "[590]\ttraining's binary_logloss: 0.0038032\n",
      "[591]\ttraining's binary_logloss: 0.00377537\n",
      "[592]\ttraining's binary_logloss: 0.00374882\n",
      "[593]\ttraining's binary_logloss: 0.00372338\n",
      "[594]\ttraining's binary_logloss: 0.00369763\n",
      "[595]\ttraining's binary_logloss: 0.00367219\n",
      "[596]\ttraining's binary_logloss: 0.00364397\n",
      "[597]\ttraining's binary_logloss: 0.00361821\n",
      "[598]\ttraining's binary_logloss: 0.00359339\n",
      "[599]\ttraining's binary_logloss: 0.0035683\n",
      "[600]\ttraining's binary_logloss: 0.00354372\n",
      "[601]\ttraining's binary_logloss: 0.00351886\n",
      "[602]\ttraining's binary_logloss: 0.00349407\n",
      "[603]\ttraining's binary_logloss: 0.00346782\n",
      "[604]\ttraining's binary_logloss: 0.00344381\n",
      "[605]\ttraining's binary_logloss: 0.0034181\n",
      "[606]\ttraining's binary_logloss: 0.0033936\n",
      "[607]\ttraining's binary_logloss: 0.00337161\n",
      "[608]\ttraining's binary_logloss: 0.00334883\n",
      "[609]\ttraining's binary_logloss: 0.00332562\n",
      "[610]\ttraining's binary_logloss: 0.00330163\n",
      "[611]\ttraining's binary_logloss: 0.00327795\n",
      "[612]\ttraining's binary_logloss: 0.00325575\n",
      "[613]\ttraining's binary_logloss: 0.00323257\n",
      "[614]\ttraining's binary_logloss: 0.00320936\n",
      "[615]\ttraining's binary_logloss: 0.00318666\n",
      "[616]\ttraining's binary_logloss: 0.00316347\n",
      "[617]\ttraining's binary_logloss: 0.00314352\n",
      "[618]\ttraining's binary_logloss: 0.00312075\n",
      "[619]\ttraining's binary_logloss: 0.00310003\n",
      "[620]\ttraining's binary_logloss: 0.00307929\n",
      "[621]\ttraining's binary_logloss: 0.00305845\n",
      "[622]\ttraining's binary_logloss: 0.00303691\n",
      "[623]\ttraining's binary_logloss: 0.00301574\n",
      "[624]\ttraining's binary_logloss: 0.00299553\n",
      "[625]\ttraining's binary_logloss: 0.00297517\n",
      "[626]\ttraining's binary_logloss: 0.00295558\n",
      "[627]\ttraining's binary_logloss: 0.0029367\n",
      "[628]\ttraining's binary_logloss: 0.00291707\n",
      "[629]\ttraining's binary_logloss: 0.00289714\n",
      "[630]\ttraining's binary_logloss: 0.00287716\n",
      "[631]\ttraining's binary_logloss: 0.00285588\n",
      "[632]\ttraining's binary_logloss: 0.00283613\n",
      "[633]\ttraining's binary_logloss: 0.00281519\n",
      "[634]\ttraining's binary_logloss: 0.00279638\n",
      "[635]\ttraining's binary_logloss: 0.00277866\n",
      "[636]\ttraining's binary_logloss: 0.00276052\n",
      "[637]\ttraining's binary_logloss: 0.00274038\n",
      "[638]\ttraining's binary_logloss: 0.0027219\n",
      "[639]\ttraining's binary_logloss: 0.00270207\n",
      "[640]\ttraining's binary_logloss: 0.00268275\n",
      "[641]\ttraining's binary_logloss: 0.00266509\n",
      "[642]\ttraining's binary_logloss: 0.00264655\n",
      "[643]\ttraining's binary_logloss: 0.00262658\n",
      "[644]\ttraining's binary_logloss: 0.00260756\n",
      "[645]\ttraining's binary_logloss: 0.00258937\n",
      "[646]\ttraining's binary_logloss: 0.00257311\n",
      "[647]\ttraining's binary_logloss: 0.00255476\n",
      "[648]\ttraining's binary_logloss: 0.0025377\n",
      "[649]\ttraining's binary_logloss: 0.00252215\n",
      "[650]\ttraining's binary_logloss: 0.0025045\n",
      "[651]\ttraining's binary_logloss: 0.00248768\n",
      "[652]\ttraining's binary_logloss: 0.00247063\n",
      "[653]\ttraining's binary_logloss: 0.00245304\n",
      "[654]\ttraining's binary_logloss: 0.00243707\n",
      "[655]\ttraining's binary_logloss: 0.00242079\n",
      "[656]\ttraining's binary_logloss: 0.00240528\n",
      "[657]\ttraining's binary_logloss: 0.0023891\n",
      "[658]\ttraining's binary_logloss: 0.00237327\n",
      "[659]\ttraining's binary_logloss: 0.0023567\n",
      "[660]\ttraining's binary_logloss: 0.00234169\n",
      "[661]\ttraining's binary_logloss: 0.00232692\n",
      "[662]\ttraining's binary_logloss: 0.00231262\n",
      "[663]\ttraining's binary_logloss: 0.00229565\n",
      "[664]\ttraining's binary_logloss: 0.00228168\n",
      "[665]\ttraining's binary_logloss: 0.00226674\n",
      "[666]\ttraining's binary_logloss: 0.00225148\n",
      "[667]\ttraining's binary_logloss: 0.00223721\n",
      "[668]\ttraining's binary_logloss: 0.00222364\n",
      "[669]\ttraining's binary_logloss: 0.00220935\n",
      "[670]\ttraining's binary_logloss: 0.00219494\n",
      "[671]\ttraining's binary_logloss: 0.00218134\n",
      "[672]\ttraining's binary_logloss: 0.00216819\n",
      "[673]\ttraining's binary_logloss: 0.00215447\n",
      "[674]\ttraining's binary_logloss: 0.00213859\n",
      "[675]\ttraining's binary_logloss: 0.00212494\n",
      "[676]\ttraining's binary_logloss: 0.00211093\n",
      "[677]\ttraining's binary_logloss: 0.00209729\n",
      "[678]\ttraining's binary_logloss: 0.00208409\n",
      "[679]\ttraining's binary_logloss: 0.00207003\n",
      "[680]\ttraining's binary_logloss: 0.00205742\n",
      "[681]\ttraining's binary_logloss: 0.00204289\n",
      "[682]\ttraining's binary_logloss: 0.0020299\n",
      "[683]\ttraining's binary_logloss: 0.00201553\n",
      "[684]\ttraining's binary_logloss: 0.00200205\n",
      "[685]\ttraining's binary_logloss: 0.00198994\n",
      "[686]\ttraining's binary_logloss: 0.00197767\n",
      "[687]\ttraining's binary_logloss: 0.0019655\n",
      "[688]\ttraining's binary_logloss: 0.00195309\n",
      "[689]\ttraining's binary_logloss: 0.00193957\n",
      "[690]\ttraining's binary_logloss: 0.00192792\n",
      "[691]\ttraining's binary_logloss: 0.00191631\n",
      "[692]\ttraining's binary_logloss: 0.00190319\n",
      "[693]\ttraining's binary_logloss: 0.00189036\n",
      "[694]\ttraining's binary_logloss: 0.00187844\n",
      "[695]\ttraining's binary_logloss: 0.00186557\n",
      "[696]\ttraining's binary_logloss: 0.00185324\n",
      "[697]\ttraining's binary_logloss: 0.00184265\n",
      "[698]\ttraining's binary_logloss: 0.00183193\n",
      "[699]\ttraining's binary_logloss: 0.00182106\n",
      "[700]\ttraining's binary_logloss: 0.00180977\n",
      "[701]\ttraining's binary_logloss: 0.001799\n",
      "[702]\ttraining's binary_logloss: 0.00178826\n",
      "[703]\ttraining's binary_logloss: 0.00177617\n",
      "[704]\ttraining's binary_logloss: 0.0017648\n",
      "[705]\ttraining's binary_logloss: 0.00175166\n",
      "[706]\ttraining's binary_logloss: 0.00174199\n",
      "[707]\ttraining's binary_logloss: 0.00173185\n",
      "[708]\ttraining's binary_logloss: 0.00172026\n",
      "[709]\ttraining's binary_logloss: 0.00171021\n",
      "[710]\ttraining's binary_logloss: 0.00169997\n",
      "[711]\ttraining's binary_logloss: 0.00166088\n",
      "[712]\ttraining's binary_logloss: 0.00162726\n",
      "[713]\ttraining's binary_logloss: 0.00160026\n",
      "[714]\ttraining's binary_logloss: 0.00157917\n",
      "[715]\ttraining's binary_logloss: 0.00155891\n",
      "[716]\ttraining's binary_logloss: 0.00153742\n",
      "[717]\ttraining's binary_logloss: 0.00151925\n",
      "[718]\ttraining's binary_logloss: 0.00150183\n",
      "[719]\ttraining's binary_logloss: 0.0014864\n",
      "[720]\ttraining's binary_logloss: 0.00147098\n",
      "[721]\ttraining's binary_logloss: 0.00145558\n",
      "[722]\ttraining's binary_logloss: 0.001442\n",
      "[723]\ttraining's binary_logloss: 0.00142807\n",
      "[724]\ttraining's binary_logloss: 0.00141392\n",
      "[725]\ttraining's binary_logloss: 0.00140134\n",
      "[726]\ttraining's binary_logloss: 0.00138849\n",
      "[727]\ttraining's binary_logloss: 0.00137657\n",
      "[728]\ttraining's binary_logloss: 0.00136481\n",
      "[729]\ttraining's binary_logloss: 0.00135335\n",
      "[730]\ttraining's binary_logloss: 0.00134117\n",
      "[731]\ttraining's binary_logloss: 0.00132954\n",
      "[732]\ttraining's binary_logloss: 0.00131801\n",
      "[733]\ttraining's binary_logloss: 0.00130696\n",
      "[734]\ttraining's binary_logloss: 0.00129615\n",
      "[735]\ttraining's binary_logloss: 0.00128503\n",
      "[736]\ttraining's binary_logloss: 0.00127396\n",
      "[737]\ttraining's binary_logloss: 0.00126359\n",
      "[738]\ttraining's binary_logloss: 0.00125352\n",
      "[739]\ttraining's binary_logloss: 0.00124338\n",
      "[740]\ttraining's binary_logloss: 0.00123319\n",
      "[741]\ttraining's binary_logloss: 0.00122344\n",
      "[742]\ttraining's binary_logloss: 0.00121384\n",
      "[743]\ttraining's binary_logloss: 0.00120416\n",
      "[744]\ttraining's binary_logloss: 0.00119492\n",
      "[745]\ttraining's binary_logloss: 0.0011856\n",
      "[746]\ttraining's binary_logloss: 0.00117625\n",
      "[747]\ttraining's binary_logloss: 0.00116676\n",
      "[748]\ttraining's binary_logloss: 0.00115759\n",
      "[749]\ttraining's binary_logloss: 0.00114864\n",
      "[750]\ttraining's binary_logloss: 0.00114002\n",
      "[751]\ttraining's binary_logloss: 0.00113149\n",
      "[752]\ttraining's binary_logloss: 0.00112303\n",
      "[753]\ttraining's binary_logloss: 0.00111437\n",
      "[754]\ttraining's binary_logloss: 0.00110509\n",
      "[755]\ttraining's binary_logloss: 0.00109621\n",
      "[756]\ttraining's binary_logloss: 0.00108805\n",
      "[757]\ttraining's binary_logloss: 0.0010797\n",
      "[758]\ttraining's binary_logloss: 0.00107133\n",
      "[759]\ttraining's binary_logloss: 0.00106305\n",
      "[760]\ttraining's binary_logloss: 0.00105497\n",
      "[761]\ttraining's binary_logloss: 0.0010466\n",
      "[762]\ttraining's binary_logloss: 0.0010383\n",
      "[763]\ttraining's binary_logloss: 0.00103005\n",
      "[764]\ttraining's binary_logloss: 0.00102244\n",
      "[765]\ttraining's binary_logloss: 0.00101468\n",
      "[766]\ttraining's binary_logloss: 0.00100691\n",
      "[767]\ttraining's binary_logloss: 0.000999504\n",
      "[768]\ttraining's binary_logloss: 0.000991858\n",
      "[769]\ttraining's binary_logloss: 0.000984214\n",
      "[770]\ttraining's binary_logloss: 0.000976777\n",
      "[771]\ttraining's binary_logloss: 0.000968783\n",
      "[772]\ttraining's binary_logloss: 0.000961577\n",
      "[773]\ttraining's binary_logloss: 0.000954919\n",
      "[774]\ttraining's binary_logloss: 0.000947551\n",
      "[775]\ttraining's binary_logloss: 0.000939862\n",
      "[776]\ttraining's binary_logloss: 0.000932297\n",
      "[777]\ttraining's binary_logloss: 0.000924699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[778]\ttraining's binary_logloss: 0.000917744\n",
      "[779]\ttraining's binary_logloss: 0.000911321\n",
      "[780]\ttraining's binary_logloss: 0.000904474\n",
      "[781]\ttraining's binary_logloss: 0.000897863\n",
      "[782]\ttraining's binary_logloss: 0.000891265\n",
      "[783]\ttraining's binary_logloss: 0.000884333\n",
      "[784]\ttraining's binary_logloss: 0.000877636\n",
      "[785]\ttraining's binary_logloss: 0.000871198\n",
      "[786]\ttraining's binary_logloss: 0.000864699\n",
      "[787]\ttraining's binary_logloss: 0.000857901\n",
      "[788]\ttraining's binary_logloss: 0.000851647\n",
      "[789]\ttraining's binary_logloss: 0.000845216\n",
      "[790]\ttraining's binary_logloss: 0.000838978\n",
      "[791]\ttraining's binary_logloss: 0.000832331\n",
      "[792]\ttraining's binary_logloss: 0.000826494\n",
      "[793]\ttraining's binary_logloss: 0.000820733\n",
      "[794]\ttraining's binary_logloss: 0.000814784\n",
      "[795]\ttraining's binary_logloss: 0.000808437\n",
      "[796]\ttraining's binary_logloss: 0.000802418\n",
      "[797]\ttraining's binary_logloss: 0.000796565\n",
      "[798]\ttraining's binary_logloss: 0.000790911\n",
      "[799]\ttraining's binary_logloss: 0.000784638\n",
      "[800]\ttraining's binary_logloss: 0.000778713\n",
      "[801]\ttraining's binary_logloss: 0.000772973\n",
      "[802]\ttraining's binary_logloss: 0.00076701\n",
      "[803]\ttraining's binary_logloss: 0.000761176\n",
      "[804]\ttraining's binary_logloss: 0.000755599\n",
      "[805]\ttraining's binary_logloss: 0.000749759\n",
      "[806]\ttraining's binary_logloss: 0.000744452\n",
      "[807]\ttraining's binary_logloss: 0.000739323\n",
      "[808]\ttraining's binary_logloss: 0.00073385\n",
      "[809]\ttraining's binary_logloss: 0.000728736\n",
      "[810]\ttraining's binary_logloss: 0.000722985\n",
      "[811]\ttraining's binary_logloss: 0.000718112\n",
      "[812]\ttraining's binary_logloss: 0.00071334\n",
      "[813]\ttraining's binary_logloss: 0.000708243\n",
      "[814]\ttraining's binary_logloss: 0.000702684\n",
      "[815]\ttraining's binary_logloss: 0.000697325\n",
      "[816]\ttraining's binary_logloss: 0.000692405\n",
      "[817]\ttraining's binary_logloss: 0.000687453\n",
      "[818]\ttraining's binary_logloss: 0.000682462\n",
      "[819]\ttraining's binary_logloss: 0.000677327\n",
      "[820]\ttraining's binary_logloss: 0.000672635\n",
      "[821]\ttraining's binary_logloss: 0.000667608\n",
      "[822]\ttraining's binary_logloss: 0.00066288\n",
      "[823]\ttraining's binary_logloss: 0.000658221\n",
      "[824]\ttraining's binary_logloss: 0.00065338\n",
      "[825]\ttraining's binary_logloss: 0.00064861\n",
      "[826]\ttraining's binary_logloss: 0.000644019\n",
      "[827]\ttraining's binary_logloss: 0.000639143\n",
      "[828]\ttraining's binary_logloss: 0.000634421\n",
      "[829]\ttraining's binary_logloss: 0.000630201\n",
      "[830]\ttraining's binary_logloss: 0.000625477\n",
      "[831]\ttraining's binary_logloss: 0.000620447\n",
      "[832]\ttraining's binary_logloss: 0.000616003\n",
      "[833]\ttraining's binary_logloss: 0.000611747\n",
      "[834]\ttraining's binary_logloss: 0.000607026\n",
      "[835]\ttraining's binary_logloss: 0.000602484\n",
      "[836]\ttraining's binary_logloss: 0.000598051\n",
      "[837]\ttraining's binary_logloss: 0.000593345\n",
      "[838]\ttraining's binary_logloss: 0.000589302\n",
      "[839]\ttraining's binary_logloss: 0.000585161\n",
      "[840]\ttraining's binary_logloss: 0.000580567\n",
      "[841]\ttraining's binary_logloss: 0.000576252\n",
      "[842]\ttraining's binary_logloss: 0.000571955\n",
      "[843]\ttraining's binary_logloss: 0.000567972\n",
      "[844]\ttraining's binary_logloss: 0.000564017\n",
      "[845]\ttraining's binary_logloss: 0.00055966\n",
      "[846]\ttraining's binary_logloss: 0.000555725\n",
      "[847]\ttraining's binary_logloss: 0.000551606\n",
      "[848]\ttraining's binary_logloss: 0.000547293\n",
      "[849]\ttraining's binary_logloss: 0.000543114\n",
      "[850]\ttraining's binary_logloss: 0.000539148\n",
      "[851]\ttraining's binary_logloss: 0.000535376\n",
      "[852]\ttraining's binary_logloss: 0.00053135\n",
      "[853]\ttraining's binary_logloss: 0.000527699\n",
      "[854]\ttraining's binary_logloss: 0.000523941\n",
      "[855]\ttraining's binary_logloss: 0.000519949\n",
      "[856]\ttraining's binary_logloss: 0.000515916\n",
      "[857]\ttraining's binary_logloss: 0.000511905\n",
      "[858]\ttraining's binary_logloss: 0.000507825\n",
      "[859]\ttraining's binary_logloss: 0.000504474\n",
      "[860]\ttraining's binary_logloss: 0.0005009\n",
      "[861]\ttraining's binary_logloss: 0.000497022\n",
      "[862]\ttraining's binary_logloss: 0.000493305\n",
      "[863]\ttraining's binary_logloss: 0.000490132\n",
      "[864]\ttraining's binary_logloss: 0.00048681\n",
      "[865]\ttraining's binary_logloss: 0.000483234\n",
      "[866]\ttraining's binary_logloss: 0.00048003\n",
      "[867]\ttraining's binary_logloss: 0.000476749\n",
      "[868]\ttraining's binary_logloss: 0.000473258\n",
      "[869]\ttraining's binary_logloss: 0.000469671\n",
      "[870]\ttraining's binary_logloss: 0.000466161\n",
      "[871]\ttraining's binary_logloss: 0.000462991\n",
      "[872]\ttraining's binary_logloss: 0.00045941\n",
      "[873]\ttraining's binary_logloss: 0.000456185\n",
      "[874]\ttraining's binary_logloss: 0.000452731\n",
      "[875]\ttraining's binary_logloss: 0.000449778\n",
      "[876]\ttraining's binary_logloss: 0.000446368\n",
      "[877]\ttraining's binary_logloss: 0.000443031\n",
      "[878]\ttraining's binary_logloss: 0.000440004\n",
      "[879]\ttraining's binary_logloss: 0.000436703\n",
      "[880]\ttraining's binary_logloss: 0.000433447\n",
      "[881]\ttraining's binary_logloss: 0.000430577\n",
      "[882]\ttraining's binary_logloss: 0.000427592\n",
      "[883]\ttraining's binary_logloss: 0.00042445\n",
      "[884]\ttraining's binary_logloss: 0.000420946\n",
      "[885]\ttraining's binary_logloss: 0.000417693\n",
      "[886]\ttraining's binary_logloss: 0.000414996\n",
      "[887]\ttraining's binary_logloss: 0.000412251\n",
      "[888]\ttraining's binary_logloss: 0.000409453\n",
      "[889]\ttraining's binary_logloss: 0.000406656\n",
      "[890]\ttraining's binary_logloss: 0.000403647\n",
      "[891]\ttraining's binary_logloss: 0.00040048\n",
      "[892]\ttraining's binary_logloss: 0.000397256\n",
      "[893]\ttraining's binary_logloss: 0.00039452\n",
      "[894]\ttraining's binary_logloss: 0.000391409\n",
      "[895]\ttraining's binary_logloss: 0.000388487\n",
      "[896]\ttraining's binary_logloss: 0.000385862\n",
      "[897]\ttraining's binary_logloss: 0.000383004\n",
      "[898]\ttraining's binary_logloss: 0.000380455\n",
      "[899]\ttraining's binary_logloss: 0.000377607\n",
      "[900]\ttraining's binary_logloss: 0.000375149\n",
      "[901]\ttraining's binary_logloss: 0.000372606\n",
      "[902]\ttraining's binary_logloss: 0.000370192\n",
      "[903]\ttraining's binary_logloss: 0.000367834\n",
      "[904]\ttraining's binary_logloss: 0.000365632\n",
      "[905]\ttraining's binary_logloss: 0.000363218\n",
      "[906]\ttraining's binary_logloss: 0.00036048\n",
      "[907]\ttraining's binary_logloss: 0.000358135\n",
      "[908]\ttraining's binary_logloss: 0.000355512\n",
      "[909]\ttraining's binary_logloss: 0.000353182\n",
      "[910]\ttraining's binary_logloss: 0.00035043\n",
      "[911]\ttraining's binary_logloss: 0.000347701\n",
      "[912]\ttraining's binary_logloss: 0.000345516\n",
      "[913]\ttraining's binary_logloss: 0.000342875\n",
      "[914]\ttraining's binary_logloss: 0.000340628\n",
      "[915]\ttraining's binary_logloss: 0.000338504\n",
      "[916]\ttraining's binary_logloss: 0.000336038\n",
      "[917]\ttraining's binary_logloss: 0.000333332\n",
      "[918]\ttraining's binary_logloss: 0.000331141\n",
      "[919]\ttraining's binary_logloss: 0.000329207\n",
      "[920]\ttraining's binary_logloss: 0.000326972\n",
      "[921]\ttraining's binary_logloss: 0.000324642\n",
      "[922]\ttraining's binary_logloss: 0.000322146\n",
      "[923]\ttraining's binary_logloss: 0.000319782\n",
      "[924]\ttraining's binary_logloss: 0.000317598\n",
      "[925]\ttraining's binary_logloss: 0.000315179\n",
      "[926]\ttraining's binary_logloss: 0.000313192\n",
      "[927]\ttraining's binary_logloss: 0.000311033\n",
      "[928]\ttraining's binary_logloss: 0.000308732\n",
      "[929]\ttraining's binary_logloss: 0.000306521\n",
      "[930]\ttraining's binary_logloss: 0.000304546\n",
      "[931]\ttraining's binary_logloss: 0.00030266\n",
      "[932]\ttraining's binary_logloss: 0.000300747\n",
      "[933]\ttraining's binary_logloss: 0.000298449\n",
      "[934]\ttraining's binary_logloss: 0.000296555\n",
      "[935]\ttraining's binary_logloss: 0.000294369\n",
      "[936]\ttraining's binary_logloss: 0.000292591\n",
      "[937]\ttraining's binary_logloss: 0.000290401\n",
      "[938]\ttraining's binary_logloss: 0.000288247\n",
      "[939]\ttraining's binary_logloss: 0.000286485\n",
      "[940]\ttraining's binary_logloss: 0.000284362\n",
      "[941]\ttraining's binary_logloss: 0.000282199\n",
      "[942]\ttraining's binary_logloss: 0.000280158\n",
      "[943]\ttraining's binary_logloss: 0.00027857\n",
      "[944]\ttraining's binary_logloss: 0.000276653\n",
      "[945]\ttraining's binary_logloss: 0.000274936\n",
      "[946]\ttraining's binary_logloss: 0.000272895\n",
      "[947]\ttraining's binary_logloss: 0.00027124\n",
      "[948]\ttraining's binary_logloss: 0.000269126\n",
      "[949]\ttraining's binary_logloss: 0.000267523\n",
      "[950]\ttraining's binary_logloss: 0.000265377\n",
      "[951]\ttraining's binary_logloss: 0.000263492\n",
      "[952]\ttraining's binary_logloss: 0.000261398\n",
      "[953]\ttraining's binary_logloss: 0.000259519\n",
      "[954]\ttraining's binary_logloss: 0.00025756\n",
      "[955]\ttraining's binary_logloss: 0.000255683\n",
      "[956]\ttraining's binary_logloss: 0.000253662\n",
      "[957]\ttraining's binary_logloss: 0.000252104\n",
      "[958]\ttraining's binary_logloss: 0.000250617\n",
      "[959]\ttraining's binary_logloss: 0.000249074\n",
      "[960]\ttraining's binary_logloss: 0.000247431\n",
      "[961]\ttraining's binary_logloss: 0.000245759\n",
      "[962]\ttraining's binary_logloss: 0.000244181\n",
      "[963]\ttraining's binary_logloss: 0.000242473\n",
      "[964]\ttraining's binary_logloss: 0.000240642\n",
      "[965]\ttraining's binary_logloss: 0.000238839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[966]\ttraining's binary_logloss: 0.000237133\n",
      "[967]\ttraining's binary_logloss: 0.000235747\n",
      "[968]\ttraining's binary_logloss: 0.000234227\n",
      "[969]\ttraining's binary_logloss: 0.000232402\n",
      "[970]\ttraining's binary_logloss: 0.000231023\n",
      "[971]\ttraining's binary_logloss: 0.000229196\n",
      "[972]\ttraining's binary_logloss: 0.000227612\n",
      "[973]\ttraining's binary_logloss: 0.00022639\n",
      "[974]\ttraining's binary_logloss: 0.000225063\n",
      "[975]\ttraining's binary_logloss: 0.000223813\n",
      "[976]\ttraining's binary_logloss: 0.000222086\n",
      "[977]\ttraining's binary_logloss: 0.000220834\n",
      "[978]\ttraining's binary_logloss: 0.000219167\n",
      "[979]\ttraining's binary_logloss: 0.000217519\n",
      "[980]\ttraining's binary_logloss: 0.000216224\n",
      "[981]\ttraining's binary_logloss: 0.000214986\n",
      "[982]\ttraining's binary_logloss: 0.000213927\n",
      "[983]\ttraining's binary_logloss: 0.000212762\n",
      "[984]\ttraining's binary_logloss: 0.000211161\n",
      "[985]\ttraining's binary_logloss: 0.000209501\n",
      "[986]\ttraining's binary_logloss: 0.000207771\n",
      "[987]\ttraining's binary_logloss: 0.000206628\n",
      "[988]\ttraining's binary_logloss: 0.000205247\n",
      "[989]\ttraining's binary_logloss: 0.000203633\n",
      "[990]\ttraining's binary_logloss: 0.000202256\n",
      "[991]\ttraining's binary_logloss: 0.000201047\n",
      "[992]\ttraining's binary_logloss: 0.000199609\n",
      "[993]\ttraining's binary_logloss: 0.000198428\n",
      "[994]\ttraining's binary_logloss: 0.000196885\n",
      "[995]\ttraining's binary_logloss: 0.000195703\n",
      "[996]\ttraining's binary_logloss: 0.000194197\n",
      "[997]\ttraining's binary_logloss: 0.000193169\n",
      "[998]\ttraining's binary_logloss: 0.000192135\n",
      "[999]\ttraining's binary_logloss: 0.000191064\n",
      "[1000]\ttraining's binary_logloss: 0.00018982\n",
      "[1001]\ttraining's binary_logloss: 0.000188895\n",
      "[1002]\ttraining's binary_logloss: 0.000187462\n",
      "[1003]\ttraining's binary_logloss: 0.000185962\n",
      "[1004]\ttraining's binary_logloss: 0.000184683\n",
      "[1005]\ttraining's binary_logloss: 0.000183597\n",
      "[1006]\ttraining's binary_logloss: 0.00018222\n",
      "[1007]\ttraining's binary_logloss: 0.000180717\n",
      "[1008]\ttraining's binary_logloss: 0.000179688\n",
      "[1009]\ttraining's binary_logloss: 0.000178289\n",
      "[1010]\ttraining's binary_logloss: 0.000177166\n",
      "[1011]\ttraining's binary_logloss: 0.000176184\n",
      "[1012]\ttraining's binary_logloss: 0.000174946\n",
      "[1013]\ttraining's binary_logloss: 0.000173952\n",
      "[1014]\ttraining's binary_logloss: 0.000172987\n",
      "[1015]\ttraining's binary_logloss: 0.000172078\n",
      "[1016]\ttraining's binary_logloss: 0.000170934\n",
      "[1017]\ttraining's binary_logloss: 0.000169576\n",
      "[1018]\ttraining's binary_logloss: 0.00016877\n",
      "[1019]\ttraining's binary_logloss: 0.000167523\n",
      "[1020]\ttraining's binary_logloss: 0.000166785\n",
      "[1021]\ttraining's binary_logloss: 0.000165559\n",
      "[1022]\ttraining's binary_logloss: 0.000164763\n",
      "[1023]\ttraining's binary_logloss: 0.000163813\n",
      "[1024]\ttraining's binary_logloss: 0.000162712\n",
      "[1025]\ttraining's binary_logloss: 0.000161927\n",
      "[1026]\ttraining's binary_logloss: 0.000161059\n",
      "[1027]\ttraining's binary_logloss: 0.000160241\n",
      "[1028]\ttraining's binary_logloss: 0.000159293\n",
      "[1029]\ttraining's binary_logloss: 0.00015809\n",
      "[1030]\ttraining's binary_logloss: 0.000157465\n",
      "[1031]\ttraining's binary_logloss: 0.000156185\n",
      "[1032]\ttraining's binary_logloss: 0.000155452\n",
      "[1033]\ttraining's binary_logloss: 0.000154567\n",
      "[1034]\ttraining's binary_logloss: 0.000153342\n",
      "[1035]\ttraining's binary_logloss: 0.000152744\n",
      "[1036]\ttraining's binary_logloss: 0.000151865\n",
      "[1037]\ttraining's binary_logloss: 0.000150617\n",
      "[1038]\ttraining's binary_logloss: 0.000149472\n",
      "[1039]\ttraining's binary_logloss: 0.000148805\n",
      "[1040]\ttraining's binary_logloss: 0.000147942\n",
      "[1041]\ttraining's binary_logloss: 0.00014698\n",
      "[1042]\ttraining's binary_logloss: 0.000146404\n",
      "[1043]\ttraining's binary_logloss: 0.000145496\n",
      "[1044]\ttraining's binary_logloss: 0.000144661\n",
      "[1045]\ttraining's binary_logloss: 0.000143821\n",
      "[1046]\ttraining's binary_logloss: 0.000143189\n",
      "[1047]\ttraining's binary_logloss: 0.000142133\n",
      "[1048]\ttraining's binary_logloss: 0.000141208\n",
      "[1049]\ttraining's binary_logloss: 0.000140313\n",
      "[1050]\ttraining's binary_logloss: 0.000139267\n",
      "[1051]\ttraining's binary_logloss: 0.000138726\n",
      "[1052]\ttraining's binary_logloss: 0.000137814\n",
      "[1053]\ttraining's binary_logloss: 0.000137177\n",
      "[1054]\ttraining's binary_logloss: 0.000136201\n",
      "[1055]\ttraining's binary_logloss: 0.000135274\n",
      "[1056]\ttraining's binary_logloss: 0.00013419\n",
      "[1057]\ttraining's binary_logloss: 0.000133687\n",
      "[1058]\ttraining's binary_logloss: 0.000132644\n",
      "[1059]\ttraining's binary_logloss: 0.000131979\n",
      "[1060]\ttraining's binary_logloss: 0.000130848\n",
      "[1061]\ttraining's binary_logloss: 0.000129722\n",
      "[1062]\ttraining's binary_logloss: 0.000129292\n",
      "[1063]\ttraining's binary_logloss: 0.0001285\n",
      "[1064]\ttraining's binary_logloss: 0.000128057\n",
      "[1065]\ttraining's binary_logloss: 0.00012717\n",
      "[1066]\ttraining's binary_logloss: 0.00012671\n",
      "[1067]\ttraining's binary_logloss: 0.000126249\n",
      "[1068]\ttraining's binary_logloss: 0.000125332\n",
      "[1069]\ttraining's binary_logloss: 0.000124886\n",
      "[1070]\ttraining's binary_logloss: 0.000124504\n",
      "[1071]\ttraining's binary_logloss: 0.000124019\n",
      "[1072]\ttraining's binary_logloss: 0.000123596\n",
      "[1073]\ttraining's binary_logloss: 0.000123159\n",
      "[1074]\ttraining's binary_logloss: 0.000122693\n",
      "[1075]\ttraining's binary_logloss: 0.000121662\n",
      "[1076]\ttraining's binary_logloss: 0.000120922\n",
      "[1077]\ttraining's binary_logloss: 0.000120465\n",
      "[1078]\ttraining's binary_logloss: 0.00011936\n",
      "[1079]\ttraining's binary_logloss: 0.00011844\n",
      "[1080]\ttraining's binary_logloss: 0.000117949\n",
      "[1081]\ttraining's binary_logloss: 0.000117229\n",
      "[1082]\ttraining's binary_logloss: 0.000116888\n",
      "[1083]\ttraining's binary_logloss: 0.000115975\n",
      "[1084]\ttraining's binary_logloss: 0.00011557\n",
      "[1085]\ttraining's binary_logloss: 0.000115255\n",
      "[1086]\ttraining's binary_logloss: 0.000114934\n",
      "[1087]\ttraining's binary_logloss: 0.000114685\n",
      "[1088]\ttraining's binary_logloss: 0.000113702\n",
      "[1089]\ttraining's binary_logloss: 0.000112856\n",
      "[1090]\ttraining's binary_logloss: 0.000111809\n",
      "[1091]\ttraining's binary_logloss: 0.000111122\n",
      "[1092]\ttraining's binary_logloss: 0.000110345\n",
      "[1093]\ttraining's binary_logloss: 0.000109413\n",
      "[1094]\ttraining's binary_logloss: 0.000108638\n",
      "[1095]\ttraining's binary_logloss: 0.000107685\n",
      "[1096]\ttraining's binary_logloss: 0.000107159\n",
      "[1097]\ttraining's binary_logloss: 0.000106354\n",
      "[1098]\ttraining's binary_logloss: 0.000105567\n",
      "[1099]\ttraining's binary_logloss: 0.000104773\n",
      "[1100]\ttraining's binary_logloss: 0.000104478\n",
      "[1101]\ttraining's binary_logloss: 0.000103536\n",
      "[1102]\ttraining's binary_logloss: 0.000103195\n",
      "[1103]\ttraining's binary_logloss: 0.000102459\n",
      "[1104]\ttraining's binary_logloss: 0.000101619\n",
      "[1105]\ttraining's binary_logloss: 0.000101226\n",
      "[1106]\ttraining's binary_logloss: 0.000100339\n",
      "[1107]\ttraining's binary_logloss: 0.000100077\n",
      "[1108]\ttraining's binary_logloss: 9.94696e-05\n",
      "[1109]\ttraining's binary_logloss: 9.87492e-05\n",
      "[1110]\ttraining's binary_logloss: 9.78944e-05\n",
      "[1111]\ttraining's binary_logloss: 9.75052e-05\n",
      "[1112]\ttraining's binary_logloss: 9.70236e-05\n",
      "[1113]\ttraining's binary_logloss: 9.61892e-05\n",
      "[1114]\ttraining's binary_logloss: 9.56606e-05\n",
      "[1115]\ttraining's binary_logloss: 9.48396e-05\n",
      "[1116]\ttraining's binary_logloss: 9.40722e-05\n",
      "[1117]\ttraining's binary_logloss: 9.34058e-05\n",
      "[1118]\ttraining's binary_logloss: 9.255e-05\n",
      "[1119]\ttraining's binary_logloss: 9.18932e-05\n",
      "[1120]\ttraining's binary_logloss: 9.14164e-05\n",
      "[1121]\ttraining's binary_logloss: 9.1085e-05\n",
      "[1122]\ttraining's binary_logloss: 9.09619e-05\n",
      "[1123]\ttraining's binary_logloss: 9.08088e-05\n",
      "[1124]\ttraining's binary_logloss: 9.01153e-05\n",
      "[1125]\ttraining's binary_logloss: 8.94244e-05\n",
      "[1126]\ttraining's binary_logloss: 8.87134e-05\n",
      "[1127]\ttraining's binary_logloss: 8.85982e-05\n",
      "[1128]\ttraining's binary_logloss: 8.84456e-05\n",
      "[1129]\ttraining's binary_logloss: 8.76789e-05\n",
      "[1130]\ttraining's binary_logloss: 8.68932e-05\n",
      "[1131]\ttraining's binary_logloss: 8.61358e-05\n",
      "[1132]\ttraining's binary_logloss: 8.53242e-05\n",
      "[1133]\ttraining's binary_logloss: 8.46742e-05\n",
      "[1134]\ttraining's binary_logloss: 8.39233e-05\n",
      "[1135]\ttraining's binary_logloss: 8.34557e-05\n",
      "[1136]\ttraining's binary_logloss: 8.29668e-05\n",
      "[1137]\ttraining's binary_logloss: 8.2726e-05\n",
      "[1138]\ttraining's binary_logloss: 8.19687e-05\n",
      "[1139]\ttraining's binary_logloss: 8.12392e-05\n",
      "[1140]\ttraining's binary_logloss: 8.10243e-05\n",
      "[1141]\ttraining's binary_logloss: 8.07194e-05\n",
      "[1142]\ttraining's binary_logloss: 8.01353e-05\n",
      "[1143]\ttraining's binary_logloss: 7.98742e-05\n",
      "[1144]\ttraining's binary_logloss: 7.90943e-05\n",
      "[1145]\ttraining's binary_logloss: 7.81338e-05\n",
      "[1146]\ttraining's binary_logloss: 7.72333e-05\n",
      "[1147]\ttraining's binary_logloss: 7.62974e-05\n",
      "[1148]\ttraining's binary_logloss: 7.54405e-05\n",
      "[1149]\ttraining's binary_logloss: 7.45554e-05\n",
      "[1150]\ttraining's binary_logloss: 7.3704e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1151]\ttraining's binary_logloss: 7.28559e-05\n",
      "[1152]\ttraining's binary_logloss: 7.2054e-05\n",
      "[1153]\ttraining's binary_logloss: 7.12271e-05\n",
      "[1154]\ttraining's binary_logloss: 7.04427e-05\n",
      "[1155]\ttraining's binary_logloss: 6.96573e-05\n",
      "[1156]\ttraining's binary_logloss: 6.8886e-05\n",
      "[1157]\ttraining's binary_logloss: 6.81261e-05\n",
      "[1158]\ttraining's binary_logloss: 6.74114e-05\n",
      "[1159]\ttraining's binary_logloss: 6.67075e-05\n",
      "[1160]\ttraining's binary_logloss: 6.60037e-05\n",
      "[1161]\ttraining's binary_logloss: 6.53071e-05\n",
      "[1162]\ttraining's binary_logloss: 6.46151e-05\n",
      "[1163]\ttraining's binary_logloss: 6.39462e-05\n",
      "[1164]\ttraining's binary_logloss: 6.32633e-05\n",
      "[1165]\ttraining's binary_logloss: 6.25969e-05\n",
      "[1166]\ttraining's binary_logloss: 6.19462e-05\n",
      "[1167]\ttraining's binary_logloss: 6.13293e-05\n",
      "[1168]\ttraining's binary_logloss: 6.06975e-05\n",
      "[1169]\ttraining's binary_logloss: 6.00733e-05\n",
      "[1170]\ttraining's binary_logloss: 5.94693e-05\n",
      "[1171]\ttraining's binary_logloss: 5.88608e-05\n",
      "[1172]\ttraining's binary_logloss: 5.82693e-05\n",
      "[1173]\ttraining's binary_logloss: 5.76909e-05\n",
      "[1174]\ttraining's binary_logloss: 5.71327e-05\n",
      "[1175]\ttraining's binary_logloss: 5.65633e-05\n",
      "[1176]\ttraining's binary_logloss: 5.60328e-05\n",
      "[1177]\ttraining's binary_logloss: 5.55119e-05\n",
      "[1178]\ttraining's binary_logloss: 5.49711e-05\n",
      "[1179]\ttraining's binary_logloss: 5.44623e-05\n",
      "[1180]\ttraining's binary_logloss: 5.39478e-05\n",
      "[1181]\ttraining's binary_logloss: 5.34326e-05\n",
      "[1182]\ttraining's binary_logloss: 5.29374e-05\n",
      "[1183]\ttraining's binary_logloss: 5.24521e-05\n",
      "[1184]\ttraining's binary_logloss: 5.19486e-05\n",
      "[1185]\ttraining's binary_logloss: 5.14775e-05\n",
      "[1186]\ttraining's binary_logloss: 5.10039e-05\n",
      "[1187]\ttraining's binary_logloss: 5.05449e-05\n",
      "[1188]\ttraining's binary_logloss: 5.00768e-05\n",
      "[1189]\ttraining's binary_logloss: 4.96186e-05\n",
      "[1190]\ttraining's binary_logloss: 4.91684e-05\n",
      "[1191]\ttraining's binary_logloss: 4.87261e-05\n",
      "[1192]\ttraining's binary_logloss: 4.82923e-05\n",
      "[1193]\ttraining's binary_logloss: 4.78685e-05\n",
      "[1194]\ttraining's binary_logloss: 4.74448e-05\n",
      "[1195]\ttraining's binary_logloss: 4.70299e-05\n",
      "[1196]\ttraining's binary_logloss: 4.66172e-05\n",
      "[1197]\ttraining's binary_logloss: 4.6212e-05\n",
      "[1198]\ttraining's binary_logloss: 4.57995e-05\n",
      "[1199]\ttraining's binary_logloss: 4.54102e-05\n",
      "[1200]\ttraining's binary_logloss: 4.50222e-05\n",
      "[1201]\ttraining's binary_logloss: 4.46512e-05\n",
      "[1202]\ttraining's binary_logloss: 4.42796e-05\n",
      "[1203]\ttraining's binary_logloss: 4.39024e-05\n",
      "[1204]\ttraining's binary_logloss: 4.35465e-05\n",
      "[1205]\ttraining's binary_logloss: 4.31735e-05\n",
      "[1206]\ttraining's binary_logloss: 4.28058e-05\n",
      "[1207]\ttraining's binary_logloss: 4.24326e-05\n",
      "[1208]\ttraining's binary_logloss: 4.20718e-05\n",
      "[1209]\ttraining's binary_logloss: 4.17269e-05\n",
      "[1210]\ttraining's binary_logloss: 4.13774e-05\n",
      "[1211]\ttraining's binary_logloss: 4.10528e-05\n",
      "[1212]\ttraining's binary_logloss: 4.07227e-05\n",
      "[1213]\ttraining's binary_logloss: 4.03887e-05\n",
      "[1214]\ttraining's binary_logloss: 4.00509e-05\n",
      "[1215]\ttraining's binary_logloss: 3.97292e-05\n",
      "[1216]\ttraining's binary_logloss: 3.94052e-05\n",
      "[1217]\ttraining's binary_logloss: 3.90771e-05\n",
      "[1218]\ttraining's binary_logloss: 3.876e-05\n",
      "[1219]\ttraining's binary_logloss: 3.84541e-05\n",
      "[1220]\ttraining's binary_logloss: 3.81625e-05\n",
      "[1221]\ttraining's binary_logloss: 3.7872e-05\n",
      "[1222]\ttraining's binary_logloss: 3.75833e-05\n",
      "[1223]\ttraining's binary_logloss: 3.72891e-05\n",
      "[1224]\ttraining's binary_logloss: 3.69994e-05\n",
      "[1225]\ttraining's binary_logloss: 3.67186e-05\n",
      "[1226]\ttraining's binary_logloss: 3.64322e-05\n",
      "[1227]\ttraining's binary_logloss: 3.61573e-05\n",
      "[1228]\ttraining's binary_logloss: 3.58792e-05\n",
      "[1229]\ttraining's binary_logloss: 3.56231e-05\n",
      "[1230]\ttraining's binary_logloss: 3.53477e-05\n",
      "[1231]\ttraining's binary_logloss: 3.50716e-05\n",
      "[1232]\ttraining's binary_logloss: 3.48179e-05\n",
      "[1233]\ttraining's binary_logloss: 3.45483e-05\n",
      "[1234]\ttraining's binary_logloss: 3.42866e-05\n",
      "[1235]\ttraining's binary_logloss: 3.40284e-05\n",
      "[1236]\ttraining's binary_logloss: 3.37778e-05\n",
      "[1237]\ttraining's binary_logloss: 3.35366e-05\n",
      "[1238]\ttraining's binary_logloss: 3.32917e-05\n",
      "[1239]\ttraining's binary_logloss: 3.30542e-05\n",
      "[1240]\ttraining's binary_logloss: 3.2814e-05\n",
      "[1241]\ttraining's binary_logloss: 3.25822e-05\n",
      "[1242]\ttraining's binary_logloss: 3.23505e-05\n",
      "[1243]\ttraining's binary_logloss: 3.21223e-05\n",
      "[1244]\ttraining's binary_logloss: 3.18993e-05\n",
      "[1245]\ttraining's binary_logloss: 3.16738e-05\n",
      "[1246]\ttraining's binary_logloss: 3.14519e-05\n",
      "[1247]\ttraining's binary_logloss: 3.12348e-05\n",
      "[1248]\ttraining's binary_logloss: 3.10037e-05\n",
      "[1249]\ttraining's binary_logloss: 3.07882e-05\n",
      "[1250]\ttraining's binary_logloss: 3.05747e-05\n",
      "[1251]\ttraining's binary_logloss: 3.03741e-05\n",
      "[1252]\ttraining's binary_logloss: 3.01624e-05\n",
      "[1253]\ttraining's binary_logloss: 2.99561e-05\n",
      "[1254]\ttraining's binary_logloss: 2.97473e-05\n",
      "[1255]\ttraining's binary_logloss: 2.95527e-05\n",
      "[1256]\ttraining's binary_logloss: 2.93546e-05\n",
      "[1257]\ttraining's binary_logloss: 2.91539e-05\n",
      "[1258]\ttraining's binary_logloss: 2.89582e-05\n",
      "[1259]\ttraining's binary_logloss: 2.8763e-05\n",
      "[1260]\ttraining's binary_logloss: 2.85671e-05\n",
      "[1261]\ttraining's binary_logloss: 2.83706e-05\n",
      "[1262]\ttraining's binary_logloss: 2.81781e-05\n",
      "[1263]\ttraining's binary_logloss: 2.79929e-05\n",
      "[1264]\ttraining's binary_logloss: 2.78064e-05\n",
      "[1265]\ttraining's binary_logloss: 2.76251e-05\n",
      "[1266]\ttraining's binary_logloss: 2.74473e-05\n",
      "[1267]\ttraining's binary_logloss: 2.72797e-05\n",
      "[1268]\ttraining's binary_logloss: 2.71134e-05\n",
      "[1269]\ttraining's binary_logloss: 2.69423e-05\n",
      "[1270]\ttraining's binary_logloss: 2.67797e-05\n",
      "[1271]\ttraining's binary_logloss: 2.661e-05\n",
      "[1272]\ttraining's binary_logloss: 2.64562e-05\n",
      "[1273]\ttraining's binary_logloss: 2.63018e-05\n",
      "[1274]\ttraining's binary_logloss: 2.61436e-05\n",
      "[1275]\ttraining's binary_logloss: 2.59879e-05\n",
      "[1276]\ttraining's binary_logloss: 2.58372e-05\n",
      "[1277]\ttraining's binary_logloss: 2.56866e-05\n",
      "[1278]\ttraining's binary_logloss: 2.55236e-05\n",
      "[1279]\ttraining's binary_logloss: 2.53639e-05\n",
      "[1280]\ttraining's binary_logloss: 2.52121e-05\n",
      "[1281]\ttraining's binary_logloss: 2.5061e-05\n",
      "[1282]\ttraining's binary_logloss: 2.49033e-05\n",
      "[1283]\ttraining's binary_logloss: 2.47616e-05\n",
      "[1284]\ttraining's binary_logloss: 2.46235e-05\n",
      "[1285]\ttraining's binary_logloss: 2.44777e-05\n",
      "[1286]\ttraining's binary_logloss: 2.43309e-05\n",
      "[1287]\ttraining's binary_logloss: 2.41817e-05\n",
      "[1288]\ttraining's binary_logloss: 2.40528e-05\n",
      "[1289]\ttraining's binary_logloss: 2.39145e-05\n",
      "[1290]\ttraining's binary_logloss: 2.37849e-05\n",
      "[1291]\ttraining's binary_logloss: 2.36493e-05\n",
      "[1292]\ttraining's binary_logloss: 2.3519e-05\n",
      "[1293]\ttraining's binary_logloss: 2.33854e-05\n",
      "[1294]\ttraining's binary_logloss: 2.32665e-05\n",
      "[1295]\ttraining's binary_logloss: 2.31447e-05\n",
      "[1296]\ttraining's binary_logloss: 2.3013e-05\n",
      "[1297]\ttraining's binary_logloss: 2.28851e-05\n",
      "[1298]\ttraining's binary_logloss: 2.27509e-05\n",
      "[1299]\ttraining's binary_logloss: 2.26296e-05\n",
      "[1300]\ttraining's binary_logloss: 2.25037e-05\n",
      "[1301]\ttraining's binary_logloss: 2.23764e-05\n",
      "[1302]\ttraining's binary_logloss: 2.22659e-05\n",
      "[1303]\ttraining's binary_logloss: 2.21418e-05\n",
      "[1304]\ttraining's binary_logloss: 2.20267e-05\n",
      "[1305]\ttraining's binary_logloss: 2.19073e-05\n",
      "[1306]\ttraining's binary_logloss: 2.17926e-05\n",
      "[1307]\ttraining's binary_logloss: 2.16764e-05\n",
      "[1308]\ttraining's binary_logloss: 2.15645e-05\n",
      "[1309]\ttraining's binary_logloss: 2.14488e-05\n",
      "[1310]\ttraining's binary_logloss: 2.13384e-05\n",
      "[1311]\ttraining's binary_logloss: 2.12276e-05\n",
      "[1312]\ttraining's binary_logloss: 2.11203e-05\n",
      "[1313]\ttraining's binary_logloss: 2.10126e-05\n",
      "[1314]\ttraining's binary_logloss: 2.09052e-05\n",
      "[1315]\ttraining's binary_logloss: 2.07993e-05\n",
      "[1316]\ttraining's binary_logloss: 2.06886e-05\n",
      "[1317]\ttraining's binary_logloss: 2.05921e-05\n",
      "[1318]\ttraining's binary_logloss: 2.04903e-05\n",
      "[1319]\ttraining's binary_logloss: 2.03921e-05\n",
      "[1320]\ttraining's binary_logloss: 2.02983e-05\n",
      "[1321]\ttraining's binary_logloss: 2.01997e-05\n",
      "[1322]\ttraining's binary_logloss: 2.0098e-05\n",
      "[1323]\ttraining's binary_logloss: 2.00032e-05\n",
      "[1324]\ttraining's binary_logloss: 1.99097e-05\n",
      "[1325]\ttraining's binary_logloss: 1.98212e-05\n",
      "[1326]\ttraining's binary_logloss: 1.9731e-05\n",
      "[1327]\ttraining's binary_logloss: 1.96319e-05\n",
      "[1328]\ttraining's binary_logloss: 1.95388e-05\n",
      "[1329]\ttraining's binary_logloss: 1.94495e-05\n",
      "[1330]\ttraining's binary_logloss: 1.93583e-05\n",
      "[1331]\ttraining's binary_logloss: 1.92669e-05\n",
      "[1332]\ttraining's binary_logloss: 1.91781e-05\n",
      "[1333]\ttraining's binary_logloss: 1.90877e-05\n",
      "[1334]\ttraining's binary_logloss: 1.89895e-05\n",
      "[1335]\ttraining's binary_logloss: 1.89035e-05\n",
      "[1336]\ttraining's binary_logloss: 1.88156e-05\n",
      "[1337]\ttraining's binary_logloss: 1.87276e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1338]\ttraining's binary_logloss: 1.86435e-05\n",
      "[1339]\ttraining's binary_logloss: 1.85559e-05\n",
      "[1340]\ttraining's binary_logloss: 1.84692e-05\n",
      "[1341]\ttraining's binary_logloss: 1.83826e-05\n",
      "[1342]\ttraining's binary_logloss: 1.83039e-05\n",
      "[1343]\ttraining's binary_logloss: 1.82201e-05\n",
      "[1344]\ttraining's binary_logloss: 1.81407e-05\n",
      "[1345]\ttraining's binary_logloss: 1.80676e-05\n",
      "[1346]\ttraining's binary_logloss: 1.79917e-05\n",
      "[1347]\ttraining's binary_logloss: 1.79126e-05\n",
      "[1348]\ttraining's binary_logloss: 1.7833e-05\n",
      "[1349]\ttraining's binary_logloss: 1.77569e-05\n",
      "[1350]\ttraining's binary_logloss: 1.7679e-05\n",
      "[1351]\ttraining's binary_logloss: 1.75983e-05\n",
      "[1352]\ttraining's binary_logloss: 1.75279e-05\n",
      "[1353]\ttraining's binary_logloss: 1.74535e-05\n",
      "[1354]\ttraining's binary_logloss: 1.73776e-05\n",
      "[1355]\ttraining's binary_logloss: 1.7304e-05\n",
      "[1356]\ttraining's binary_logloss: 1.7228e-05\n",
      "[1357]\ttraining's binary_logloss: 1.71516e-05\n",
      "[1358]\ttraining's binary_logloss: 1.70838e-05\n",
      "[1359]\ttraining's binary_logloss: 1.70124e-05\n",
      "[1360]\ttraining's binary_logloss: 1.69455e-05\n",
      "[1361]\ttraining's binary_logloss: 1.68737e-05\n",
      "[1362]\ttraining's binary_logloss: 1.68054e-05\n",
      "[1363]\ttraining's binary_logloss: 1.67347e-05\n",
      "[1364]\ttraining's binary_logloss: 1.66698e-05\n",
      "[1365]\ttraining's binary_logloss: 1.66012e-05\n",
      "[1366]\ttraining's binary_logloss: 1.6537e-05\n",
      "[1367]\ttraining's binary_logloss: 1.647e-05\n",
      "[1368]\ttraining's binary_logloss: 1.64028e-05\n",
      "[1369]\ttraining's binary_logloss: 1.6338e-05\n",
      "[1370]\ttraining's binary_logloss: 1.62793e-05\n",
      "[1371]\ttraining's binary_logloss: 1.6217e-05\n",
      "[1372]\ttraining's binary_logloss: 1.61536e-05\n",
      "[1373]\ttraining's binary_logloss: 1.6096e-05\n",
      "[1374]\ttraining's binary_logloss: 1.60369e-05\n",
      "[1375]\ttraining's binary_logloss: 1.59726e-05\n",
      "[1376]\ttraining's binary_logloss: 1.59109e-05\n",
      "[1377]\ttraining's binary_logloss: 1.58473e-05\n",
      "[1378]\ttraining's binary_logloss: 1.57877e-05\n",
      "[1379]\ttraining's binary_logloss: 1.57238e-05\n",
      "[1380]\ttraining's binary_logloss: 1.56654e-05\n",
      "[1381]\ttraining's binary_logloss: 1.5609e-05\n",
      "[1382]\ttraining's binary_logloss: 1.55519e-05\n",
      "[1383]\ttraining's binary_logloss: 1.54921e-05\n",
      "[1384]\ttraining's binary_logloss: 1.54309e-05\n",
      "[1385]\ttraining's binary_logloss: 1.53776e-05\n",
      "[1386]\ttraining's binary_logloss: 1.53218e-05\n",
      "[1387]\ttraining's binary_logloss: 1.52696e-05\n",
      "[1388]\ttraining's binary_logloss: 1.52132e-05\n",
      "[1389]\ttraining's binary_logloss: 1.51575e-05\n",
      "[1390]\ttraining's binary_logloss: 1.51024e-05\n",
      "[1391]\ttraining's binary_logloss: 1.50449e-05\n",
      "[1392]\ttraining's binary_logloss: 1.49938e-05\n",
      "[1393]\ttraining's binary_logloss: 1.49397e-05\n",
      "[1394]\ttraining's binary_logloss: 1.48891e-05\n",
      "[1395]\ttraining's binary_logloss: 1.48321e-05\n",
      "[1396]\ttraining's binary_logloss: 1.4779e-05\n",
      "[1397]\ttraining's binary_logloss: 1.47245e-05\n",
      "[1398]\ttraining's binary_logloss: 1.46761e-05\n",
      "[1399]\ttraining's binary_logloss: 1.46259e-05\n",
      "[1400]\ttraining's binary_logloss: 1.45793e-05\n",
      "[1401]\ttraining's binary_logloss: 1.45257e-05\n",
      "[1402]\ttraining's binary_logloss: 1.44805e-05\n",
      "[1403]\ttraining's binary_logloss: 1.44329e-05\n",
      "[1404]\ttraining's binary_logloss: 1.4388e-05\n",
      "[1405]\ttraining's binary_logloss: 1.43355e-05\n",
      "[1406]\ttraining's binary_logloss: 1.42881e-05\n",
      "[1407]\ttraining's binary_logloss: 1.42388e-05\n",
      "[1408]\ttraining's binary_logloss: 1.41909e-05\n",
      "[1409]\ttraining's binary_logloss: 1.41407e-05\n",
      "[1410]\ttraining's binary_logloss: 1.40901e-05\n",
      "[1411]\ttraining's binary_logloss: 1.4044e-05\n",
      "[1412]\ttraining's binary_logloss: 1.39983e-05\n",
      "[1413]\ttraining's binary_logloss: 1.39502e-05\n",
      "[1414]\ttraining's binary_logloss: 1.39024e-05\n",
      "[1415]\ttraining's binary_logloss: 1.38534e-05\n",
      "[1416]\ttraining's binary_logloss: 1.38029e-05\n",
      "[1417]\ttraining's binary_logloss: 1.37555e-05\n",
      "[1418]\ttraining's binary_logloss: 1.3713e-05\n",
      "[1419]\ttraining's binary_logloss: 1.36651e-05\n",
      "[1420]\ttraining's binary_logloss: 1.36224e-05\n",
      "[1421]\ttraining's binary_logloss: 1.35761e-05\n",
      "[1422]\ttraining's binary_logloss: 1.3531e-05\n",
      "[1423]\ttraining's binary_logloss: 1.34861e-05\n",
      "[1424]\ttraining's binary_logloss: 1.34398e-05\n",
      "[1425]\ttraining's binary_logloss: 1.33944e-05\n",
      "[1426]\ttraining's binary_logloss: 1.33511e-05\n",
      "[1427]\ttraining's binary_logloss: 1.33145e-05\n",
      "[1428]\ttraining's binary_logloss: 1.32737e-05\n",
      "[1429]\ttraining's binary_logloss: 1.32291e-05\n",
      "[1430]\ttraining's binary_logloss: 1.31843e-05\n",
      "[1431]\ttraining's binary_logloss: 1.31435e-05\n",
      "[1432]\ttraining's binary_logloss: 1.31031e-05\n",
      "[1433]\ttraining's binary_logloss: 1.30649e-05\n",
      "[1434]\ttraining's binary_logloss: 1.30255e-05\n",
      "[1435]\ttraining's binary_logloss: 1.29857e-05\n",
      "[1436]\ttraining's binary_logloss: 1.29426e-05\n",
      "[1437]\ttraining's binary_logloss: 1.29037e-05\n",
      "[1438]\ttraining's binary_logloss: 1.28671e-05\n",
      "[1439]\ttraining's binary_logloss: 1.28315e-05\n",
      "[1440]\ttraining's binary_logloss: 1.27924e-05\n",
      "[1441]\ttraining's binary_logloss: 1.27492e-05\n",
      "[1442]\ttraining's binary_logloss: 1.27086e-05\n",
      "[1443]\ttraining's binary_logloss: 1.2669e-05\n",
      "[1444]\ttraining's binary_logloss: 1.26303e-05\n",
      "[1445]\ttraining's binary_logloss: 1.25942e-05\n",
      "[1446]\ttraining's binary_logloss: 1.25575e-05\n",
      "[1447]\ttraining's binary_logloss: 1.25217e-05\n",
      "[1448]\ttraining's binary_logloss: 1.24827e-05\n",
      "[1449]\ttraining's binary_logloss: 1.24472e-05\n",
      "[1450]\ttraining's binary_logloss: 1.24043e-05\n",
      "[1451]\ttraining's binary_logloss: 1.23675e-05\n",
      "[1452]\ttraining's binary_logloss: 1.23307e-05\n",
      "[1453]\ttraining's binary_logloss: 1.22912e-05\n",
      "[1454]\ttraining's binary_logloss: 1.22494e-05\n",
      "[1455]\ttraining's binary_logloss: 1.22072e-05\n",
      "[1456]\ttraining's binary_logloss: 1.21707e-05\n",
      "[1457]\ttraining's binary_logloss: 1.21332e-05\n",
      "[1458]\ttraining's binary_logloss: 1.20931e-05\n",
      "[1459]\ttraining's binary_logloss: 1.20585e-05\n",
      "[1460]\ttraining's binary_logloss: 1.20199e-05\n",
      "[1461]\ttraining's binary_logloss: 1.1983e-05\n",
      "[1462]\ttraining's binary_logloss: 1.19463e-05\n",
      "[1463]\ttraining's binary_logloss: 1.19099e-05\n",
      "[1464]\ttraining's binary_logloss: 1.18742e-05\n",
      "[1465]\ttraining's binary_logloss: 1.18408e-05\n",
      "[1466]\ttraining's binary_logloss: 1.18044e-05\n",
      "[1467]\ttraining's binary_logloss: 1.17701e-05\n",
      "[1468]\ttraining's binary_logloss: 1.1734e-05\n",
      "[1469]\ttraining's binary_logloss: 1.16993e-05\n",
      "[1470]\ttraining's binary_logloss: 1.16653e-05\n",
      "[1471]\ttraining's binary_logloss: 1.16315e-05\n",
      "[1472]\ttraining's binary_logloss: 1.15981e-05\n",
      "[1473]\ttraining's binary_logloss: 1.15657e-05\n",
      "[1474]\ttraining's binary_logloss: 1.15332e-05\n",
      "[1475]\ttraining's binary_logloss: 1.15009e-05\n",
      "[1476]\ttraining's binary_logloss: 1.147e-05\n",
      "[1477]\ttraining's binary_logloss: 1.14349e-05\n",
      "[1478]\ttraining's binary_logloss: 1.14017e-05\n",
      "[1479]\ttraining's binary_logloss: 1.13664e-05\n",
      "[1480]\ttraining's binary_logloss: 1.13333e-05\n",
      "[1481]\ttraining's binary_logloss: 1.12997e-05\n",
      "[1482]\ttraining's binary_logloss: 1.12624e-05\n",
      "[1483]\ttraining's binary_logloss: 1.12303e-05\n",
      "[1484]\ttraining's binary_logloss: 1.11964e-05\n",
      "[1485]\ttraining's binary_logloss: 1.11645e-05\n",
      "[1486]\ttraining's binary_logloss: 1.11326e-05\n",
      "[1487]\ttraining's binary_logloss: 1.11021e-05\n",
      "[1488]\ttraining's binary_logloss: 1.10721e-05\n",
      "[1489]\ttraining's binary_logloss: 1.10407e-05\n",
      "[1490]\ttraining's binary_logloss: 1.1012e-05\n",
      "[1491]\ttraining's binary_logloss: 1.09824e-05\n",
      "[1492]\ttraining's binary_logloss: 1.09542e-05\n",
      "[1493]\ttraining's binary_logloss: 1.09251e-05\n",
      "[1494]\ttraining's binary_logloss: 1.08937e-05\n",
      "[1495]\ttraining's binary_logloss: 1.08635e-05\n",
      "[1496]\ttraining's binary_logloss: 1.08351e-05\n",
      "[1497]\ttraining's binary_logloss: 1.08041e-05\n",
      "[1498]\ttraining's binary_logloss: 1.0777e-05\n",
      "[1499]\ttraining's binary_logloss: 1.07495e-05\n",
      "[1500]\ttraining's binary_logloss: 1.07218e-05\n",
      "[1501]\ttraining's binary_logloss: 1.06933e-05\n",
      "[1502]\ttraining's binary_logloss: 1.06666e-05\n",
      "[1503]\ttraining's binary_logloss: 1.0641e-05\n",
      "[1504]\ttraining's binary_logloss: 1.06126e-05\n",
      "[1505]\ttraining's binary_logloss: 1.05858e-05\n",
      "[1506]\ttraining's binary_logloss: 1.05586e-05\n",
      "[1507]\ttraining's binary_logloss: 1.05323e-05\n",
      "[1508]\ttraining's binary_logloss: 1.05065e-05\n",
      "[1509]\ttraining's binary_logloss: 1.04786e-05\n",
      "[1510]\ttraining's binary_logloss: 1.04551e-05\n",
      "[1511]\ttraining's binary_logloss: 1.04279e-05\n",
      "[1512]\ttraining's binary_logloss: 1.04012e-05\n",
      "[1513]\ttraining's binary_logloss: 1.03738e-05\n",
      "[1514]\ttraining's binary_logloss: 1.0347e-05\n",
      "[1515]\ttraining's binary_logloss: 1.03201e-05\n",
      "[1516]\ttraining's binary_logloss: 1.02923e-05\n",
      "[1517]\ttraining's binary_logloss: 1.0265e-05\n",
      "[1518]\ttraining's binary_logloss: 1.02366e-05\n",
      "[1519]\ttraining's binary_logloss: 1.02108e-05\n",
      "[1520]\ttraining's binary_logloss: 1.01859e-05\n",
      "[1521]\ttraining's binary_logloss: 1.01615e-05\n",
      "[1522]\ttraining's binary_logloss: 1.01358e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1523]\ttraining's binary_logloss: 1.01089e-05\n",
      "[1524]\ttraining's binary_logloss: 1.00826e-05\n",
      "[1525]\ttraining's binary_logloss: 1.00551e-05\n",
      "[1526]\ttraining's binary_logloss: 1.0032e-05\n",
      "[1527]\ttraining's binary_logloss: 1.00089e-05\n",
      "[1528]\ttraining's binary_logloss: 9.98494e-06\n",
      "[1529]\ttraining's binary_logloss: 9.961e-06\n",
      "[1530]\ttraining's binary_logloss: 9.93624e-06\n",
      "[1531]\ttraining's binary_logloss: 9.91411e-06\n",
      "[1532]\ttraining's binary_logloss: 9.89048e-06\n",
      "[1533]\ttraining's binary_logloss: 9.86731e-06\n",
      "[1534]\ttraining's binary_logloss: 9.84421e-06\n",
      "[1535]\ttraining's binary_logloss: 9.82192e-06\n",
      "[1536]\ttraining's binary_logloss: 9.79646e-06\n",
      "[1537]\ttraining's binary_logloss: 9.77435e-06\n",
      "[1538]\ttraining's binary_logloss: 9.75123e-06\n",
      "[1539]\ttraining's binary_logloss: 9.72864e-06\n",
      "[1540]\ttraining's binary_logloss: 9.70609e-06\n",
      "[1541]\ttraining's binary_logloss: 9.68156e-06\n",
      "[1542]\ttraining's binary_logloss: 9.65961e-06\n",
      "[1543]\ttraining's binary_logloss: 9.63833e-06\n",
      "[1544]\ttraining's binary_logloss: 9.61808e-06\n",
      "[1545]\ttraining's binary_logloss: 9.59662e-06\n",
      "[1546]\ttraining's binary_logloss: 9.57293e-06\n",
      "[1547]\ttraining's binary_logloss: 9.5495e-06\n",
      "[1548]\ttraining's binary_logloss: 9.52765e-06\n",
      "[1549]\ttraining's binary_logloss: 9.50714e-06\n",
      "[1550]\ttraining's binary_logloss: 9.48744e-06\n",
      "[1551]\ttraining's binary_logloss: 9.46827e-06\n",
      "[1552]\ttraining's binary_logloss: 9.44662e-06\n",
      "[1553]\ttraining's binary_logloss: 9.42582e-06\n",
      "[1554]\ttraining's binary_logloss: 9.40259e-06\n",
      "[1555]\ttraining's binary_logloss: 9.38044e-06\n",
      "[1556]\ttraining's binary_logloss: 9.3574e-06\n",
      "[1557]\ttraining's binary_logloss: 9.33604e-06\n",
      "[1558]\ttraining's binary_logloss: 9.31287e-06\n",
      "[1559]\ttraining's binary_logloss: 9.29365e-06\n",
      "[1560]\ttraining's binary_logloss: 9.27472e-06\n",
      "[1561]\ttraining's binary_logloss: 9.2571e-06\n",
      "[1562]\ttraining's binary_logloss: 9.23868e-06\n",
      "[1563]\ttraining's binary_logloss: 9.2169e-06\n",
      "[1564]\ttraining's binary_logloss: 9.19652e-06\n",
      "[1565]\ttraining's binary_logloss: 9.17515e-06\n",
      "[1566]\ttraining's binary_logloss: 9.15703e-06\n",
      "[1567]\ttraining's binary_logloss: 9.13912e-06\n",
      "[1568]\ttraining's binary_logloss: 9.12025e-06\n",
      "[1569]\ttraining's binary_logloss: 9.10297e-06\n",
      "[1570]\ttraining's binary_logloss: 9.08436e-06\n",
      "[1571]\ttraining's binary_logloss: 9.0654e-06\n",
      "[1572]\ttraining's binary_logloss: 9.04566e-06\n",
      "[1573]\ttraining's binary_logloss: 9.02581e-06\n",
      "[1574]\ttraining's binary_logloss: 9.00657e-06\n",
      "[1575]\ttraining's binary_logloss: 8.98714e-06\n",
      "[1576]\ttraining's binary_logloss: 8.96817e-06\n",
      "[1577]\ttraining's binary_logloss: 8.94909e-06\n",
      "[1578]\ttraining's binary_logloss: 8.92942e-06\n",
      "[1579]\ttraining's binary_logloss: 8.90936e-06\n",
      "[1580]\ttraining's binary_logloss: 8.89107e-06\n",
      "[1581]\ttraining's binary_logloss: 8.87195e-06\n",
      "[1582]\ttraining's binary_logloss: 8.85173e-06\n",
      "[1583]\ttraining's binary_logloss: 8.83328e-06\n",
      "[1584]\ttraining's binary_logloss: 8.81421e-06\n",
      "[1585]\ttraining's binary_logloss: 8.79501e-06\n",
      "[1586]\ttraining's binary_logloss: 8.77643e-06\n",
      "[1587]\ttraining's binary_logloss: 8.75849e-06\n",
      "[1588]\ttraining's binary_logloss: 8.74042e-06\n",
      "[1589]\ttraining's binary_logloss: 8.72356e-06\n",
      "[1590]\ttraining's binary_logloss: 8.70341e-06\n",
      "[1591]\ttraining's binary_logloss: 8.68685e-06\n",
      "[1592]\ttraining's binary_logloss: 8.66925e-06\n",
      "[1593]\ttraining's binary_logloss: 8.65285e-06\n",
      "[1594]\ttraining's binary_logloss: 8.63464e-06\n",
      "[1595]\ttraining's binary_logloss: 8.61848e-06\n",
      "[1596]\ttraining's binary_logloss: 8.59951e-06\n",
      "[1597]\ttraining's binary_logloss: 8.58142e-06\n",
      "[1598]\ttraining's binary_logloss: 8.56457e-06\n",
      "[1599]\ttraining's binary_logloss: 8.54725e-06\n",
      "[1600]\ttraining's binary_logloss: 8.53093e-06\n",
      "[1601]\ttraining's binary_logloss: 8.5148e-06\n",
      "[1602]\ttraining's binary_logloss: 8.49755e-06\n",
      "[1603]\ttraining's binary_logloss: 8.48037e-06\n",
      "[1604]\ttraining's binary_logloss: 8.46246e-06\n",
      "[1605]\ttraining's binary_logloss: 8.44324e-06\n",
      "[1606]\ttraining's binary_logloss: 8.42817e-06\n",
      "[1607]\ttraining's binary_logloss: 8.41263e-06\n",
      "[1608]\ttraining's binary_logloss: 8.39621e-06\n",
      "[1609]\ttraining's binary_logloss: 8.37881e-06\n",
      "[1610]\ttraining's binary_logloss: 8.3642e-06\n",
      "[1611]\ttraining's binary_logloss: 8.34741e-06\n",
      "[1612]\ttraining's binary_logloss: 8.33129e-06\n",
      "[1613]\ttraining's binary_logloss: 8.31666e-06\n",
      "[1614]\ttraining's binary_logloss: 8.29986e-06\n",
      "[1615]\ttraining's binary_logloss: 8.28339e-06\n",
      "[1616]\ttraining's binary_logloss: 8.2688e-06\n",
      "[1617]\ttraining's binary_logloss: 8.25168e-06\n",
      "[1618]\ttraining's binary_logloss: 8.23588e-06\n",
      "[1619]\ttraining's binary_logloss: 8.21992e-06\n",
      "[1620]\ttraining's binary_logloss: 8.20301e-06\n",
      "[1621]\ttraining's binary_logloss: 8.18708e-06\n",
      "[1622]\ttraining's binary_logloss: 8.17177e-06\n",
      "[1623]\ttraining's binary_logloss: 8.15503e-06\n",
      "[1624]\ttraining's binary_logloss: 8.13854e-06\n",
      "[1625]\ttraining's binary_logloss: 8.12256e-06\n",
      "[1626]\ttraining's binary_logloss: 8.1072e-06\n",
      "[1627]\ttraining's binary_logloss: 8.09416e-06\n",
      "[1628]\ttraining's binary_logloss: 8.07898e-06\n",
      "[1629]\ttraining's binary_logloss: 8.06525e-06\n",
      "[1630]\ttraining's binary_logloss: 8.05051e-06\n",
      "[1631]\ttraining's binary_logloss: 8.03322e-06\n",
      "[1632]\ttraining's binary_logloss: 8.01646e-06\n",
      "[1633]\ttraining's binary_logloss: 8.00107e-06\n",
      "[1634]\ttraining's binary_logloss: 7.98582e-06\n",
      "[1635]\ttraining's binary_logloss: 7.9719e-06\n",
      "[1636]\ttraining's binary_logloss: 7.95781e-06\n",
      "[1637]\ttraining's binary_logloss: 7.94379e-06\n",
      "[1638]\ttraining's binary_logloss: 7.92873e-06\n",
      "[1639]\ttraining's binary_logloss: 7.91572e-06\n",
      "[1640]\ttraining's binary_logloss: 7.90109e-06\n",
      "[1641]\ttraining's binary_logloss: 7.88629e-06\n",
      "[1642]\ttraining's binary_logloss: 7.8723e-06\n",
      "[1643]\ttraining's binary_logloss: 7.85922e-06\n",
      "[1644]\ttraining's binary_logloss: 7.8444e-06\n",
      "[1645]\ttraining's binary_logloss: 7.83017e-06\n",
      "[1646]\ttraining's binary_logloss: 7.81588e-06\n",
      "[1647]\ttraining's binary_logloss: 7.80182e-06\n",
      "[1648]\ttraining's binary_logloss: 7.78755e-06\n",
      "[1649]\ttraining's binary_logloss: 7.77367e-06\n",
      "[1650]\ttraining's binary_logloss: 7.75826e-06\n",
      "[1651]\ttraining's binary_logloss: 7.74267e-06\n",
      "[1652]\ttraining's binary_logloss: 7.72907e-06\n",
      "[1653]\ttraining's binary_logloss: 7.71523e-06\n",
      "[1654]\ttraining's binary_logloss: 7.7011e-06\n",
      "[1655]\ttraining's binary_logloss: 7.68684e-06\n",
      "[1656]\ttraining's binary_logloss: 7.67276e-06\n",
      "[1657]\ttraining's binary_logloss: 7.65796e-06\n",
      "[1658]\ttraining's binary_logloss: 7.644e-06\n",
      "[1659]\ttraining's binary_logloss: 7.63152e-06\n",
      "[1660]\ttraining's binary_logloss: 7.61918e-06\n",
      "[1661]\ttraining's binary_logloss: 7.60553e-06\n",
      "[1662]\ttraining's binary_logloss: 7.59404e-06\n",
      "[1663]\ttraining's binary_logloss: 7.58126e-06\n",
      "[1664]\ttraining's binary_logloss: 7.56798e-06\n",
      "[1665]\ttraining's binary_logloss: 7.55492e-06\n",
      "[1666]\ttraining's binary_logloss: 7.54147e-06\n",
      "[1667]\ttraining's binary_logloss: 7.52778e-06\n",
      "[1668]\ttraining's binary_logloss: 7.51541e-06\n",
      "[1669]\ttraining's binary_logloss: 7.50255e-06\n",
      "[1670]\ttraining's binary_logloss: 7.48862e-06\n",
      "[1671]\ttraining's binary_logloss: 7.47625e-06\n",
      "[1672]\ttraining's binary_logloss: 7.46257e-06\n",
      "[1673]\ttraining's binary_logloss: 7.45062e-06\n",
      "[1674]\ttraining's binary_logloss: 7.43809e-06\n",
      "[1675]\ttraining's binary_logloss: 7.42562e-06\n",
      "[1676]\ttraining's binary_logloss: 7.41285e-06\n",
      "[1677]\ttraining's binary_logloss: 7.40046e-06\n",
      "[1678]\ttraining's binary_logloss: 7.38678e-06\n",
      "[1679]\ttraining's binary_logloss: 7.37308e-06\n",
      "[1680]\ttraining's binary_logloss: 7.36098e-06\n",
      "[1681]\ttraining's binary_logloss: 7.34919e-06\n",
      "[1682]\ttraining's binary_logloss: 7.33698e-06\n",
      "[1683]\ttraining's binary_logloss: 7.32545e-06\n",
      "[1684]\ttraining's binary_logloss: 7.31138e-06\n",
      "[1685]\ttraining's binary_logloss: 7.29892e-06\n",
      "[1686]\ttraining's binary_logloss: 7.28662e-06\n",
      "[1687]\ttraining's binary_logloss: 7.27482e-06\n",
      "[1688]\ttraining's binary_logloss: 7.2615e-06\n",
      "[1689]\ttraining's binary_logloss: 7.25017e-06\n",
      "[1690]\ttraining's binary_logloss: 7.23756e-06\n",
      "[1691]\ttraining's binary_logloss: 7.22688e-06\n",
      "[1692]\ttraining's binary_logloss: 7.21594e-06\n",
      "[1693]\ttraining's binary_logloss: 7.20541e-06\n",
      "[1694]\ttraining's binary_logloss: 7.19251e-06\n",
      "[1695]\ttraining's binary_logloss: 7.18094e-06\n",
      "[1696]\ttraining's binary_logloss: 7.16984e-06\n",
      "[1697]\ttraining's binary_logloss: 7.15763e-06\n",
      "[1698]\ttraining's binary_logloss: 7.14585e-06\n",
      "[1699]\ttraining's binary_logloss: 7.13356e-06\n",
      "[1700]\ttraining's binary_logloss: 7.12143e-06\n",
      "[1701]\ttraining's binary_logloss: 7.10916e-06\n",
      "[1702]\ttraining's binary_logloss: 7.09756e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1703]\ttraining's binary_logloss: 7.0865e-06\n",
      "[1704]\ttraining's binary_logloss: 7.07601e-06\n",
      "[1705]\ttraining's binary_logloss: 7.06373e-06\n",
      "[1706]\ttraining's binary_logloss: 7.05289e-06\n",
      "[1707]\ttraining's binary_logloss: 7.04251e-06\n",
      "[1708]\ttraining's binary_logloss: 7.03189e-06\n",
      "[1709]\ttraining's binary_logloss: 7.02024e-06\n",
      "[1710]\ttraining's binary_logloss: 7.00908e-06\n",
      "[1711]\ttraining's binary_logloss: 6.99807e-06\n",
      "[1712]\ttraining's binary_logloss: 6.98759e-06\n",
      "[1713]\ttraining's binary_logloss: 6.97678e-06\n",
      "[1714]\ttraining's binary_logloss: 6.96561e-06\n",
      "[1715]\ttraining's binary_logloss: 6.95475e-06\n",
      "[1716]\ttraining's binary_logloss: 6.94468e-06\n",
      "[1717]\ttraining's binary_logloss: 6.93301e-06\n",
      "[1718]\ttraining's binary_logloss: 6.92261e-06\n",
      "[1719]\ttraining's binary_logloss: 6.91172e-06\n",
      "[1720]\ttraining's binary_logloss: 6.90023e-06\n",
      "[1721]\ttraining's binary_logloss: 6.8906e-06\n",
      "[1722]\ttraining's binary_logloss: 6.88054e-06\n",
      "[1723]\ttraining's binary_logloss: 6.8698e-06\n",
      "[1724]\ttraining's binary_logloss: 6.85886e-06\n",
      "[1725]\ttraining's binary_logloss: 6.84741e-06\n",
      "[1726]\ttraining's binary_logloss: 6.83575e-06\n",
      "[1727]\ttraining's binary_logloss: 6.82454e-06\n",
      "[1728]\ttraining's binary_logloss: 6.8146e-06\n",
      "[1729]\ttraining's binary_logloss: 6.80454e-06\n",
      "[1730]\ttraining's binary_logloss: 6.79422e-06\n",
      "[1731]\ttraining's binary_logloss: 6.78403e-06\n",
      "[1732]\ttraining's binary_logloss: 6.77386e-06\n",
      "[1733]\ttraining's binary_logloss: 6.76284e-06\n",
      "[1734]\ttraining's binary_logloss: 6.75246e-06\n",
      "[1735]\ttraining's binary_logloss: 6.74308e-06\n",
      "[1736]\ttraining's binary_logloss: 6.73361e-06\n",
      "[1737]\ttraining's binary_logloss: 6.7242e-06\n",
      "[1738]\ttraining's binary_logloss: 6.71368e-06\n",
      "[1739]\ttraining's binary_logloss: 6.70389e-06\n",
      "[1740]\ttraining's binary_logloss: 6.69408e-06\n",
      "[1741]\ttraining's binary_logloss: 6.68482e-06\n",
      "[1742]\ttraining's binary_logloss: 6.67537e-06\n",
      "[1743]\ttraining's binary_logloss: 6.66578e-06\n",
      "[1744]\ttraining's binary_logloss: 6.65654e-06\n",
      "[1745]\ttraining's binary_logloss: 6.64629e-06\n",
      "[1746]\ttraining's binary_logloss: 6.638e-06\n",
      "[1747]\ttraining's binary_logloss: 6.62828e-06\n",
      "[1748]\ttraining's binary_logloss: 6.61887e-06\n",
      "[1749]\ttraining's binary_logloss: 6.60843e-06\n",
      "[1750]\ttraining's binary_logloss: 6.59889e-06\n",
      "[1751]\ttraining's binary_logloss: 6.58881e-06\n",
      "[1752]\ttraining's binary_logloss: 6.57878e-06\n",
      "[1753]\ttraining's binary_logloss: 6.5688e-06\n",
      "[1754]\ttraining's binary_logloss: 6.55866e-06\n",
      "[1755]\ttraining's binary_logloss: 6.54962e-06\n",
      "[1756]\ttraining's binary_logloss: 6.53998e-06\n",
      "[1757]\ttraining's binary_logloss: 6.52985e-06\n",
      "[1758]\ttraining's binary_logloss: 6.52068e-06\n",
      "[1759]\ttraining's binary_logloss: 6.51152e-06\n",
      "[1760]\ttraining's binary_logloss: 6.503e-06\n",
      "[1761]\ttraining's binary_logloss: 6.49335e-06\n",
      "[1762]\ttraining's binary_logloss: 6.48393e-06\n",
      "[1763]\ttraining's binary_logloss: 6.4747e-06\n",
      "[1764]\ttraining's binary_logloss: 6.46505e-06\n",
      "[1765]\ttraining's binary_logloss: 6.45512e-06\n",
      "[1766]\ttraining's binary_logloss: 6.44587e-06\n",
      "[1767]\ttraining's binary_logloss: 6.43646e-06\n",
      "[1768]\ttraining's binary_logloss: 6.42635e-06\n",
      "[1769]\ttraining's binary_logloss: 6.41704e-06\n",
      "[1770]\ttraining's binary_logloss: 6.40702e-06\n",
      "[1771]\ttraining's binary_logloss: 6.39819e-06\n",
      "[1772]\ttraining's binary_logloss: 6.38944e-06\n",
      "[1773]\ttraining's binary_logloss: 6.38073e-06\n",
      "[1774]\ttraining's binary_logloss: 6.37071e-06\n",
      "[1775]\ttraining's binary_logloss: 6.36173e-06\n",
      "[1776]\ttraining's binary_logloss: 6.35259e-06\n",
      "[1777]\ttraining's binary_logloss: 6.34316e-06\n",
      "[1778]\ttraining's binary_logloss: 6.33327e-06\n",
      "[1779]\ttraining's binary_logloss: 6.32398e-06\n",
      "[1780]\ttraining's binary_logloss: 6.31455e-06\n",
      "[1781]\ttraining's binary_logloss: 6.30545e-06\n",
      "[1782]\ttraining's binary_logloss: 6.29622e-06\n",
      "[1783]\ttraining's binary_logloss: 6.28821e-06\n",
      "[1784]\ttraining's binary_logloss: 6.28006e-06\n",
      "[1785]\ttraining's binary_logloss: 6.27058e-06\n",
      "[1786]\ttraining's binary_logloss: 6.26233e-06\n",
      "[1787]\ttraining's binary_logloss: 6.25469e-06\n",
      "[1788]\ttraining's binary_logloss: 6.24597e-06\n",
      "[1789]\ttraining's binary_logloss: 6.23619e-06\n",
      "[1790]\ttraining's binary_logloss: 6.22863e-06\n",
      "[1791]\ttraining's binary_logloss: 6.22071e-06\n",
      "[1792]\ttraining's binary_logloss: 6.21224e-06\n",
      "[1793]\ttraining's binary_logloss: 6.20312e-06\n",
      "[1794]\ttraining's binary_logloss: 6.19469e-06\n",
      "[1795]\ttraining's binary_logloss: 6.18594e-06\n",
      "[1796]\ttraining's binary_logloss: 6.17836e-06\n",
      "[1797]\ttraining's binary_logloss: 6.16908e-06\n",
      "[1798]\ttraining's binary_logloss: 6.16211e-06\n",
      "[1799]\ttraining's binary_logloss: 6.15432e-06\n",
      "[1800]\ttraining's binary_logloss: 6.14582e-06\n",
      "[1801]\ttraining's binary_logloss: 6.13757e-06\n",
      "[1802]\ttraining's binary_logloss: 6.12916e-06\n",
      "[1803]\ttraining's binary_logloss: 6.12135e-06\n",
      "[1804]\ttraining's binary_logloss: 6.11381e-06\n",
      "[1805]\ttraining's binary_logloss: 6.10483e-06\n",
      "[1806]\ttraining's binary_logloss: 6.09708e-06\n",
      "[1807]\ttraining's binary_logloss: 6.0887e-06\n",
      "[1808]\ttraining's binary_logloss: 6.08122e-06\n",
      "[1809]\ttraining's binary_logloss: 6.07299e-06\n",
      "[1810]\ttraining's binary_logloss: 6.06526e-06\n",
      "[1811]\ttraining's binary_logloss: 6.05724e-06\n",
      "[1812]\ttraining's binary_logloss: 6.04951e-06\n",
      "[1813]\ttraining's binary_logloss: 6.04165e-06\n",
      "[1814]\ttraining's binary_logloss: 6.03403e-06\n",
      "[1815]\ttraining's binary_logloss: 6.02648e-06\n",
      "[1816]\ttraining's binary_logloss: 6.01869e-06\n",
      "[1817]\ttraining's binary_logloss: 6.01148e-06\n",
      "[1818]\ttraining's binary_logloss: 6.0038e-06\n",
      "[1819]\ttraining's binary_logloss: 5.99748e-06\n",
      "[1820]\ttraining's binary_logloss: 5.98949e-06\n",
      "[1821]\ttraining's binary_logloss: 5.98137e-06\n",
      "[1822]\ttraining's binary_logloss: 5.97379e-06\n",
      "[1823]\ttraining's binary_logloss: 5.96659e-06\n",
      "[1824]\ttraining's binary_logloss: 5.95916e-06\n",
      "[1825]\ttraining's binary_logloss: 5.95171e-06\n",
      "[1826]\ttraining's binary_logloss: 5.94384e-06\n",
      "[1827]\ttraining's binary_logloss: 5.93598e-06\n",
      "[1828]\ttraining's binary_logloss: 5.92839e-06\n",
      "[1829]\ttraining's binary_logloss: 5.9204e-06\n",
      "[1830]\ttraining's binary_logloss: 5.91266e-06\n",
      "[1831]\ttraining's binary_logloss: 5.9055e-06\n",
      "[1832]\ttraining's binary_logloss: 5.898e-06\n",
      "[1833]\ttraining's binary_logloss: 5.88979e-06\n",
      "[1834]\ttraining's binary_logloss: 5.88177e-06\n",
      "[1835]\ttraining's binary_logloss: 5.87418e-06\n",
      "[1836]\ttraining's binary_logloss: 5.86667e-06\n",
      "[1837]\ttraining's binary_logloss: 5.85835e-06\n",
      "[1838]\ttraining's binary_logloss: 5.85056e-06\n",
      "[1839]\ttraining's binary_logloss: 5.84375e-06\n",
      "[1840]\ttraining's binary_logloss: 5.83696e-06\n",
      "[1841]\ttraining's binary_logloss: 5.82892e-06\n",
      "[1842]\ttraining's binary_logloss: 5.82128e-06\n",
      "[1843]\ttraining's binary_logloss: 5.81338e-06\n",
      "[1844]\ttraining's binary_logloss: 5.80591e-06\n",
      "[1845]\ttraining's binary_logloss: 5.7984e-06\n",
      "[1846]\ttraining's binary_logloss: 5.79109e-06\n",
      "[1847]\ttraining's binary_logloss: 5.78436e-06\n",
      "[1848]\ttraining's binary_logloss: 5.77714e-06\n",
      "[1849]\ttraining's binary_logloss: 5.77076e-06\n",
      "[1850]\ttraining's binary_logloss: 5.76374e-06\n",
      "[1851]\ttraining's binary_logloss: 5.7564e-06\n",
      "[1852]\ttraining's binary_logloss: 5.74997e-06\n",
      "[1853]\ttraining's binary_logloss: 5.74345e-06\n",
      "[1854]\ttraining's binary_logloss: 5.73751e-06\n",
      "[1855]\ttraining's binary_logloss: 5.72982e-06\n",
      "[1856]\ttraining's binary_logloss: 5.72254e-06\n",
      "[1857]\ttraining's binary_logloss: 5.71612e-06\n",
      "[1858]\ttraining's binary_logloss: 5.70851e-06\n",
      "[1859]\ttraining's binary_logloss: 5.70109e-06\n",
      "[1860]\ttraining's binary_logloss: 5.69381e-06\n",
      "[1861]\ttraining's binary_logloss: 5.68674e-06\n",
      "[1862]\ttraining's binary_logloss: 5.68029e-06\n",
      "[1863]\ttraining's binary_logloss: 5.67409e-06\n",
      "[1864]\ttraining's binary_logloss: 5.66721e-06\n",
      "[1865]\ttraining's binary_logloss: 5.66045e-06\n",
      "[1866]\ttraining's binary_logloss: 5.65272e-06\n",
      "[1867]\ttraining's binary_logloss: 5.64559e-06\n",
      "[1868]\ttraining's binary_logloss: 5.63835e-06\n",
      "[1869]\ttraining's binary_logloss: 5.6316e-06\n",
      "[1870]\ttraining's binary_logloss: 5.62524e-06\n",
      "[1871]\ttraining's binary_logloss: 5.61919e-06\n",
      "[1872]\ttraining's binary_logloss: 5.61278e-06\n",
      "[1873]\ttraining's binary_logloss: 5.60641e-06\n",
      "[1874]\ttraining's binary_logloss: 5.60006e-06\n",
      "[1875]\ttraining's binary_logloss: 5.59301e-06\n",
      "[1876]\ttraining's binary_logloss: 5.58651e-06\n",
      "[1877]\ttraining's binary_logloss: 5.57962e-06\n",
      "[1878]\ttraining's binary_logloss: 5.57232e-06\n",
      "[1879]\ttraining's binary_logloss: 5.56543e-06\n",
      "[1880]\ttraining's binary_logloss: 5.5586e-06\n",
      "[1881]\ttraining's binary_logloss: 5.55192e-06\n",
      "[1882]\ttraining's binary_logloss: 5.54491e-06\n",
      "[1883]\ttraining's binary_logloss: 5.53811e-06\n",
      "[1884]\ttraining's binary_logloss: 5.53191e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1885]\ttraining's binary_logloss: 5.52485e-06\n",
      "[1886]\ttraining's binary_logloss: 5.51804e-06\n",
      "[1887]\ttraining's binary_logloss: 5.51168e-06\n",
      "[1888]\ttraining's binary_logloss: 5.50587e-06\n",
      "[1889]\ttraining's binary_logloss: 5.49901e-06\n",
      "[1890]\ttraining's binary_logloss: 5.49267e-06\n",
      "[1891]\ttraining's binary_logloss: 5.48657e-06\n",
      "[1892]\ttraining's binary_logloss: 5.47892e-06\n",
      "[1893]\ttraining's binary_logloss: 5.47216e-06\n",
      "[1894]\ttraining's binary_logloss: 5.466e-06\n",
      "[1895]\ttraining's binary_logloss: 5.4598e-06\n",
      "[1896]\ttraining's binary_logloss: 5.45356e-06\n",
      "[1897]\ttraining's binary_logloss: 5.44636e-06\n",
      "[1898]\ttraining's binary_logloss: 5.43952e-06\n",
      "[1899]\ttraining's binary_logloss: 5.43297e-06\n",
      "[1900]\ttraining's binary_logloss: 5.42741e-06\n",
      "[1901]\ttraining's binary_logloss: 5.42125e-06\n",
      "[1902]\ttraining's binary_logloss: 5.4146e-06\n",
      "[1903]\ttraining's binary_logloss: 5.40882e-06\n",
      "[1904]\ttraining's binary_logloss: 5.40225e-06\n",
      "[1905]\ttraining's binary_logloss: 5.39626e-06\n",
      "[1906]\ttraining's binary_logloss: 5.39025e-06\n",
      "[1907]\ttraining's binary_logloss: 5.38434e-06\n",
      "[1908]\ttraining's binary_logloss: 5.37813e-06\n",
      "[1909]\ttraining's binary_logloss: 5.37191e-06\n",
      "[1910]\ttraining's binary_logloss: 5.36511e-06\n",
      "[1911]\ttraining's binary_logloss: 5.35761e-06\n",
      "[1912]\ttraining's binary_logloss: 5.35133e-06\n",
      "[1913]\ttraining's binary_logloss: 5.34519e-06\n",
      "[1914]\ttraining's binary_logloss: 5.33917e-06\n",
      "[1915]\ttraining's binary_logloss: 5.33341e-06\n",
      "[1916]\ttraining's binary_logloss: 5.32793e-06\n",
      "[1917]\ttraining's binary_logloss: 5.32176e-06\n",
      "[1918]\ttraining's binary_logloss: 5.31614e-06\n",
      "[1919]\ttraining's binary_logloss: 5.30983e-06\n",
      "[1920]\ttraining's binary_logloss: 5.30381e-06\n",
      "[1921]\ttraining's binary_logloss: 5.29804e-06\n",
      "[1922]\ttraining's binary_logloss: 5.29266e-06\n",
      "[1923]\ttraining's binary_logloss: 5.28709e-06\n",
      "[1924]\ttraining's binary_logloss: 5.28136e-06\n",
      "[1925]\ttraining's binary_logloss: 5.27549e-06\n",
      "[1926]\ttraining's binary_logloss: 5.26938e-06\n",
      "[1927]\ttraining's binary_logloss: 5.26373e-06\n",
      "[1928]\ttraining's binary_logloss: 5.25777e-06\n",
      "[1929]\ttraining's binary_logloss: 5.25205e-06\n",
      "[1930]\ttraining's binary_logloss: 5.24599e-06\n",
      "[1931]\ttraining's binary_logloss: 5.24066e-06\n",
      "[1932]\ttraining's binary_logloss: 5.23468e-06\n",
      "[1933]\ttraining's binary_logloss: 5.22822e-06\n",
      "[1934]\ttraining's binary_logloss: 5.2224e-06\n",
      "[1935]\ttraining's binary_logloss: 5.21638e-06\n",
      "[1936]\ttraining's binary_logloss: 5.21085e-06\n",
      "[1937]\ttraining's binary_logloss: 5.20547e-06\n",
      "[1938]\ttraining's binary_logloss: 5.19981e-06\n",
      "[1939]\ttraining's binary_logloss: 5.19434e-06\n",
      "[1940]\ttraining's binary_logloss: 5.18847e-06\n",
      "[1941]\ttraining's binary_logloss: 5.18245e-06\n",
      "[1942]\ttraining's binary_logloss: 5.17639e-06\n",
      "[1943]\ttraining's binary_logloss: 5.1712e-06\n",
      "[1944]\ttraining's binary_logloss: 5.16446e-06\n",
      "[1945]\ttraining's binary_logloss: 5.15829e-06\n",
      "[1946]\ttraining's binary_logloss: 5.15281e-06\n",
      "[1947]\ttraining's binary_logloss: 5.14727e-06\n",
      "[1948]\ttraining's binary_logloss: 5.1425e-06\n",
      "[1949]\ttraining's binary_logloss: 5.13792e-06\n",
      "[1950]\ttraining's binary_logloss: 5.13326e-06\n",
      "[1951]\ttraining's binary_logloss: 5.12788e-06\n",
      "[1952]\ttraining's binary_logloss: 5.12316e-06\n",
      "[1953]\ttraining's binary_logloss: 5.11806e-06\n",
      "[1954]\ttraining's binary_logloss: 5.11309e-06\n",
      "[1955]\ttraining's binary_logloss: 5.10749e-06\n",
      "[1956]\ttraining's binary_logloss: 5.10194e-06\n",
      "[1957]\ttraining's binary_logloss: 5.09701e-06\n",
      "[1958]\ttraining's binary_logloss: 5.09173e-06\n",
      "[1959]\ttraining's binary_logloss: 5.08641e-06\n",
      "[1960]\ttraining's binary_logloss: 5.0806e-06\n",
      "[1961]\ttraining's binary_logloss: 5.07532e-06\n",
      "[1962]\ttraining's binary_logloss: 5.06982e-06\n",
      "[1963]\ttraining's binary_logloss: 5.06381e-06\n",
      "[1964]\ttraining's binary_logloss: 5.05772e-06\n",
      "[1965]\ttraining's binary_logloss: 5.05202e-06\n",
      "[1966]\ttraining's binary_logloss: 5.04662e-06\n",
      "[1967]\ttraining's binary_logloss: 5.04113e-06\n",
      "[1968]\ttraining's binary_logloss: 5.03587e-06\n",
      "[1969]\ttraining's binary_logloss: 5.03049e-06\n",
      "[1970]\ttraining's binary_logloss: 5.02537e-06\n",
      "[1971]\ttraining's binary_logloss: 5.01967e-06\n",
      "[1972]\ttraining's binary_logloss: 5.01496e-06\n",
      "[1973]\ttraining's binary_logloss: 5.00959e-06\n",
      "[1974]\ttraining's binary_logloss: 5.00479e-06\n",
      "[1975]\ttraining's binary_logloss: 4.99947e-06\n",
      "[1976]\ttraining's binary_logloss: 4.99412e-06\n",
      "[1977]\ttraining's binary_logloss: 4.98893e-06\n",
      "[1978]\ttraining's binary_logloss: 4.98344e-06\n",
      "[1979]\ttraining's binary_logloss: 4.97827e-06\n",
      "[1980]\ttraining's binary_logloss: 4.9735e-06\n",
      "[1981]\ttraining's binary_logloss: 4.96911e-06\n",
      "[1982]\ttraining's binary_logloss: 4.964e-06\n",
      "[1983]\ttraining's binary_logloss: 4.95876e-06\n",
      "[1984]\ttraining's binary_logloss: 4.95298e-06\n",
      "[1985]\ttraining's binary_logloss: 4.94838e-06\n",
      "[1986]\ttraining's binary_logloss: 4.94294e-06\n",
      "[1987]\ttraining's binary_logloss: 4.93774e-06\n",
      "[1988]\ttraining's binary_logloss: 4.93282e-06\n",
      "[1989]\ttraining's binary_logloss: 4.92834e-06\n",
      "[1990]\ttraining's binary_logloss: 4.92286e-06\n",
      "[1991]\ttraining's binary_logloss: 4.91781e-06\n",
      "[1992]\ttraining's binary_logloss: 4.91314e-06\n",
      "[1993]\ttraining's binary_logloss: 4.90819e-06\n",
      "[1994]\ttraining's binary_logloss: 4.90324e-06\n",
      "[1995]\ttraining's binary_logloss: 4.89736e-06\n",
      "[1996]\ttraining's binary_logloss: 4.89241e-06\n",
      "[1997]\ttraining's binary_logloss: 4.88727e-06\n",
      "[1998]\ttraining's binary_logloss: 4.88254e-06\n",
      "[1999]\ttraining's binary_logloss: 4.87814e-06\n",
      "[2000]\ttraining's binary_logloss: 4.87306e-06\n"
     ]
    }
   ],
   "source": [
    "# deploy model\n",
    "lgtrain = lgb.Dataset(X_res, y_res)\n",
    "\n",
    "final_lgb = lgb.train(\n",
    "    lgbm_params,\n",
    "    lgtrain,\n",
    "    valid_sets=lgtrain,\n",
    "    num_boost_round=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the final model to the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\futai\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "preprocess = DataPreprocess(label_encoder)\n",
    "processed_payment_test = preprocess.preprocess_payment(payment_test)\n",
    "billing_test = preprocess.initialize_billing(billing_test)\n",
    "processed_billing_test = preprocess.preprocess_billing(billing_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test = preprocess.merge(processed_payment_test, processed_billing_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in transaction_col:\n",
    "    replace_value = processed_test[processed_test[col].notna()][col].mean()\n",
    "    processed_test[col] = processed_test[col].fillna(replace_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test = processed_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_01_month</th>\n",
       "      <th>transaction_02_month</th>\n",
       "      <th>transaction_03_month</th>\n",
       "      <th>transaction_04_month</th>\n",
       "      <th>transaction_05_month</th>\n",
       "      <th>transaction_06_month</th>\n",
       "      <th>transaction_07_month</th>\n",
       "      <th>transaction_08_month</th>\n",
       "      <th>transaction_09_month</th>\n",
       "      <th>transaction_10_month</th>\n",
       "      <th>...</th>\n",
       "      <th>cash_balance_06_month</th>\n",
       "      <th>cash_balance_07_month</th>\n",
       "      <th>cash_balance_08_month</th>\n",
       "      <th>cash_balance_09_month</th>\n",
       "      <th>cash_balance_10_month</th>\n",
       "      <th>cash_balance_11_month</th>\n",
       "      <th>cash_balance_12_month</th>\n",
       "      <th>MaxDelqCycle</th>\n",
       "      <th>AvgDelqCycle</th>\n",
       "      <th>LateCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10074849</th>\n",
       "      <td>411.00</td>\n",
       "      <td>340.26</td>\n",
       "      <td>993.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>906.38</td>\n",
       "      <td>363.00</td>\n",
       "      <td>915.54</td>\n",
       "      <td>609.50</td>\n",
       "      <td>626.85</td>\n",
       "      <td>396.93</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10086539</th>\n",
       "      <td>0.00</td>\n",
       "      <td>556.92</td>\n",
       "      <td>832.00</td>\n",
       "      <td>642.0</td>\n",
       "      <td>661.26</td>\n",
       "      <td>1880.00</td>\n",
       "      <td>950.86</td>\n",
       "      <td>1591.00</td>\n",
       "      <td>1048.60</td>\n",
       "      <td>500.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10140908</th>\n",
       "      <td>214.10</td>\n",
       "      <td>88.36</td>\n",
       "      <td>200.00</td>\n",
       "      <td>206.0</td>\n",
       "      <td>239.99</td>\n",
       "      <td>160.50</td>\n",
       "      <td>418.00</td>\n",
       "      <td>428.72</td>\n",
       "      <td>202.00</td>\n",
       "      <td>163.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10147994</th>\n",
       "      <td>38.11</td>\n",
       "      <td>39.52</td>\n",
       "      <td>218.40</td>\n",
       "      <td>227.9</td>\n",
       "      <td>224.70</td>\n",
       "      <td>229.69</td>\n",
       "      <td>226.00</td>\n",
       "      <td>504.29</td>\n",
       "      <td>4.24</td>\n",
       "      <td>256.20</td>\n",
       "      <td>...</td>\n",
       "      <td>17.85</td>\n",
       "      <td>55.12</td>\n",
       "      <td>28.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10152808</th>\n",
       "      <td>420.00</td>\n",
       "      <td>1030.00</td>\n",
       "      <td>510.00</td>\n",
       "      <td>423.3</td>\n",
       "      <td>877.50</td>\n",
       "      <td>1157.44</td>\n",
       "      <td>709.00</td>\n",
       "      <td>995.00</td>\n",
       "      <td>1015.00</td>\n",
       "      <td>515.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          transaction_01_month  transaction_02_month  transaction_03_month  \\\n",
       "ID_CPTE                                                                      \n",
       "10074849                411.00                340.26                993.92   \n",
       "10086539                  0.00                556.92                832.00   \n",
       "10140908                214.10                 88.36                200.00   \n",
       "10147994                 38.11                 39.52                218.40   \n",
       "10152808                420.00               1030.00                510.00   \n",
       "\n",
       "          transaction_04_month  transaction_05_month  transaction_06_month  \\\n",
       "ID_CPTE                                                                      \n",
       "10074849                   0.0                906.38                363.00   \n",
       "10086539                 642.0                661.26               1880.00   \n",
       "10140908                 206.0                239.99                160.50   \n",
       "10147994                 227.9                224.70                229.69   \n",
       "10152808                 423.3                877.50               1157.44   \n",
       "\n",
       "          transaction_07_month  transaction_08_month  transaction_09_month  \\\n",
       "ID_CPTE                                                                      \n",
       "10074849                915.54                609.50                626.85   \n",
       "10086539                950.86               1591.00               1048.60   \n",
       "10140908                418.00                428.72                202.00   \n",
       "10147994                226.00                504.29                  4.24   \n",
       "10152808                709.00                995.00               1015.00   \n",
       "\n",
       "          transaction_10_month    ...      cash_balance_06_month  \\\n",
       "ID_CPTE                           ...                              \n",
       "10074849                396.93    ...                       0.00   \n",
       "10086539                500.00    ...                       0.00   \n",
       "10140908                163.20    ...                       1.03   \n",
       "10147994                256.20    ...                      17.85   \n",
       "10152808                515.00    ...                       0.00   \n",
       "\n",
       "          cash_balance_07_month  cash_balance_08_month  cash_balance_09_month  \\\n",
       "ID_CPTE                                                                         \n",
       "10074849                   0.00                   0.00                    0.0   \n",
       "10086539                   0.00                   0.00                    0.0   \n",
       "10140908                   0.00                   0.00                    0.0   \n",
       "10147994                  55.12                  28.35                    0.0   \n",
       "10152808                   0.00                   0.00                    0.0   \n",
       "\n",
       "          cash_balance_10_month  cash_balance_11_month  cash_balance_12_month  \\\n",
       "ID_CPTE                                                                         \n",
       "10074849                   0.00                   0.00                    0.0   \n",
       "10086539                   0.00                   0.00                    0.0   \n",
       "10140908                   3.06                   2.04                    0.0   \n",
       "10147994                   0.00                   0.00                    0.0   \n",
       "10152808                   0.00                   0.00                    0.0   \n",
       "\n",
       "          MaxDelqCycle  AvgDelqCycle  LateCount  \n",
       "ID_CPTE                                          \n",
       "10074849             0           0.0          0  \n",
       "10086539             0           0.0          0  \n",
       "10140908             2           1.0         12  \n",
       "10147994             0           0.0         10  \n",
       "10152808             0           0.0         12  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(processed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5100, 40)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lgb = clf.predict(X_test)\n",
    "#predict_lgb = np.array([0 if i < 0.6 else 1 for i in predict_lgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test['Default'] = predict_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = processed_test.reset_index()[['ID_CPTE', 'Default']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../raw_data/performance_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71424379</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64887111</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69431075</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31823308</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39407834</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE PERIODID_MY  Default\n",
       "0  71424379  2014-12-01      NaN\n",
       "1  64887111  2015-12-01      NaN\n",
       "2  69431075  2014-12-01      NaN\n",
       "3  31823308  2016-12-01      NaN\n",
       "4  39407834  2012-12-01      NaN"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10074849</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10086539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10140908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10147994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10152808</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  Default\n",
       "0  10074849        0\n",
       "1  10086539        0\n",
       "2  10140908        0\n",
       "3  10147994        0\n",
       "4  10152808        0"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission[['ID_CPTE', 'Default']].merge(results, on='ID_CPTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission[['ID_CPTE', 'Default_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission.rename(columns={'Default_y': 'Default'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71424379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64887111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69431075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31823308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39407834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  Default\n",
       "0  71424379        0\n",
       "1  64887111        0\n",
       "2  69431075        0\n",
       "3  31823308        0\n",
       "4  39407834        0"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('logistic_submission.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71424379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64887111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69431075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31823308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39407834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  Default\n",
       "0  71424379        0\n",
       "1  64887111        0\n",
       "2  69431075        0\n",
       "3  31823308        0\n",
       "4  39407834        0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5100"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71424379</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64887111</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69431075</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31823308</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39407834</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE PERIODID_MY  Default\n",
       "0  71424379  2014-12-01      NaN\n",
       "1  64887111  2015-12-01      NaN\n",
       "2  69431075  2014-12-01      NaN\n",
       "3  31823308  2016-12-01      NaN\n",
       "4  39407834  2012-12-01      NaN"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
