{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Test(Logistic regression, random forest, LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# import the relevant computational modules\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd #data processing\n",
    "import numpy as np #linear algebra\n",
    "\n",
    "# Models Packages\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Gradient Boosting\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Basic Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# visualization \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "transaction_training = pd.read_csv('../raw_data/transactions_train.csv')\n",
    "payment_training = pd.read_csv('../raw_data/paiements_train.csv')\n",
    "billing_training = pd.read_csv('../raw_data/facturation_train.csv')\n",
    "performance_training = pd.read_csv('../raw_data/performance_train.csv')\n",
    "\n",
    "\n",
    "transaction_test = pd.read_csv('../raw_data/transactions_test.csv')\n",
    "payment_test = pd.read_csv('../raw_data/paiements_test.csv')\n",
    "billing_test = pd.read_csv('../raw_data/facturation_test.csv')\n",
    "performance_test = pd.read_csv('../raw_data/performance_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>TRANSACTION_AMT</th>\n",
       "      <th>TRANSACTION_DTTM</th>\n",
       "      <th>PAYMENT_REVERSAL_XFLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99690111</td>\n",
       "      <td>208.0</td>\n",
       "      <td>2015-04-26 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99690111</td>\n",
       "      <td>176.8</td>\n",
       "      <td>2015-05-28 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99690111</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2015-03-27 04:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99690111</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2015-04-02 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99690111</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2015-11-24 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  TRANSACTION_AMT     TRANSACTION_DTTM PAYMENT_REVERSAL_XFLG\n",
       "0  99690111            208.0  2015-04-26 00:00:00                     Q\n",
       "1  99690111            176.8  2015-05-28 00:00:00                     Q\n",
       "2  99690111            200.0  2015-03-27 04:00:00                     Q\n",
       "3  99690111             80.8  2015-04-02 00:00:00                     Q\n",
       "4  99690111            250.0  2015-11-24 00:00:00                     Q"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payment_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>StatementDate</th>\n",
       "      <th>CurrentTotalBalance</th>\n",
       "      <th>CashBalance</th>\n",
       "      <th>CreditLimit</th>\n",
       "      <th>DelqCycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>2015-05-03</td>\n",
       "      <td>8497.84</td>\n",
       "      <td>4293.12</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>2014-11-03</td>\n",
       "      <td>866.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>2015-05-31</td>\n",
       "      <td>10790.95</td>\n",
       "      <td>5224.44</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>2015-10-04</td>\n",
       "      <td>12388.46</td>\n",
       "      <td>4786.08</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>2015-11-02</td>\n",
       "      <td>12746.50</td>\n",
       "      <td>4818.48</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE PERIODID_MY StatementDate  CurrentTotalBalance  CashBalance  \\\n",
       "0  99690111  2015-05-01    2015-05-03              8497.84      4293.12   \n",
       "1  99690111  2014-11-01    2014-11-03               866.00         0.00   \n",
       "2  99690111  2015-06-01    2015-05-31             10790.95      5224.44   \n",
       "3  99690111  2015-10-01    2015-10-04             12388.46      4786.08   \n",
       "4  99690111  2015-11-01    2015-11-02             12746.50      4818.48   \n",
       "\n",
       "   CreditLimit  DelqCycle  \n",
       "0      16200.0          0  \n",
       "1      12000.0          0  \n",
       "2      16200.0          0  \n",
       "3      16200.0          0  \n",
       "4      16200.0          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billing_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57427180</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29617912</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61632809</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14117855</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE PERIODID_MY  Default\n",
       "0  99690111  2015-12-01        0\n",
       "1  57427180  2012-12-01        0\n",
       "2  29617912  2015-12-01        0\n",
       "3  61632809  2015-12-01        0\n",
       "4  14117855  2013-12-01        0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basic scikit-learn wrapper model class\n",
    "class SklearnWrapper:\n",
    "    def __init__(self, clf, seed=0, params=None, seed_bool=True):\n",
    "        if (seed_bool == True):\n",
    "            params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "    \n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create basic xgboost wrapper model class\n",
    "class XgbWrapper:\n",
    "    def __init__(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 250)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(xgb.DMatrix(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create basic lightGBM wrapper model class\n",
    "class LightGbmWrapper:\n",
    "    def __init(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 1550)\n",
    "        self.verbose_eval = params.pop('verbose_eval', 100)\n",
    "        \n",
    "    def train(self, x_train, y_train):\n",
    "        lgtrain = lgb.Dataset(x_train, y_train)\n",
    "        self.lgbm = lgb.train(self.param, lgtrain, num_boost_round=self.nrounds, verbose_eval=self.verbose_eval)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.lgbm.predict(lgb.Dataset(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create out-of-fold predictions \n",
    "# make good use of k-fold CV's result \n",
    "# serving for the staking alogrithm \n",
    "# create a new column generated from model's score\n",
    "\n",
    "def get_oof(clf, x_train, y, x_test):\n",
    "    '''\n",
    "    clf: the classifer, which can be logistic regression, SVM regression, Bayes classifier, etc.\n",
    "    x_train: the training x in training dataset\n",
    "    y: the training y in training dataset\n",
    "    x_test: the testing x in training dataset \n",
    "    '''\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        print('\\nFold {}'.format(i))\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "        \n",
    "        clf.fit(x_tr, y_tr)\n",
    "        \n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "    \n",
    "    m = stats.mode(oof_test_skf, axis=1)\n",
    "    oof_test[:] = m[0][0]\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocess\n",
    "\n",
    "class DataPreprocess:\n",
    "    def __init__(self, label_encoder):\n",
    "        self.lbl = label_encoder\n",
    "    \n",
    "    def convert_date(self, statement_date, period_date):\n",
    "        statement_day = statement_date.split('-')[-1]\n",
    "        period_day = period_date.split('-')[-1]\n",
    "        statement_month = statement_date.split('-')[-2]\n",
    "        period_month = period_date.split('-')[-2]\n",
    "        if int(statement_month) < int(period_month):\n",
    "            tmp = 0\n",
    "        else:\n",
    "            if int(statement_day) > 20:\n",
    "                tmp = 1\n",
    "            else:\n",
    "                tmp = 0\n",
    "        return tmp\n",
    "    \n",
    "    \n",
    "    def initialize_billing(self, billing_df):\n",
    "        tmp = []\n",
    "        for index, row in billing_df.iterrows():\n",
    "            tmp.append(self.convert_date(row['StatementDate'], row['PERIODID_MY']))\n",
    "\n",
    "        billing_df['statement_time'] = tmp\n",
    "        \n",
    "        return billing_df\n",
    "    \n",
    "    def preprocess_transcation(self, transaction_df):\n",
    "        categorical_columns = ['MERCHANT_CATEGORY_XCD', 'MERCHANT_CITY_NAME', 'MERCHANT_COUNTRY_XCD', \n",
    "                               'DECISION_XCD', 'TRANSACTION_CATEGORY_XCD', 'TRANSACTION_TYPE_XCD', 'SICGROUP']\n",
    "        \n",
    "        for col in categorical_columns:\n",
    "            transaction_df[col].fillna('unknown')\n",
    "            transaction_df[col] = self.lbl.fit_transform(transaction_df[col].astype(str))\n",
    "        \n",
    "        transaction_df = transaction_df.groupby(['ID_CPTE', 'MERCHANT_CATEGORY_XCD'])['TRANSACTION_AMT'].sum()\n",
    "        transaction_df = transaction_df.reset_index()\n",
    "        transaction_df = transaction_df.pivot_table('TRANSACTION_AMT', ['ID_CPTE'], 'MERCHANT_CATEGORY_XCD')\n",
    "        transaction_df.columns = ['MERCHANT_CATEGORY_' + str(i) for i in transaction_df.columns]\n",
    "        transaction_df = transaction_df.fillna(0)\n",
    "        \n",
    "        return transaction_df\n",
    "    \n",
    "    def preprocess_payment(self, payment_df):\n",
    "        payment_df = payment_df.dropna()\n",
    "        payment_df['TRANSACTION_DTTM'] = payment_df['TRANSACTION_DTTM'].apply(lambda x: str(x).split(' ')[0][:-3])\n",
    "        payment_df = payment_df.sort_values(['ID_CPTE', 'TRANSACTION_DTTM'])\n",
    "        payment_df['PAYMENT_N_COUNT'] = payment_df['PAYMENT_REVERSAL_XFLG'] == 'N'\n",
    "        \n",
    "        payment_df = payment_df.groupby(['ID_CPTE', 'TRANSACTION_DTTM'])[['TRANSACTION_AMT', 'PAYMENT_N_COUNT']].sum().reset_index()\n",
    "        payment_df = payment_df.groupby('ID_CPTE').tail(12)\n",
    "        \n",
    "        tmp = payment_df.groupby(['ID_CPTE'])['PAYMENT_N_COUNT'].sum().reset_index()\n",
    "        \n",
    "        payment_df['TRANSACTION_DTTM'] = payment_df['TRANSACTION_DTTM'].apply(lambda x: x.split('-')[1])\n",
    "        payment_df = payment_df.pivot_table('TRANSACTION_AMT', ['ID_CPTE'], 'TRANSACTION_DTTM')\n",
    "        payment_df.columns = ['transaction_' + str(i) for i in payment_df.columns + '_month']\n",
    "        payment_df = payment_df.reset_index()\n",
    "        payment_df = payment_df.fillna(0)\n",
    "        \n",
    "        payment_df = payment_df.merge(tmp, on='ID_CPTE')\n",
    "        \n",
    "        return payment_df\n",
    "    \n",
    "    def preprocess_billing(self, billing_df):\n",
    "        billing_df['PERIODID_MY'] = billing_df['PERIODID_MY'].apply(lambda x: x[:-3])\n",
    "        billing_df = billing_df.sort_values(['ID_CPTE', 'PERIODID_MY'])\n",
    "        billing_df = billing_df.reset_index(drop=True)\n",
    "        billing_df = billing_df.groupby('ID_CPTE').tail(12)\n",
    "        billing_df = billing_df.reset_index(drop=True)\n",
    "        billing_df['CreditLeft'] = billing_df['CreditLimit'] - billing_df['CurrentTotalBalance']\n",
    "        \n",
    "        billing_df['PERIODID_MY'] = billing_df['PERIODID_MY'].apply(lambda x: x[-2:])\n",
    "        credit_left = billing_df.pivot_table('CreditLeft', ['ID_CPTE'], 'PERIODID_MY')\n",
    "        credit_left.columns = ['credit_left_' + str(i) for i in credit_left.columns + '_month']\n",
    "        cash_balance = billing_df.pivot_table('CashBalance', ['ID_CPTE'], 'PERIODID_MY')\n",
    "        cash_balance.columns = ['cash_balance_' + str(i) for i in cash_balance.columns + '_month']\n",
    "        \n",
    "        delq_cycle_avg = billing_df.groupby(['ID_CPTE'])['DelqCycle'].mean().reset_index()\n",
    "        delq_cycle_avg = delq_cycle_avg.rename(columns={'DelqCycle': 'AvgDelqCycle'})\n",
    "        \n",
    "        delq_cycle = billing_df.groupby(['ID_CPTE'])['DelqCycle'].max().reset_index()\n",
    "        delq_cycle = delq_cycle.rename(columns={'DelqCycle': 'MaxDelqCycle'})\n",
    "        \n",
    "        late_count = billing_df.groupby(['ID_CPTE'])['statement_time'].sum().reset_index()\n",
    "        late_count = late_count.rename(columns={'statement_time': 'LateCount'})\n",
    "        \n",
    "        credit_limit_avg = billing_df.groupby(['ID_CPTE'])['CreditLimit'].mean().reset_index()\n",
    "        credit_limit_avg = credit_limit_avg.rename(columns={'CreditLimit': 'CreditLimitAvg'})\n",
    "        \n",
    "        credit_limit_min = billing_df.groupby(['ID_CPTE'])['CreditLimit'].min().reset_index()\n",
    "        credit_limit_min = credit_limit_min.rename(columns={'CreditLimit': 'CreditLimitMin'})\n",
    "        \n",
    "        credit_limit_max = billing_df.groupby(['ID_CPTE'])['CreditLimit'].max().reset_index()\n",
    "        credit_limit_max = credit_limit_max.rename(columns={'CreditLimit': 'CreditLimitMax'})\n",
    "        \n",
    "        tmp1 = billing_df.groupby(['ID_CPTE'])[['ID_CPTE', 'CreditLimit']].head(1).set_index('ID_CPTE')\n",
    "        tmp2 = billing_df.groupby(['ID_CPTE'])[['ID_CPTE', 'CreditLimit']].tail(1).set_index('ID_CPTE')\n",
    "        credit_change = tmp2 - tmp1\n",
    "        credit_change = credit_change.reset_index()\n",
    "        credit_change = credit_change.rename(columns={'CreditLimit': 'CreditChange'})\n",
    "        \n",
    "        credit_left = credit_left.reset_index()\n",
    "        cash_balance = cash_balance.reset_index()\n",
    "        \n",
    "        tmp = credit_left.merge(cash_balance, on='ID_CPTE')\n",
    "        tmp = tmp.merge(credit_limit_avg, on='ID_CPTE')\n",
    "        tmp = tmp.merge(credit_limit_min, on='ID_CPTE')\n",
    "        tmp = tmp.merge(credit_limit_max, on='ID_CPTE')\n",
    "        tmp = tmp.merge(credit_change, on='ID_CPTE')\n",
    "        \n",
    "        tmp = tmp.merge(delq_cycle, on='ID_CPTE')\n",
    "        tmp = tmp.merge(delq_cycle_avg, on='ID_CPTE')\n",
    "        tmp = tmp.merge(late_count, on='ID_CPTE')\n",
    "        \n",
    "        return tmp\n",
    "    \n",
    "    def merge(self, payment, billing):\n",
    "        merge_df = payment.merge(billing, on='ID_CPTE', how='right')\n",
    "        return merge_df.set_index(['ID_CPTE']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>StatementDate</th>\n",
       "      <th>CurrentTotalBalance</th>\n",
       "      <th>CashBalance</th>\n",
       "      <th>CreditLimit</th>\n",
       "      <th>DelqCycle</th>\n",
       "      <th>statement_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-05</td>\n",
       "      <td>2015-05-03</td>\n",
       "      <td>8497.84</td>\n",
       "      <td>4293.12</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2014-11</td>\n",
       "      <td>2014-11-03</td>\n",
       "      <td>866.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-06</td>\n",
       "      <td>2015-05-31</td>\n",
       "      <td>10790.95</td>\n",
       "      <td>5224.44</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-10</td>\n",
       "      <td>2015-10-04</td>\n",
       "      <td>12388.46</td>\n",
       "      <td>4786.08</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-11</td>\n",
       "      <td>2015-11-02</td>\n",
       "      <td>12746.50</td>\n",
       "      <td>4818.48</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE PERIODID_MY StatementDate  CurrentTotalBalance  CashBalance  \\\n",
       "0  99690111     2015-05    2015-05-03              8497.84      4293.12   \n",
       "1  99690111     2014-11    2014-11-03               866.00         0.00   \n",
       "2  99690111     2015-06    2015-05-31             10790.95      5224.44   \n",
       "3  99690111     2015-10    2015-10-04             12388.46      4786.08   \n",
       "4  99690111     2015-11    2015-11-02             12746.50      4818.48   \n",
       "\n",
       "   CreditLimit  DelqCycle  statement_time  \n",
       "0      16200.0          0               0  \n",
       "1      12000.0          0               0  \n",
       "2      16200.0          0               0  \n",
       "3      16200.0          0               0  \n",
       "4      16200.0          0               0  "
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billing_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = billing_test.groupby(['ID_CPTE'])[['ID_CPTE', 'CreditLimit']].head(1).set_index('ID_CPTE')\n",
    "tmp2 = billing_test.groupby(['ID_CPTE'])[['ID_CPTE', 'CreditLimit']].tail(1).set_index('ID_CPTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_ = tmp2 - tmp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>CreditChange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71424379</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64887111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69431075</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31823308</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39407834</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>94576690</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35602796</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>94837853</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>84623445</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>62980143</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>78059616</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>40860073</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12768522</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>93960571</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>58415730</td>\n",
       "      <td>-6000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>45730545</td>\n",
       "      <td>2100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>96459912</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>69410008</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20848541</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86440680</td>\n",
       "      <td>1300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35064939</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>81456942</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>62558908</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>62765622</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>36769705</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>99373407</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>78189606</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>80652578</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>60690382</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>33092863</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5070</th>\n",
       "      <td>35369571</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5071</th>\n",
       "      <td>24962046</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5072</th>\n",
       "      <td>46385661</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5073</th>\n",
       "      <td>57155809</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5074</th>\n",
       "      <td>94911841</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5075</th>\n",
       "      <td>54251939</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5076</th>\n",
       "      <td>65118937</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5077</th>\n",
       "      <td>96741398</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5078</th>\n",
       "      <td>38630468</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5079</th>\n",
       "      <td>50554471</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5080</th>\n",
       "      <td>77478864</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5081</th>\n",
       "      <td>94000533</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5082</th>\n",
       "      <td>68711935</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5083</th>\n",
       "      <td>98388790</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5084</th>\n",
       "      <td>97151763</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5085</th>\n",
       "      <td>60708624</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5086</th>\n",
       "      <td>53576335</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5087</th>\n",
       "      <td>49709568</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5088</th>\n",
       "      <td>14053880</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5089</th>\n",
       "      <td>71310581</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5090</th>\n",
       "      <td>95205019</td>\n",
       "      <td>-5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5091</th>\n",
       "      <td>19511976</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5092</th>\n",
       "      <td>82837590</td>\n",
       "      <td>-7000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5093</th>\n",
       "      <td>18613831</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5094</th>\n",
       "      <td>87834116</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>80846785</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5096</th>\n",
       "      <td>53041557</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5097</th>\n",
       "      <td>11958724</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5098</th>\n",
       "      <td>24058348</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099</th>\n",
       "      <td>86972474</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID_CPTE  CreditChange\n",
       "0     71424379           0.0\n",
       "1     64887111           0.0\n",
       "2     69431075           0.0\n",
       "3     31823308           0.0\n",
       "4     39407834           0.0\n",
       "5     94576690           0.0\n",
       "6     35602796           0.0\n",
       "7     94837853           0.0\n",
       "8     84623445           0.0\n",
       "9     62980143           0.0\n",
       "10    78059616           0.0\n",
       "11    40860073           0.0\n",
       "12    12768522           0.0\n",
       "13    93960571           0.0\n",
       "14    58415730       -6000.0\n",
       "15    45730545        2100.0\n",
       "16    96459912           0.0\n",
       "17    69410008           0.0\n",
       "18    20848541           0.0\n",
       "19    86440680        1300.0\n",
       "20    35064939           0.0\n",
       "21    81456942           0.0\n",
       "22    62558908           0.0\n",
       "23    62765622           0.0\n",
       "24    36769705           0.0\n",
       "25    99373407           0.0\n",
       "26    78189606           0.0\n",
       "27    80652578           0.0\n",
       "28    60690382           0.0\n",
       "29    33092863           0.0\n",
       "...        ...           ...\n",
       "5070  35369571           0.0\n",
       "5071  24962046           0.0\n",
       "5072  46385661           0.0\n",
       "5073  57155809           0.0\n",
       "5074  94911841           0.0\n",
       "5075  54251939           0.0\n",
       "5076  65118937           0.0\n",
       "5077  96741398           0.0\n",
       "5078  38630468           0.0\n",
       "5079  50554471           0.0\n",
       "5080  77478864           0.0\n",
       "5081  94000533           0.0\n",
       "5082  68711935        5000.0\n",
       "5083  98388790           0.0\n",
       "5084  97151763           0.0\n",
       "5085  60708624           0.0\n",
       "5086  53576335           0.0\n",
       "5087  49709568           0.0\n",
       "5088  14053880           0.0\n",
       "5089  71310581           0.0\n",
       "5090  95205019       -5000.0\n",
       "5091  19511976           0.0\n",
       "5092  82837590       -7000.0\n",
       "5093  18613831           0.0\n",
       "5094  87834116           0.0\n",
       "5095  80846785           0.0\n",
       "5096  53041557           0.0\n",
       "5097  11958724           0.0\n",
       "5098  24058348           0.0\n",
       "5099  86972474           0.0\n",
       "\n",
       "[5100 rows x 2 columns]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_.reset_index().rename(columns={'CreditLimit': 'CreditChange'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = DataPreprocess(label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "billing_training = preprocess.initialize_billing(billing_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "processed_payment = preprocess.preprocess_payment(payment_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_billing = preprocess.preprocess_billing(billing_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_left_2_month</th>\n",
       "      <th>cash_balance_2_month</th>\n",
       "      <th>CreditLimitAvg</th>\n",
       "      <th>CreditLimitMin</th>\n",
       "      <th>CreditLimitMax</th>\n",
       "      <th>CreditChange</th>\n",
       "      <th>MaxDelqCycle</th>\n",
       "      <th>AvgDelqCycle</th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>LateCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [credit_left_2_month, cash_balance_2_month, CreditLimitAvg, CreditLimitMin, CreditLimitMax, CreditChange, MaxDelqCycle, AvgDelqCycle, ID_CPTE, LateCount]\n",
       "Index: []"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_billing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = preprocess.merge(processed_payment, processed_billing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_col = processed_data.iloc[:, :12].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with missing value in payment\n",
    "for col in transaction_col:\n",
    "    replace_value = processed_data[processed_data[col].notna()][col].mean()\n",
    "    processed_data[col] = processed_data[col].fillna(replace_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.merge(performance_training[['ID_CPTE', 'Default']], on='ID_CPTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.set_index('ID_CPTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_01_month</th>\n",
       "      <th>transaction_02_month</th>\n",
       "      <th>transaction_03_month</th>\n",
       "      <th>transaction_04_month</th>\n",
       "      <th>transaction_05_month</th>\n",
       "      <th>transaction_06_month</th>\n",
       "      <th>transaction_07_month</th>\n",
       "      <th>transaction_08_month</th>\n",
       "      <th>transaction_09_month</th>\n",
       "      <th>transaction_10_month</th>\n",
       "      <th>...</th>\n",
       "      <th>cash_balance_11_month</th>\n",
       "      <th>cash_balance_12_month</th>\n",
       "      <th>CreditLimitAvg</th>\n",
       "      <th>CreditLimitMin</th>\n",
       "      <th>CreditLimitMax</th>\n",
       "      <th>CreditChange</th>\n",
       "      <th>MaxDelqCycle</th>\n",
       "      <th>AvgDelqCycle</th>\n",
       "      <th>LateCount</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [transaction_01_month, transaction_02_month, transaction_03_month, transaction_04_month, transaction_05_month, transaction_06_month, transaction_07_month, transaction_08_month, transaction_09_month, transaction_10_month, transaction_11_month, transaction_12_month, PAYMENT_N_COUNT, credit_left_01_month, credit_left_02_month, credit_left_03_month, credit_left_04_month, credit_left_05_month, credit_left_06_month, credit_left_07_month, credit_left_08_month, credit_left_09_month, credit_left_10_month, credit_left_11_month, credit_left_12_month, cash_balance_01_month, cash_balance_02_month, cash_balance_03_month, cash_balance_04_month, cash_balance_05_month, cash_balance_06_month, cash_balance_07_month, cash_balance_08_month, cash_balance_09_month, cash_balance_10_month, cash_balance_11_month, cash_balance_12_month, CreditLimitAvg, CreditLimitMin, CreditLimitMax, CreditChange, MaxDelqCycle, AvgDelqCycle, LateCount, Default]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 45 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features correlation and distribution analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_01_month</th>\n",
       "      <th>transaction_02_month</th>\n",
       "      <th>transaction_03_month</th>\n",
       "      <th>transaction_04_month</th>\n",
       "      <th>transaction_05_month</th>\n",
       "      <th>transaction_06_month</th>\n",
       "      <th>transaction_07_month</th>\n",
       "      <th>transaction_08_month</th>\n",
       "      <th>transaction_09_month</th>\n",
       "      <th>transaction_10_month</th>\n",
       "      <th>...</th>\n",
       "      <th>cash_balance_10_month</th>\n",
       "      <th>cash_balance_11_month</th>\n",
       "      <th>cash_balance_12_month</th>\n",
       "      <th>CreditLimitAvg</th>\n",
       "      <th>CreditLimitMin</th>\n",
       "      <th>CreditLimitMax</th>\n",
       "      <th>MaxDelqCycle</th>\n",
       "      <th>AvgDelqCycle</th>\n",
       "      <th>LateCount</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10001822</th>\n",
       "      <td>318.00</td>\n",
       "      <td>522.50</td>\n",
       "      <td>374.50</td>\n",
       "      <td>4200.00</td>\n",
       "      <td>262.5</td>\n",
       "      <td>265.00</td>\n",
       "      <td>267.50</td>\n",
       "      <td>300.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>231.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.0</td>\n",
       "      <td>11500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10007972</th>\n",
       "      <td>784.34</td>\n",
       "      <td>168.28</td>\n",
       "      <td>1050.00</td>\n",
       "      <td>559.50</td>\n",
       "      <td>664.0</td>\n",
       "      <td>313.50</td>\n",
       "      <td>843.71</td>\n",
       "      <td>191.9</td>\n",
       "      <td>945.9</td>\n",
       "      <td>701.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012520</th>\n",
       "      <td>0.00</td>\n",
       "      <td>86.10</td>\n",
       "      <td>458.00</td>\n",
       "      <td>1177.31</td>\n",
       "      <td>315.0</td>\n",
       "      <td>525.00</td>\n",
       "      <td>505.00</td>\n",
       "      <td>50.5</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>612.00</td>\n",
       "      <td>...</td>\n",
       "      <td>849.66</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>777.65</td>\n",
       "      <td>2533.333333</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10025534</th>\n",
       "      <td>131.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>260.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6264.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2080.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6100.000000</td>\n",
       "      <td>6100.0</td>\n",
       "      <td>6100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10033579</th>\n",
       "      <td>574.55</td>\n",
       "      <td>391.30</td>\n",
       "      <td>412.23</td>\n",
       "      <td>470.53</td>\n",
       "      <td>546.8</td>\n",
       "      <td>419.61</td>\n",
       "      <td>283.92</td>\n",
       "      <td>106.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>219.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          transaction_01_month  transaction_02_month  transaction_03_month  \\\n",
       "ID_CPTE                                                                      \n",
       "10001822                318.00                522.50                374.50   \n",
       "10007972                784.34                168.28               1050.00   \n",
       "10012520                  0.00                 86.10                458.00   \n",
       "10025534                131.30                  0.00                260.00   \n",
       "10033579                574.55                391.30                412.23   \n",
       "\n",
       "          transaction_04_month  transaction_05_month  transaction_06_month  \\\n",
       "ID_CPTE                                                                      \n",
       "10001822               4200.00                 262.5                265.00   \n",
       "10007972                559.50                 664.0                313.50   \n",
       "10012520               1177.31                 315.0                525.00   \n",
       "10025534                  0.00                6264.0                  0.00   \n",
       "10033579                470.53                 546.8                419.61   \n",
       "\n",
       "          transaction_07_month  transaction_08_month  transaction_09_month  \\\n",
       "ID_CPTE                                                                      \n",
       "10001822                267.50                 300.0                 250.0   \n",
       "10007972                843.71                 191.9                 945.9   \n",
       "10012520                505.00                  50.5                1115.0   \n",
       "10025534               2080.00                   0.0                 318.0   \n",
       "10033579                283.92                 106.0                  84.0   \n",
       "\n",
       "          transaction_10_month   ...     cash_balance_10_month  \\\n",
       "ID_CPTE                          ...                             \n",
       "10001822                231.75   ...                      0.00   \n",
       "10007972                701.47   ...                      0.00   \n",
       "10012520                612.00   ...                    849.66   \n",
       "10025534                  0.00   ...                      0.00   \n",
       "10033579                219.60   ...                      0.00   \n",
       "\n",
       "          cash_balance_11_month  cash_balance_12_month  CreditLimitAvg  \\\n",
       "ID_CPTE                                                                  \n",
       "10001822                  101.0                   0.00    11500.000000   \n",
       "10007972                    0.0                   0.00      700.000000   \n",
       "10012520                 1224.0                 777.65     2533.333333   \n",
       "10025534                    0.0                   0.00     6100.000000   \n",
       "10033579                    0.0                   0.00      500.000000   \n",
       "\n",
       "          CreditLimitMin  CreditLimitMax  MaxDelqCycle  AvgDelqCycle  \\\n",
       "ID_CPTE                                                                \n",
       "10001822         11500.0         11500.0             0      0.000000   \n",
       "10007972           700.0           700.0             0      0.000000   \n",
       "10012520          2200.0          3200.0             0      0.000000   \n",
       "10025534          6100.0          6100.0             1      0.416667   \n",
       "10033579           500.0           500.0             1      0.083333   \n",
       "\n",
       "          LateCount  Default  \n",
       "ID_CPTE                       \n",
       "10001822          0        0  \n",
       "10007972          1        0  \n",
       "10012520          0        0  \n",
       "10025534         12        1  \n",
       "10033579          0        0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11900, 44)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(processed_data.iloc[:, :-1])\n",
    "y = np.array(processed_data.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp = normalize(X[:, :-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((X_tmp, X[:, -3:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\futai\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42, ratio=1)\n",
    "X_res, y_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    " \n",
    "clf = LogisticRegression()\n",
    "rf = RandomForestClassifier(min_samples_split=200, max_depth=20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=200,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_clf = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7747653837193327"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(predict_clf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7740196078431373"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(predict_rf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>credit_left_11_month</th>\n",
       "      <td>0.168163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_12_month</th>\n",
       "      <td>0.118133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_10_month</th>\n",
       "      <td>0.092951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_08_month</th>\n",
       "      <td>0.076884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AvgDelqCycle</th>\n",
       "      <td>0.076745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_09_month</th>\n",
       "      <td>0.075158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_04_month</th>\n",
       "      <td>0.066963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxDelqCycle</th>\n",
       "      <td>0.047234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_06_month</th>\n",
       "      <td>0.043250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_12_month</th>\n",
       "      <td>0.030504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_07_month</th>\n",
       "      <td>0.028292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_11_month</th>\n",
       "      <td>0.015283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_03_month</th>\n",
       "      <td>0.014939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_12_month</th>\n",
       "      <td>0.013477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_11_month</th>\n",
       "      <td>0.011624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreditLimitAvg</th>\n",
       "      <td>0.011014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_10_month</th>\n",
       "      <td>0.009993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_01_month</th>\n",
       "      <td>0.007367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_09_month</th>\n",
       "      <td>0.006731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_02_month</th>\n",
       "      <td>0.006658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_08_month</th>\n",
       "      <td>0.006196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_10_month</th>\n",
       "      <td>0.005800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreditLimitMin</th>\n",
       "      <td>0.005712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_05_month</th>\n",
       "      <td>0.004860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_02_month</th>\n",
       "      <td>0.004666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_08_month</th>\n",
       "      <td>0.004324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_03_month</th>\n",
       "      <td>0.004166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_01_month</th>\n",
       "      <td>0.004054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_05_month</th>\n",
       "      <td>0.003895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_06_month</th>\n",
       "      <td>0.003818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_07_month</th>\n",
       "      <td>0.003704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_06_month</th>\n",
       "      <td>0.003653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_04_month</th>\n",
       "      <td>0.003403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreditLimitMax</th>\n",
       "      <td>0.003319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_09_month</th>\n",
       "      <td>0.003232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_05_month</th>\n",
       "      <td>0.002582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_01_month</th>\n",
       "      <td>0.002538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_02_month</th>\n",
       "      <td>0.002247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_04_month</th>\n",
       "      <td>0.002201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_03_month</th>\n",
       "      <td>0.002191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_balance_07_month</th>\n",
       "      <td>0.001995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LateCount</th>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAYMENT_N_COUNT</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Importance\n",
       "credit_left_11_month     0.168163\n",
       "credit_left_12_month     0.118133\n",
       "credit_left_10_month     0.092951\n",
       "credit_left_08_month     0.076884\n",
       "AvgDelqCycle             0.076745\n",
       "credit_left_09_month     0.075158\n",
       "credit_left_04_month     0.066963\n",
       "MaxDelqCycle             0.047234\n",
       "credit_left_06_month     0.043250\n",
       "transaction_12_month     0.030504\n",
       "credit_left_07_month     0.028292\n",
       "cash_balance_11_month    0.015283\n",
       "cash_balance_03_month    0.014939\n",
       "cash_balance_12_month    0.013477\n",
       "transaction_11_month     0.011624\n",
       "CreditLimitAvg           0.011014\n",
       "transaction_10_month     0.009993\n",
       "credit_left_01_month     0.007367\n",
       "cash_balance_09_month    0.006731\n",
       "credit_left_02_month     0.006658\n",
       "cash_balance_08_month    0.006196\n",
       "cash_balance_10_month    0.005800\n",
       "CreditLimitMin           0.005712\n",
       "transaction_05_month     0.004860\n",
       "cash_balance_02_month    0.004666\n",
       "transaction_08_month     0.004324\n",
       "credit_left_03_month     0.004166\n",
       "cash_balance_01_month    0.004054\n",
       "credit_left_05_month     0.003895\n",
       "transaction_06_month     0.003818\n",
       "transaction_07_month     0.003704\n",
       "cash_balance_06_month    0.003653\n",
       "transaction_04_month     0.003403\n",
       "CreditLimitMax           0.003319\n",
       "transaction_09_month     0.003232\n",
       "cash_balance_05_month    0.002582\n",
       "transaction_01_month     0.002538\n",
       "transaction_02_month     0.002247\n",
       "cash_balance_04_month    0.002201\n",
       "transaction_03_month     0.002191\n",
       "cash_balance_07_month    0.001995\n",
       "LateCount                0.000082\n",
       "PAYMENT_N_COUNT          0.000000"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = rf.feature_importances_\n",
    "importance = pd.DataFrame(importance, index=processed_data.iloc[:, :-1].columns, columns=[\"Importance\"])\n",
    "importance.sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = importance.reset_index().sort_values(['Importance'], ascending=False)['index'][:14].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(processed_data[features_test])\n",
    "y = np.array(processed_data['Default'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "rf = RandomForestClassifier(min_samples_split=200, max_depth=20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=200,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7941357704862216"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_clf = clf.predict(X_test)\n",
    "roc_auc_score(predict_clf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7950622543686302"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rf = rf.predict(X_test)\n",
    "roc_auc_score(predict_rf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params =  {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    #'max_depth': 15,\n",
    "    'num_leaves': 270,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 2,\n",
    "    'learning_rate': 0.0175,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgtrain = lgb.Dataset(X_train, y_train)\n",
    "lgtest = lgb.Dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.483921\n",
      "[2]\ttraining's binary_logloss: 0.47423\n",
      "[3]\ttraining's binary_logloss: 0.465425\n",
      "[4]\ttraining's binary_logloss: 0.45699\n",
      "[5]\ttraining's binary_logloss: 0.449553\n",
      "[6]\ttraining's binary_logloss: 0.441479\n",
      "[7]\ttraining's binary_logloss: 0.433863\n",
      "[8]\ttraining's binary_logloss: 0.426356\n",
      "[9]\ttraining's binary_logloss: 0.419756\n",
      "[10]\ttraining's binary_logloss: 0.413428\n",
      "[11]\ttraining's binary_logloss: 0.407148\n",
      "[12]\ttraining's binary_logloss: 0.401119\n",
      "[13]\ttraining's binary_logloss: 0.395703\n",
      "[14]\ttraining's binary_logloss: 0.390192\n",
      "[15]\ttraining's binary_logloss: 0.385123\n",
      "[16]\ttraining's binary_logloss: 0.379749\n",
      "[17]\ttraining's binary_logloss: 0.374884\n",
      "[18]\ttraining's binary_logloss: 0.370104\n",
      "[19]\ttraining's binary_logloss: 0.365283\n",
      "[20]\ttraining's binary_logloss: 0.360606\n",
      "[21]\ttraining's binary_logloss: 0.356278\n",
      "[22]\ttraining's binary_logloss: 0.35178\n",
      "[23]\ttraining's binary_logloss: 0.34769\n",
      "[24]\ttraining's binary_logloss: 0.343617\n",
      "[25]\ttraining's binary_logloss: 0.339676\n",
      "[26]\ttraining's binary_logloss: 0.335714\n",
      "[27]\ttraining's binary_logloss: 0.331711\n",
      "[28]\ttraining's binary_logloss: 0.328051\n",
      "[29]\ttraining's binary_logloss: 0.324528\n",
      "[30]\ttraining's binary_logloss: 0.32103\n",
      "[31]\ttraining's binary_logloss: 0.317515\n",
      "[32]\ttraining's binary_logloss: 0.314213\n",
      "[33]\ttraining's binary_logloss: 0.310803\n",
      "[34]\ttraining's binary_logloss: 0.30755\n",
      "[35]\ttraining's binary_logloss: 0.304397\n",
      "[36]\ttraining's binary_logloss: 0.301216\n",
      "[37]\ttraining's binary_logloss: 0.298061\n",
      "[38]\ttraining's binary_logloss: 0.29515\n",
      "[39]\ttraining's binary_logloss: 0.292179\n",
      "[40]\ttraining's binary_logloss: 0.289249\n",
      "[41]\ttraining's binary_logloss: 0.286484\n",
      "[42]\ttraining's binary_logloss: 0.283692\n",
      "[43]\ttraining's binary_logloss: 0.280986\n",
      "[44]\ttraining's binary_logloss: 0.278323\n",
      "[45]\ttraining's binary_logloss: 0.275731\n",
      "[46]\ttraining's binary_logloss: 0.273196\n",
      "[47]\ttraining's binary_logloss: 0.270681\n",
      "[48]\ttraining's binary_logloss: 0.268221\n",
      "[49]\ttraining's binary_logloss: 0.265791\n",
      "[50]\ttraining's binary_logloss: 0.263414\n",
      "[51]\ttraining's binary_logloss: 0.261138\n",
      "[52]\ttraining's binary_logloss: 0.258847\n",
      "[53]\ttraining's binary_logloss: 0.256514\n",
      "[54]\ttraining's binary_logloss: 0.254353\n",
      "[55]\ttraining's binary_logloss: 0.25221\n",
      "[56]\ttraining's binary_logloss: 0.249988\n",
      "[57]\ttraining's binary_logloss: 0.24787\n",
      "[58]\ttraining's binary_logloss: 0.245828\n",
      "[59]\ttraining's binary_logloss: 0.243789\n",
      "[60]\ttraining's binary_logloss: 0.241748\n",
      "[61]\ttraining's binary_logloss: 0.239873\n",
      "[62]\ttraining's binary_logloss: 0.237936\n",
      "[63]\ttraining's binary_logloss: 0.236091\n",
      "[64]\ttraining's binary_logloss: 0.23424\n",
      "[65]\ttraining's binary_logloss: 0.232367\n",
      "[66]\ttraining's binary_logloss: 0.230452\n",
      "[67]\ttraining's binary_logloss: 0.228705\n",
      "[68]\ttraining's binary_logloss: 0.226869\n",
      "[69]\ttraining's binary_logloss: 0.225035\n",
      "[70]\ttraining's binary_logloss: 0.223342\n",
      "[71]\ttraining's binary_logloss: 0.221586\n",
      "[72]\ttraining's binary_logloss: 0.219887\n",
      "[73]\ttraining's binary_logloss: 0.21821\n",
      "[74]\ttraining's binary_logloss: 0.216558\n",
      "[75]\ttraining's binary_logloss: 0.214912\n",
      "[76]\ttraining's binary_logloss: 0.213236\n",
      "[77]\ttraining's binary_logloss: 0.211621\n",
      "[78]\ttraining's binary_logloss: 0.210028\n",
      "[79]\ttraining's binary_logloss: 0.208379\n",
      "[80]\ttraining's binary_logloss: 0.206869\n",
      "[81]\ttraining's binary_logloss: 0.205346\n",
      "[82]\ttraining's binary_logloss: 0.203819\n",
      "[83]\ttraining's binary_logloss: 0.202392\n",
      "[84]\ttraining's binary_logloss: 0.200883\n",
      "[85]\ttraining's binary_logloss: 0.199503\n",
      "[86]\ttraining's binary_logloss: 0.198042\n",
      "[87]\ttraining's binary_logloss: 0.196569\n",
      "[88]\ttraining's binary_logloss: 0.195089\n",
      "[89]\ttraining's binary_logloss: 0.193661\n",
      "[90]\ttraining's binary_logloss: 0.192193\n",
      "[91]\ttraining's binary_logloss: 0.190663\n",
      "[92]\ttraining's binary_logloss: 0.189336\n",
      "[93]\ttraining's binary_logloss: 0.187974\n",
      "[94]\ttraining's binary_logloss: 0.186656\n",
      "[95]\ttraining's binary_logloss: 0.185293\n",
      "[96]\ttraining's binary_logloss: 0.184024\n",
      "[97]\ttraining's binary_logloss: 0.182696\n",
      "[98]\ttraining's binary_logloss: 0.181365\n",
      "[99]\ttraining's binary_logloss: 0.180039\n",
      "[100]\ttraining's binary_logloss: 0.178854\n",
      "[101]\ttraining's binary_logloss: 0.177561\n",
      "[102]\ttraining's binary_logloss: 0.176288\n",
      "[103]\ttraining's binary_logloss: 0.174967\n",
      "[104]\ttraining's binary_logloss: 0.173723\n",
      "[105]\ttraining's binary_logloss: 0.172515\n",
      "[106]\ttraining's binary_logloss: 0.171365\n",
      "[107]\ttraining's binary_logloss: 0.170185\n",
      "[108]\ttraining's binary_logloss: 0.169008\n",
      "[109]\ttraining's binary_logloss: 0.167849\n",
      "[110]\ttraining's binary_logloss: 0.166692\n",
      "[111]\ttraining's binary_logloss: 0.165482\n",
      "[112]\ttraining's binary_logloss: 0.164354\n",
      "[113]\ttraining's binary_logloss: 0.16319\n",
      "[114]\ttraining's binary_logloss: 0.16202\n",
      "[115]\ttraining's binary_logloss: 0.160839\n",
      "[116]\ttraining's binary_logloss: 0.159748\n",
      "[117]\ttraining's binary_logloss: 0.158597\n",
      "[118]\ttraining's binary_logloss: 0.157458\n",
      "[119]\ttraining's binary_logloss: 0.156296\n",
      "[120]\ttraining's binary_logloss: 0.155233\n",
      "[121]\ttraining's binary_logloss: 0.154157\n",
      "[122]\ttraining's binary_logloss: 0.153046\n",
      "[123]\ttraining's binary_logloss: 0.151982\n",
      "[124]\ttraining's binary_logloss: 0.15094\n",
      "[125]\ttraining's binary_logloss: 0.149811\n",
      "[126]\ttraining's binary_logloss: 0.148753\n",
      "[127]\ttraining's binary_logloss: 0.147733\n",
      "[128]\ttraining's binary_logloss: 0.146698\n",
      "[129]\ttraining's binary_logloss: 0.145601\n",
      "[130]\ttraining's binary_logloss: 0.144523\n",
      "[131]\ttraining's binary_logloss: 0.143571\n",
      "[132]\ttraining's binary_logloss: 0.142556\n",
      "[133]\ttraining's binary_logloss: 0.141645\n",
      "[134]\ttraining's binary_logloss: 0.140612\n",
      "[135]\ttraining's binary_logloss: 0.13972\n",
      "[136]\ttraining's binary_logloss: 0.138801\n",
      "[137]\ttraining's binary_logloss: 0.137863\n",
      "[138]\ttraining's binary_logloss: 0.136945\n",
      "[139]\ttraining's binary_logloss: 0.136019\n",
      "[140]\ttraining's binary_logloss: 0.135125\n",
      "[141]\ttraining's binary_logloss: 0.134184\n",
      "[142]\ttraining's binary_logloss: 0.133263\n",
      "[143]\ttraining's binary_logloss: 0.132349\n",
      "[144]\ttraining's binary_logloss: 0.131442\n",
      "[145]\ttraining's binary_logloss: 0.13051\n",
      "[146]\ttraining's binary_logloss: 0.129555\n",
      "[147]\ttraining's binary_logloss: 0.128645\n",
      "[148]\ttraining's binary_logloss: 0.127695\n",
      "[149]\ttraining's binary_logloss: 0.126807\n",
      "[150]\ttraining's binary_logloss: 0.125946\n",
      "[151]\ttraining's binary_logloss: 0.125093\n",
      "[152]\ttraining's binary_logloss: 0.124262\n",
      "[153]\ttraining's binary_logloss: 0.123397\n",
      "[154]\ttraining's binary_logloss: 0.122609\n",
      "[155]\ttraining's binary_logloss: 0.121793\n",
      "[156]\ttraining's binary_logloss: 0.121011\n",
      "[157]\ttraining's binary_logloss: 0.12021\n",
      "[158]\ttraining's binary_logloss: 0.11939\n",
      "[159]\ttraining's binary_logloss: 0.11857\n",
      "[160]\ttraining's binary_logloss: 0.117754\n",
      "[161]\ttraining's binary_logloss: 0.116973\n",
      "[162]\ttraining's binary_logloss: 0.116111\n",
      "[163]\ttraining's binary_logloss: 0.115291\n",
      "[164]\ttraining's binary_logloss: 0.114544\n",
      "[165]\ttraining's binary_logloss: 0.113775\n",
      "[166]\ttraining's binary_logloss: 0.113002\n",
      "[167]\ttraining's binary_logloss: 0.112226\n",
      "[168]\ttraining's binary_logloss: 0.111423\n",
      "[169]\ttraining's binary_logloss: 0.110648\n",
      "[170]\ttraining's binary_logloss: 0.109874\n",
      "[171]\ttraining's binary_logloss: 0.10913\n",
      "[172]\ttraining's binary_logloss: 0.108403\n",
      "[173]\ttraining's binary_logloss: 0.107676\n",
      "[174]\ttraining's binary_logloss: 0.106957\n",
      "[175]\ttraining's binary_logloss: 0.106229\n",
      "[176]\ttraining's binary_logloss: 0.105571\n",
      "[177]\ttraining's binary_logloss: 0.10483\n",
      "[178]\ttraining's binary_logloss: 0.104148\n",
      "[179]\ttraining's binary_logloss: 0.103457\n",
      "[180]\ttraining's binary_logloss: 0.102745\n",
      "[181]\ttraining's binary_logloss: 0.10202\n",
      "[182]\ttraining's binary_logloss: 0.101253\n",
      "[183]\ttraining's binary_logloss: 0.100568\n",
      "[184]\ttraining's binary_logloss: 0.0999094\n",
      "[185]\ttraining's binary_logloss: 0.0992157\n",
      "[186]\ttraining's binary_logloss: 0.0985609\n",
      "[187]\ttraining's binary_logloss: 0.0978252\n",
      "[188]\ttraining's binary_logloss: 0.0971506\n",
      "[189]\ttraining's binary_logloss: 0.0964738\n",
      "[190]\ttraining's binary_logloss: 0.0958102\n",
      "[191]\ttraining's binary_logloss: 0.0951314\n",
      "[192]\ttraining's binary_logloss: 0.0944572\n",
      "[193]\ttraining's binary_logloss: 0.0937658\n",
      "[194]\ttraining's binary_logloss: 0.0931606\n",
      "[195]\ttraining's binary_logloss: 0.0924885\n",
      "[196]\ttraining's binary_logloss: 0.0918601\n",
      "[197]\ttraining's binary_logloss: 0.091225\n",
      "[198]\ttraining's binary_logloss: 0.090629\n",
      "[199]\ttraining's binary_logloss: 0.0900459\n",
      "[200]\ttraining's binary_logloss: 0.0894308\n",
      "[201]\ttraining's binary_logloss: 0.0887813\n",
      "[202]\ttraining's binary_logloss: 0.0881986\n",
      "[203]\ttraining's binary_logloss: 0.0876179\n",
      "[204]\ttraining's binary_logloss: 0.0870819\n",
      "[205]\ttraining's binary_logloss: 0.0864381\n",
      "[206]\ttraining's binary_logloss: 0.0858604\n",
      "[207]\ttraining's binary_logloss: 0.0852508\n",
      "[208]\ttraining's binary_logloss: 0.0846807\n",
      "[209]\ttraining's binary_logloss: 0.0841208\n",
      "[210]\ttraining's binary_logloss: 0.0836126\n",
      "[211]\ttraining's binary_logloss: 0.0830772\n",
      "[212]\ttraining's binary_logloss: 0.0825414\n",
      "[213]\ttraining's binary_logloss: 0.0820027\n",
      "[214]\ttraining's binary_logloss: 0.0814262\n",
      "[215]\ttraining's binary_logloss: 0.0809193\n",
      "[216]\ttraining's binary_logloss: 0.0804037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[217]\ttraining's binary_logloss: 0.0798726\n",
      "[218]\ttraining's binary_logloss: 0.0793293\n",
      "[219]\ttraining's binary_logloss: 0.0788381\n",
      "[220]\ttraining's binary_logloss: 0.0783138\n",
      "[221]\ttraining's binary_logloss: 0.0777764\n",
      "[222]\ttraining's binary_logloss: 0.077262\n",
      "[223]\ttraining's binary_logloss: 0.0767359\n",
      "[224]\ttraining's binary_logloss: 0.0762566\n",
      "[225]\ttraining's binary_logloss: 0.0757493\n",
      "[226]\ttraining's binary_logloss: 0.0752602\n",
      "[227]\ttraining's binary_logloss: 0.0747924\n",
      "[228]\ttraining's binary_logloss: 0.0743064\n",
      "[229]\ttraining's binary_logloss: 0.0738308\n",
      "[230]\ttraining's binary_logloss: 0.0733236\n",
      "[231]\ttraining's binary_logloss: 0.0728383\n",
      "[232]\ttraining's binary_logloss: 0.0723516\n",
      "[233]\ttraining's binary_logloss: 0.0718944\n",
      "[234]\ttraining's binary_logloss: 0.071447\n",
      "[235]\ttraining's binary_logloss: 0.0709896\n",
      "[236]\ttraining's binary_logloss: 0.0705045\n",
      "[237]\ttraining's binary_logloss: 0.0700671\n",
      "[238]\ttraining's binary_logloss: 0.0696074\n",
      "[239]\ttraining's binary_logloss: 0.0691581\n",
      "[240]\ttraining's binary_logloss: 0.0687089\n",
      "[241]\ttraining's binary_logloss: 0.0682422\n",
      "[242]\ttraining's binary_logloss: 0.0678206\n",
      "[243]\ttraining's binary_logloss: 0.0673962\n",
      "[244]\ttraining's binary_logloss: 0.0669248\n",
      "[245]\ttraining's binary_logloss: 0.0664872\n",
      "[246]\ttraining's binary_logloss: 0.0660398\n",
      "[247]\ttraining's binary_logloss: 0.0655796\n",
      "[248]\ttraining's binary_logloss: 0.0651593\n",
      "[249]\ttraining's binary_logloss: 0.0647116\n",
      "[250]\ttraining's binary_logloss: 0.0643088\n",
      "[251]\ttraining's binary_logloss: 0.0639101\n",
      "[252]\ttraining's binary_logloss: 0.0635048\n",
      "[253]\ttraining's binary_logloss: 0.0630849\n",
      "[254]\ttraining's binary_logloss: 0.0627062\n",
      "[255]\ttraining's binary_logloss: 0.0622807\n",
      "[256]\ttraining's binary_logloss: 0.0618453\n",
      "[257]\ttraining's binary_logloss: 0.0614299\n",
      "[258]\ttraining's binary_logloss: 0.0610709\n",
      "[259]\ttraining's binary_logloss: 0.0606711\n",
      "[260]\ttraining's binary_logloss: 0.0602441\n",
      "[261]\ttraining's binary_logloss: 0.0598427\n",
      "[262]\ttraining's binary_logloss: 0.0594033\n",
      "[263]\ttraining's binary_logloss: 0.0590557\n",
      "[264]\ttraining's binary_logloss: 0.058684\n",
      "[265]\ttraining's binary_logloss: 0.0583095\n",
      "[266]\ttraining's binary_logloss: 0.0579371\n",
      "[267]\ttraining's binary_logloss: 0.0575847\n",
      "[268]\ttraining's binary_logloss: 0.0572002\n",
      "[269]\ttraining's binary_logloss: 0.0568492\n",
      "[270]\ttraining's binary_logloss: 0.0564808\n",
      "[271]\ttraining's binary_logloss: 0.0561044\n",
      "[272]\ttraining's binary_logloss: 0.0557342\n",
      "[273]\ttraining's binary_logloss: 0.0554029\n",
      "[274]\ttraining's binary_logloss: 0.0550429\n",
      "[275]\ttraining's binary_logloss: 0.0546984\n",
      "[276]\ttraining's binary_logloss: 0.0543646\n",
      "[277]\ttraining's binary_logloss: 0.0540097\n",
      "[278]\ttraining's binary_logloss: 0.0536496\n",
      "[279]\ttraining's binary_logloss: 0.0532744\n",
      "[280]\ttraining's binary_logloss: 0.0529099\n",
      "[281]\ttraining's binary_logloss: 0.0525404\n",
      "[282]\ttraining's binary_logloss: 0.0521909\n",
      "[283]\ttraining's binary_logloss: 0.0518419\n",
      "[284]\ttraining's binary_logloss: 0.0515176\n",
      "[285]\ttraining's binary_logloss: 0.0511916\n",
      "[286]\ttraining's binary_logloss: 0.0508071\n",
      "[287]\ttraining's binary_logloss: 0.0504948\n",
      "[288]\ttraining's binary_logloss: 0.0502016\n",
      "[289]\ttraining's binary_logloss: 0.0498762\n",
      "[290]\ttraining's binary_logloss: 0.0495326\n",
      "[291]\ttraining's binary_logloss: 0.0492356\n",
      "[292]\ttraining's binary_logloss: 0.0489457\n",
      "[293]\ttraining's binary_logloss: 0.0486201\n",
      "[294]\ttraining's binary_logloss: 0.0483273\n",
      "[295]\ttraining's binary_logloss: 0.0480306\n",
      "[296]\ttraining's binary_logloss: 0.0476972\n",
      "[297]\ttraining's binary_logloss: 0.0474034\n",
      "[298]\ttraining's binary_logloss: 0.0471279\n",
      "[299]\ttraining's binary_logloss: 0.0468239\n",
      "[300]\ttraining's binary_logloss: 0.0465241\n",
      "[301]\ttraining's binary_logloss: 0.0462257\n",
      "[302]\ttraining's binary_logloss: 0.0459424\n",
      "[303]\ttraining's binary_logloss: 0.0456632\n",
      "[304]\ttraining's binary_logloss: 0.0453833\n",
      "[305]\ttraining's binary_logloss: 0.0450962\n",
      "[306]\ttraining's binary_logloss: 0.0448308\n",
      "[307]\ttraining's binary_logloss: 0.0445609\n",
      "[308]\ttraining's binary_logloss: 0.0442975\n",
      "[309]\ttraining's binary_logloss: 0.0440046\n",
      "[310]\ttraining's binary_logloss: 0.0437424\n",
      "[311]\ttraining's binary_logloss: 0.0434889\n",
      "[312]\ttraining's binary_logloss: 0.0432342\n",
      "[313]\ttraining's binary_logloss: 0.0429576\n",
      "[314]\ttraining's binary_logloss: 0.0426833\n",
      "[315]\ttraining's binary_logloss: 0.0423942\n",
      "[316]\ttraining's binary_logloss: 0.042136\n",
      "[317]\ttraining's binary_logloss: 0.0418618\n",
      "[318]\ttraining's binary_logloss: 0.0416122\n",
      "[319]\ttraining's binary_logloss: 0.0413422\n",
      "[320]\ttraining's binary_logloss: 0.0410698\n",
      "[321]\ttraining's binary_logloss: 0.0408002\n",
      "[322]\ttraining's binary_logloss: 0.0405568\n",
      "[323]\ttraining's binary_logloss: 0.0403163\n",
      "[324]\ttraining's binary_logloss: 0.0400746\n",
      "[325]\ttraining's binary_logloss: 0.0398205\n",
      "[326]\ttraining's binary_logloss: 0.0395838\n",
      "[327]\ttraining's binary_logloss: 0.0393282\n",
      "[328]\ttraining's binary_logloss: 0.039086\n",
      "[329]\ttraining's binary_logloss: 0.0388376\n",
      "[330]\ttraining's binary_logloss: 0.0385628\n",
      "[331]\ttraining's binary_logloss: 0.0382967\n",
      "[332]\ttraining's binary_logloss: 0.0380517\n",
      "[333]\ttraining's binary_logloss: 0.0378214\n",
      "[334]\ttraining's binary_logloss: 0.0375842\n",
      "[335]\ttraining's binary_logloss: 0.0373384\n",
      "[336]\ttraining's binary_logloss: 0.0371019\n",
      "[337]\ttraining's binary_logloss: 0.0368934\n",
      "[338]\ttraining's binary_logloss: 0.0366713\n",
      "[339]\ttraining's binary_logloss: 0.0364463\n",
      "[340]\ttraining's binary_logloss: 0.0362145\n",
      "[341]\ttraining's binary_logloss: 0.0359746\n",
      "[342]\ttraining's binary_logloss: 0.0357568\n",
      "[343]\ttraining's binary_logloss: 0.0355205\n",
      "[344]\ttraining's binary_logloss: 0.0352954\n",
      "[345]\ttraining's binary_logloss: 0.0350871\n",
      "[346]\ttraining's binary_logloss: 0.0348668\n",
      "[347]\ttraining's binary_logloss: 0.03463\n",
      "[348]\ttraining's binary_logloss: 0.0344249\n",
      "[349]\ttraining's binary_logloss: 0.0342161\n",
      "[350]\ttraining's binary_logloss: 0.0340074\n",
      "[351]\ttraining's binary_logloss: 0.0338001\n",
      "[352]\ttraining's binary_logloss: 0.0335838\n",
      "[353]\ttraining's binary_logloss: 0.0333721\n",
      "[354]\ttraining's binary_logloss: 0.0331346\n",
      "[355]\ttraining's binary_logloss: 0.0329154\n",
      "[356]\ttraining's binary_logloss: 0.0327178\n",
      "[357]\ttraining's binary_logloss: 0.0325064\n",
      "[358]\ttraining's binary_logloss: 0.0323107\n",
      "[359]\ttraining's binary_logloss: 0.0321108\n",
      "[360]\ttraining's binary_logloss: 0.0319104\n",
      "[361]\ttraining's binary_logloss: 0.0317337\n",
      "[362]\ttraining's binary_logloss: 0.0315375\n",
      "[363]\ttraining's binary_logloss: 0.0313408\n",
      "[364]\ttraining's binary_logloss: 0.0311295\n",
      "[365]\ttraining's binary_logloss: 0.0309289\n",
      "[366]\ttraining's binary_logloss: 0.0307532\n",
      "[367]\ttraining's binary_logloss: 0.0305673\n",
      "[368]\ttraining's binary_logloss: 0.0303892\n",
      "[369]\ttraining's binary_logloss: 0.0302091\n",
      "[370]\ttraining's binary_logloss: 0.0300246\n",
      "[371]\ttraining's binary_logloss: 0.0298296\n",
      "[372]\ttraining's binary_logloss: 0.0296494\n",
      "[373]\ttraining's binary_logloss: 0.0294488\n",
      "[374]\ttraining's binary_logloss: 0.0292757\n",
      "[375]\ttraining's binary_logloss: 0.0290911\n",
      "[376]\ttraining's binary_logloss: 0.0289157\n",
      "[377]\ttraining's binary_logloss: 0.0287239\n",
      "[378]\ttraining's binary_logloss: 0.0285336\n",
      "[379]\ttraining's binary_logloss: 0.0283696\n",
      "[380]\ttraining's binary_logloss: 0.0281881\n",
      "[381]\ttraining's binary_logloss: 0.0280152\n",
      "[382]\ttraining's binary_logloss: 0.027848\n",
      "[383]\ttraining's binary_logloss: 0.0276736\n",
      "[384]\ttraining's binary_logloss: 0.0275111\n",
      "[385]\ttraining's binary_logloss: 0.0273377\n",
      "[386]\ttraining's binary_logloss: 0.0271752\n",
      "[387]\ttraining's binary_logloss: 0.0270204\n",
      "[388]\ttraining's binary_logloss: 0.026861\n",
      "[389]\ttraining's binary_logloss: 0.0267074\n",
      "[390]\ttraining's binary_logloss: 0.026538\n",
      "[391]\ttraining's binary_logloss: 0.0263754\n",
      "[392]\ttraining's binary_logloss: 0.0262258\n",
      "[393]\ttraining's binary_logloss: 0.026079\n",
      "[394]\ttraining's binary_logloss: 0.02593\n",
      "[395]\ttraining's binary_logloss: 0.0257632\n",
      "[396]\ttraining's binary_logloss: 0.0256128\n",
      "[397]\ttraining's binary_logloss: 0.0254423\n",
      "[398]\ttraining's binary_logloss: 0.0252703\n",
      "[399]\ttraining's binary_logloss: 0.0251187\n",
      "[400]\ttraining's binary_logloss: 0.0249684\n",
      "[401]\ttraining's binary_logloss: 0.0248242\n",
      "[402]\ttraining's binary_logloss: 0.0246742\n",
      "[403]\ttraining's binary_logloss: 0.0245211\n",
      "[404]\ttraining's binary_logloss: 0.0243683\n",
      "[405]\ttraining's binary_logloss: 0.0242139\n",
      "[406]\ttraining's binary_logloss: 0.0240664\n",
      "[407]\ttraining's binary_logloss: 0.0239285\n",
      "[408]\ttraining's binary_logloss: 0.0237882\n",
      "[409]\ttraining's binary_logloss: 0.023621\n",
      "[410]\ttraining's binary_logloss: 0.0234691\n",
      "[411]\ttraining's binary_logloss: 0.0233162\n",
      "[412]\ttraining's binary_logloss: 0.0231772\n",
      "[413]\ttraining's binary_logloss: 0.0230428\n",
      "[414]\ttraining's binary_logloss: 0.0229052\n",
      "[415]\ttraining's binary_logloss: 0.0227604\n",
      "[416]\ttraining's binary_logloss: 0.0226233\n",
      "[417]\ttraining's binary_logloss: 0.0224954\n",
      "[418]\ttraining's binary_logloss: 0.0223627\n",
      "[419]\ttraining's binary_logloss: 0.02224\n",
      "[420]\ttraining's binary_logloss: 0.0221075\n",
      "[421]\ttraining's binary_logloss: 0.0219716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[422]\ttraining's binary_logloss: 0.0218415\n",
      "[423]\ttraining's binary_logloss: 0.0217076\n",
      "[424]\ttraining's binary_logloss: 0.0215794\n",
      "[425]\ttraining's binary_logloss: 0.0214538\n",
      "[426]\ttraining's binary_logloss: 0.0213401\n",
      "[427]\ttraining's binary_logloss: 0.0212038\n",
      "[428]\ttraining's binary_logloss: 0.0210724\n",
      "[429]\ttraining's binary_logloss: 0.0209343\n",
      "[430]\ttraining's binary_logloss: 0.0207948\n",
      "[431]\ttraining's binary_logloss: 0.0206777\n",
      "[432]\ttraining's binary_logloss: 0.0205529\n",
      "[433]\ttraining's binary_logloss: 0.0204317\n",
      "[434]\ttraining's binary_logloss: 0.0202993\n",
      "[435]\ttraining's binary_logloss: 0.0201688\n",
      "[436]\ttraining's binary_logloss: 0.0200414\n",
      "[437]\ttraining's binary_logloss: 0.0199326\n",
      "[438]\ttraining's binary_logloss: 0.0198185\n",
      "[439]\ttraining's binary_logloss: 0.0196926\n",
      "[440]\ttraining's binary_logloss: 0.0195745\n",
      "[441]\ttraining's binary_logloss: 0.0194529\n",
      "[442]\ttraining's binary_logloss: 0.0193428\n",
      "[443]\ttraining's binary_logloss: 0.0192264\n",
      "[444]\ttraining's binary_logloss: 0.0191097\n",
      "[445]\ttraining's binary_logloss: 0.0190057\n",
      "[446]\ttraining's binary_logloss: 0.0188883\n",
      "[447]\ttraining's binary_logloss: 0.0187568\n",
      "[448]\ttraining's binary_logloss: 0.0186304\n",
      "[449]\ttraining's binary_logloss: 0.0185105\n",
      "[450]\ttraining's binary_logloss: 0.0183998\n",
      "[451]\ttraining's binary_logloss: 0.0182747\n",
      "[452]\ttraining's binary_logloss: 0.0181703\n",
      "[453]\ttraining's binary_logloss: 0.0180665\n",
      "[454]\ttraining's binary_logloss: 0.0179659\n",
      "[455]\ttraining's binary_logloss: 0.0178545\n",
      "[456]\ttraining's binary_logloss: 0.0177534\n",
      "[457]\ttraining's binary_logloss: 0.0176479\n",
      "[458]\ttraining's binary_logloss: 0.0175541\n",
      "[459]\ttraining's binary_logloss: 0.0174513\n",
      "[460]\ttraining's binary_logloss: 0.0173484\n",
      "[461]\ttraining's binary_logloss: 0.0172426\n",
      "[462]\ttraining's binary_logloss: 0.0171364\n",
      "[463]\ttraining's binary_logloss: 0.0170308\n",
      "[464]\ttraining's binary_logloss: 0.016919\n",
      "[465]\ttraining's binary_logloss: 0.0168214\n",
      "[466]\ttraining's binary_logloss: 0.0167181\n",
      "[467]\ttraining's binary_logloss: 0.0166106\n",
      "[468]\ttraining's binary_logloss: 0.0165146\n",
      "[469]\ttraining's binary_logloss: 0.0164283\n",
      "[470]\ttraining's binary_logloss: 0.0163323\n",
      "[471]\ttraining's binary_logloss: 0.0162305\n",
      "[472]\ttraining's binary_logloss: 0.0161254\n",
      "[473]\ttraining's binary_logloss: 0.0160363\n",
      "[474]\ttraining's binary_logloss: 0.0159446\n",
      "[475]\ttraining's binary_logloss: 0.0158485\n",
      "[476]\ttraining's binary_logloss: 0.0157489\n",
      "[477]\ttraining's binary_logloss: 0.0156541\n",
      "[478]\ttraining's binary_logloss: 0.0155653\n",
      "[479]\ttraining's binary_logloss: 0.0154811\n",
      "[480]\ttraining's binary_logloss: 0.0153959\n",
      "[481]\ttraining's binary_logloss: 0.0153112\n",
      "[482]\ttraining's binary_logloss: 0.0152272\n",
      "[483]\ttraining's binary_logloss: 0.0151343\n",
      "[484]\ttraining's binary_logloss: 0.0150557\n",
      "[485]\ttraining's binary_logloss: 0.0149667\n",
      "[486]\ttraining's binary_logloss: 0.0148802\n",
      "[487]\ttraining's binary_logloss: 0.0148009\n",
      "[488]\ttraining's binary_logloss: 0.0147128\n",
      "[489]\ttraining's binary_logloss: 0.0146279\n",
      "[490]\ttraining's binary_logloss: 0.0145379\n",
      "[491]\ttraining's binary_logloss: 0.0144511\n",
      "[492]\ttraining's binary_logloss: 0.0143639\n",
      "[493]\ttraining's binary_logloss: 0.0142787\n",
      "[494]\ttraining's binary_logloss: 0.0141921\n",
      "[495]\ttraining's binary_logloss: 0.0141061\n",
      "[496]\ttraining's binary_logloss: 0.014032\n",
      "[497]\ttraining's binary_logloss: 0.013948\n",
      "[498]\ttraining's binary_logloss: 0.0138579\n",
      "[499]\ttraining's binary_logloss: 0.0137783\n",
      "[500]\ttraining's binary_logloss: 0.013701\n",
      "[501]\ttraining's binary_logloss: 0.0136247\n",
      "[502]\ttraining's binary_logloss: 0.0135482\n",
      "[503]\ttraining's binary_logloss: 0.0134662\n",
      "[504]\ttraining's binary_logloss: 0.0133923\n",
      "[505]\ttraining's binary_logloss: 0.0133098\n",
      "[506]\ttraining's binary_logloss: 0.0132346\n",
      "[507]\ttraining's binary_logloss: 0.0131601\n",
      "[508]\ttraining's binary_logloss: 0.0130876\n",
      "[509]\ttraining's binary_logloss: 0.0130078\n",
      "[510]\ttraining's binary_logloss: 0.0129212\n",
      "[511]\ttraining's binary_logloss: 0.0128451\n",
      "[512]\ttraining's binary_logloss: 0.0127823\n",
      "[513]\ttraining's binary_logloss: 0.0127098\n",
      "[514]\ttraining's binary_logloss: 0.0126422\n",
      "[515]\ttraining's binary_logloss: 0.0125624\n",
      "[516]\ttraining's binary_logloss: 0.012498\n",
      "[517]\ttraining's binary_logloss: 0.0124255\n",
      "[518]\ttraining's binary_logloss: 0.0123541\n",
      "[519]\ttraining's binary_logloss: 0.0122881\n",
      "[520]\ttraining's binary_logloss: 0.0122141\n",
      "[521]\ttraining's binary_logloss: 0.0121385\n",
      "[522]\ttraining's binary_logloss: 0.0120643\n",
      "[523]\ttraining's binary_logloss: 0.0119972\n",
      "[524]\ttraining's binary_logloss: 0.0119132\n",
      "[525]\ttraining's binary_logloss: 0.0118421\n",
      "[526]\ttraining's binary_logloss: 0.0117773\n",
      "[527]\ttraining's binary_logloss: 0.0117017\n",
      "[528]\ttraining's binary_logloss: 0.0116432\n",
      "[529]\ttraining's binary_logloss: 0.0115745\n",
      "[530]\ttraining's binary_logloss: 0.0114999\n",
      "[531]\ttraining's binary_logloss: 0.0114312\n",
      "[532]\ttraining's binary_logloss: 0.0113631\n",
      "[533]\ttraining's binary_logloss: 0.0112973\n",
      "[534]\ttraining's binary_logloss: 0.0112278\n",
      "[535]\ttraining's binary_logloss: 0.0111613\n",
      "[536]\ttraining's binary_logloss: 0.0110975\n",
      "[537]\ttraining's binary_logloss: 0.0110377\n",
      "[538]\ttraining's binary_logloss: 0.0109763\n",
      "[539]\ttraining's binary_logloss: 0.0109109\n",
      "[540]\ttraining's binary_logloss: 0.0108501\n",
      "[541]\ttraining's binary_logloss: 0.0107803\n",
      "[542]\ttraining's binary_logloss: 0.0107139\n",
      "[543]\ttraining's binary_logloss: 0.010647\n",
      "[544]\ttraining's binary_logloss: 0.010589\n",
      "[545]\ttraining's binary_logloss: 0.0105208\n",
      "[546]\ttraining's binary_logloss: 0.0104521\n",
      "[547]\ttraining's binary_logloss: 0.0103938\n",
      "[548]\ttraining's binary_logloss: 0.0103383\n",
      "[549]\ttraining's binary_logloss: 0.0102751\n",
      "[550]\ttraining's binary_logloss: 0.0102222\n",
      "[551]\ttraining's binary_logloss: 0.0101678\n",
      "[552]\ttraining's binary_logloss: 0.0101126\n",
      "[553]\ttraining's binary_logloss: 0.0100529\n",
      "[554]\ttraining's binary_logloss: 0.00999146\n",
      "[555]\ttraining's binary_logloss: 0.009927\n",
      "[556]\ttraining's binary_logloss: 0.00987454\n",
      "[557]\ttraining's binary_logloss: 0.00980778\n",
      "[558]\ttraining's binary_logloss: 0.00974941\n",
      "[559]\ttraining's binary_logloss: 0.0096946\n",
      "[560]\ttraining's binary_logloss: 0.00963539\n",
      "[561]\ttraining's binary_logloss: 0.00958238\n",
      "[562]\ttraining's binary_logloss: 0.00952897\n",
      "[563]\ttraining's binary_logloss: 0.00946642\n",
      "[564]\ttraining's binary_logloss: 0.00941676\n",
      "[565]\ttraining's binary_logloss: 0.00936244\n",
      "[566]\ttraining's binary_logloss: 0.00930766\n",
      "[567]\ttraining's binary_logloss: 0.0092566\n",
      "[568]\ttraining's binary_logloss: 0.00920034\n",
      "[569]\ttraining's binary_logloss: 0.00914817\n",
      "[570]\ttraining's binary_logloss: 0.00909647\n",
      "[571]\ttraining's binary_logloss: 0.00904497\n",
      "[572]\ttraining's binary_logloss: 0.00899036\n",
      "[573]\ttraining's binary_logloss: 0.00893445\n",
      "[574]\ttraining's binary_logloss: 0.00888529\n",
      "[575]\ttraining's binary_logloss: 0.00883256\n",
      "[576]\ttraining's binary_logloss: 0.00878105\n",
      "[577]\ttraining's binary_logloss: 0.00872781\n",
      "[578]\ttraining's binary_logloss: 0.008673\n",
      "[579]\ttraining's binary_logloss: 0.00862126\n",
      "[580]\ttraining's binary_logloss: 0.0085738\n",
      "[581]\ttraining's binary_logloss: 0.00852869\n",
      "[582]\ttraining's binary_logloss: 0.00847946\n",
      "[583]\ttraining's binary_logloss: 0.00842994\n",
      "[584]\ttraining's binary_logloss: 0.00838155\n",
      "[585]\ttraining's binary_logloss: 0.00833435\n",
      "[586]\ttraining's binary_logloss: 0.00828455\n",
      "[587]\ttraining's binary_logloss: 0.00823458\n",
      "[588]\ttraining's binary_logloss: 0.00819276\n",
      "[589]\ttraining's binary_logloss: 0.00814627\n",
      "[590]\ttraining's binary_logloss: 0.00809446\n",
      "[591]\ttraining's binary_logloss: 0.00805004\n",
      "[592]\ttraining's binary_logloss: 0.00800858\n",
      "[593]\ttraining's binary_logloss: 0.00796729\n",
      "[594]\ttraining's binary_logloss: 0.00792316\n",
      "[595]\ttraining's binary_logloss: 0.00787736\n",
      "[596]\ttraining's binary_logloss: 0.00783677\n",
      "[597]\ttraining's binary_logloss: 0.00779383\n",
      "[598]\ttraining's binary_logloss: 0.00774957\n",
      "[599]\ttraining's binary_logloss: 0.00770904\n",
      "[600]\ttraining's binary_logloss: 0.00766205\n",
      "[601]\ttraining's binary_logloss: 0.00761966\n",
      "[602]\ttraining's binary_logloss: 0.00757434\n",
      "[603]\ttraining's binary_logloss: 0.00753081\n",
      "[604]\ttraining's binary_logloss: 0.00749063\n",
      "[605]\ttraining's binary_logloss: 0.00744799\n",
      "[606]\ttraining's binary_logloss: 0.00740576\n",
      "[607]\ttraining's binary_logloss: 0.00736512\n",
      "[608]\ttraining's binary_logloss: 0.00732295\n",
      "[609]\ttraining's binary_logloss: 0.00727916\n",
      "[610]\ttraining's binary_logloss: 0.00723314\n",
      "[611]\ttraining's binary_logloss: 0.00718936\n",
      "[612]\ttraining's binary_logloss: 0.00715044\n",
      "[613]\ttraining's binary_logloss: 0.00710827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[614]\ttraining's binary_logloss: 0.0070722\n",
      "[615]\ttraining's binary_logloss: 0.00702785\n",
      "[616]\ttraining's binary_logloss: 0.00698927\n",
      "[617]\ttraining's binary_logloss: 0.00695216\n",
      "[618]\ttraining's binary_logloss: 0.00691558\n",
      "[619]\ttraining's binary_logloss: 0.00687379\n",
      "[620]\ttraining's binary_logloss: 0.00682668\n",
      "[621]\ttraining's binary_logloss: 0.00678841\n",
      "[622]\ttraining's binary_logloss: 0.00674601\n",
      "[623]\ttraining's binary_logloss: 0.00670685\n",
      "[624]\ttraining's binary_logloss: 0.00666821\n",
      "[625]\ttraining's binary_logloss: 0.00662948\n",
      "[626]\ttraining's binary_logloss: 0.00658736\n",
      "[627]\ttraining's binary_logloss: 0.00654766\n",
      "[628]\ttraining's binary_logloss: 0.00651091\n",
      "[629]\ttraining's binary_logloss: 0.00646586\n",
      "[630]\ttraining's binary_logloss: 0.00643026\n",
      "[631]\ttraining's binary_logloss: 0.00639167\n",
      "[632]\ttraining's binary_logloss: 0.00635977\n",
      "[633]\ttraining's binary_logloss: 0.00632338\n",
      "[634]\ttraining's binary_logloss: 0.006289\n",
      "[635]\ttraining's binary_logloss: 0.00624829\n",
      "[636]\ttraining's binary_logloss: 0.00621388\n",
      "[637]\ttraining's binary_logloss: 0.00617446\n",
      "[638]\ttraining's binary_logloss: 0.00613752\n",
      "[639]\ttraining's binary_logloss: 0.00610251\n",
      "[640]\ttraining's binary_logloss: 0.006065\n",
      "[641]\ttraining's binary_logloss: 0.00602712\n",
      "[642]\ttraining's binary_logloss: 0.0059915\n",
      "[643]\ttraining's binary_logloss: 0.00595726\n",
      "[644]\ttraining's binary_logloss: 0.00591949\n",
      "[645]\ttraining's binary_logloss: 0.00588647\n",
      "[646]\ttraining's binary_logloss: 0.00585307\n",
      "[647]\ttraining's binary_logloss: 0.00581779\n",
      "[648]\ttraining's binary_logloss: 0.00578524\n",
      "[649]\ttraining's binary_logloss: 0.00574896\n",
      "[650]\ttraining's binary_logloss: 0.00572083\n",
      "[651]\ttraining's binary_logloss: 0.00569021\n",
      "[652]\ttraining's binary_logloss: 0.00565945\n",
      "[653]\ttraining's binary_logloss: 0.00563132\n",
      "[654]\ttraining's binary_logloss: 0.0056024\n",
      "[655]\ttraining's binary_logloss: 0.00556695\n",
      "[656]\ttraining's binary_logloss: 0.00553486\n",
      "[657]\ttraining's binary_logloss: 0.00550343\n",
      "[658]\ttraining's binary_logloss: 0.00546972\n",
      "[659]\ttraining's binary_logloss: 0.00543718\n",
      "[660]\ttraining's binary_logloss: 0.00540601\n",
      "[661]\ttraining's binary_logloss: 0.00537793\n",
      "[662]\ttraining's binary_logloss: 0.0053476\n",
      "[663]\ttraining's binary_logloss: 0.00531492\n",
      "[664]\ttraining's binary_logloss: 0.00528471\n",
      "[665]\ttraining's binary_logloss: 0.00525314\n",
      "[666]\ttraining's binary_logloss: 0.00522674\n",
      "[667]\ttraining's binary_logloss: 0.0051972\n",
      "[668]\ttraining's binary_logloss: 0.00516401\n",
      "[669]\ttraining's binary_logloss: 0.00513296\n",
      "[670]\ttraining's binary_logloss: 0.00510697\n",
      "[671]\ttraining's binary_logloss: 0.0050776\n",
      "[672]\ttraining's binary_logloss: 0.00505066\n",
      "[673]\ttraining's binary_logloss: 0.00502128\n",
      "[674]\ttraining's binary_logloss: 0.00499706\n",
      "[675]\ttraining's binary_logloss: 0.00496812\n",
      "[676]\ttraining's binary_logloss: 0.00493995\n",
      "[677]\ttraining's binary_logloss: 0.00491432\n",
      "[678]\ttraining's binary_logloss: 0.0048899\n",
      "[679]\ttraining's binary_logloss: 0.00485735\n",
      "[680]\ttraining's binary_logloss: 0.00482828\n",
      "[681]\ttraining's binary_logloss: 0.0048011\n",
      "[682]\ttraining's binary_logloss: 0.00477354\n",
      "[683]\ttraining's binary_logloss: 0.00474358\n",
      "[684]\ttraining's binary_logloss: 0.00471343\n",
      "[685]\ttraining's binary_logloss: 0.00468158\n",
      "[686]\ttraining's binary_logloss: 0.00465294\n",
      "[687]\ttraining's binary_logloss: 0.00463019\n",
      "[688]\ttraining's binary_logloss: 0.00460321\n",
      "[689]\ttraining's binary_logloss: 0.00457373\n",
      "[690]\ttraining's binary_logloss: 0.00454522\n",
      "[691]\ttraining's binary_logloss: 0.00451989\n",
      "[692]\ttraining's binary_logloss: 0.0044963\n",
      "[693]\ttraining's binary_logloss: 0.00447151\n",
      "[694]\ttraining's binary_logloss: 0.00444639\n",
      "[695]\ttraining's binary_logloss: 0.00442075\n",
      "[696]\ttraining's binary_logloss: 0.00439422\n",
      "[697]\ttraining's binary_logloss: 0.00436964\n",
      "[698]\ttraining's binary_logloss: 0.00433943\n",
      "[699]\ttraining's binary_logloss: 0.00431357\n",
      "[700]\ttraining's binary_logloss: 0.00428769\n",
      "[701]\ttraining's binary_logloss: 0.00426156\n",
      "[702]\ttraining's binary_logloss: 0.00424027\n",
      "[703]\ttraining's binary_logloss: 0.00421383\n",
      "[704]\ttraining's binary_logloss: 0.00418492\n",
      "[705]\ttraining's binary_logloss: 0.00416101\n",
      "[706]\ttraining's binary_logloss: 0.00413257\n",
      "[707]\ttraining's binary_logloss: 0.0041053\n",
      "[708]\ttraining's binary_logloss: 0.00408233\n",
      "[709]\ttraining's binary_logloss: 0.00406173\n",
      "[710]\ttraining's binary_logloss: 0.00403887\n",
      "[711]\ttraining's binary_logloss: 0.00401585\n",
      "[712]\ttraining's binary_logloss: 0.00399424\n",
      "[713]\ttraining's binary_logloss: 0.00397259\n",
      "[714]\ttraining's binary_logloss: 0.00394757\n",
      "[715]\ttraining's binary_logloss: 0.00392569\n",
      "[716]\ttraining's binary_logloss: 0.00390446\n",
      "[717]\ttraining's binary_logloss: 0.00388496\n",
      "[718]\ttraining's binary_logloss: 0.00386194\n",
      "[719]\ttraining's binary_logloss: 0.00383994\n",
      "[720]\ttraining's binary_logloss: 0.00381862\n",
      "[721]\ttraining's binary_logloss: 0.00379726\n",
      "[722]\ttraining's binary_logloss: 0.00377707\n",
      "[723]\ttraining's binary_logloss: 0.0037588\n",
      "[724]\ttraining's binary_logloss: 0.00374036\n",
      "[725]\ttraining's binary_logloss: 0.0037187\n",
      "[726]\ttraining's binary_logloss: 0.00369495\n",
      "[727]\ttraining's binary_logloss: 0.00367246\n",
      "[728]\ttraining's binary_logloss: 0.00365118\n",
      "[729]\ttraining's binary_logloss: 0.00362959\n",
      "[730]\ttraining's binary_logloss: 0.00361188\n",
      "[731]\ttraining's binary_logloss: 0.0035916\n",
      "[732]\ttraining's binary_logloss: 0.00357153\n",
      "[733]\ttraining's binary_logloss: 0.00355443\n",
      "[734]\ttraining's binary_logloss: 0.00353031\n",
      "[735]\ttraining's binary_logloss: 0.00350751\n",
      "[736]\ttraining's binary_logloss: 0.00348751\n",
      "[737]\ttraining's binary_logloss: 0.00346778\n",
      "[738]\ttraining's binary_logloss: 0.00344677\n",
      "[739]\ttraining's binary_logloss: 0.00342809\n",
      "[740]\ttraining's binary_logloss: 0.00340898\n",
      "[741]\ttraining's binary_logloss: 0.00338721\n",
      "[742]\ttraining's binary_logloss: 0.00336666\n",
      "[743]\ttraining's binary_logloss: 0.0033454\n",
      "[744]\ttraining's binary_logloss: 0.00333081\n",
      "[745]\ttraining's binary_logloss: 0.00331373\n",
      "[746]\ttraining's binary_logloss: 0.00329302\n",
      "[747]\ttraining's binary_logloss: 0.00327731\n",
      "[748]\ttraining's binary_logloss: 0.00325984\n",
      "[749]\ttraining's binary_logloss: 0.00324191\n",
      "[750]\ttraining's binary_logloss: 0.00322422\n",
      "[751]\ttraining's binary_logloss: 0.00320194\n",
      "[752]\ttraining's binary_logloss: 0.00318225\n",
      "[753]\ttraining's binary_logloss: 0.00316585\n",
      "[754]\ttraining's binary_logloss: 0.00314875\n",
      "[755]\ttraining's binary_logloss: 0.00312937\n",
      "[756]\ttraining's binary_logloss: 0.00311197\n",
      "[757]\ttraining's binary_logloss: 0.00309414\n",
      "[758]\ttraining's binary_logloss: 0.00307234\n",
      "[759]\ttraining's binary_logloss: 0.00305508\n",
      "[760]\ttraining's binary_logloss: 0.00303819\n",
      "[761]\ttraining's binary_logloss: 0.00302109\n",
      "[762]\ttraining's binary_logloss: 0.00300518\n",
      "[763]\ttraining's binary_logloss: 0.00298837\n",
      "[764]\ttraining's binary_logloss: 0.00297355\n",
      "[765]\ttraining's binary_logloss: 0.00295782\n",
      "[766]\ttraining's binary_logloss: 0.00294352\n",
      "[767]\ttraining's binary_logloss: 0.00292807\n",
      "[768]\ttraining's binary_logloss: 0.00291375\n",
      "[769]\ttraining's binary_logloss: 0.00289856\n",
      "[770]\ttraining's binary_logloss: 0.00288042\n",
      "[771]\ttraining's binary_logloss: 0.00286553\n",
      "[772]\ttraining's binary_logloss: 0.00284963\n",
      "[773]\ttraining's binary_logloss: 0.0028367\n",
      "[774]\ttraining's binary_logloss: 0.00282212\n",
      "[775]\ttraining's binary_logloss: 0.00280868\n",
      "[776]\ttraining's binary_logloss: 0.00279336\n",
      "[777]\ttraining's binary_logloss: 0.00277736\n",
      "[778]\ttraining's binary_logloss: 0.00276429\n",
      "[779]\ttraining's binary_logloss: 0.00274871\n",
      "[780]\ttraining's binary_logloss: 0.00273378\n",
      "[781]\ttraining's binary_logloss: 0.0027169\n",
      "[782]\ttraining's binary_logloss: 0.00269969\n",
      "[783]\ttraining's binary_logloss: 0.00268635\n",
      "[784]\ttraining's binary_logloss: 0.00267086\n",
      "[785]\ttraining's binary_logloss: 0.00265581\n",
      "[786]\ttraining's binary_logloss: 0.00263793\n",
      "[787]\ttraining's binary_logloss: 0.00262122\n",
      "[788]\ttraining's binary_logloss: 0.0026057\n",
      "[789]\ttraining's binary_logloss: 0.00259292\n",
      "[790]\ttraining's binary_logloss: 0.00257809\n",
      "[791]\ttraining's binary_logloss: 0.00256504\n",
      "[792]\ttraining's binary_logloss: 0.00255023\n",
      "[793]\ttraining's binary_logloss: 0.002536\n",
      "[794]\ttraining's binary_logloss: 0.00252219\n",
      "[795]\ttraining's binary_logloss: 0.00250852\n",
      "[796]\ttraining's binary_logloss: 0.00249427\n",
      "[797]\ttraining's binary_logloss: 0.00247815\n",
      "[798]\ttraining's binary_logloss: 0.00246468\n",
      "[799]\ttraining's binary_logloss: 0.00245232\n",
      "[800]\ttraining's binary_logloss: 0.00243953\n",
      "[801]\ttraining's binary_logloss: 0.00242545\n",
      "[802]\ttraining's binary_logloss: 0.00241318\n",
      "[803]\ttraining's binary_logloss: 0.00240081\n",
      "[804]\ttraining's binary_logloss: 0.00238852\n",
      "[805]\ttraining's binary_logloss: 0.00237445\n",
      "[806]\ttraining's binary_logloss: 0.00236176\n",
      "[807]\ttraining's binary_logloss: 0.00234973\n",
      "[808]\ttraining's binary_logloss: 0.00234002\n",
      "[809]\ttraining's binary_logloss: 0.00232819\n",
      "[810]\ttraining's binary_logloss: 0.00231512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[811]\ttraining's binary_logloss: 0.00230331\n",
      "[812]\ttraining's binary_logloss: 0.00229155\n",
      "[813]\ttraining's binary_logloss: 0.00228093\n",
      "[814]\ttraining's binary_logloss: 0.00226763\n",
      "[815]\ttraining's binary_logloss: 0.00225562\n",
      "[816]\ttraining's binary_logloss: 0.00224411\n",
      "[817]\ttraining's binary_logloss: 0.00223347\n",
      "[818]\ttraining's binary_logloss: 0.00222154\n",
      "[819]\ttraining's binary_logloss: 0.00220878\n",
      "[820]\ttraining's binary_logloss: 0.00220002\n",
      "[821]\ttraining's binary_logloss: 0.00218629\n",
      "[822]\ttraining's binary_logloss: 0.00217443\n",
      "[823]\ttraining's binary_logloss: 0.00216013\n",
      "[824]\ttraining's binary_logloss: 0.0021465\n",
      "[825]\ttraining's binary_logloss: 0.00213531\n",
      "[826]\ttraining's binary_logloss: 0.00212401\n",
      "[827]\ttraining's binary_logloss: 0.00211153\n",
      "[828]\ttraining's binary_logloss: 0.00209901\n",
      "[829]\ttraining's binary_logloss: 0.00208591\n",
      "[830]\ttraining's binary_logloss: 0.00207619\n",
      "[831]\ttraining's binary_logloss: 0.00206427\n",
      "[832]\ttraining's binary_logloss: 0.0020509\n",
      "[833]\ttraining's binary_logloss: 0.00204136\n",
      "[834]\ttraining's binary_logloss: 0.00203111\n",
      "[835]\ttraining's binary_logloss: 0.00202036\n",
      "[836]\ttraining's binary_logloss: 0.00201218\n",
      "[837]\ttraining's binary_logloss: 0.0019975\n",
      "[838]\ttraining's binary_logloss: 0.00198451\n",
      "[839]\ttraining's binary_logloss: 0.00197551\n",
      "[840]\ttraining's binary_logloss: 0.00196449\n",
      "[841]\ttraining's binary_logloss: 0.00195021\n",
      "[842]\ttraining's binary_logloss: 0.00193631\n",
      "[843]\ttraining's binary_logloss: 0.00192548\n",
      "[844]\ttraining's binary_logloss: 0.00191639\n",
      "[845]\ttraining's binary_logloss: 0.0019056\n",
      "[846]\ttraining's binary_logloss: 0.00189617\n",
      "[847]\ttraining's binary_logloss: 0.00188542\n",
      "[848]\ttraining's binary_logloss: 0.00187332\n",
      "[849]\ttraining's binary_logloss: 0.00186178\n",
      "[850]\ttraining's binary_logloss: 0.00185359\n",
      "[851]\ttraining's binary_logloss: 0.00184492\n",
      "[852]\ttraining's binary_logloss: 0.0018347\n",
      "[853]\ttraining's binary_logloss: 0.00182537\n",
      "[854]\ttraining's binary_logloss: 0.0018159\n",
      "[855]\ttraining's binary_logloss: 0.00180458\n",
      "[856]\ttraining's binary_logloss: 0.0017922\n",
      "[857]\ttraining's binary_logloss: 0.00178188\n",
      "[858]\ttraining's binary_logloss: 0.00177051\n",
      "[859]\ttraining's binary_logloss: 0.00176212\n",
      "[860]\ttraining's binary_logloss: 0.00175356\n",
      "[861]\ttraining's binary_logloss: 0.00174304\n",
      "[862]\ttraining's binary_logloss: 0.0017328\n",
      "[863]\ttraining's binary_logloss: 0.00172397\n",
      "[864]\ttraining's binary_logloss: 0.00171552\n",
      "[865]\ttraining's binary_logloss: 0.00170704\n",
      "[866]\ttraining's binary_logloss: 0.00169842\n",
      "[867]\ttraining's binary_logloss: 0.00168928\n",
      "[868]\ttraining's binary_logloss: 0.0016813\n",
      "[869]\ttraining's binary_logloss: 0.00167139\n",
      "[870]\ttraining's binary_logloss: 0.00166202\n",
      "[871]\ttraining's binary_logloss: 0.00165268\n",
      "[872]\ttraining's binary_logloss: 0.00164033\n",
      "[873]\ttraining's binary_logloss: 0.00163254\n",
      "[874]\ttraining's binary_logloss: 0.00162488\n",
      "[875]\ttraining's binary_logloss: 0.00161404\n",
      "[876]\ttraining's binary_logloss: 0.00160435\n",
      "[877]\ttraining's binary_logloss: 0.00159412\n",
      "[878]\ttraining's binary_logloss: 0.00158451\n",
      "[879]\ttraining's binary_logloss: 0.00157606\n",
      "[880]\ttraining's binary_logloss: 0.00156908\n",
      "[881]\ttraining's binary_logloss: 0.00156128\n",
      "[882]\ttraining's binary_logloss: 0.00155454\n",
      "[883]\ttraining's binary_logloss: 0.00154678\n",
      "[884]\ttraining's binary_logloss: 0.00153661\n",
      "[885]\ttraining's binary_logloss: 0.00152776\n",
      "[886]\ttraining's binary_logloss: 0.00151712\n",
      "[887]\ttraining's binary_logloss: 0.0015061\n",
      "[888]\ttraining's binary_logloss: 0.00149663\n",
      "[889]\ttraining's binary_logloss: 0.00148829\n",
      "[890]\ttraining's binary_logloss: 0.00148056\n",
      "[891]\ttraining's binary_logloss: 0.00147183\n",
      "[892]\ttraining's binary_logloss: 0.00146369\n",
      "[893]\ttraining's binary_logloss: 0.00145574\n",
      "[894]\ttraining's binary_logloss: 0.00144715\n",
      "[895]\ttraining's binary_logloss: 0.00143877\n",
      "[896]\ttraining's binary_logloss: 0.00142917\n",
      "[897]\ttraining's binary_logloss: 0.00141987\n",
      "[898]\ttraining's binary_logloss: 0.00141047\n",
      "[899]\ttraining's binary_logloss: 0.00140274\n",
      "[900]\ttraining's binary_logloss: 0.00139567\n",
      "[901]\ttraining's binary_logloss: 0.0013876\n",
      "[902]\ttraining's binary_logloss: 0.00137885\n",
      "[903]\ttraining's binary_logloss: 0.00137265\n",
      "[904]\ttraining's binary_logloss: 0.00136437\n",
      "[905]\ttraining's binary_logloss: 0.00135742\n",
      "[906]\ttraining's binary_logloss: 0.00135092\n",
      "[907]\ttraining's binary_logloss: 0.00134215\n",
      "[908]\ttraining's binary_logloss: 0.00133164\n",
      "[909]\ttraining's binary_logloss: 0.00132311\n",
      "[910]\ttraining's binary_logloss: 0.00131521\n",
      "[911]\ttraining's binary_logloss: 0.00130633\n",
      "[912]\ttraining's binary_logloss: 0.00129833\n",
      "[913]\ttraining's binary_logloss: 0.00128926\n",
      "[914]\ttraining's binary_logloss: 0.00128122\n",
      "[915]\ttraining's binary_logloss: 0.0012731\n",
      "[916]\ttraining's binary_logloss: 0.00126489\n",
      "[917]\ttraining's binary_logloss: 0.00125757\n",
      "[918]\ttraining's binary_logloss: 0.00125013\n",
      "[919]\ttraining's binary_logloss: 0.00124511\n",
      "[920]\ttraining's binary_logloss: 0.0012393\n",
      "[921]\ttraining's binary_logloss: 0.0012312\n",
      "[922]\ttraining's binary_logloss: 0.00122317\n",
      "[923]\ttraining's binary_logloss: 0.00121487\n",
      "[924]\ttraining's binary_logloss: 0.00120599\n",
      "[925]\ttraining's binary_logloss: 0.00119944\n",
      "[926]\ttraining's binary_logloss: 0.00119269\n",
      "[927]\ttraining's binary_logloss: 0.00118562\n",
      "[928]\ttraining's binary_logloss: 0.00117857\n",
      "[929]\ttraining's binary_logloss: 0.0011734\n",
      "[930]\ttraining's binary_logloss: 0.00116732\n",
      "[931]\ttraining's binary_logloss: 0.00116171\n",
      "[932]\ttraining's binary_logloss: 0.00115465\n",
      "[933]\ttraining's binary_logloss: 0.0011483\n",
      "[934]\ttraining's binary_logloss: 0.00114213\n",
      "[935]\ttraining's binary_logloss: 0.00113549\n",
      "[936]\ttraining's binary_logloss: 0.00112923\n",
      "[937]\ttraining's binary_logloss: 0.00112386\n",
      "[938]\ttraining's binary_logloss: 0.0011184\n",
      "[939]\ttraining's binary_logloss: 0.00111274\n",
      "[940]\ttraining's binary_logloss: 0.00110734\n",
      "[941]\ttraining's binary_logloss: 0.00110089\n",
      "[942]\ttraining's binary_logloss: 0.00109451\n",
      "[943]\ttraining's binary_logloss: 0.00108791\n",
      "[944]\ttraining's binary_logloss: 0.00108052\n",
      "[945]\ttraining's binary_logloss: 0.0010746\n",
      "[946]\ttraining's binary_logloss: 0.00106759\n",
      "[947]\ttraining's binary_logloss: 0.0010605\n",
      "[948]\ttraining's binary_logloss: 0.00105475\n",
      "[949]\ttraining's binary_logloss: 0.00104869\n",
      "[950]\ttraining's binary_logloss: 0.00104218\n",
      "[951]\ttraining's binary_logloss: 0.00103796\n",
      "[952]\ttraining's binary_logloss: 0.00103264\n",
      "[953]\ttraining's binary_logloss: 0.00102667\n",
      "[954]\ttraining's binary_logloss: 0.0010209\n",
      "[955]\ttraining's binary_logloss: 0.00101409\n",
      "[956]\ttraining's binary_logloss: 0.00100816\n",
      "[957]\ttraining's binary_logloss: 0.00100469\n",
      "[958]\ttraining's binary_logloss: 0.000997466\n",
      "[959]\ttraining's binary_logloss: 0.000992564\n",
      "[960]\ttraining's binary_logloss: 0.000987447\n",
      "[961]\ttraining's binary_logloss: 0.000983214\n",
      "[962]\ttraining's binary_logloss: 0.000978631\n",
      "[963]\ttraining's binary_logloss: 0.000972832\n",
      "[964]\ttraining's binary_logloss: 0.000967641\n",
      "[965]\ttraining's binary_logloss: 0.00096214\n",
      "[966]\ttraining's binary_logloss: 0.000956618\n",
      "[967]\ttraining's binary_logloss: 0.000951535\n",
      "[968]\ttraining's binary_logloss: 0.00094671\n",
      "[969]\ttraining's binary_logloss: 0.000941483\n",
      "[970]\ttraining's binary_logloss: 0.00093547\n",
      "[971]\ttraining's binary_logloss: 0.000930535\n",
      "[972]\ttraining's binary_logloss: 0.000926011\n",
      "[973]\ttraining's binary_logloss: 0.000920036\n",
      "[974]\ttraining's binary_logloss: 0.000915737\n",
      "[975]\ttraining's binary_logloss: 0.00091124\n",
      "[976]\ttraining's binary_logloss: 0.000905248\n",
      "[977]\ttraining's binary_logloss: 0.000900372\n",
      "[978]\ttraining's binary_logloss: 0.000895659\n",
      "[979]\ttraining's binary_logloss: 0.000890205\n",
      "[980]\ttraining's binary_logloss: 0.000886241\n",
      "[981]\ttraining's binary_logloss: 0.000880659\n",
      "[982]\ttraining's binary_logloss: 0.000875348\n",
      "[983]\ttraining's binary_logloss: 0.000870282\n",
      "[984]\ttraining's binary_logloss: 0.000865637\n",
      "[985]\ttraining's binary_logloss: 0.00086061\n",
      "[986]\ttraining's binary_logloss: 0.000855865\n",
      "[987]\ttraining's binary_logloss: 0.000851456\n",
      "[988]\ttraining's binary_logloss: 0.000845181\n",
      "[989]\ttraining's binary_logloss: 0.000839286\n",
      "[990]\ttraining's binary_logloss: 0.000833259\n",
      "[991]\ttraining's binary_logloss: 0.00082905\n",
      "[992]\ttraining's binary_logloss: 0.000824611\n",
      "[993]\ttraining's binary_logloss: 0.000819727\n",
      "[994]\ttraining's binary_logloss: 0.000814913\n",
      "[995]\ttraining's binary_logloss: 0.000810952\n",
      "[996]\ttraining's binary_logloss: 0.000807239\n",
      "[997]\ttraining's binary_logloss: 0.000802307\n",
      "[998]\ttraining's binary_logloss: 0.000797822\n",
      "[999]\ttraining's binary_logloss: 0.000793411\n",
      "[1000]\ttraining's binary_logloss: 0.000788338\n",
      "[1001]\ttraining's binary_logloss: 0.000784658\n",
      "[1002]\ttraining's binary_logloss: 0.000779725\n",
      "[1003]\ttraining's binary_logloss: 0.000775283\n",
      "[1004]\ttraining's binary_logloss: 0.000771\n",
      "[1005]\ttraining's binary_logloss: 0.000767439\n",
      "[1006]\ttraining's binary_logloss: 0.000764042\n",
      "[1007]\ttraining's binary_logloss: 0.000760351\n",
      "[1008]\ttraining's binary_logloss: 0.000757454\n",
      "[1009]\ttraining's binary_logloss: 0.000752797\n",
      "[1010]\ttraining's binary_logloss: 0.000748976\n",
      "[1011]\ttraining's binary_logloss: 0.000745499\n",
      "[1012]\ttraining's binary_logloss: 0.000741494\n",
      "[1013]\ttraining's binary_logloss: 0.000737245\n",
      "[1014]\ttraining's binary_logloss: 0.000734288\n",
      "[1015]\ttraining's binary_logloss: 0.000730271\n",
      "[1016]\ttraining's binary_logloss: 0.000726419\n",
      "[1017]\ttraining's binary_logloss: 0.000721638\n",
      "[1018]\ttraining's binary_logloss: 0.00071757\n",
      "[1019]\ttraining's binary_logloss: 0.000714396\n",
      "[1020]\ttraining's binary_logloss: 0.000709633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1021]\ttraining's binary_logloss: 0.000704837\n",
      "[1022]\ttraining's binary_logloss: 0.000700978\n",
      "[1023]\ttraining's binary_logloss: 0.000697095\n",
      "[1024]\ttraining's binary_logloss: 0.000693944\n",
      "[1025]\ttraining's binary_logloss: 0.000689583\n",
      "[1026]\ttraining's binary_logloss: 0.000686081\n",
      "[1027]\ttraining's binary_logloss: 0.000682515\n",
      "[1028]\ttraining's binary_logloss: 0.000679164\n",
      "[1029]\ttraining's binary_logloss: 0.000674972\n",
      "[1030]\ttraining's binary_logloss: 0.000671144\n",
      "[1031]\ttraining's binary_logloss: 0.000668002\n",
      "[1032]\ttraining's binary_logloss: 0.000664017\n",
      "[1033]\ttraining's binary_logloss: 0.000661339\n",
      "[1034]\ttraining's binary_logloss: 0.000657808\n",
      "[1035]\ttraining's binary_logloss: 0.000654455\n",
      "[1036]\ttraining's binary_logloss: 0.000651213\n",
      "[1037]\ttraining's binary_logloss: 0.000646696\n",
      "[1038]\ttraining's binary_logloss: 0.000642739\n",
      "[1039]\ttraining's binary_logloss: 0.000639192\n",
      "[1040]\ttraining's binary_logloss: 0.000635799\n",
      "[1041]\ttraining's binary_logloss: 0.000632057\n",
      "[1042]\ttraining's binary_logloss: 0.000628701\n",
      "[1043]\ttraining's binary_logloss: 0.00062521\n",
      "[1044]\ttraining's binary_logloss: 0.000622593\n",
      "[1045]\ttraining's binary_logloss: 0.00061926\n",
      "[1046]\ttraining's binary_logloss: 0.000615774\n",
      "[1047]\ttraining's binary_logloss: 0.000611875\n",
      "[1048]\ttraining's binary_logloss: 0.000607498\n",
      "[1049]\ttraining's binary_logloss: 0.000604212\n",
      "[1050]\ttraining's binary_logloss: 0.000600332\n",
      "[1051]\ttraining's binary_logloss: 0.000597385\n",
      "[1052]\ttraining's binary_logloss: 0.000594129\n",
      "[1053]\ttraining's binary_logloss: 0.000590791\n",
      "[1054]\ttraining's binary_logloss: 0.000587717\n",
      "[1055]\ttraining's binary_logloss: 0.000585054\n",
      "[1056]\ttraining's binary_logloss: 0.000581468\n",
      "[1057]\ttraining's binary_logloss: 0.000579008\n",
      "[1058]\ttraining's binary_logloss: 0.000575414\n",
      "[1059]\ttraining's binary_logloss: 0.000572867\n",
      "[1060]\ttraining's binary_logloss: 0.000569394\n",
      "[1061]\ttraining's binary_logloss: 0.000566137\n",
      "[1062]\ttraining's binary_logloss: 0.000563233\n",
      "[1063]\ttraining's binary_logloss: 0.000558995\n",
      "[1064]\ttraining's binary_logloss: 0.000555249\n",
      "[1065]\ttraining's binary_logloss: 0.000551651\n",
      "[1066]\ttraining's binary_logloss: 0.000549041\n",
      "[1067]\ttraining's binary_logloss: 0.000545027\n",
      "[1068]\ttraining's binary_logloss: 0.000541964\n",
      "[1069]\ttraining's binary_logloss: 0.000538458\n",
      "[1070]\ttraining's binary_logloss: 0.000536032\n",
      "[1071]\ttraining's binary_logloss: 0.00053275\n",
      "[1072]\ttraining's binary_logloss: 0.000528931\n",
      "[1073]\ttraining's binary_logloss: 0.000525629\n",
      "[1074]\ttraining's binary_logloss: 0.000522725\n",
      "[1075]\ttraining's binary_logloss: 0.00051927\n",
      "[1076]\ttraining's binary_logloss: 0.000515087\n",
      "[1077]\ttraining's binary_logloss: 0.000511715\n",
      "[1078]\ttraining's binary_logloss: 0.000508489\n",
      "[1079]\ttraining's binary_logloss: 0.000504803\n",
      "[1080]\ttraining's binary_logloss: 0.000501867\n",
      "[1081]\ttraining's binary_logloss: 0.00049958\n",
      "[1082]\ttraining's binary_logloss: 0.000496794\n",
      "[1083]\ttraining's binary_logloss: 0.000493564\n",
      "[1084]\ttraining's binary_logloss: 0.000490744\n",
      "[1085]\ttraining's binary_logloss: 0.000488271\n",
      "[1086]\ttraining's binary_logloss: 0.000485795\n",
      "[1087]\ttraining's binary_logloss: 0.000482491\n",
      "[1088]\ttraining's binary_logloss: 0.000480022\n",
      "[1089]\ttraining's binary_logloss: 0.000477028\n",
      "[1090]\ttraining's binary_logloss: 0.000473957\n",
      "[1091]\ttraining's binary_logloss: 0.000471272\n",
      "[1092]\ttraining's binary_logloss: 0.000468863\n",
      "[1093]\ttraining's binary_logloss: 0.000466785\n",
      "[1094]\ttraining's binary_logloss: 0.000464574\n",
      "[1095]\ttraining's binary_logloss: 0.000461308\n",
      "[1096]\ttraining's binary_logloss: 0.000457999\n",
      "[1097]\ttraining's binary_logloss: 0.000455606\n",
      "[1098]\ttraining's binary_logloss: 0.000452763\n",
      "[1099]\ttraining's binary_logloss: 0.000450298\n",
      "[1100]\ttraining's binary_logloss: 0.000447805\n",
      "[1101]\ttraining's binary_logloss: 0.000445748\n",
      "[1102]\ttraining's binary_logloss: 0.000442689\n",
      "[1103]\ttraining's binary_logloss: 0.000439777\n",
      "[1104]\ttraining's binary_logloss: 0.00043684\n",
      "[1105]\ttraining's binary_logloss: 0.000434796\n",
      "[1106]\ttraining's binary_logloss: 0.000432787\n",
      "[1107]\ttraining's binary_logloss: 0.000431061\n",
      "[1108]\ttraining's binary_logloss: 0.000428521\n",
      "[1109]\ttraining's binary_logloss: 0.000425781\n",
      "[1110]\ttraining's binary_logloss: 0.000422858\n",
      "[1111]\ttraining's binary_logloss: 0.000420279\n",
      "[1112]\ttraining's binary_logloss: 0.000417375\n",
      "[1113]\ttraining's binary_logloss: 0.000414561\n",
      "[1114]\ttraining's binary_logloss: 0.000411833\n",
      "[1115]\ttraining's binary_logloss: 0.000408889\n",
      "[1116]\ttraining's binary_logloss: 0.000406511\n",
      "[1117]\ttraining's binary_logloss: 0.00040388\n",
      "[1118]\ttraining's binary_logloss: 0.000401577\n",
      "[1119]\ttraining's binary_logloss: 0.000398547\n",
      "[1120]\ttraining's binary_logloss: 0.000395851\n",
      "[1121]\ttraining's binary_logloss: 0.000394183\n",
      "[1122]\ttraining's binary_logloss: 0.00039193\n",
      "[1123]\ttraining's binary_logloss: 0.000389872\n",
      "[1124]\ttraining's binary_logloss: 0.000387946\n",
      "[1125]\ttraining's binary_logloss: 0.000385388\n",
      "[1126]\ttraining's binary_logloss: 0.000382873\n",
      "[1127]\ttraining's binary_logloss: 0.000380748\n",
      "[1128]\ttraining's binary_logloss: 0.000378573\n",
      "[1129]\ttraining's binary_logloss: 0.000376815\n",
      "[1130]\ttraining's binary_logloss: 0.000374771\n",
      "[1131]\ttraining's binary_logloss: 0.000372733\n",
      "[1132]\ttraining's binary_logloss: 0.000370978\n",
      "[1133]\ttraining's binary_logloss: 0.000368075\n",
      "[1134]\ttraining's binary_logloss: 0.000365612\n",
      "[1135]\ttraining's binary_logloss: 0.000363785\n",
      "[1136]\ttraining's binary_logloss: 0.000362115\n",
      "[1137]\ttraining's binary_logloss: 0.00036053\n",
      "[1138]\ttraining's binary_logloss: 0.000358827\n",
      "[1139]\ttraining's binary_logloss: 0.000356645\n",
      "[1140]\ttraining's binary_logloss: 0.000354224\n",
      "[1141]\ttraining's binary_logloss: 0.000352335\n",
      "[1142]\ttraining's binary_logloss: 0.000350119\n",
      "[1143]\ttraining's binary_logloss: 0.000347749\n",
      "[1144]\ttraining's binary_logloss: 0.000345406\n",
      "[1145]\ttraining's binary_logloss: 0.000343768\n",
      "[1146]\ttraining's binary_logloss: 0.00034249\n",
      "[1147]\ttraining's binary_logloss: 0.000340034\n",
      "[1148]\ttraining's binary_logloss: 0.00033788\n",
      "[1149]\ttraining's binary_logloss: 0.000335775\n",
      "[1150]\ttraining's binary_logloss: 0.000333687\n",
      "[1151]\ttraining's binary_logloss: 0.000331213\n",
      "[1152]\ttraining's binary_logloss: 0.000329093\n",
      "[1153]\ttraining's binary_logloss: 0.000326915\n",
      "[1154]\ttraining's binary_logloss: 0.000324726\n",
      "[1155]\ttraining's binary_logloss: 0.000323107\n",
      "[1156]\ttraining's binary_logloss: 0.000321283\n",
      "[1157]\ttraining's binary_logloss: 0.000319029\n",
      "[1158]\ttraining's binary_logloss: 0.000317193\n",
      "[1159]\ttraining's binary_logloss: 0.000315182\n",
      "[1160]\ttraining's binary_logloss: 0.000312972\n",
      "[1161]\ttraining's binary_logloss: 0.000311232\n",
      "[1162]\ttraining's binary_logloss: 0.000309781\n",
      "[1163]\ttraining's binary_logloss: 0.000307965\n",
      "[1164]\ttraining's binary_logloss: 0.000306239\n",
      "[1165]\ttraining's binary_logloss: 0.000304118\n",
      "[1166]\ttraining's binary_logloss: 0.000302286\n",
      "[1167]\ttraining's binary_logloss: 0.000300974\n",
      "[1168]\ttraining's binary_logloss: 0.000299186\n",
      "[1169]\ttraining's binary_logloss: 0.000297569\n",
      "[1170]\ttraining's binary_logloss: 0.000295934\n",
      "[1171]\ttraining's binary_logloss: 0.000294554\n",
      "[1172]\ttraining's binary_logloss: 0.000292798\n",
      "[1173]\ttraining's binary_logloss: 0.000291605\n",
      "[1174]\ttraining's binary_logloss: 0.000290038\n",
      "[1175]\ttraining's binary_logloss: 0.000288364\n",
      "[1176]\ttraining's binary_logloss: 0.000286513\n",
      "[1177]\ttraining's binary_logloss: 0.000284693\n",
      "[1178]\ttraining's binary_logloss: 0.00028313\n",
      "[1179]\ttraining's binary_logloss: 0.000281353\n",
      "[1180]\ttraining's binary_logloss: 0.000279799\n",
      "[1181]\ttraining's binary_logloss: 0.000278549\n",
      "[1182]\ttraining's binary_logloss: 0.00027654\n",
      "[1183]\ttraining's binary_logloss: 0.000275251\n",
      "[1184]\ttraining's binary_logloss: 0.000274092\n",
      "[1185]\ttraining's binary_logloss: 0.000273027\n",
      "[1186]\ttraining's binary_logloss: 0.000271393\n",
      "[1187]\ttraining's binary_logloss: 0.000269674\n",
      "[1188]\ttraining's binary_logloss: 0.00026797\n",
      "[1189]\ttraining's binary_logloss: 0.000266494\n",
      "[1190]\ttraining's binary_logloss: 0.000265228\n",
      "[1191]\ttraining's binary_logloss: 0.000263374\n",
      "[1192]\ttraining's binary_logloss: 0.000261751\n",
      "[1193]\ttraining's binary_logloss: 0.000260359\n",
      "[1194]\ttraining's binary_logloss: 0.000259078\n",
      "[1195]\ttraining's binary_logloss: 0.000257172\n",
      "[1196]\ttraining's binary_logloss: 0.000255588\n",
      "[1197]\ttraining's binary_logloss: 0.000254432\n",
      "[1198]\ttraining's binary_logloss: 0.000253085\n",
      "[1199]\ttraining's binary_logloss: 0.000251741\n",
      "[1200]\ttraining's binary_logloss: 0.000250702\n",
      "[1201]\ttraining's binary_logloss: 0.000249452\n",
      "[1202]\ttraining's binary_logloss: 0.000247776\n",
      "[1203]\ttraining's binary_logloss: 0.000246271\n",
      "[1204]\ttraining's binary_logloss: 0.000244793\n",
      "[1205]\ttraining's binary_logloss: 0.000243108\n",
      "[1206]\ttraining's binary_logloss: 0.000241451\n",
      "[1207]\ttraining's binary_logloss: 0.000240361\n",
      "[1208]\ttraining's binary_logloss: 0.00023902\n",
      "[1209]\ttraining's binary_logloss: 0.000237547\n",
      "[1210]\ttraining's binary_logloss: 0.000235952\n",
      "[1211]\ttraining's binary_logloss: 0.000234753\n",
      "[1212]\ttraining's binary_logloss: 0.000233571\n",
      "[1213]\ttraining's binary_logloss: 0.00023222\n",
      "[1214]\ttraining's binary_logloss: 0.000230985\n",
      "[1215]\ttraining's binary_logloss: 0.000229626\n",
      "[1216]\ttraining's binary_logloss: 0.000227835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1217]\ttraining's binary_logloss: 0.000226349\n",
      "[1218]\ttraining's binary_logloss: 0.000224876\n",
      "[1219]\ttraining's binary_logloss: 0.000223841\n",
      "[1220]\ttraining's binary_logloss: 0.000222698\n",
      "[1221]\ttraining's binary_logloss: 0.000221445\n",
      "[1222]\ttraining's binary_logloss: 0.000220322\n",
      "[1223]\ttraining's binary_logloss: 0.000219257\n",
      "[1224]\ttraining's binary_logloss: 0.000217975\n",
      "[1225]\ttraining's binary_logloss: 0.000216707\n",
      "[1226]\ttraining's binary_logloss: 0.000215453\n",
      "[1227]\ttraining's binary_logloss: 0.00021417\n",
      "[1228]\ttraining's binary_logloss: 0.000213147\n",
      "[1229]\ttraining's binary_logloss: 0.00021215\n",
      "[1230]\ttraining's binary_logloss: 0.000211007\n",
      "[1231]\ttraining's binary_logloss: 0.000209548\n",
      "[1232]\ttraining's binary_logloss: 0.000208191\n",
      "[1233]\ttraining's binary_logloss: 0.000206903\n",
      "[1234]\ttraining's binary_logloss: 0.000205691\n",
      "[1235]\ttraining's binary_logloss: 0.000204331\n",
      "[1236]\ttraining's binary_logloss: 0.000203209\n",
      "[1237]\ttraining's binary_logloss: 0.000202052\n",
      "[1238]\ttraining's binary_logloss: 0.000200773\n",
      "[1239]\ttraining's binary_logloss: 0.000199558\n",
      "[1240]\ttraining's binary_logloss: 0.000198258\n",
      "[1241]\ttraining's binary_logloss: 0.000197046\n",
      "[1242]\ttraining's binary_logloss: 0.000195972\n",
      "[1243]\ttraining's binary_logloss: 0.000194667\n",
      "[1244]\ttraining's binary_logloss: 0.000193462\n",
      "[1245]\ttraining's binary_logloss: 0.000192191\n",
      "[1246]\ttraining's binary_logloss: 0.000190936\n",
      "[1247]\ttraining's binary_logloss: 0.00018962\n",
      "[1248]\ttraining's binary_logloss: 0.000188447\n",
      "[1249]\ttraining's binary_logloss: 0.000187214\n",
      "[1250]\ttraining's binary_logloss: 0.000186201\n",
      "[1251]\ttraining's binary_logloss: 0.000185159\n",
      "[1252]\ttraining's binary_logloss: 0.000184117\n",
      "[1253]\ttraining's binary_logloss: 0.000183135\n",
      "[1254]\ttraining's binary_logloss: 0.000182041\n",
      "[1255]\ttraining's binary_logloss: 0.000180748\n",
      "[1256]\ttraining's binary_logloss: 0.000179792\n",
      "[1257]\ttraining's binary_logloss: 0.000178699\n",
      "[1258]\ttraining's binary_logloss: 0.00017747\n",
      "[1259]\ttraining's binary_logloss: 0.000176505\n",
      "[1260]\ttraining's binary_logloss: 0.000175539\n",
      "[1261]\ttraining's binary_logloss: 0.000174543\n",
      "[1262]\ttraining's binary_logloss: 0.000173708\n",
      "[1263]\ttraining's binary_logloss: 0.000172697\n",
      "[1264]\ttraining's binary_logloss: 0.000171662\n",
      "[1265]\ttraining's binary_logloss: 0.000170704\n",
      "[1266]\ttraining's binary_logloss: 0.000169805\n",
      "[1267]\ttraining's binary_logloss: 0.000168812\n",
      "[1268]\ttraining's binary_logloss: 0.00016787\n",
      "[1269]\ttraining's binary_logloss: 0.000167025\n",
      "[1270]\ttraining's binary_logloss: 0.000166091\n",
      "[1271]\ttraining's binary_logloss: 0.000165123\n",
      "[1272]\ttraining's binary_logloss: 0.000163965\n",
      "[1273]\ttraining's binary_logloss: 0.00016302\n",
      "[1274]\ttraining's binary_logloss: 0.000162168\n",
      "[1275]\ttraining's binary_logloss: 0.000161252\n",
      "[1276]\ttraining's binary_logloss: 0.000160242\n",
      "[1277]\ttraining's binary_logloss: 0.000159389\n",
      "[1278]\ttraining's binary_logloss: 0.000158417\n",
      "[1279]\ttraining's binary_logloss: 0.000157401\n",
      "[1280]\ttraining's binary_logloss: 0.000156459\n",
      "[1281]\ttraining's binary_logloss: 0.000155611\n",
      "[1282]\ttraining's binary_logloss: 0.000154806\n",
      "[1283]\ttraining's binary_logloss: 0.000153936\n",
      "[1284]\ttraining's binary_logloss: 0.000152979\n",
      "[1285]\ttraining's binary_logloss: 0.000152183\n",
      "[1286]\ttraining's binary_logloss: 0.000151565\n",
      "[1287]\ttraining's binary_logloss: 0.000150874\n",
      "[1288]\ttraining's binary_logloss: 0.000150019\n",
      "[1289]\ttraining's binary_logloss: 0.000149206\n",
      "[1290]\ttraining's binary_logloss: 0.000148222\n",
      "[1291]\ttraining's binary_logloss: 0.000147387\n",
      "[1292]\ttraining's binary_logloss: 0.000146529\n",
      "[1293]\ttraining's binary_logloss: 0.000145734\n",
      "[1294]\ttraining's binary_logloss: 0.000144818\n",
      "[1295]\ttraining's binary_logloss: 0.000143946\n",
      "[1296]\ttraining's binary_logloss: 0.000142982\n",
      "[1297]\ttraining's binary_logloss: 0.000142133\n",
      "[1298]\ttraining's binary_logloss: 0.000141346\n",
      "[1299]\ttraining's binary_logloss: 0.000140519\n",
      "[1300]\ttraining's binary_logloss: 0.000139746\n",
      "[1301]\ttraining's binary_logloss: 0.000138882\n",
      "[1302]\ttraining's binary_logloss: 0.000138139\n",
      "[1303]\ttraining's binary_logloss: 0.000137321\n",
      "[1304]\ttraining's binary_logloss: 0.000136598\n",
      "[1305]\ttraining's binary_logloss: 0.000135744\n",
      "[1306]\ttraining's binary_logloss: 0.000134938\n",
      "[1307]\ttraining's binary_logloss: 0.000134309\n",
      "[1308]\ttraining's binary_logloss: 0.00013373\n",
      "[1309]\ttraining's binary_logloss: 0.000132947\n",
      "[1310]\ttraining's binary_logloss: 0.000132246\n",
      "[1311]\ttraining's binary_logloss: 0.00013154\n",
      "[1312]\ttraining's binary_logloss: 0.00013095\n",
      "[1313]\ttraining's binary_logloss: 0.000130386\n",
      "[1314]\ttraining's binary_logloss: 0.000129792\n",
      "[1315]\ttraining's binary_logloss: 0.000129087\n",
      "[1316]\ttraining's binary_logloss: 0.000128338\n",
      "[1317]\ttraining's binary_logloss: 0.000127521\n",
      "[1318]\ttraining's binary_logloss: 0.000126762\n",
      "[1319]\ttraining's binary_logloss: 0.000126061\n",
      "[1320]\ttraining's binary_logloss: 0.000125416\n",
      "[1321]\ttraining's binary_logloss: 0.000124756\n",
      "[1322]\ttraining's binary_logloss: 0.000124053\n",
      "[1323]\ttraining's binary_logloss: 0.000123383\n",
      "[1324]\ttraining's binary_logloss: 0.000122676\n",
      "[1325]\ttraining's binary_logloss: 0.000122001\n",
      "[1326]\ttraining's binary_logloss: 0.0001214\n",
      "[1327]\ttraining's binary_logloss: 0.000120755\n",
      "[1328]\ttraining's binary_logloss: 0.000119987\n",
      "[1329]\ttraining's binary_logloss: 0.000119279\n",
      "[1330]\ttraining's binary_logloss: 0.000118625\n",
      "[1331]\ttraining's binary_logloss: 0.000117936\n",
      "[1332]\ttraining's binary_logloss: 0.00011718\n",
      "[1333]\ttraining's binary_logloss: 0.000116551\n",
      "[1334]\ttraining's binary_logloss: 0.000115848\n",
      "[1335]\ttraining's binary_logloss: 0.000115214\n",
      "[1336]\ttraining's binary_logloss: 0.000114519\n",
      "[1337]\ttraining's binary_logloss: 0.000113879\n",
      "[1338]\ttraining's binary_logloss: 0.000113105\n",
      "[1339]\ttraining's binary_logloss: 0.000112526\n",
      "[1340]\ttraining's binary_logloss: 0.000111938\n",
      "[1341]\ttraining's binary_logloss: 0.000111363\n",
      "[1342]\ttraining's binary_logloss: 0.00011083\n",
      "[1343]\ttraining's binary_logloss: 0.000110238\n",
      "[1344]\ttraining's binary_logloss: 0.000109639\n",
      "[1345]\ttraining's binary_logloss: 0.000108961\n",
      "[1346]\ttraining's binary_logloss: 0.000108355\n",
      "[1347]\ttraining's binary_logloss: 0.000107695\n",
      "[1348]\ttraining's binary_logloss: 0.000107024\n",
      "[1349]\ttraining's binary_logloss: 0.000106427\n",
      "[1350]\ttraining's binary_logloss: 0.000105896\n",
      "[1351]\ttraining's binary_logloss: 0.000105293\n",
      "[1352]\ttraining's binary_logloss: 0.000104611\n",
      "[1353]\ttraining's binary_logloss: 0.000104059\n",
      "[1354]\ttraining's binary_logloss: 0.000103539\n",
      "[1355]\ttraining's binary_logloss: 0.000102982\n",
      "[1356]\ttraining's binary_logloss: 0.000102407\n",
      "[1357]\ttraining's binary_logloss: 0.000101843\n",
      "[1358]\ttraining's binary_logloss: 0.00010134\n",
      "[1359]\ttraining's binary_logloss: 0.000100822\n",
      "[1360]\ttraining's binary_logloss: 0.000100269\n",
      "[1361]\ttraining's binary_logloss: 9.97063e-05\n",
      "[1362]\ttraining's binary_logloss: 9.9189e-05\n",
      "[1363]\ttraining's binary_logloss: 9.85474e-05\n",
      "[1364]\ttraining's binary_logloss: 9.79975e-05\n",
      "[1365]\ttraining's binary_logloss: 9.74928e-05\n",
      "[1366]\ttraining's binary_logloss: 9.69951e-05\n",
      "[1367]\ttraining's binary_logloss: 9.64507e-05\n",
      "[1368]\ttraining's binary_logloss: 9.5907e-05\n",
      "[1369]\ttraining's binary_logloss: 9.53367e-05\n",
      "[1370]\ttraining's binary_logloss: 9.47308e-05\n",
      "[1371]\ttraining's binary_logloss: 9.42425e-05\n",
      "[1372]\ttraining's binary_logloss: 9.37349e-05\n",
      "[1373]\ttraining's binary_logloss: 9.32422e-05\n",
      "[1374]\ttraining's binary_logloss: 9.26834e-05\n",
      "[1375]\ttraining's binary_logloss: 9.21139e-05\n",
      "[1376]\ttraining's binary_logloss: 9.16325e-05\n",
      "[1377]\ttraining's binary_logloss: 9.11296e-05\n",
      "[1378]\ttraining's binary_logloss: 9.06219e-05\n",
      "[1379]\ttraining's binary_logloss: 9.01405e-05\n",
      "[1380]\ttraining's binary_logloss: 8.96817e-05\n",
      "[1381]\ttraining's binary_logloss: 8.92267e-05\n",
      "[1382]\ttraining's binary_logloss: 8.87601e-05\n",
      "[1383]\ttraining's binary_logloss: 8.8354e-05\n",
      "[1384]\ttraining's binary_logloss: 8.78273e-05\n",
      "[1385]\ttraining's binary_logloss: 8.73724e-05\n",
      "[1386]\ttraining's binary_logloss: 8.69286e-05\n",
      "[1387]\ttraining's binary_logloss: 8.645e-05\n",
      "[1388]\ttraining's binary_logloss: 8.59741e-05\n",
      "[1389]\ttraining's binary_logloss: 8.55395e-05\n",
      "[1390]\ttraining's binary_logloss: 8.50623e-05\n",
      "[1391]\ttraining's binary_logloss: 8.46724e-05\n",
      "[1392]\ttraining's binary_logloss: 8.42105e-05\n",
      "[1393]\ttraining's binary_logloss: 8.36865e-05\n",
      "[1394]\ttraining's binary_logloss: 8.32458e-05\n",
      "[1395]\ttraining's binary_logloss: 8.27829e-05\n",
      "[1396]\ttraining's binary_logloss: 8.23604e-05\n",
      "[1397]\ttraining's binary_logloss: 8.1925e-05\n",
      "[1398]\ttraining's binary_logloss: 8.14515e-05\n",
      "[1399]\ttraining's binary_logloss: 8.10426e-05\n",
      "[1400]\ttraining's binary_logloss: 8.06041e-05\n",
      "[1401]\ttraining's binary_logloss: 8.01818e-05\n",
      "[1402]\ttraining's binary_logloss: 7.97424e-05\n",
      "[1403]\ttraining's binary_logloss: 7.93061e-05\n",
      "[1404]\ttraining's binary_logloss: 7.8874e-05\n",
      "[1405]\ttraining's binary_logloss: 7.84545e-05\n",
      "[1406]\ttraining's binary_logloss: 7.8053e-05\n",
      "[1407]\ttraining's binary_logloss: 7.76895e-05\n",
      "[1408]\ttraining's binary_logloss: 7.73048e-05\n",
      "[1409]\ttraining's binary_logloss: 7.69097e-05\n",
      "[1410]\ttraining's binary_logloss: 7.65284e-05\n",
      "[1411]\ttraining's binary_logloss: 7.60927e-05\n",
      "[1412]\ttraining's binary_logloss: 7.57304e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1413]\ttraining's binary_logloss: 7.53527e-05\n",
      "[1414]\ttraining's binary_logloss: 7.49939e-05\n",
      "[1415]\ttraining's binary_logloss: 7.46025e-05\n",
      "[1416]\ttraining's binary_logloss: 7.42137e-05\n",
      "[1417]\ttraining's binary_logloss: 7.38108e-05\n",
      "[1418]\ttraining's binary_logloss: 7.33782e-05\n",
      "[1419]\ttraining's binary_logloss: 7.30081e-05\n",
      "[1420]\ttraining's binary_logloss: 7.26269e-05\n",
      "[1421]\ttraining's binary_logloss: 7.22448e-05\n",
      "[1422]\ttraining's binary_logloss: 7.18732e-05\n",
      "[1423]\ttraining's binary_logloss: 7.14708e-05\n",
      "[1424]\ttraining's binary_logloss: 7.11167e-05\n",
      "[1425]\ttraining's binary_logloss: 7.07089e-05\n",
      "[1426]\ttraining's binary_logloss: 7.03736e-05\n",
      "[1427]\ttraining's binary_logloss: 6.9979e-05\n",
      "[1428]\ttraining's binary_logloss: 6.96185e-05\n",
      "[1429]\ttraining's binary_logloss: 6.92715e-05\n",
      "[1430]\ttraining's binary_logloss: 6.89348e-05\n",
      "[1431]\ttraining's binary_logloss: 6.86006e-05\n",
      "[1432]\ttraining's binary_logloss: 6.82339e-05\n",
      "[1433]\ttraining's binary_logloss: 6.78668e-05\n",
      "[1434]\ttraining's binary_logloss: 6.75047e-05\n",
      "[1435]\ttraining's binary_logloss: 6.71694e-05\n",
      "[1436]\ttraining's binary_logloss: 6.68165e-05\n",
      "[1437]\ttraining's binary_logloss: 6.65011e-05\n",
      "[1438]\ttraining's binary_logloss: 6.60857e-05\n",
      "[1439]\ttraining's binary_logloss: 6.57523e-05\n",
      "[1440]\ttraining's binary_logloss: 6.53893e-05\n",
      "[1441]\ttraining's binary_logloss: 6.50516e-05\n",
      "[1442]\ttraining's binary_logloss: 6.47324e-05\n",
      "[1443]\ttraining's binary_logloss: 6.43688e-05\n",
      "[1444]\ttraining's binary_logloss: 6.40419e-05\n",
      "[1445]\ttraining's binary_logloss: 6.36774e-05\n",
      "[1446]\ttraining's binary_logloss: 6.33514e-05\n",
      "[1447]\ttraining's binary_logloss: 6.30084e-05\n",
      "[1448]\ttraining's binary_logloss: 6.26886e-05\n",
      "[1449]\ttraining's binary_logloss: 6.23759e-05\n",
      "[1450]\ttraining's binary_logloss: 6.20372e-05\n",
      "[1451]\ttraining's binary_logloss: 6.17471e-05\n",
      "[1452]\ttraining's binary_logloss: 6.14434e-05\n",
      "[1453]\ttraining's binary_logloss: 6.11313e-05\n",
      "[1454]\ttraining's binary_logloss: 6.08253e-05\n",
      "[1455]\ttraining's binary_logloss: 6.05131e-05\n",
      "[1456]\ttraining's binary_logloss: 6.01692e-05\n",
      "[1457]\ttraining's binary_logloss: 5.98687e-05\n",
      "[1458]\ttraining's binary_logloss: 5.9556e-05\n",
      "[1459]\ttraining's binary_logloss: 5.92524e-05\n",
      "[1460]\ttraining's binary_logloss: 5.89239e-05\n",
      "[1461]\ttraining's binary_logloss: 5.86244e-05\n",
      "[1462]\ttraining's binary_logloss: 5.8297e-05\n",
      "[1463]\ttraining's binary_logloss: 5.80096e-05\n",
      "[1464]\ttraining's binary_logloss: 5.77342e-05\n",
      "[1465]\ttraining's binary_logloss: 5.73878e-05\n",
      "[1466]\ttraining's binary_logloss: 5.71008e-05\n",
      "[1467]\ttraining's binary_logloss: 5.68095e-05\n",
      "[1468]\ttraining's binary_logloss: 5.65402e-05\n",
      "[1469]\ttraining's binary_logloss: 5.62979e-05\n",
      "[1470]\ttraining's binary_logloss: 5.60055e-05\n",
      "[1471]\ttraining's binary_logloss: 5.56979e-05\n",
      "[1472]\ttraining's binary_logloss: 5.54155e-05\n",
      "[1473]\ttraining's binary_logloss: 5.51187e-05\n",
      "[1474]\ttraining's binary_logloss: 5.48518e-05\n",
      "[1475]\ttraining's binary_logloss: 5.45624e-05\n",
      "[1476]\ttraining's binary_logloss: 5.42647e-05\n",
      "[1477]\ttraining's binary_logloss: 5.39878e-05\n",
      "[1478]\ttraining's binary_logloss: 5.36868e-05\n",
      "[1479]\ttraining's binary_logloss: 5.34161e-05\n",
      "[1480]\ttraining's binary_logloss: 5.3149e-05\n",
      "[1481]\ttraining's binary_logloss: 5.28898e-05\n",
      "[1482]\ttraining's binary_logloss: 5.26091e-05\n",
      "[1483]\ttraining's binary_logloss: 5.23567e-05\n",
      "[1484]\ttraining's binary_logloss: 5.20937e-05\n",
      "[1485]\ttraining's binary_logloss: 5.18392e-05\n",
      "[1486]\ttraining's binary_logloss: 5.16044e-05\n",
      "[1487]\ttraining's binary_logloss: 5.1342e-05\n",
      "[1488]\ttraining's binary_logloss: 5.1075e-05\n",
      "[1489]\ttraining's binary_logloss: 5.08324e-05\n",
      "[1490]\ttraining's binary_logloss: 5.05563e-05\n",
      "[1491]\ttraining's binary_logloss: 5.03222e-05\n",
      "[1492]\ttraining's binary_logloss: 5.00829e-05\n",
      "[1493]\ttraining's binary_logloss: 4.98539e-05\n",
      "[1494]\ttraining's binary_logloss: 4.9577e-05\n",
      "[1495]\ttraining's binary_logloss: 4.93552e-05\n",
      "[1496]\ttraining's binary_logloss: 4.9135e-05\n",
      "[1497]\ttraining's binary_logloss: 4.89082e-05\n",
      "[1498]\ttraining's binary_logloss: 4.86614e-05\n",
      "[1499]\ttraining's binary_logloss: 4.8438e-05\n",
      "[1500]\ttraining's binary_logloss: 4.82112e-05\n",
      "[1501]\ttraining's binary_logloss: 4.80015e-05\n",
      "[1502]\ttraining's binary_logloss: 4.77621e-05\n",
      "[1503]\ttraining's binary_logloss: 4.75437e-05\n",
      "[1504]\ttraining's binary_logloss: 4.73109e-05\n",
      "[1505]\ttraining's binary_logloss: 4.70539e-05\n",
      "[1506]\ttraining's binary_logloss: 4.68375e-05\n",
      "[1507]\ttraining's binary_logloss: 4.66067e-05\n",
      "[1508]\ttraining's binary_logloss: 4.63635e-05\n",
      "[1509]\ttraining's binary_logloss: 4.61418e-05\n",
      "[1510]\ttraining's binary_logloss: 4.5932e-05\n",
      "[1511]\ttraining's binary_logloss: 4.5693e-05\n",
      "[1512]\ttraining's binary_logloss: 4.54448e-05\n",
      "[1513]\ttraining's binary_logloss: 4.52153e-05\n",
      "[1514]\ttraining's binary_logloss: 4.50081e-05\n",
      "[1515]\ttraining's binary_logloss: 4.48008e-05\n",
      "[1516]\ttraining's binary_logloss: 4.45615e-05\n",
      "[1517]\ttraining's binary_logloss: 4.43427e-05\n",
      "[1518]\ttraining's binary_logloss: 4.41521e-05\n",
      "[1519]\ttraining's binary_logloss: 4.39371e-05\n",
      "[1520]\ttraining's binary_logloss: 4.37323e-05\n",
      "[1521]\ttraining's binary_logloss: 4.35313e-05\n",
      "[1522]\ttraining's binary_logloss: 4.33255e-05\n",
      "[1523]\ttraining's binary_logloss: 4.31144e-05\n",
      "[1524]\ttraining's binary_logloss: 4.29251e-05\n",
      "[1525]\ttraining's binary_logloss: 4.27102e-05\n",
      "[1526]\ttraining's binary_logloss: 4.25125e-05\n",
      "[1527]\ttraining's binary_logloss: 4.23199e-05\n",
      "[1528]\ttraining's binary_logloss: 4.2139e-05\n",
      "[1529]\ttraining's binary_logloss: 4.19476e-05\n",
      "[1530]\ttraining's binary_logloss: 4.17669e-05\n",
      "[1531]\ttraining's binary_logloss: 4.15409e-05\n",
      "[1532]\ttraining's binary_logloss: 4.13484e-05\n",
      "[1533]\ttraining's binary_logloss: 4.11578e-05\n",
      "[1534]\ttraining's binary_logloss: 4.09604e-05\n",
      "[1535]\ttraining's binary_logloss: 4.07491e-05\n",
      "[1536]\ttraining's binary_logloss: 4.05624e-05\n",
      "[1537]\ttraining's binary_logloss: 4.0378e-05\n",
      "[1538]\ttraining's binary_logloss: 4.01938e-05\n",
      "[1539]\ttraining's binary_logloss: 4.00241e-05\n",
      "[1540]\ttraining's binary_logloss: 3.98472e-05\n",
      "[1541]\ttraining's binary_logloss: 3.96484e-05\n",
      "[1542]\ttraining's binary_logloss: 3.94542e-05\n",
      "[1543]\ttraining's binary_logloss: 3.92788e-05\n",
      "[1544]\ttraining's binary_logloss: 3.91027e-05\n",
      "[1545]\ttraining's binary_logloss: 3.89019e-05\n",
      "[1546]\ttraining's binary_logloss: 3.87273e-05\n",
      "[1547]\ttraining's binary_logloss: 3.85544e-05\n",
      "[1548]\ttraining's binary_logloss: 3.83897e-05\n",
      "[1549]\ttraining's binary_logloss: 3.82145e-05\n",
      "[1550]\ttraining's binary_logloss: 3.80321e-05\n",
      "[1551]\ttraining's binary_logloss: 3.78668e-05\n",
      "[1552]\ttraining's binary_logloss: 3.76995e-05\n",
      "[1553]\ttraining's binary_logloss: 3.75177e-05\n",
      "[1554]\ttraining's binary_logloss: 3.7355e-05\n",
      "[1555]\ttraining's binary_logloss: 3.71608e-05\n",
      "[1556]\ttraining's binary_logloss: 3.69993e-05\n",
      "[1557]\ttraining's binary_logloss: 3.68264e-05\n",
      "[1558]\ttraining's binary_logloss: 3.6659e-05\n",
      "[1559]\ttraining's binary_logloss: 3.64746e-05\n",
      "[1560]\ttraining's binary_logloss: 3.63131e-05\n",
      "[1561]\ttraining's binary_logloss: 3.61423e-05\n",
      "[1562]\ttraining's binary_logloss: 3.59554e-05\n",
      "[1563]\ttraining's binary_logloss: 3.57875e-05\n",
      "[1564]\ttraining's binary_logloss: 3.56359e-05\n",
      "[1565]\ttraining's binary_logloss: 3.54968e-05\n",
      "[1566]\ttraining's binary_logloss: 3.5351e-05\n",
      "[1567]\ttraining's binary_logloss: 3.51979e-05\n",
      "[1568]\ttraining's binary_logloss: 3.50266e-05\n",
      "[1569]\ttraining's binary_logloss: 3.48827e-05\n",
      "[1570]\ttraining's binary_logloss: 3.47323e-05\n",
      "[1571]\ttraining's binary_logloss: 3.45729e-05\n",
      "[1572]\ttraining's binary_logloss: 3.444e-05\n",
      "[1573]\ttraining's binary_logloss: 3.42688e-05\n",
      "[1574]\ttraining's binary_logloss: 3.41207e-05\n",
      "[1575]\ttraining's binary_logloss: 3.39553e-05\n",
      "[1576]\ttraining's binary_logloss: 3.37988e-05\n",
      "[1577]\ttraining's binary_logloss: 3.36322e-05\n",
      "[1578]\ttraining's binary_logloss: 3.34906e-05\n",
      "[1579]\ttraining's binary_logloss: 3.33376e-05\n",
      "[1580]\ttraining's binary_logloss: 3.32114e-05\n",
      "[1581]\ttraining's binary_logloss: 3.30454e-05\n",
      "[1582]\ttraining's binary_logloss: 3.28925e-05\n",
      "[1583]\ttraining's binary_logloss: 3.27364e-05\n",
      "[1584]\ttraining's binary_logloss: 3.25798e-05\n",
      "[1585]\ttraining's binary_logloss: 3.24062e-05\n",
      "[1586]\ttraining's binary_logloss: 3.2258e-05\n",
      "[1587]\ttraining's binary_logloss: 3.21223e-05\n",
      "[1588]\ttraining's binary_logloss: 3.19861e-05\n",
      "[1589]\ttraining's binary_logloss: 3.18415e-05\n",
      "[1590]\ttraining's binary_logloss: 3.16952e-05\n",
      "[1591]\ttraining's binary_logloss: 3.15618e-05\n",
      "[1592]\ttraining's binary_logloss: 3.14216e-05\n",
      "[1593]\ttraining's binary_logloss: 3.12695e-05\n",
      "[1594]\ttraining's binary_logloss: 3.11358e-05\n",
      "[1595]\ttraining's binary_logloss: 3.09812e-05\n",
      "[1596]\ttraining's binary_logloss: 3.0841e-05\n",
      "[1597]\ttraining's binary_logloss: 3.07009e-05\n",
      "[1598]\ttraining's binary_logloss: 3.05621e-05\n",
      "[1599]\ttraining's binary_logloss: 3.04468e-05\n",
      "[1600]\ttraining's binary_logloss: 3.03202e-05\n",
      "[1601]\ttraining's binary_logloss: 3.01961e-05\n",
      "[1602]\ttraining's binary_logloss: 3.00641e-05\n",
      "[1603]\ttraining's binary_logloss: 2.99453e-05\n",
      "[1604]\ttraining's binary_logloss: 2.98132e-05\n",
      "[1605]\ttraining's binary_logloss: 2.9663e-05\n",
      "[1606]\ttraining's binary_logloss: 2.95446e-05\n",
      "[1607]\ttraining's binary_logloss: 2.94168e-05\n",
      "[1608]\ttraining's binary_logloss: 2.92992e-05\n",
      "[1609]\ttraining's binary_logloss: 2.91794e-05\n",
      "[1610]\ttraining's binary_logloss: 2.9067e-05\n",
      "[1611]\ttraining's binary_logloss: 2.89436e-05\n",
      "[1612]\ttraining's binary_logloss: 2.88269e-05\n",
      "[1613]\ttraining's binary_logloss: 2.87116e-05\n",
      "[1614]\ttraining's binary_logloss: 2.85829e-05\n",
      "[1615]\ttraining's binary_logloss: 2.84756e-05\n",
      "[1616]\ttraining's binary_logloss: 2.8344e-05\n",
      "[1617]\ttraining's binary_logloss: 2.82224e-05\n",
      "[1618]\ttraining's binary_logloss: 2.8097e-05\n",
      "[1619]\ttraining's binary_logloss: 2.79741e-05\n",
      "[1620]\ttraining's binary_logloss: 2.78649e-05\n",
      "[1621]\ttraining's binary_logloss: 2.77468e-05\n",
      "[1622]\ttraining's binary_logloss: 2.76173e-05\n",
      "[1623]\ttraining's binary_logloss: 2.75157e-05\n",
      "[1624]\ttraining's binary_logloss: 2.74054e-05\n",
      "[1625]\ttraining's binary_logloss: 2.72922e-05\n",
      "[1626]\ttraining's binary_logloss: 2.71843e-05\n",
      "[1627]\ttraining's binary_logloss: 2.70644e-05\n",
      "[1628]\ttraining's binary_logloss: 2.6958e-05\n",
      "[1629]\ttraining's binary_logloss: 2.68638e-05\n",
      "[1630]\ttraining's binary_logloss: 2.67596e-05\n",
      "[1631]\ttraining's binary_logloss: 2.66516e-05\n",
      "[1632]\ttraining's binary_logloss: 2.65464e-05\n",
      "[1633]\ttraining's binary_logloss: 2.64423e-05\n",
      "[1634]\ttraining's binary_logloss: 2.63236e-05\n",
      "[1635]\ttraining's binary_logloss: 2.62267e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1636]\ttraining's binary_logloss: 2.61192e-05\n",
      "[1637]\ttraining's binary_logloss: 2.60025e-05\n",
      "[1638]\ttraining's binary_logloss: 2.58853e-05\n",
      "[1639]\ttraining's binary_logloss: 2.57791e-05\n",
      "[1640]\ttraining's binary_logloss: 2.56637e-05\n",
      "[1641]\ttraining's binary_logloss: 2.55582e-05\n",
      "[1642]\ttraining's binary_logloss: 2.54468e-05\n",
      "[1643]\ttraining's binary_logloss: 2.53401e-05\n",
      "[1644]\ttraining's binary_logloss: 2.52375e-05\n",
      "[1645]\ttraining's binary_logloss: 2.5133e-05\n",
      "[1646]\ttraining's binary_logloss: 2.50298e-05\n",
      "[1647]\ttraining's binary_logloss: 2.49357e-05\n",
      "[1648]\ttraining's binary_logloss: 2.48416e-05\n",
      "[1649]\ttraining's binary_logloss: 2.47426e-05\n",
      "[1650]\ttraining's binary_logloss: 2.46404e-05\n",
      "[1651]\ttraining's binary_logloss: 2.4536e-05\n",
      "[1652]\ttraining's binary_logloss: 2.44429e-05\n",
      "[1653]\ttraining's binary_logloss: 2.43509e-05\n",
      "[1654]\ttraining's binary_logloss: 2.42655e-05\n",
      "[1655]\ttraining's binary_logloss: 2.41641e-05\n",
      "[1656]\ttraining's binary_logloss: 2.4071e-05\n",
      "[1657]\ttraining's binary_logloss: 2.39774e-05\n",
      "[1658]\ttraining's binary_logloss: 2.38813e-05\n",
      "[1659]\ttraining's binary_logloss: 2.37855e-05\n",
      "[1660]\ttraining's binary_logloss: 2.36983e-05\n",
      "[1661]\ttraining's binary_logloss: 2.36123e-05\n",
      "[1662]\ttraining's binary_logloss: 2.35089e-05\n",
      "[1663]\ttraining's binary_logloss: 2.34004e-05\n",
      "[1664]\ttraining's binary_logloss: 2.33143e-05\n",
      "[1665]\ttraining's binary_logloss: 2.32213e-05\n",
      "[1666]\ttraining's binary_logloss: 2.31259e-05\n",
      "[1667]\ttraining's binary_logloss: 2.30354e-05\n",
      "[1668]\ttraining's binary_logloss: 2.2936e-05\n",
      "[1669]\ttraining's binary_logloss: 2.28519e-05\n",
      "[1670]\ttraining's binary_logloss: 2.27547e-05\n",
      "[1671]\ttraining's binary_logloss: 2.26678e-05\n",
      "[1672]\ttraining's binary_logloss: 2.25787e-05\n",
      "[1673]\ttraining's binary_logloss: 2.24908e-05\n",
      "[1674]\ttraining's binary_logloss: 2.24001e-05\n",
      "[1675]\ttraining's binary_logloss: 2.2322e-05\n",
      "[1676]\ttraining's binary_logloss: 2.22398e-05\n",
      "[1677]\ttraining's binary_logloss: 2.21591e-05\n",
      "[1678]\ttraining's binary_logloss: 2.2079e-05\n",
      "[1679]\ttraining's binary_logloss: 2.19853e-05\n",
      "[1680]\ttraining's binary_logloss: 2.19022e-05\n",
      "[1681]\ttraining's binary_logloss: 2.18218e-05\n",
      "[1682]\ttraining's binary_logloss: 2.17432e-05\n",
      "[1683]\ttraining's binary_logloss: 2.16525e-05\n",
      "[1684]\ttraining's binary_logloss: 2.15746e-05\n",
      "[1685]\ttraining's binary_logloss: 2.14934e-05\n",
      "[1686]\ttraining's binary_logloss: 2.14149e-05\n",
      "[1687]\ttraining's binary_logloss: 2.13348e-05\n",
      "[1688]\ttraining's binary_logloss: 2.12518e-05\n",
      "[1689]\ttraining's binary_logloss: 2.11723e-05\n",
      "[1690]\ttraining's binary_logloss: 2.10932e-05\n",
      "[1691]\ttraining's binary_logloss: 2.10188e-05\n",
      "[1692]\ttraining's binary_logloss: 2.09428e-05\n",
      "[1693]\ttraining's binary_logloss: 2.08612e-05\n",
      "[1694]\ttraining's binary_logloss: 2.07799e-05\n",
      "[1695]\ttraining's binary_logloss: 2.07016e-05\n",
      "[1696]\ttraining's binary_logloss: 2.06236e-05\n",
      "[1697]\ttraining's binary_logloss: 2.05491e-05\n",
      "[1698]\ttraining's binary_logloss: 2.04732e-05\n",
      "[1699]\ttraining's binary_logloss: 2.03987e-05\n",
      "[1700]\ttraining's binary_logloss: 2.03206e-05\n",
      "[1701]\ttraining's binary_logloss: 2.02426e-05\n",
      "[1702]\ttraining's binary_logloss: 2.01689e-05\n",
      "[1703]\ttraining's binary_logloss: 2.00989e-05\n",
      "[1704]\ttraining's binary_logloss: 2.00188e-05\n",
      "[1705]\ttraining's binary_logloss: 1.995e-05\n",
      "[1706]\ttraining's binary_logloss: 1.98743e-05\n",
      "[1707]\ttraining's binary_logloss: 1.98035e-05\n",
      "[1708]\ttraining's binary_logloss: 1.97295e-05\n",
      "[1709]\ttraining's binary_logloss: 1.96587e-05\n",
      "[1710]\ttraining's binary_logloss: 1.95935e-05\n",
      "[1711]\ttraining's binary_logloss: 1.95226e-05\n",
      "[1712]\ttraining's binary_logloss: 1.94532e-05\n",
      "[1713]\ttraining's binary_logloss: 1.9383e-05\n",
      "[1714]\ttraining's binary_logloss: 1.93101e-05\n",
      "[1715]\ttraining's binary_logloss: 1.92407e-05\n",
      "[1716]\ttraining's binary_logloss: 1.91754e-05\n",
      "[1717]\ttraining's binary_logloss: 1.91145e-05\n",
      "[1718]\ttraining's binary_logloss: 1.90484e-05\n",
      "[1719]\ttraining's binary_logloss: 1.8984e-05\n",
      "[1720]\ttraining's binary_logloss: 1.89198e-05\n",
      "[1721]\ttraining's binary_logloss: 1.88576e-05\n",
      "[1722]\ttraining's binary_logloss: 1.87888e-05\n",
      "[1723]\ttraining's binary_logloss: 1.87225e-05\n",
      "[1724]\ttraining's binary_logloss: 1.86681e-05\n",
      "[1725]\ttraining's binary_logloss: 1.86062e-05\n",
      "[1726]\ttraining's binary_logloss: 1.85434e-05\n",
      "[1727]\ttraining's binary_logloss: 1.84809e-05\n",
      "[1728]\ttraining's binary_logloss: 1.84147e-05\n",
      "[1729]\ttraining's binary_logloss: 1.83545e-05\n",
      "[1730]\ttraining's binary_logloss: 1.83017e-05\n",
      "[1731]\ttraining's binary_logloss: 1.82447e-05\n",
      "[1732]\ttraining's binary_logloss: 1.81902e-05\n",
      "[1733]\ttraining's binary_logloss: 1.81256e-05\n",
      "[1734]\ttraining's binary_logloss: 1.80668e-05\n",
      "[1735]\ttraining's binary_logloss: 1.79996e-05\n",
      "[1736]\ttraining's binary_logloss: 1.79412e-05\n",
      "[1737]\ttraining's binary_logloss: 1.78801e-05\n",
      "[1738]\ttraining's binary_logloss: 1.78178e-05\n",
      "[1739]\ttraining's binary_logloss: 1.77589e-05\n",
      "[1740]\ttraining's binary_logloss: 1.77038e-05\n",
      "[1741]\ttraining's binary_logloss: 1.76442e-05\n",
      "[1742]\ttraining's binary_logloss: 1.75927e-05\n",
      "[1743]\ttraining's binary_logloss: 1.75395e-05\n",
      "[1744]\ttraining's binary_logloss: 1.74815e-05\n",
      "[1745]\ttraining's binary_logloss: 1.74271e-05\n",
      "[1746]\ttraining's binary_logloss: 1.7377e-05\n",
      "[1747]\ttraining's binary_logloss: 1.73265e-05\n",
      "[1748]\ttraining's binary_logloss: 1.72717e-05\n",
      "[1749]\ttraining's binary_logloss: 1.72181e-05\n",
      "[1750]\ttraining's binary_logloss: 1.7164e-05\n",
      "[1751]\ttraining's binary_logloss: 1.71047e-05\n",
      "[1752]\ttraining's binary_logloss: 1.70539e-05\n",
      "[1753]\ttraining's binary_logloss: 1.69953e-05\n",
      "[1754]\ttraining's binary_logloss: 1.69361e-05\n",
      "[1755]\ttraining's binary_logloss: 1.68889e-05\n",
      "[1756]\ttraining's binary_logloss: 1.68376e-05\n",
      "[1757]\ttraining's binary_logloss: 1.67807e-05\n",
      "[1758]\ttraining's binary_logloss: 1.67282e-05\n",
      "[1759]\ttraining's binary_logloss: 1.66781e-05\n",
      "[1760]\ttraining's binary_logloss: 1.66274e-05\n",
      "[1761]\ttraining's binary_logloss: 1.65687e-05\n",
      "[1762]\ttraining's binary_logloss: 1.65217e-05\n",
      "[1763]\ttraining's binary_logloss: 1.6473e-05\n",
      "[1764]\ttraining's binary_logloss: 1.6415e-05\n",
      "[1765]\ttraining's binary_logloss: 1.63629e-05\n",
      "[1766]\ttraining's binary_logloss: 1.63137e-05\n",
      "[1767]\ttraining's binary_logloss: 1.62641e-05\n",
      "[1768]\ttraining's binary_logloss: 1.6216e-05\n",
      "[1769]\ttraining's binary_logloss: 1.61707e-05\n",
      "[1770]\ttraining's binary_logloss: 1.61187e-05\n",
      "[1771]\ttraining's binary_logloss: 1.60676e-05\n",
      "[1772]\ttraining's binary_logloss: 1.60251e-05\n",
      "[1773]\ttraining's binary_logloss: 1.59798e-05\n",
      "[1774]\ttraining's binary_logloss: 1.59308e-05\n",
      "[1775]\ttraining's binary_logloss: 1.58824e-05\n",
      "[1776]\ttraining's binary_logloss: 1.58383e-05\n",
      "[1777]\ttraining's binary_logloss: 1.57909e-05\n",
      "[1778]\ttraining's binary_logloss: 1.57421e-05\n",
      "[1779]\ttraining's binary_logloss: 1.56959e-05\n",
      "[1780]\ttraining's binary_logloss: 1.56455e-05\n",
      "[1781]\ttraining's binary_logloss: 1.55967e-05\n",
      "[1782]\ttraining's binary_logloss: 1.55551e-05\n",
      "[1783]\ttraining's binary_logloss: 1.55093e-05\n",
      "[1784]\ttraining's binary_logloss: 1.54651e-05\n",
      "[1785]\ttraining's binary_logloss: 1.54177e-05\n",
      "[1786]\ttraining's binary_logloss: 1.53737e-05\n",
      "[1787]\ttraining's binary_logloss: 1.53309e-05\n",
      "[1788]\ttraining's binary_logloss: 1.52859e-05\n",
      "[1789]\ttraining's binary_logloss: 1.52358e-05\n",
      "[1790]\ttraining's binary_logloss: 1.5193e-05\n",
      "[1791]\ttraining's binary_logloss: 1.51465e-05\n",
      "[1792]\ttraining's binary_logloss: 1.51092e-05\n",
      "[1793]\ttraining's binary_logloss: 1.50685e-05\n",
      "[1794]\ttraining's binary_logloss: 1.50288e-05\n",
      "[1795]\ttraining's binary_logloss: 1.49847e-05\n",
      "[1796]\ttraining's binary_logloss: 1.49502e-05\n",
      "[1797]\ttraining's binary_logloss: 1.49137e-05\n",
      "[1798]\ttraining's binary_logloss: 1.48707e-05\n",
      "[1799]\ttraining's binary_logloss: 1.48299e-05\n",
      "[1800]\ttraining's binary_logloss: 1.47902e-05\n",
      "[1801]\ttraining's binary_logloss: 1.47483e-05\n",
      "[1802]\ttraining's binary_logloss: 1.47024e-05\n",
      "[1803]\ttraining's binary_logloss: 1.46651e-05\n",
      "[1804]\ttraining's binary_logloss: 1.46283e-05\n",
      "[1805]\ttraining's binary_logloss: 1.45922e-05\n",
      "[1806]\ttraining's binary_logloss: 1.45464e-05\n",
      "[1807]\ttraining's binary_logloss: 1.45046e-05\n",
      "[1808]\ttraining's binary_logloss: 1.44726e-05\n",
      "[1809]\ttraining's binary_logloss: 1.44345e-05\n",
      "[1810]\ttraining's binary_logloss: 1.44007e-05\n",
      "[1811]\ttraining's binary_logloss: 1.43621e-05\n",
      "[1812]\ttraining's binary_logloss: 1.43302e-05\n",
      "[1813]\ttraining's binary_logloss: 1.42966e-05\n",
      "[1814]\ttraining's binary_logloss: 1.42596e-05\n",
      "[1815]\ttraining's binary_logloss: 1.4221e-05\n",
      "[1816]\ttraining's binary_logloss: 1.41824e-05\n",
      "[1817]\ttraining's binary_logloss: 1.41467e-05\n",
      "[1818]\ttraining's binary_logloss: 1.41114e-05\n",
      "[1819]\ttraining's binary_logloss: 1.40762e-05\n",
      "[1820]\ttraining's binary_logloss: 1.40398e-05\n",
      "[1821]\ttraining's binary_logloss: 1.4001e-05\n",
      "[1822]\ttraining's binary_logloss: 1.3963e-05\n",
      "[1823]\ttraining's binary_logloss: 1.39287e-05\n",
      "[1824]\ttraining's binary_logloss: 1.38936e-05\n",
      "[1825]\ttraining's binary_logloss: 1.38562e-05\n",
      "[1826]\ttraining's binary_logloss: 1.38181e-05\n",
      "[1827]\ttraining's binary_logloss: 1.37841e-05\n",
      "[1828]\ttraining's binary_logloss: 1.37499e-05\n",
      "[1829]\ttraining's binary_logloss: 1.37165e-05\n",
      "[1830]\ttraining's binary_logloss: 1.36864e-05\n",
      "[1831]\ttraining's binary_logloss: 1.3652e-05\n",
      "[1832]\ttraining's binary_logloss: 1.36197e-05\n",
      "[1833]\ttraining's binary_logloss: 1.35871e-05\n",
      "[1834]\ttraining's binary_logloss: 1.35505e-05\n",
      "[1835]\ttraining's binary_logloss: 1.35159e-05\n",
      "[1836]\ttraining's binary_logloss: 1.34816e-05\n",
      "[1837]\ttraining's binary_logloss: 1.34473e-05\n",
      "[1838]\ttraining's binary_logloss: 1.34155e-05\n",
      "[1839]\ttraining's binary_logloss: 1.33829e-05\n",
      "[1840]\ttraining's binary_logloss: 1.33509e-05\n",
      "[1841]\ttraining's binary_logloss: 1.33191e-05\n",
      "[1842]\ttraining's binary_logloss: 1.32845e-05\n",
      "[1843]\ttraining's binary_logloss: 1.32524e-05\n",
      "[1844]\ttraining's binary_logloss: 1.32209e-05\n",
      "[1845]\ttraining's binary_logloss: 1.31877e-05\n",
      "[1846]\ttraining's binary_logloss: 1.31576e-05\n",
      "[1847]\ttraining's binary_logloss: 1.31279e-05\n",
      "[1848]\ttraining's binary_logloss: 1.30959e-05\n",
      "[1849]\ttraining's binary_logloss: 1.30632e-05\n",
      "[1850]\ttraining's binary_logloss: 1.30314e-05\n",
      "[1851]\ttraining's binary_logloss: 1.29987e-05\n",
      "[1852]\ttraining's binary_logloss: 1.29696e-05\n",
      "[1853]\ttraining's binary_logloss: 1.29395e-05\n",
      "[1854]\ttraining's binary_logloss: 1.29097e-05\n",
      "[1855]\ttraining's binary_logloss: 1.2878e-05\n",
      "[1856]\ttraining's binary_logloss: 1.28458e-05\n",
      "[1857]\ttraining's binary_logloss: 1.28161e-05\n",
      "[1858]\ttraining's binary_logloss: 1.27858e-05\n",
      "[1859]\ttraining's binary_logloss: 1.27546e-05\n",
      "[1860]\ttraining's binary_logloss: 1.2725e-05\n",
      "[1861]\ttraining's binary_logloss: 1.26903e-05\n",
      "[1862]\ttraining's binary_logloss: 1.26597e-05\n",
      "[1863]\ttraining's binary_logloss: 1.26346e-05\n",
      "[1864]\ttraining's binary_logloss: 1.26035e-05\n",
      "[1865]\ttraining's binary_logloss: 1.2575e-05\n",
      "[1866]\ttraining's binary_logloss: 1.25468e-05\n",
      "[1867]\ttraining's binary_logloss: 1.25217e-05\n",
      "[1868]\ttraining's binary_logloss: 1.24926e-05\n",
      "[1869]\ttraining's binary_logloss: 1.24627e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1870]\ttraining's binary_logloss: 1.24342e-05\n",
      "[1871]\ttraining's binary_logloss: 1.24039e-05\n",
      "[1872]\ttraining's binary_logloss: 1.23791e-05\n",
      "[1873]\ttraining's binary_logloss: 1.23518e-05\n",
      "[1874]\ttraining's binary_logloss: 1.23231e-05\n",
      "[1875]\ttraining's binary_logloss: 1.22991e-05\n",
      "[1876]\ttraining's binary_logloss: 1.22736e-05\n",
      "[1877]\ttraining's binary_logloss: 1.22464e-05\n",
      "[1878]\ttraining's binary_logloss: 1.22221e-05\n",
      "[1879]\ttraining's binary_logloss: 1.21976e-05\n",
      "[1880]\ttraining's binary_logloss: 1.21701e-05\n",
      "[1881]\ttraining's binary_logloss: 1.21434e-05\n",
      "[1882]\ttraining's binary_logloss: 1.21202e-05\n",
      "[1883]\ttraining's binary_logloss: 1.20954e-05\n",
      "[1884]\ttraining's binary_logloss: 1.20623e-05\n",
      "[1885]\ttraining's binary_logloss: 1.20342e-05\n",
      "[1886]\ttraining's binary_logloss: 1.20074e-05\n",
      "[1887]\ttraining's binary_logloss: 1.19826e-05\n",
      "[1888]\ttraining's binary_logloss: 1.1954e-05\n",
      "[1889]\ttraining's binary_logloss: 1.19308e-05\n",
      "[1890]\ttraining's binary_logloss: 1.19068e-05\n",
      "[1891]\ttraining's binary_logloss: 1.18787e-05\n",
      "[1892]\ttraining's binary_logloss: 1.18529e-05\n",
      "[1893]\ttraining's binary_logloss: 1.18279e-05\n",
      "[1894]\ttraining's binary_logloss: 1.18007e-05\n",
      "[1895]\ttraining's binary_logloss: 1.17749e-05\n",
      "[1896]\ttraining's binary_logloss: 1.17533e-05\n",
      "[1897]\ttraining's binary_logloss: 1.17289e-05\n",
      "[1898]\ttraining's binary_logloss: 1.17041e-05\n",
      "[1899]\ttraining's binary_logloss: 1.16778e-05\n",
      "[1900]\ttraining's binary_logloss: 1.16525e-05\n",
      "[1901]\ttraining's binary_logloss: 1.16298e-05\n",
      "[1902]\ttraining's binary_logloss: 1.1609e-05\n",
      "[1903]\ttraining's binary_logloss: 1.15828e-05\n",
      "[1904]\ttraining's binary_logloss: 1.15598e-05\n",
      "[1905]\ttraining's binary_logloss: 1.15342e-05\n",
      "[1906]\ttraining's binary_logloss: 1.15097e-05\n",
      "[1907]\ttraining's binary_logloss: 1.1487e-05\n",
      "[1908]\ttraining's binary_logloss: 1.14669e-05\n",
      "[1909]\ttraining's binary_logloss: 1.1443e-05\n",
      "[1910]\ttraining's binary_logloss: 1.14223e-05\n",
      "[1911]\ttraining's binary_logloss: 1.14009e-05\n",
      "[1912]\ttraining's binary_logloss: 1.13788e-05\n",
      "[1913]\ttraining's binary_logloss: 1.13544e-05\n",
      "[1914]\ttraining's binary_logloss: 1.13315e-05\n",
      "[1915]\ttraining's binary_logloss: 1.13097e-05\n",
      "[1916]\ttraining's binary_logloss: 1.12887e-05\n",
      "[1917]\ttraining's binary_logloss: 1.1265e-05\n",
      "[1918]\ttraining's binary_logloss: 1.12414e-05\n",
      "[1919]\ttraining's binary_logloss: 1.12196e-05\n",
      "[1920]\ttraining's binary_logloss: 1.12013e-05\n",
      "[1921]\ttraining's binary_logloss: 1.1182e-05\n",
      "[1922]\ttraining's binary_logloss: 1.11578e-05\n",
      "[1923]\ttraining's binary_logloss: 1.11366e-05\n",
      "[1924]\ttraining's binary_logloss: 1.11143e-05\n",
      "[1925]\ttraining's binary_logloss: 1.10906e-05\n",
      "[1926]\ttraining's binary_logloss: 1.10695e-05\n",
      "[1927]\ttraining's binary_logloss: 1.10498e-05\n",
      "[1928]\ttraining's binary_logloss: 1.10302e-05\n",
      "[1929]\ttraining's binary_logloss: 1.10096e-05\n",
      "[1930]\ttraining's binary_logloss: 1.09862e-05\n",
      "[1931]\ttraining's binary_logloss: 1.09666e-05\n",
      "[1932]\ttraining's binary_logloss: 1.09449e-05\n",
      "[1933]\ttraining's binary_logloss: 1.09232e-05\n",
      "[1934]\ttraining's binary_logloss: 1.09026e-05\n",
      "[1935]\ttraining's binary_logloss: 1.08791e-05\n",
      "[1936]\ttraining's binary_logloss: 1.0858e-05\n",
      "[1937]\ttraining's binary_logloss: 1.08367e-05\n",
      "[1938]\ttraining's binary_logloss: 1.08176e-05\n",
      "[1939]\ttraining's binary_logloss: 1.08004e-05\n",
      "[1940]\ttraining's binary_logloss: 1.07799e-05\n",
      "[1941]\ttraining's binary_logloss: 1.07592e-05\n",
      "[1942]\ttraining's binary_logloss: 1.07381e-05\n",
      "[1943]\ttraining's binary_logloss: 1.07168e-05\n",
      "[1944]\ttraining's binary_logloss: 1.06954e-05\n",
      "[1945]\ttraining's binary_logloss: 1.06727e-05\n",
      "[1946]\ttraining's binary_logloss: 1.06541e-05\n",
      "[1947]\ttraining's binary_logloss: 1.06325e-05\n",
      "[1948]\ttraining's binary_logloss: 1.06151e-05\n",
      "[1949]\ttraining's binary_logloss: 1.05957e-05\n",
      "[1950]\ttraining's binary_logloss: 1.05748e-05\n",
      "[1951]\ttraining's binary_logloss: 1.05562e-05\n",
      "[1952]\ttraining's binary_logloss: 1.05387e-05\n",
      "[1953]\ttraining's binary_logloss: 1.05217e-05\n",
      "[1954]\ttraining's binary_logloss: 1.05043e-05\n",
      "[1955]\ttraining's binary_logloss: 1.04869e-05\n",
      "[1956]\ttraining's binary_logloss: 1.04673e-05\n",
      "[1957]\ttraining's binary_logloss: 1.04484e-05\n",
      "[1958]\ttraining's binary_logloss: 1.04305e-05\n",
      "[1959]\ttraining's binary_logloss: 1.04071e-05\n",
      "[1960]\ttraining's binary_logloss: 1.03869e-05\n",
      "[1961]\ttraining's binary_logloss: 1.037e-05\n",
      "[1962]\ttraining's binary_logloss: 1.03524e-05\n",
      "[1963]\ttraining's binary_logloss: 1.03366e-05\n",
      "[1964]\ttraining's binary_logloss: 1.03183e-05\n",
      "[1965]\ttraining's binary_logloss: 1.03018e-05\n",
      "[1966]\ttraining's binary_logloss: 1.02844e-05\n",
      "[1967]\ttraining's binary_logloss: 1.02653e-05\n",
      "[1968]\ttraining's binary_logloss: 1.02469e-05\n",
      "[1969]\ttraining's binary_logloss: 1.023e-05\n",
      "[1970]\ttraining's binary_logloss: 1.02122e-05\n",
      "[1971]\ttraining's binary_logloss: 1.01909e-05\n",
      "[1972]\ttraining's binary_logloss: 1.01741e-05\n",
      "[1973]\ttraining's binary_logloss: 1.01565e-05\n",
      "[1974]\ttraining's binary_logloss: 1.01398e-05\n",
      "[1975]\ttraining's binary_logloss: 1.01203e-05\n",
      "[1976]\ttraining's binary_logloss: 1.01007e-05\n",
      "[1977]\ttraining's binary_logloss: 1.00837e-05\n",
      "[1978]\ttraining's binary_logloss: 1.00654e-05\n",
      "[1979]\ttraining's binary_logloss: 1.00447e-05\n",
      "[1980]\ttraining's binary_logloss: 1.00281e-05\n",
      "[1981]\ttraining's binary_logloss: 1.00125e-05\n",
      "[1982]\ttraining's binary_logloss: 9.9937e-06\n",
      "[1983]\ttraining's binary_logloss: 9.97586e-06\n",
      "[1984]\ttraining's binary_logloss: 9.95823e-06\n",
      "[1985]\ttraining's binary_logloss: 9.94136e-06\n",
      "[1986]\ttraining's binary_logloss: 9.92375e-06\n",
      "[1987]\ttraining's binary_logloss: 9.90646e-06\n",
      "[1988]\ttraining's binary_logloss: 9.89102e-06\n",
      "[1989]\ttraining's binary_logloss: 9.87702e-06\n",
      "[1990]\ttraining's binary_logloss: 9.86053e-06\n",
      "[1991]\ttraining's binary_logloss: 9.84475e-06\n",
      "[1992]\ttraining's binary_logloss: 9.82864e-06\n",
      "[1993]\ttraining's binary_logloss: 9.81208e-06\n",
      "[1994]\ttraining's binary_logloss: 9.79468e-06\n",
      "[1995]\ttraining's binary_logloss: 9.77814e-06\n",
      "[1996]\ttraining's binary_logloss: 9.76236e-06\n",
      "[1997]\ttraining's binary_logloss: 9.748e-06\n",
      "[1998]\ttraining's binary_logloss: 9.73516e-06\n",
      "[1999]\ttraining's binary_logloss: 9.71986e-06\n",
      "[2000]\ttraining's binary_logloss: 9.70602e-06\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = lgb.train(\n",
    "    lgbm_params,\n",
    "    lgtrain,\n",
    "    valid_sets=lgtrain,\n",
    "    num_boost_round=2000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lgb = lgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lgb = np.array([0 if i < 0.6 else 1 for i in predict_lgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7988009557998792"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(predict_lgb, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV based auroc score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(rf, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8596627858253821"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search, tune parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameters to search\n",
    "gridParams = {\n",
    "    'learning_rate': [0.0125, 0.0175, 0.0225],\n",
    "    'n_estimators': [40],\n",
    "    'num_leaves': [170, 220, 270, 320],\n",
    "    #'max_depth': [15, 25, 35],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'feature_fraction': [0.4, 0.5, 0.6]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classifier to use. Note that parameters have to be input manually\n",
    "# not as a dict!\n",
    "mdl = lgb.LGBMClassifier(boosting_type= 'gbdt', objective = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(mdl, gridParams, verbose=0, cv=5, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "        n_jobs=-1, num_leaves=31, objective='binary', random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=0),\n",
       "       fit_params=None, iid=True, n_jobs=2,\n",
       "       param_grid={'learning_rate': [0.0125, 0.0175, 0.0225], 'n_estimators': [40], 'num_leaves': [170, 220, 270, 320], 'boosting_type': ['gbdt'], 'objective': ['binary'], 'feature_fraction': [0.4, 0.5, 0.6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'gbdt', 'feature_fraction': 0.5, 'learning_rate': 0.0225, 'n_estimators': 40, 'num_leaves': 320, 'objective': 'binary'}\n",
      "0.8844150432336702\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters found\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using parameters already set above, replace in the best from the grid search\n",
    "\n",
    "# params['max_bin'] = grid.best_params_['max_bin']\n",
    "lgbm_params['feature_fraction'] = grid.best_params_['feature_fraction']\n",
    "lgbm_params['learning_rate'] = grid.best_params_['learning_rate']\n",
    "lgbm_params['num_leaves'] = grid.best_params_['num_leaves']\n",
    "#lgbm_params['max_depth'] = grid.best_params_['max_depth']\n",
    "#lgbm_params['reg_alpha'] = grid.best_params_['reg_alpha']\n",
    "#lgbm_params['reg_lambda'] = grid.best_params_['reg_lambda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with params: \n",
      "{'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'binary_logloss', 'num_leaves': 320, 'feature_fraction': 0.5, 'bagging_fraction': 0.75, 'bagging_freq': 2, 'learning_rate': 0.0225, 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "print('Fitting with params: ')\n",
    "print(lgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'binary_logloss', 'num_leaves': 320, 'feature_fraction': 0.5, 'bagging_fraction': 0.75, 'bagging_freq': 2, 'learning_rate': 0.0225, 'verbose': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgtrain = lgb.Dataset(X_train, y_train)\n",
    "lgtest = lgb.Dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.48389\n",
      "[2]\ttraining's binary_logloss: 0.474278\n",
      "[3]\ttraining's binary_logloss: 0.465419\n",
      "[4]\ttraining's binary_logloss: 0.457028\n",
      "[5]\ttraining's binary_logloss: 0.449707\n",
      "[6]\ttraining's binary_logloss: 0.441757\n",
      "[7]\ttraining's binary_logloss: 0.434344\n",
      "[8]\ttraining's binary_logloss: 0.426919\n",
      "[9]\ttraining's binary_logloss: 0.420335\n",
      "[10]\ttraining's binary_logloss: 0.413895\n",
      "[11]\ttraining's binary_logloss: 0.407566\n",
      "[12]\ttraining's binary_logloss: 0.40167\n",
      "[13]\ttraining's binary_logloss: 0.39614\n",
      "[14]\ttraining's binary_logloss: 0.390756\n",
      "[15]\ttraining's binary_logloss: 0.385582\n",
      "[16]\ttraining's binary_logloss: 0.38014\n",
      "[17]\ttraining's binary_logloss: 0.375172\n",
      "[18]\ttraining's binary_logloss: 0.370514\n",
      "[19]\ttraining's binary_logloss: 0.365811\n",
      "[20]\ttraining's binary_logloss: 0.361176\n",
      "[21]\ttraining's binary_logloss: 0.356688\n",
      "[22]\ttraining's binary_logloss: 0.352116\n",
      "[23]\ttraining's binary_logloss: 0.34796\n",
      "[24]\ttraining's binary_logloss: 0.343785\n",
      "[25]\ttraining's binary_logloss: 0.339794\n",
      "[26]\ttraining's binary_logloss: 0.33588\n",
      "[27]\ttraining's binary_logloss: 0.331926\n",
      "[28]\ttraining's binary_logloss: 0.328377\n",
      "[29]\ttraining's binary_logloss: 0.324875\n",
      "[30]\ttraining's binary_logloss: 0.321391\n",
      "[31]\ttraining's binary_logloss: 0.31785\n",
      "[32]\ttraining's binary_logloss: 0.314609\n",
      "[33]\ttraining's binary_logloss: 0.311225\n",
      "[34]\ttraining's binary_logloss: 0.307998\n",
      "[35]\ttraining's binary_logloss: 0.304963\n",
      "[36]\ttraining's binary_logloss: 0.301751\n",
      "[37]\ttraining's binary_logloss: 0.298596\n",
      "[38]\ttraining's binary_logloss: 0.295711\n",
      "[39]\ttraining's binary_logloss: 0.292763\n",
      "[40]\ttraining's binary_logloss: 0.289903\n",
      "[41]\ttraining's binary_logloss: 0.28704\n",
      "[42]\ttraining's binary_logloss: 0.284316\n",
      "[43]\ttraining's binary_logloss: 0.281667\n",
      "[44]\ttraining's binary_logloss: 0.279147\n",
      "[45]\ttraining's binary_logloss: 0.276534\n",
      "[46]\ttraining's binary_logloss: 0.274064\n",
      "[47]\ttraining's binary_logloss: 0.27163\n",
      "[48]\ttraining's binary_logloss: 0.269189\n",
      "[49]\ttraining's binary_logloss: 0.266743\n",
      "[50]\ttraining's binary_logloss: 0.264314\n",
      "[51]\ttraining's binary_logloss: 0.262045\n",
      "[52]\ttraining's binary_logloss: 0.25983\n",
      "[53]\ttraining's binary_logloss: 0.257627\n",
      "[54]\ttraining's binary_logloss: 0.255391\n",
      "[55]\ttraining's binary_logloss: 0.253225\n",
      "[56]\ttraining's binary_logloss: 0.25102\n",
      "[57]\ttraining's binary_logloss: 0.24882\n",
      "[58]\ttraining's binary_logloss: 0.246724\n",
      "[59]\ttraining's binary_logloss: 0.244707\n",
      "[60]\ttraining's binary_logloss: 0.242665\n",
      "[61]\ttraining's binary_logloss: 0.240807\n",
      "[62]\ttraining's binary_logloss: 0.238826\n",
      "[63]\ttraining's binary_logloss: 0.236873\n",
      "[64]\ttraining's binary_logloss: 0.235035\n",
      "[65]\ttraining's binary_logloss: 0.233135\n",
      "[66]\ttraining's binary_logloss: 0.231166\n",
      "[67]\ttraining's binary_logloss: 0.229303\n",
      "[68]\ttraining's binary_logloss: 0.227568\n",
      "[69]\ttraining's binary_logloss: 0.225828\n",
      "[70]\ttraining's binary_logloss: 0.224051\n",
      "[71]\ttraining's binary_logloss: 0.222278\n",
      "[72]\ttraining's binary_logloss: 0.220558\n",
      "[73]\ttraining's binary_logloss: 0.218765\n",
      "[74]\ttraining's binary_logloss: 0.217069\n",
      "[75]\ttraining's binary_logloss: 0.215451\n",
      "[76]\ttraining's binary_logloss: 0.213757\n",
      "[77]\ttraining's binary_logloss: 0.212185\n",
      "[78]\ttraining's binary_logloss: 0.210671\n",
      "[79]\ttraining's binary_logloss: 0.209083\n",
      "[80]\ttraining's binary_logloss: 0.207497\n",
      "[81]\ttraining's binary_logloss: 0.205949\n",
      "[82]\ttraining's binary_logloss: 0.204476\n",
      "[83]\ttraining's binary_logloss: 0.202964\n",
      "[84]\ttraining's binary_logloss: 0.20142\n",
      "[85]\ttraining's binary_logloss: 0.200025\n",
      "[86]\ttraining's binary_logloss: 0.198529\n",
      "[87]\ttraining's binary_logloss: 0.196976\n",
      "[88]\ttraining's binary_logloss: 0.195546\n",
      "[89]\ttraining's binary_logloss: 0.194201\n",
      "[90]\ttraining's binary_logloss: 0.192775\n",
      "[91]\ttraining's binary_logloss: 0.191268\n",
      "[92]\ttraining's binary_logloss: 0.189935\n",
      "[93]\ttraining's binary_logloss: 0.188561\n",
      "[94]\ttraining's binary_logloss: 0.187187\n",
      "[95]\ttraining's binary_logloss: 0.185834\n",
      "[96]\ttraining's binary_logloss: 0.184448\n",
      "[97]\ttraining's binary_logloss: 0.18319\n",
      "[98]\ttraining's binary_logloss: 0.181883\n",
      "[99]\ttraining's binary_logloss: 0.180548\n",
      "[100]\ttraining's binary_logloss: 0.179316\n",
      "[101]\ttraining's binary_logloss: 0.177953\n",
      "[102]\ttraining's binary_logloss: 0.176676\n",
      "[103]\ttraining's binary_logloss: 0.175366\n",
      "[104]\ttraining's binary_logloss: 0.174167\n",
      "[105]\ttraining's binary_logloss: 0.172906\n",
      "[106]\ttraining's binary_logloss: 0.171642\n",
      "[107]\ttraining's binary_logloss: 0.170473\n",
      "[108]\ttraining's binary_logloss: 0.169299\n",
      "[109]\ttraining's binary_logloss: 0.168141\n",
      "[110]\ttraining's binary_logloss: 0.167043\n",
      "[111]\ttraining's binary_logloss: 0.165885\n",
      "[112]\ttraining's binary_logloss: 0.164785\n",
      "[113]\ttraining's binary_logloss: 0.16351\n",
      "[114]\ttraining's binary_logloss: 0.162349\n",
      "[115]\ttraining's binary_logloss: 0.161207\n",
      "[116]\ttraining's binary_logloss: 0.160102\n",
      "[117]\ttraining's binary_logloss: 0.158935\n",
      "[118]\ttraining's binary_logloss: 0.157782\n",
      "[119]\ttraining's binary_logloss: 0.156673\n",
      "[120]\ttraining's binary_logloss: 0.155495\n",
      "[121]\ttraining's binary_logloss: 0.154451\n",
      "[122]\ttraining's binary_logloss: 0.153344\n",
      "[123]\ttraining's binary_logloss: 0.152283\n",
      "[124]\ttraining's binary_logloss: 0.151225\n",
      "[125]\ttraining's binary_logloss: 0.150157\n",
      "[126]\ttraining's binary_logloss: 0.14907\n",
      "[127]\ttraining's binary_logloss: 0.148051\n",
      "[128]\ttraining's binary_logloss: 0.147054\n",
      "[129]\ttraining's binary_logloss: 0.145918\n",
      "[130]\ttraining's binary_logloss: 0.144898\n",
      "[131]\ttraining's binary_logloss: 0.143899\n",
      "[132]\ttraining's binary_logloss: 0.142856\n",
      "[133]\ttraining's binary_logloss: 0.141863\n",
      "[134]\ttraining's binary_logloss: 0.140812\n",
      "[135]\ttraining's binary_logloss: 0.139869\n",
      "[136]\ttraining's binary_logloss: 0.138898\n",
      "[137]\ttraining's binary_logloss: 0.138016\n",
      "[138]\ttraining's binary_logloss: 0.137116\n",
      "[139]\ttraining's binary_logloss: 0.136234\n",
      "[140]\ttraining's binary_logloss: 0.135283\n",
      "[141]\ttraining's binary_logloss: 0.134418\n",
      "[142]\ttraining's binary_logloss: 0.133557\n",
      "[143]\ttraining's binary_logloss: 0.132647\n",
      "[144]\ttraining's binary_logloss: 0.131731\n",
      "[145]\ttraining's binary_logloss: 0.130788\n",
      "[146]\ttraining's binary_logloss: 0.129894\n",
      "[147]\ttraining's binary_logloss: 0.129033\n",
      "[148]\ttraining's binary_logloss: 0.128124\n",
      "[149]\ttraining's binary_logloss: 0.127225\n",
      "[150]\ttraining's binary_logloss: 0.12638\n",
      "[151]\ttraining's binary_logloss: 0.125552\n",
      "[152]\ttraining's binary_logloss: 0.124684\n",
      "[153]\ttraining's binary_logloss: 0.123791\n",
      "[154]\ttraining's binary_logloss: 0.122956\n",
      "[155]\ttraining's binary_logloss: 0.12207\n",
      "[156]\ttraining's binary_logloss: 0.121267\n",
      "[157]\ttraining's binary_logloss: 0.120388\n",
      "[158]\ttraining's binary_logloss: 0.119561\n",
      "[159]\ttraining's binary_logloss: 0.118714\n",
      "[160]\ttraining's binary_logloss: 0.117846\n",
      "[161]\ttraining's binary_logloss: 0.117083\n",
      "[162]\ttraining's binary_logloss: 0.116238\n",
      "[163]\ttraining's binary_logloss: 0.115433\n",
      "[164]\ttraining's binary_logloss: 0.114669\n",
      "[165]\ttraining's binary_logloss: 0.113867\n",
      "[166]\ttraining's binary_logloss: 0.113134\n",
      "[167]\ttraining's binary_logloss: 0.112297\n",
      "[168]\ttraining's binary_logloss: 0.111495\n",
      "[169]\ttraining's binary_logloss: 0.110681\n",
      "[170]\ttraining's binary_logloss: 0.109914\n",
      "[171]\ttraining's binary_logloss: 0.109045\n",
      "[172]\ttraining's binary_logloss: 0.108318\n",
      "[173]\ttraining's binary_logloss: 0.107609\n",
      "[174]\ttraining's binary_logloss: 0.106945\n",
      "[175]\ttraining's binary_logloss: 0.106254\n",
      "[176]\ttraining's binary_logloss: 0.105544\n",
      "[177]\ttraining's binary_logloss: 0.104791\n",
      "[178]\ttraining's binary_logloss: 0.104062\n",
      "[179]\ttraining's binary_logloss: 0.103398\n",
      "[180]\ttraining's binary_logloss: 0.102694\n",
      "[181]\ttraining's binary_logloss: 0.102016\n",
      "[182]\ttraining's binary_logloss: 0.10126\n",
      "[183]\ttraining's binary_logloss: 0.100562\n",
      "[184]\ttraining's binary_logloss: 0.09985\n",
      "[185]\ttraining's binary_logloss: 0.0991335\n",
      "[186]\ttraining's binary_logloss: 0.0984561\n",
      "[187]\ttraining's binary_logloss: 0.097779\n",
      "[188]\ttraining's binary_logloss: 0.0971024\n",
      "[189]\ttraining's binary_logloss: 0.096436\n",
      "[190]\ttraining's binary_logloss: 0.0958268\n",
      "[191]\ttraining's binary_logloss: 0.0951621\n",
      "[192]\ttraining's binary_logloss: 0.0944561\n",
      "[193]\ttraining's binary_logloss: 0.0938171\n",
      "[194]\ttraining's binary_logloss: 0.0932061\n",
      "[195]\ttraining's binary_logloss: 0.0925596\n",
      "[196]\ttraining's binary_logloss: 0.0919416\n",
      "[197]\ttraining's binary_logloss: 0.0912845\n",
      "[198]\ttraining's binary_logloss: 0.0906135\n",
      "[199]\ttraining's binary_logloss: 0.0899927\n",
      "[200]\ttraining's binary_logloss: 0.0893651\n",
      "[201]\ttraining's binary_logloss: 0.0887293\n",
      "[202]\ttraining's binary_logloss: 0.0881344\n",
      "[203]\ttraining's binary_logloss: 0.0875016\n",
      "[204]\ttraining's binary_logloss: 0.0869135\n",
      "[205]\ttraining's binary_logloss: 0.0863496\n",
      "[206]\ttraining's binary_logloss: 0.0857757\n",
      "[207]\ttraining's binary_logloss: 0.0852042\n",
      "[208]\ttraining's binary_logloss: 0.0846026\n",
      "[209]\ttraining's binary_logloss: 0.0840149\n",
      "[210]\ttraining's binary_logloss: 0.0835043\n",
      "[211]\ttraining's binary_logloss: 0.0829857\n",
      "[212]\ttraining's binary_logloss: 0.0824953\n",
      "[213]\ttraining's binary_logloss: 0.0819818\n",
      "[214]\ttraining's binary_logloss: 0.0814433\n",
      "[215]\ttraining's binary_logloss: 0.080919\n",
      "[216]\ttraining's binary_logloss: 0.0803866\n",
      "[217]\ttraining's binary_logloss: 0.07984\n",
      "[218]\ttraining's binary_logloss: 0.0792693\n",
      "[219]\ttraining's binary_logloss: 0.0787457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[220]\ttraining's binary_logloss: 0.078174\n",
      "[221]\ttraining's binary_logloss: 0.0776206\n",
      "[222]\ttraining's binary_logloss: 0.0770574\n",
      "[223]\ttraining's binary_logloss: 0.0765112\n",
      "[224]\ttraining's binary_logloss: 0.0760052\n",
      "[225]\ttraining's binary_logloss: 0.0754996\n",
      "[226]\ttraining's binary_logloss: 0.0749912\n",
      "[227]\ttraining's binary_logloss: 0.0744813\n",
      "[228]\ttraining's binary_logloss: 0.0739605\n",
      "[229]\ttraining's binary_logloss: 0.0735121\n",
      "[230]\ttraining's binary_logloss: 0.0730239\n",
      "[231]\ttraining's binary_logloss: 0.0725395\n",
      "[232]\ttraining's binary_logloss: 0.0720216\n",
      "[233]\ttraining's binary_logloss: 0.0715387\n",
      "[234]\ttraining's binary_logloss: 0.0710778\n",
      "[235]\ttraining's binary_logloss: 0.0706146\n",
      "[236]\ttraining's binary_logloss: 0.0701231\n",
      "[237]\ttraining's binary_logloss: 0.0696934\n",
      "[238]\ttraining's binary_logloss: 0.0691961\n",
      "[239]\ttraining's binary_logloss: 0.0687162\n",
      "[240]\ttraining's binary_logloss: 0.0682545\n",
      "[241]\ttraining's binary_logloss: 0.0678161\n",
      "[242]\ttraining's binary_logloss: 0.0673949\n",
      "[243]\ttraining's binary_logloss: 0.0669676\n",
      "[244]\ttraining's binary_logloss: 0.0665229\n",
      "[245]\ttraining's binary_logloss: 0.0660528\n",
      "[246]\ttraining's binary_logloss: 0.0656062\n",
      "[247]\ttraining's binary_logloss: 0.0651624\n",
      "[248]\ttraining's binary_logloss: 0.0647381\n",
      "[249]\ttraining's binary_logloss: 0.0642847\n",
      "[250]\ttraining's binary_logloss: 0.0638581\n",
      "[251]\ttraining's binary_logloss: 0.06344\n",
      "[252]\ttraining's binary_logloss: 0.0630531\n",
      "[253]\ttraining's binary_logloss: 0.0626722\n",
      "[254]\ttraining's binary_logloss: 0.0622765\n",
      "[255]\ttraining's binary_logloss: 0.0618364\n",
      "[256]\ttraining's binary_logloss: 0.061433\n",
      "[257]\ttraining's binary_logloss: 0.0610247\n",
      "[258]\ttraining's binary_logloss: 0.0606643\n",
      "[259]\ttraining's binary_logloss: 0.0602542\n",
      "[260]\ttraining's binary_logloss: 0.0598294\n",
      "[261]\ttraining's binary_logloss: 0.0594156\n",
      "[262]\ttraining's binary_logloss: 0.059027\n",
      "[263]\ttraining's binary_logloss: 0.0586649\n",
      "[264]\ttraining's binary_logloss: 0.0582875\n",
      "[265]\ttraining's binary_logloss: 0.0579197\n",
      "[266]\ttraining's binary_logloss: 0.0575503\n",
      "[267]\ttraining's binary_logloss: 0.0571957\n",
      "[268]\ttraining's binary_logloss: 0.0567927\n",
      "[269]\ttraining's binary_logloss: 0.0564421\n",
      "[270]\ttraining's binary_logloss: 0.0560656\n",
      "[271]\ttraining's binary_logloss: 0.0557202\n",
      "[272]\ttraining's binary_logloss: 0.0553626\n",
      "[273]\ttraining's binary_logloss: 0.0550011\n",
      "[274]\ttraining's binary_logloss: 0.0546002\n",
      "[275]\ttraining's binary_logloss: 0.0542049\n",
      "[276]\ttraining's binary_logloss: 0.0538394\n",
      "[277]\ttraining's binary_logloss: 0.0535113\n",
      "[278]\ttraining's binary_logloss: 0.053131\n",
      "[279]\ttraining's binary_logloss: 0.0527248\n",
      "[280]\ttraining's binary_logloss: 0.0523538\n",
      "[281]\ttraining's binary_logloss: 0.0520154\n",
      "[282]\ttraining's binary_logloss: 0.0516795\n",
      "[283]\ttraining's binary_logloss: 0.0513235\n",
      "[284]\ttraining's binary_logloss: 0.0510067\n",
      "[285]\ttraining's binary_logloss: 0.0506698\n",
      "[286]\ttraining's binary_logloss: 0.0503272\n",
      "[287]\ttraining's binary_logloss: 0.0500472\n",
      "[288]\ttraining's binary_logloss: 0.0497237\n",
      "[289]\ttraining's binary_logloss: 0.0493868\n",
      "[290]\ttraining's binary_logloss: 0.0490561\n",
      "[291]\ttraining's binary_logloss: 0.048739\n",
      "[292]\ttraining's binary_logloss: 0.048444\n",
      "[293]\ttraining's binary_logloss: 0.0481207\n",
      "[294]\ttraining's binary_logloss: 0.0478126\n",
      "[295]\ttraining's binary_logloss: 0.0475163\n",
      "[296]\ttraining's binary_logloss: 0.0472\n",
      "[297]\ttraining's binary_logloss: 0.0468743\n",
      "[298]\ttraining's binary_logloss: 0.0465651\n",
      "[299]\ttraining's binary_logloss: 0.0462799\n",
      "[300]\ttraining's binary_logloss: 0.0459647\n",
      "[301]\ttraining's binary_logloss: 0.0456547\n",
      "[302]\ttraining's binary_logloss: 0.0453626\n",
      "[303]\ttraining's binary_logloss: 0.045074\n",
      "[304]\ttraining's binary_logloss: 0.044784\n",
      "[305]\ttraining's binary_logloss: 0.0444812\n",
      "[306]\ttraining's binary_logloss: 0.0442042\n",
      "[307]\ttraining's binary_logloss: 0.0439177\n",
      "[308]\ttraining's binary_logloss: 0.0436461\n",
      "[309]\ttraining's binary_logloss: 0.0433738\n",
      "[310]\ttraining's binary_logloss: 0.0430868\n",
      "[311]\ttraining's binary_logloss: 0.0428418\n",
      "[312]\ttraining's binary_logloss: 0.042602\n",
      "[313]\ttraining's binary_logloss: 0.0423211\n",
      "[314]\ttraining's binary_logloss: 0.0420577\n",
      "[315]\ttraining's binary_logloss: 0.0417742\n",
      "[316]\ttraining's binary_logloss: 0.0415067\n",
      "[317]\ttraining's binary_logloss: 0.0412366\n",
      "[318]\ttraining's binary_logloss: 0.0409856\n",
      "[319]\ttraining's binary_logloss: 0.0406892\n",
      "[320]\ttraining's binary_logloss: 0.040435\n",
      "[321]\ttraining's binary_logloss: 0.0401732\n",
      "[322]\ttraining's binary_logloss: 0.0399282\n",
      "[323]\ttraining's binary_logloss: 0.0396797\n",
      "[324]\ttraining's binary_logloss: 0.0394374\n",
      "[325]\ttraining's binary_logloss: 0.039193\n",
      "[326]\ttraining's binary_logloss: 0.0389533\n",
      "[327]\ttraining's binary_logloss: 0.0386968\n",
      "[328]\ttraining's binary_logloss: 0.0384623\n",
      "[329]\ttraining's binary_logloss: 0.0382018\n",
      "[330]\ttraining's binary_logloss: 0.0379537\n",
      "[331]\ttraining's binary_logloss: 0.0377134\n",
      "[332]\ttraining's binary_logloss: 0.0374632\n",
      "[333]\ttraining's binary_logloss: 0.0372184\n",
      "[334]\ttraining's binary_logloss: 0.0369894\n",
      "[335]\ttraining's binary_logloss: 0.0367669\n",
      "[336]\ttraining's binary_logloss: 0.0365556\n",
      "[337]\ttraining's binary_logloss: 0.0363485\n",
      "[338]\ttraining's binary_logloss: 0.0361091\n",
      "[339]\ttraining's binary_logloss: 0.0358931\n",
      "[340]\ttraining's binary_logloss: 0.0356745\n",
      "[341]\ttraining's binary_logloss: 0.0354458\n",
      "[342]\ttraining's binary_logloss: 0.0352084\n",
      "[343]\ttraining's binary_logloss: 0.0349919\n",
      "[344]\ttraining's binary_logloss: 0.0347811\n",
      "[345]\ttraining's binary_logloss: 0.0345737\n",
      "[346]\ttraining's binary_logloss: 0.0343524\n",
      "[347]\ttraining's binary_logloss: 0.0341235\n",
      "[348]\ttraining's binary_logloss: 0.0338945\n",
      "[349]\ttraining's binary_logloss: 0.0336867\n",
      "[350]\ttraining's binary_logloss: 0.0334712\n",
      "[351]\ttraining's binary_logloss: 0.0332554\n",
      "[352]\ttraining's binary_logloss: 0.0330629\n",
      "[353]\ttraining's binary_logloss: 0.0328657\n",
      "[354]\ttraining's binary_logloss: 0.0326491\n",
      "[355]\ttraining's binary_logloss: 0.03245\n",
      "[356]\ttraining's binary_logloss: 0.032234\n",
      "[357]\ttraining's binary_logloss: 0.032023\n",
      "[358]\ttraining's binary_logloss: 0.0318063\n",
      "[359]\ttraining's binary_logloss: 0.0316041\n",
      "[360]\ttraining's binary_logloss: 0.0314165\n",
      "[361]\ttraining's binary_logloss: 0.0312439\n",
      "[362]\ttraining's binary_logloss: 0.0310625\n",
      "[363]\ttraining's binary_logloss: 0.0308718\n",
      "[364]\ttraining's binary_logloss: 0.0306873\n",
      "[365]\ttraining's binary_logloss: 0.0305074\n",
      "[366]\ttraining's binary_logloss: 0.0303409\n",
      "[367]\ttraining's binary_logloss: 0.0301551\n",
      "[368]\ttraining's binary_logloss: 0.0299741\n",
      "[369]\ttraining's binary_logloss: 0.0297747\n",
      "[370]\ttraining's binary_logloss: 0.0295662\n",
      "[371]\ttraining's binary_logloss: 0.0293802\n",
      "[372]\ttraining's binary_logloss: 0.0291886\n",
      "[373]\ttraining's binary_logloss: 0.0289764\n",
      "[374]\ttraining's binary_logloss: 0.0287946\n",
      "[375]\ttraining's binary_logloss: 0.0286268\n",
      "[376]\ttraining's binary_logloss: 0.0284586\n",
      "[377]\ttraining's binary_logloss: 0.0282892\n",
      "[378]\ttraining's binary_logloss: 0.0281189\n",
      "[379]\ttraining's binary_logloss: 0.0279391\n",
      "[380]\ttraining's binary_logloss: 0.0277586\n",
      "[381]\ttraining's binary_logloss: 0.0275879\n",
      "[382]\ttraining's binary_logloss: 0.0274139\n",
      "[383]\ttraining's binary_logloss: 0.0272431\n",
      "[384]\ttraining's binary_logloss: 0.0270786\n",
      "[385]\ttraining's binary_logloss: 0.0269105\n",
      "[386]\ttraining's binary_logloss: 0.0267494\n",
      "[387]\ttraining's binary_logloss: 0.0266015\n",
      "[388]\ttraining's binary_logloss: 0.026459\n",
      "[389]\ttraining's binary_logloss: 0.0263024\n",
      "[390]\ttraining's binary_logloss: 0.026142\n",
      "[391]\ttraining's binary_logloss: 0.0259887\n",
      "[392]\ttraining's binary_logloss: 0.0258404\n",
      "[393]\ttraining's binary_logloss: 0.0256966\n",
      "[394]\ttraining's binary_logloss: 0.0255466\n",
      "[395]\ttraining's binary_logloss: 0.025381\n",
      "[396]\ttraining's binary_logloss: 0.0252384\n",
      "[397]\ttraining's binary_logloss: 0.0250845\n",
      "[398]\ttraining's binary_logloss: 0.0249304\n",
      "[399]\ttraining's binary_logloss: 0.0247907\n",
      "[400]\ttraining's binary_logloss: 0.02464\n",
      "[401]\ttraining's binary_logloss: 0.0245066\n",
      "[402]\ttraining's binary_logloss: 0.0243691\n",
      "[403]\ttraining's binary_logloss: 0.0242169\n",
      "[404]\ttraining's binary_logloss: 0.0240586\n",
      "[405]\ttraining's binary_logloss: 0.0238929\n",
      "[406]\ttraining's binary_logloss: 0.0237509\n",
      "[407]\ttraining's binary_logloss: 0.0236053\n",
      "[408]\ttraining's binary_logloss: 0.0234506\n",
      "[409]\ttraining's binary_logloss: 0.0232926\n",
      "[410]\ttraining's binary_logloss: 0.023143\n",
      "[411]\ttraining's binary_logloss: 0.023\n",
      "[412]\ttraining's binary_logloss: 0.022864\n",
      "[413]\ttraining's binary_logloss: 0.022736\n",
      "[414]\ttraining's binary_logloss: 0.0225937\n",
      "[415]\ttraining's binary_logloss: 0.0224534\n",
      "[416]\ttraining's binary_logloss: 0.0223085\n",
      "[417]\ttraining's binary_logloss: 0.0221728\n",
      "[418]\ttraining's binary_logloss: 0.0220428\n",
      "[419]\ttraining's binary_logloss: 0.0219213\n",
      "[420]\ttraining's binary_logloss: 0.0217951\n",
      "[421]\ttraining's binary_logloss: 0.0216604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[422]\ttraining's binary_logloss: 0.0215401\n",
      "[423]\ttraining's binary_logloss: 0.0214098\n",
      "[424]\ttraining's binary_logloss: 0.0212868\n",
      "[425]\ttraining's binary_logloss: 0.0211618\n",
      "[426]\ttraining's binary_logloss: 0.0210383\n",
      "[427]\ttraining's binary_logloss: 0.0209066\n",
      "[428]\ttraining's binary_logloss: 0.0207839\n",
      "[429]\ttraining's binary_logloss: 0.0206506\n",
      "[430]\ttraining's binary_logloss: 0.0205182\n",
      "[431]\ttraining's binary_logloss: 0.0203889\n",
      "[432]\ttraining's binary_logloss: 0.0202745\n",
      "[433]\ttraining's binary_logloss: 0.020153\n",
      "[434]\ttraining's binary_logloss: 0.020022\n",
      "[435]\ttraining's binary_logloss: 0.0199043\n",
      "[436]\ttraining's binary_logloss: 0.0197824\n",
      "[437]\ttraining's binary_logloss: 0.0196756\n",
      "[438]\ttraining's binary_logloss: 0.0195644\n",
      "[439]\ttraining's binary_logloss: 0.0194422\n",
      "[440]\ttraining's binary_logloss: 0.0193272\n",
      "[441]\ttraining's binary_logloss: 0.0192142\n",
      "[442]\ttraining's binary_logloss: 0.01912\n",
      "[443]\ttraining's binary_logloss: 0.0189857\n",
      "[444]\ttraining's binary_logloss: 0.0188637\n",
      "[445]\ttraining's binary_logloss: 0.018757\n",
      "[446]\ttraining's binary_logloss: 0.0186405\n",
      "[447]\ttraining's binary_logloss: 0.0185085\n",
      "[448]\ttraining's binary_logloss: 0.0183884\n",
      "[449]\ttraining's binary_logloss: 0.0182764\n",
      "[450]\ttraining's binary_logloss: 0.0181661\n",
      "[451]\ttraining's binary_logloss: 0.0180517\n",
      "[452]\ttraining's binary_logloss: 0.0179468\n",
      "[453]\ttraining's binary_logloss: 0.0178401\n",
      "[454]\ttraining's binary_logloss: 0.0177384\n",
      "[455]\ttraining's binary_logloss: 0.0176366\n",
      "[456]\ttraining's binary_logloss: 0.0175342\n",
      "[457]\ttraining's binary_logloss: 0.0174358\n",
      "[458]\ttraining's binary_logloss: 0.0173372\n",
      "[459]\ttraining's binary_logloss: 0.017237\n",
      "[460]\ttraining's binary_logloss: 0.0171436\n",
      "[461]\ttraining's binary_logloss: 0.0170401\n",
      "[462]\ttraining's binary_logloss: 0.0169354\n",
      "[463]\ttraining's binary_logloss: 0.0168398\n",
      "[464]\ttraining's binary_logloss: 0.0167435\n",
      "[465]\ttraining's binary_logloss: 0.0166525\n",
      "[466]\ttraining's binary_logloss: 0.0165558\n",
      "[467]\ttraining's binary_logloss: 0.0164448\n",
      "[468]\ttraining's binary_logloss: 0.0163424\n",
      "[469]\ttraining's binary_logloss: 0.016253\n",
      "[470]\ttraining's binary_logloss: 0.0161583\n",
      "[471]\ttraining's binary_logloss: 0.0160612\n",
      "[472]\ttraining's binary_logloss: 0.0159694\n",
      "[473]\ttraining's binary_logloss: 0.0158733\n",
      "[474]\ttraining's binary_logloss: 0.0157776\n",
      "[475]\ttraining's binary_logloss: 0.0156838\n",
      "[476]\ttraining's binary_logloss: 0.0155926\n",
      "[477]\ttraining's binary_logloss: 0.0154861\n",
      "[478]\ttraining's binary_logloss: 0.0153973\n",
      "[479]\ttraining's binary_logloss: 0.0153137\n",
      "[480]\ttraining's binary_logloss: 0.0152324\n",
      "[481]\ttraining's binary_logloss: 0.0151451\n",
      "[482]\ttraining's binary_logloss: 0.0150568\n",
      "[483]\ttraining's binary_logloss: 0.0149749\n",
      "[484]\ttraining's binary_logloss: 0.0148899\n",
      "[485]\ttraining's binary_logloss: 0.0148076\n",
      "[486]\ttraining's binary_logloss: 0.0147238\n",
      "[487]\ttraining's binary_logloss: 0.0146386\n",
      "[488]\ttraining's binary_logloss: 0.0145584\n",
      "[489]\ttraining's binary_logloss: 0.0144732\n",
      "[490]\ttraining's binary_logloss: 0.0143796\n",
      "[491]\ttraining's binary_logloss: 0.014294\n",
      "[492]\ttraining's binary_logloss: 0.0142034\n",
      "[493]\ttraining's binary_logloss: 0.0141227\n",
      "[494]\ttraining's binary_logloss: 0.0140313\n",
      "[495]\ttraining's binary_logloss: 0.0139496\n",
      "[496]\ttraining's binary_logloss: 0.0138707\n",
      "[497]\ttraining's binary_logloss: 0.0137919\n",
      "[498]\ttraining's binary_logloss: 0.0137107\n",
      "[499]\ttraining's binary_logloss: 0.0136251\n",
      "[500]\ttraining's binary_logloss: 0.0135386\n",
      "[501]\ttraining's binary_logloss: 0.0134539\n",
      "[502]\ttraining's binary_logloss: 0.013378\n",
      "[503]\ttraining's binary_logloss: 0.0132934\n",
      "[504]\ttraining's binary_logloss: 0.0132183\n",
      "[505]\ttraining's binary_logloss: 0.0131398\n",
      "[506]\ttraining's binary_logloss: 0.013066\n",
      "[507]\ttraining's binary_logloss: 0.0129974\n",
      "[508]\ttraining's binary_logloss: 0.0129196\n",
      "[509]\ttraining's binary_logloss: 0.0128348\n",
      "[510]\ttraining's binary_logloss: 0.0127563\n",
      "[511]\ttraining's binary_logloss: 0.0126745\n",
      "[512]\ttraining's binary_logloss: 0.0125998\n",
      "[513]\ttraining's binary_logloss: 0.0125293\n",
      "[514]\ttraining's binary_logloss: 0.0124558\n",
      "[515]\ttraining's binary_logloss: 0.0123793\n",
      "[516]\ttraining's binary_logloss: 0.0123052\n",
      "[517]\ttraining's binary_logloss: 0.0122332\n",
      "[518]\ttraining's binary_logloss: 0.0121666\n",
      "[519]\ttraining's binary_logloss: 0.0120994\n",
      "[520]\ttraining's binary_logloss: 0.0120255\n",
      "[521]\ttraining's binary_logloss: 0.0119536\n",
      "[522]\ttraining's binary_logloss: 0.01188\n",
      "[523]\ttraining's binary_logloss: 0.0118106\n",
      "[524]\ttraining's binary_logloss: 0.011733\n",
      "[525]\ttraining's binary_logloss: 0.011664\n",
      "[526]\ttraining's binary_logloss: 0.0116001\n",
      "[527]\ttraining's binary_logloss: 0.0115152\n",
      "[528]\ttraining's binary_logloss: 0.0114471\n",
      "[529]\ttraining's binary_logloss: 0.0113752\n",
      "[530]\ttraining's binary_logloss: 0.0113124\n",
      "[531]\ttraining's binary_logloss: 0.0112455\n",
      "[532]\ttraining's binary_logloss: 0.0111819\n",
      "[533]\ttraining's binary_logloss: 0.0111134\n",
      "[534]\ttraining's binary_logloss: 0.0110415\n",
      "[535]\ttraining's binary_logloss: 0.0109703\n",
      "[536]\ttraining's binary_logloss: 0.0109048\n",
      "[537]\ttraining's binary_logloss: 0.0108433\n",
      "[538]\ttraining's binary_logloss: 0.0107779\n",
      "[539]\ttraining's binary_logloss: 0.010714\n",
      "[540]\ttraining's binary_logloss: 0.010655\n",
      "[541]\ttraining's binary_logloss: 0.0105869\n",
      "[542]\ttraining's binary_logloss: 0.010521\n",
      "[543]\ttraining's binary_logloss: 0.0104553\n",
      "[544]\ttraining's binary_logloss: 0.0103988\n",
      "[545]\ttraining's binary_logloss: 0.0103386\n",
      "[546]\ttraining's binary_logloss: 0.0102763\n",
      "[547]\ttraining's binary_logloss: 0.0102224\n",
      "[548]\ttraining's binary_logloss: 0.0101652\n",
      "[549]\ttraining's binary_logloss: 0.0100976\n",
      "[550]\ttraining's binary_logloss: 0.0100357\n",
      "[551]\ttraining's binary_logloss: 0.00998089\n",
      "[552]\ttraining's binary_logloss: 0.0099246\n",
      "[553]\ttraining's binary_logloss: 0.00986666\n",
      "[554]\ttraining's binary_logloss: 0.0097993\n",
      "[555]\ttraining's binary_logloss: 0.00974269\n",
      "[556]\ttraining's binary_logloss: 0.00968819\n",
      "[557]\ttraining's binary_logloss: 0.00962888\n",
      "[558]\ttraining's binary_logloss: 0.00957491\n",
      "[559]\ttraining's binary_logloss: 0.00951516\n",
      "[560]\ttraining's binary_logloss: 0.00945512\n",
      "[561]\ttraining's binary_logloss: 0.00940101\n",
      "[562]\ttraining's binary_logloss: 0.00935053\n",
      "[563]\ttraining's binary_logloss: 0.00928465\n",
      "[564]\ttraining's binary_logloss: 0.00922309\n",
      "[565]\ttraining's binary_logloss: 0.00916694\n",
      "[566]\ttraining's binary_logloss: 0.00910942\n",
      "[567]\ttraining's binary_logloss: 0.00906141\n",
      "[568]\ttraining's binary_logloss: 0.00900161\n",
      "[569]\ttraining's binary_logloss: 0.00894004\n",
      "[570]\ttraining's binary_logloss: 0.00888919\n",
      "[571]\ttraining's binary_logloss: 0.00884048\n",
      "[572]\ttraining's binary_logloss: 0.00879289\n",
      "[573]\ttraining's binary_logloss: 0.00874211\n",
      "[574]\ttraining's binary_logloss: 0.00868669\n",
      "[575]\ttraining's binary_logloss: 0.00862984\n",
      "[576]\ttraining's binary_logloss: 0.00858302\n",
      "[577]\ttraining's binary_logloss: 0.00853235\n",
      "[578]\ttraining's binary_logloss: 0.008485\n",
      "[579]\ttraining's binary_logloss: 0.0084384\n",
      "[580]\ttraining's binary_logloss: 0.00839\n",
      "[581]\ttraining's binary_logloss: 0.00834101\n",
      "[582]\ttraining's binary_logloss: 0.00829258\n",
      "[583]\ttraining's binary_logloss: 0.00824672\n",
      "[584]\ttraining's binary_logloss: 0.0081993\n",
      "[585]\ttraining's binary_logloss: 0.00815596\n",
      "[586]\ttraining's binary_logloss: 0.00810477\n",
      "[587]\ttraining's binary_logloss: 0.00804984\n",
      "[588]\ttraining's binary_logloss: 0.0080002\n",
      "[589]\ttraining's binary_logloss: 0.00795332\n",
      "[590]\ttraining's binary_logloss: 0.00790604\n",
      "[591]\ttraining's binary_logloss: 0.00785458\n",
      "[592]\ttraining's binary_logloss: 0.00780569\n",
      "[593]\ttraining's binary_logloss: 0.00776251\n",
      "[594]\ttraining's binary_logloss: 0.00772298\n",
      "[595]\ttraining's binary_logloss: 0.00767792\n",
      "[596]\ttraining's binary_logloss: 0.00763399\n",
      "[597]\ttraining's binary_logloss: 0.00758886\n",
      "[598]\ttraining's binary_logloss: 0.0075415\n",
      "[599]\ttraining's binary_logloss: 0.00750238\n",
      "[600]\ttraining's binary_logloss: 0.00746049\n",
      "[601]\ttraining's binary_logloss: 0.00742256\n",
      "[602]\ttraining's binary_logloss: 0.00737864\n",
      "[603]\ttraining's binary_logloss: 0.00732765\n",
      "[604]\ttraining's binary_logloss: 0.00728671\n",
      "[605]\ttraining's binary_logloss: 0.00724208\n",
      "[606]\ttraining's binary_logloss: 0.00718702\n",
      "[607]\ttraining's binary_logloss: 0.00714582\n",
      "[608]\ttraining's binary_logloss: 0.00709774\n",
      "[609]\ttraining's binary_logloss: 0.00705544\n",
      "[610]\ttraining's binary_logloss: 0.00700973\n",
      "[611]\ttraining's binary_logloss: 0.00696871\n",
      "[612]\ttraining's binary_logloss: 0.00693193\n",
      "[613]\ttraining's binary_logloss: 0.00689096\n",
      "[614]\ttraining's binary_logloss: 0.00685018\n",
      "[615]\ttraining's binary_logloss: 0.00680885\n",
      "[616]\ttraining's binary_logloss: 0.00676603\n",
      "[617]\ttraining's binary_logloss: 0.00672904\n",
      "[618]\ttraining's binary_logloss: 0.00668742\n",
      "[619]\ttraining's binary_logloss: 0.00664826\n",
      "[620]\ttraining's binary_logloss: 0.00660544\n",
      "[621]\ttraining's binary_logloss: 0.00656526\n",
      "[622]\ttraining's binary_logloss: 0.00652171\n",
      "[623]\ttraining's binary_logloss: 0.00648197\n",
      "[624]\ttraining's binary_logloss: 0.00644341\n",
      "[625]\ttraining's binary_logloss: 0.00640762\n",
      "[626]\ttraining's binary_logloss: 0.00637024\n",
      "[627]\ttraining's binary_logloss: 0.00633277\n",
      "[628]\ttraining's binary_logloss: 0.00629658\n",
      "[629]\ttraining's binary_logloss: 0.00625853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[630]\ttraining's binary_logloss: 0.00621669\n",
      "[631]\ttraining's binary_logloss: 0.006182\n",
      "[632]\ttraining's binary_logloss: 0.0061465\n",
      "[633]\ttraining's binary_logloss: 0.00610969\n",
      "[634]\ttraining's binary_logloss: 0.0060752\n",
      "[635]\ttraining's binary_logloss: 0.00603915\n",
      "[636]\ttraining's binary_logloss: 0.00600874\n",
      "[637]\ttraining's binary_logloss: 0.00597243\n",
      "[638]\ttraining's binary_logloss: 0.00593535\n",
      "[639]\ttraining's binary_logloss: 0.00589821\n",
      "[640]\ttraining's binary_logloss: 0.00586767\n",
      "[641]\ttraining's binary_logloss: 0.00583341\n",
      "[642]\ttraining's binary_logloss: 0.00580063\n",
      "[643]\ttraining's binary_logloss: 0.00575977\n",
      "[644]\ttraining's binary_logloss: 0.00572943\n",
      "[645]\ttraining's binary_logloss: 0.00569473\n",
      "[646]\ttraining's binary_logloss: 0.00566273\n",
      "[647]\ttraining's binary_logloss: 0.00562896\n",
      "[648]\ttraining's binary_logloss: 0.00559706\n",
      "[649]\ttraining's binary_logloss: 0.00556078\n",
      "[650]\ttraining's binary_logloss: 0.00553222\n",
      "[651]\ttraining's binary_logloss: 0.00549751\n",
      "[652]\ttraining's binary_logloss: 0.00546792\n",
      "[653]\ttraining's binary_logloss: 0.00543579\n",
      "[654]\ttraining's binary_logloss: 0.00540482\n",
      "[655]\ttraining's binary_logloss: 0.00537413\n",
      "[656]\ttraining's binary_logloss: 0.00534434\n",
      "[657]\ttraining's binary_logloss: 0.00531474\n",
      "[658]\ttraining's binary_logloss: 0.00528351\n",
      "[659]\ttraining's binary_logloss: 0.00525335\n",
      "[660]\ttraining's binary_logloss: 0.00522279\n",
      "[661]\ttraining's binary_logloss: 0.00519154\n",
      "[662]\ttraining's binary_logloss: 0.00516303\n",
      "[663]\ttraining's binary_logloss: 0.00513393\n",
      "[664]\ttraining's binary_logloss: 0.00510195\n",
      "[665]\ttraining's binary_logloss: 0.00507339\n",
      "[666]\ttraining's binary_logloss: 0.00504266\n",
      "[667]\ttraining's binary_logloss: 0.00501335\n",
      "[668]\ttraining's binary_logloss: 0.0049833\n",
      "[669]\ttraining's binary_logloss: 0.0049536\n",
      "[670]\ttraining's binary_logloss: 0.00492427\n",
      "[671]\ttraining's binary_logloss: 0.00489593\n",
      "[672]\ttraining's binary_logloss: 0.00486771\n",
      "[673]\ttraining's binary_logloss: 0.00483536\n",
      "[674]\ttraining's binary_logloss: 0.00480892\n",
      "[675]\ttraining's binary_logloss: 0.00478388\n",
      "[676]\ttraining's binary_logloss: 0.00476057\n",
      "[677]\ttraining's binary_logloss: 0.00473257\n",
      "[678]\ttraining's binary_logloss: 0.00470409\n",
      "[679]\ttraining's binary_logloss: 0.0046727\n",
      "[680]\ttraining's binary_logloss: 0.00464492\n",
      "[681]\ttraining's binary_logloss: 0.00461496\n",
      "[682]\ttraining's binary_logloss: 0.00458669\n",
      "[683]\ttraining's binary_logloss: 0.00455955\n",
      "[684]\ttraining's binary_logloss: 0.00453026\n",
      "[685]\ttraining's binary_logloss: 0.00450101\n",
      "[686]\ttraining's binary_logloss: 0.00447694\n",
      "[687]\ttraining's binary_logloss: 0.00445165\n",
      "[688]\ttraining's binary_logloss: 0.00442697\n",
      "[689]\ttraining's binary_logloss: 0.00440516\n",
      "[690]\ttraining's binary_logloss: 0.00437836\n",
      "[691]\ttraining's binary_logloss: 0.00435432\n",
      "[692]\ttraining's binary_logloss: 0.00432922\n",
      "[693]\ttraining's binary_logloss: 0.00430277\n",
      "[694]\ttraining's binary_logloss: 0.00427691\n",
      "[695]\ttraining's binary_logloss: 0.00424903\n",
      "[696]\ttraining's binary_logloss: 0.00422557\n",
      "[697]\ttraining's binary_logloss: 0.00420417\n",
      "[698]\ttraining's binary_logloss: 0.00418158\n",
      "[699]\ttraining's binary_logloss: 0.00415747\n",
      "[700]\ttraining's binary_logloss: 0.00413277\n",
      "[701]\ttraining's binary_logloss: 0.00410774\n",
      "[702]\ttraining's binary_logloss: 0.00408689\n",
      "[703]\ttraining's binary_logloss: 0.00406125\n",
      "[704]\ttraining's binary_logloss: 0.00403829\n",
      "[705]\ttraining's binary_logloss: 0.0040131\n",
      "[706]\ttraining's binary_logloss: 0.00398678\n",
      "[707]\ttraining's binary_logloss: 0.0039631\n",
      "[708]\ttraining's binary_logloss: 0.00394048\n",
      "[709]\ttraining's binary_logloss: 0.0039185\n",
      "[710]\ttraining's binary_logloss: 0.00389887\n",
      "[711]\ttraining's binary_logloss: 0.00387556\n",
      "[712]\ttraining's binary_logloss: 0.00385425\n",
      "[713]\ttraining's binary_logloss: 0.00383288\n",
      "[714]\ttraining's binary_logloss: 0.00380974\n",
      "[715]\ttraining's binary_logloss: 0.00378667\n",
      "[716]\ttraining's binary_logloss: 0.0037607\n",
      "[717]\ttraining's binary_logloss: 0.00374086\n",
      "[718]\ttraining's binary_logloss: 0.00371987\n",
      "[719]\ttraining's binary_logloss: 0.00369097\n",
      "[720]\ttraining's binary_logloss: 0.00366996\n",
      "[721]\ttraining's binary_logloss: 0.00364757\n",
      "[722]\ttraining's binary_logloss: 0.00362445\n",
      "[723]\ttraining's binary_logloss: 0.00360405\n",
      "[724]\ttraining's binary_logloss: 0.00358483\n",
      "[725]\ttraining's binary_logloss: 0.00356589\n",
      "[726]\ttraining's binary_logloss: 0.00354762\n",
      "[727]\ttraining's binary_logloss: 0.00352757\n",
      "[728]\ttraining's binary_logloss: 0.00350876\n",
      "[729]\ttraining's binary_logloss: 0.00348646\n",
      "[730]\ttraining's binary_logloss: 0.00346993\n",
      "[731]\ttraining's binary_logloss: 0.00344787\n",
      "[732]\ttraining's binary_logloss: 0.00342851\n",
      "[733]\ttraining's binary_logloss: 0.00340733\n",
      "[734]\ttraining's binary_logloss: 0.00338682\n",
      "[735]\ttraining's binary_logloss: 0.00336462\n",
      "[736]\ttraining's binary_logloss: 0.00334368\n",
      "[737]\ttraining's binary_logloss: 0.00332314\n",
      "[738]\ttraining's binary_logloss: 0.00330144\n",
      "[739]\ttraining's binary_logloss: 0.00328375\n",
      "[740]\ttraining's binary_logloss: 0.00326165\n",
      "[741]\ttraining's binary_logloss: 0.00324446\n",
      "[742]\ttraining's binary_logloss: 0.00322613\n",
      "[743]\ttraining's binary_logloss: 0.00320554\n",
      "[744]\ttraining's binary_logloss: 0.00318862\n",
      "[745]\ttraining's binary_logloss: 0.00317019\n",
      "[746]\ttraining's binary_logloss: 0.00315305\n",
      "[747]\ttraining's binary_logloss: 0.00313444\n",
      "[748]\ttraining's binary_logloss: 0.00311666\n",
      "[749]\ttraining's binary_logloss: 0.0031011\n",
      "[750]\ttraining's binary_logloss: 0.00308332\n",
      "[751]\ttraining's binary_logloss: 0.00306554\n",
      "[752]\ttraining's binary_logloss: 0.0030482\n",
      "[753]\ttraining's binary_logloss: 0.00303076\n",
      "[754]\ttraining's binary_logloss: 0.00301252\n",
      "[755]\ttraining's binary_logloss: 0.00299281\n",
      "[756]\ttraining's binary_logloss: 0.00297374\n",
      "[757]\ttraining's binary_logloss: 0.00295739\n",
      "[758]\ttraining's binary_logloss: 0.00293948\n",
      "[759]\ttraining's binary_logloss: 0.00292321\n",
      "[760]\ttraining's binary_logloss: 0.00290786\n",
      "[761]\ttraining's binary_logloss: 0.0028925\n",
      "[762]\ttraining's binary_logloss: 0.0028781\n",
      "[763]\ttraining's binary_logloss: 0.00286125\n",
      "[764]\ttraining's binary_logloss: 0.00284469\n",
      "[765]\ttraining's binary_logloss: 0.0028285\n",
      "[766]\ttraining's binary_logloss: 0.00281226\n",
      "[767]\ttraining's binary_logloss: 0.00279886\n",
      "[768]\ttraining's binary_logloss: 0.00278269\n",
      "[769]\ttraining's binary_logloss: 0.00276728\n",
      "[770]\ttraining's binary_logloss: 0.00275248\n",
      "[771]\ttraining's binary_logloss: 0.00273835\n",
      "[772]\ttraining's binary_logloss: 0.00272387\n",
      "[773]\ttraining's binary_logloss: 0.00271139\n",
      "[774]\ttraining's binary_logloss: 0.0026962\n",
      "[775]\ttraining's binary_logloss: 0.00267829\n",
      "[776]\ttraining's binary_logloss: 0.00266465\n",
      "[777]\ttraining's binary_logloss: 0.00264777\n",
      "[778]\ttraining's binary_logloss: 0.00263212\n",
      "[779]\ttraining's binary_logloss: 0.00261776\n",
      "[780]\ttraining's binary_logloss: 0.00260315\n",
      "[781]\ttraining's binary_logloss: 0.00258838\n",
      "[782]\ttraining's binary_logloss: 0.00257133\n",
      "[783]\ttraining's binary_logloss: 0.00255701\n",
      "[784]\ttraining's binary_logloss: 0.00254377\n",
      "[785]\ttraining's binary_logloss: 0.00252875\n",
      "[786]\ttraining's binary_logloss: 0.00251309\n",
      "[787]\ttraining's binary_logloss: 0.00249936\n",
      "[788]\ttraining's binary_logloss: 0.00248567\n",
      "[789]\ttraining's binary_logloss: 0.00247242\n",
      "[790]\ttraining's binary_logloss: 0.00245918\n",
      "[791]\ttraining's binary_logloss: 0.00244475\n",
      "[792]\ttraining's binary_logloss: 0.00242986\n",
      "[793]\ttraining's binary_logloss: 0.00241744\n",
      "[794]\ttraining's binary_logloss: 0.00240105\n",
      "[795]\ttraining's binary_logloss: 0.00238796\n",
      "[796]\ttraining's binary_logloss: 0.00237072\n",
      "[797]\ttraining's binary_logloss: 0.00235406\n",
      "[798]\ttraining's binary_logloss: 0.00233999\n",
      "[799]\ttraining's binary_logloss: 0.00232592\n",
      "[800]\ttraining's binary_logloss: 0.00230972\n",
      "[801]\ttraining's binary_logloss: 0.00229761\n",
      "[802]\ttraining's binary_logloss: 0.00228528\n",
      "[803]\ttraining's binary_logloss: 0.00227214\n",
      "[804]\ttraining's binary_logloss: 0.00225862\n",
      "[805]\ttraining's binary_logloss: 0.00224349\n",
      "[806]\ttraining's binary_logloss: 0.0022304\n",
      "[807]\ttraining's binary_logloss: 0.00221724\n",
      "[808]\ttraining's binary_logloss: 0.0022038\n",
      "[809]\ttraining's binary_logloss: 0.00219114\n",
      "[810]\ttraining's binary_logloss: 0.00217728\n",
      "[811]\ttraining's binary_logloss: 0.00216528\n",
      "[812]\ttraining's binary_logloss: 0.0021523\n",
      "[813]\ttraining's binary_logloss: 0.00214035\n",
      "[814]\ttraining's binary_logloss: 0.00212822\n",
      "[815]\ttraining's binary_logloss: 0.00211557\n",
      "[816]\ttraining's binary_logloss: 0.00210282\n",
      "[817]\ttraining's binary_logloss: 0.00209307\n",
      "[818]\ttraining's binary_logloss: 0.0020823\n",
      "[819]\ttraining's binary_logloss: 0.00207044\n",
      "[820]\ttraining's binary_logloss: 0.00205872\n",
      "[821]\ttraining's binary_logloss: 0.00204797\n",
      "[822]\ttraining's binary_logloss: 0.00203636\n",
      "[823]\ttraining's binary_logloss: 0.00202429\n",
      "[824]\ttraining's binary_logloss: 0.00201102\n",
      "[825]\ttraining's binary_logloss: 0.00199997\n",
      "[826]\ttraining's binary_logloss: 0.00198726\n",
      "[827]\ttraining's binary_logloss: 0.00197557\n",
      "[828]\ttraining's binary_logloss: 0.00196425\n",
      "[829]\ttraining's binary_logloss: 0.00195201\n",
      "[830]\ttraining's binary_logloss: 0.00194222\n",
      "[831]\ttraining's binary_logloss: 0.00193229\n",
      "[832]\ttraining's binary_logloss: 0.00192082\n",
      "[833]\ttraining's binary_logloss: 0.00190887\n",
      "[834]\ttraining's binary_logloss: 0.00189658\n",
      "[835]\ttraining's binary_logloss: 0.00188615\n",
      "[836]\ttraining's binary_logloss: 0.00187699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[837]\ttraining's binary_logloss: 0.00186615\n",
      "[838]\ttraining's binary_logloss: 0.00185577\n",
      "[839]\ttraining's binary_logloss: 0.00184575\n",
      "[840]\ttraining's binary_logloss: 0.00183529\n",
      "[841]\ttraining's binary_logloss: 0.00182382\n",
      "[842]\ttraining's binary_logloss: 0.00181351\n",
      "[843]\ttraining's binary_logloss: 0.00180279\n",
      "[844]\ttraining's binary_logloss: 0.00179381\n",
      "[845]\ttraining's binary_logloss: 0.00178375\n",
      "[846]\ttraining's binary_logloss: 0.00177296\n",
      "[847]\ttraining's binary_logloss: 0.00176383\n",
      "[848]\ttraining's binary_logloss: 0.00175437\n",
      "[849]\ttraining's binary_logloss: 0.00174424\n",
      "[850]\ttraining's binary_logloss: 0.00173306\n",
      "[851]\ttraining's binary_logloss: 0.00172428\n",
      "[852]\ttraining's binary_logloss: 0.00171539\n",
      "[853]\ttraining's binary_logloss: 0.00170646\n",
      "[854]\ttraining's binary_logloss: 0.0016959\n",
      "[855]\ttraining's binary_logloss: 0.0016873\n",
      "[856]\ttraining's binary_logloss: 0.00167714\n",
      "[857]\ttraining's binary_logloss: 0.00166795\n",
      "[858]\ttraining's binary_logloss: 0.00165821\n",
      "[859]\ttraining's binary_logloss: 0.00164977\n",
      "[860]\ttraining's binary_logloss: 0.00164068\n",
      "[861]\ttraining's binary_logloss: 0.00163252\n",
      "[862]\ttraining's binary_logloss: 0.00162386\n",
      "[863]\ttraining's binary_logloss: 0.00161545\n",
      "[864]\ttraining's binary_logloss: 0.00160617\n",
      "[865]\ttraining's binary_logloss: 0.00159741\n",
      "[866]\ttraining's binary_logloss: 0.00158722\n",
      "[867]\ttraining's binary_logloss: 0.00157851\n",
      "[868]\ttraining's binary_logloss: 0.0015708\n",
      "[869]\ttraining's binary_logloss: 0.00156278\n",
      "[870]\ttraining's binary_logloss: 0.00155305\n",
      "[871]\ttraining's binary_logloss: 0.00154353\n",
      "[872]\ttraining's binary_logloss: 0.00153313\n",
      "[873]\ttraining's binary_logloss: 0.00152426\n",
      "[874]\ttraining's binary_logloss: 0.00151613\n",
      "[875]\ttraining's binary_logloss: 0.00150661\n",
      "[876]\ttraining's binary_logloss: 0.00149786\n",
      "[877]\ttraining's binary_logloss: 0.00148848\n",
      "[878]\ttraining's binary_logloss: 0.00147963\n",
      "[879]\ttraining's binary_logloss: 0.00147263\n",
      "[880]\ttraining's binary_logloss: 0.00146502\n",
      "[881]\ttraining's binary_logloss: 0.00145586\n",
      "[882]\ttraining's binary_logloss: 0.00144821\n",
      "[883]\ttraining's binary_logloss: 0.00144057\n",
      "[884]\ttraining's binary_logloss: 0.00143335\n",
      "[885]\ttraining's binary_logloss: 0.00142698\n",
      "[886]\ttraining's binary_logloss: 0.00141997\n",
      "[887]\ttraining's binary_logloss: 0.00141222\n",
      "[888]\ttraining's binary_logloss: 0.00140416\n",
      "[889]\ttraining's binary_logloss: 0.00139471\n",
      "[890]\ttraining's binary_logloss: 0.00138769\n",
      "[891]\ttraining's binary_logloss: 0.00138192\n",
      "[892]\ttraining's binary_logloss: 0.00137414\n",
      "[893]\ttraining's binary_logloss: 0.00136576\n",
      "[894]\ttraining's binary_logloss: 0.00135887\n",
      "[895]\ttraining's binary_logloss: 0.00135013\n",
      "[896]\ttraining's binary_logloss: 0.00134184\n",
      "[897]\ttraining's binary_logloss: 0.00133421\n",
      "[898]\ttraining's binary_logloss: 0.00132652\n",
      "[899]\ttraining's binary_logloss: 0.00131831\n",
      "[900]\ttraining's binary_logloss: 0.001311\n",
      "[901]\ttraining's binary_logloss: 0.0013039\n",
      "[902]\ttraining's binary_logloss: 0.00129717\n",
      "[903]\ttraining's binary_logloss: 0.00129012\n",
      "[904]\ttraining's binary_logloss: 0.00128325\n",
      "[905]\ttraining's binary_logloss: 0.00127705\n",
      "[906]\ttraining's binary_logloss: 0.00127103\n",
      "[907]\ttraining's binary_logloss: 0.00126205\n",
      "[908]\ttraining's binary_logloss: 0.00125595\n",
      "[909]\ttraining's binary_logloss: 0.0012488\n",
      "[910]\ttraining's binary_logloss: 0.0012423\n",
      "[911]\ttraining's binary_logloss: 0.00123507\n",
      "[912]\ttraining's binary_logloss: 0.00122725\n",
      "[913]\ttraining's binary_logloss: 0.00121937\n",
      "[914]\ttraining's binary_logloss: 0.00121259\n",
      "[915]\ttraining's binary_logloss: 0.00120564\n",
      "[916]\ttraining's binary_logloss: 0.00119967\n",
      "[917]\ttraining's binary_logloss: 0.00119358\n",
      "[918]\ttraining's binary_logloss: 0.00118574\n",
      "[919]\ttraining's binary_logloss: 0.00117977\n",
      "[920]\ttraining's binary_logloss: 0.00117351\n",
      "[921]\ttraining's binary_logloss: 0.00116749\n",
      "[922]\ttraining's binary_logloss: 0.0011606\n",
      "[923]\ttraining's binary_logloss: 0.00115226\n",
      "[924]\ttraining's binary_logloss: 0.00114598\n",
      "[925]\ttraining's binary_logloss: 0.00114014\n",
      "[926]\ttraining's binary_logloss: 0.0011347\n",
      "[927]\ttraining's binary_logloss: 0.00112782\n",
      "[928]\ttraining's binary_logloss: 0.00112168\n",
      "[929]\ttraining's binary_logloss: 0.00111614\n",
      "[930]\ttraining's binary_logloss: 0.00110935\n",
      "[931]\ttraining's binary_logloss: 0.00110347\n",
      "[932]\ttraining's binary_logloss: 0.00109734\n",
      "[933]\ttraining's binary_logloss: 0.00109099\n",
      "[934]\ttraining's binary_logloss: 0.00108494\n",
      "[935]\ttraining's binary_logloss: 0.00107949\n",
      "[936]\ttraining's binary_logloss: 0.00107474\n",
      "[937]\ttraining's binary_logloss: 0.00106814\n",
      "[938]\ttraining's binary_logloss: 0.00106118\n",
      "[939]\ttraining's binary_logloss: 0.0010556\n",
      "[940]\ttraining's binary_logloss: 0.0010504\n",
      "[941]\ttraining's binary_logloss: 0.00104461\n",
      "[942]\ttraining's binary_logloss: 0.00103798\n",
      "[943]\ttraining's binary_logloss: 0.00103162\n",
      "[944]\ttraining's binary_logloss: 0.00102473\n",
      "[945]\ttraining's binary_logloss: 0.00101803\n",
      "[946]\ttraining's binary_logloss: 0.00101246\n",
      "[947]\ttraining's binary_logloss: 0.00100563\n",
      "[948]\ttraining's binary_logloss: 0.000998388\n",
      "[949]\ttraining's binary_logloss: 0.000993008\n",
      "[950]\ttraining's binary_logloss: 0.000988169\n",
      "[951]\ttraining's binary_logloss: 0.000983375\n",
      "[952]\ttraining's binary_logloss: 0.000979387\n",
      "[953]\ttraining's binary_logloss: 0.000973478\n",
      "[954]\ttraining's binary_logloss: 0.000967487\n",
      "[955]\ttraining's binary_logloss: 0.000961604\n",
      "[956]\ttraining's binary_logloss: 0.00095634\n",
      "[957]\ttraining's binary_logloss: 0.000950599\n",
      "[958]\ttraining's binary_logloss: 0.000945394\n",
      "[959]\ttraining's binary_logloss: 0.000940103\n",
      "[960]\ttraining's binary_logloss: 0.000933869\n",
      "[961]\ttraining's binary_logloss: 0.000929993\n",
      "[962]\ttraining's binary_logloss: 0.000925866\n",
      "[963]\ttraining's binary_logloss: 0.000919998\n",
      "[964]\ttraining's binary_logloss: 0.00091493\n",
      "[965]\ttraining's binary_logloss: 0.000909757\n",
      "[966]\ttraining's binary_logloss: 0.000904896\n",
      "[967]\ttraining's binary_logloss: 0.000900722\n",
      "[968]\ttraining's binary_logloss: 0.000896452\n",
      "[969]\ttraining's binary_logloss: 0.000890999\n",
      "[970]\ttraining's binary_logloss: 0.000886925\n",
      "[971]\ttraining's binary_logloss: 0.000881696\n",
      "[972]\ttraining's binary_logloss: 0.000876121\n",
      "[973]\ttraining's binary_logloss: 0.000872156\n",
      "[974]\ttraining's binary_logloss: 0.000867079\n",
      "[975]\ttraining's binary_logloss: 0.000861553\n",
      "[976]\ttraining's binary_logloss: 0.000856163\n",
      "[977]\ttraining's binary_logloss: 0.000851805\n",
      "[978]\ttraining's binary_logloss: 0.000847462\n",
      "[979]\ttraining's binary_logloss: 0.00084281\n",
      "[980]\ttraining's binary_logloss: 0.000838334\n",
      "[981]\ttraining's binary_logloss: 0.000832609\n",
      "[982]\ttraining's binary_logloss: 0.000827639\n",
      "[983]\ttraining's binary_logloss: 0.000821879\n",
      "[984]\ttraining's binary_logloss: 0.000817815\n",
      "[985]\ttraining's binary_logloss: 0.000813452\n",
      "[986]\ttraining's binary_logloss: 0.000809338\n",
      "[987]\ttraining's binary_logloss: 0.000805707\n",
      "[988]\ttraining's binary_logloss: 0.000801872\n",
      "[989]\ttraining's binary_logloss: 0.000796293\n",
      "[990]\ttraining's binary_logloss: 0.000790619\n",
      "[991]\ttraining's binary_logloss: 0.000786566\n",
      "[992]\ttraining's binary_logloss: 0.000782166\n",
      "[993]\ttraining's binary_logloss: 0.000778241\n",
      "[994]\ttraining's binary_logloss: 0.000774679\n",
      "[995]\ttraining's binary_logloss: 0.000770673\n",
      "[996]\ttraining's binary_logloss: 0.000767635\n",
      "[997]\ttraining's binary_logloss: 0.000763584\n",
      "[998]\ttraining's binary_logloss: 0.000759199\n",
      "[999]\ttraining's binary_logloss: 0.000753727\n",
      "[1000]\ttraining's binary_logloss: 0.000748044\n",
      "[1001]\ttraining's binary_logloss: 0.000744527\n",
      "[1002]\ttraining's binary_logloss: 0.000740985\n",
      "[1003]\ttraining's binary_logloss: 0.000735622\n",
      "[1004]\ttraining's binary_logloss: 0.000730677\n",
      "[1005]\ttraining's binary_logloss: 0.000727248\n",
      "[1006]\ttraining's binary_logloss: 0.000724508\n",
      "[1007]\ttraining's binary_logloss: 0.000720189\n",
      "[1008]\ttraining's binary_logloss: 0.000717058\n",
      "[1009]\ttraining's binary_logloss: 0.00071338\n",
      "[1010]\ttraining's binary_logloss: 0.000709093\n",
      "[1011]\ttraining's binary_logloss: 0.000704985\n",
      "[1012]\ttraining's binary_logloss: 0.000701055\n",
      "[1013]\ttraining's binary_logloss: 0.000697853\n",
      "[1014]\ttraining's binary_logloss: 0.000694064\n",
      "[1015]\ttraining's binary_logloss: 0.000690893\n",
      "[1016]\ttraining's binary_logloss: 0.000685861\n",
      "[1017]\ttraining's binary_logloss: 0.000682706\n",
      "[1018]\ttraining's binary_logloss: 0.000679714\n",
      "[1019]\ttraining's binary_logloss: 0.000676225\n",
      "[1020]\ttraining's binary_logloss: 0.000673012\n",
      "[1021]\ttraining's binary_logloss: 0.00066886\n",
      "[1022]\ttraining's binary_logloss: 0.000664222\n",
      "[1023]\ttraining's binary_logloss: 0.000661493\n",
      "[1024]\ttraining's binary_logloss: 0.000658421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1025]\ttraining's binary_logloss: 0.000653633\n",
      "[1026]\ttraining's binary_logloss: 0.000649204\n",
      "[1027]\ttraining's binary_logloss: 0.000645639\n",
      "[1028]\ttraining's binary_logloss: 0.000641737\n",
      "[1029]\ttraining's binary_logloss: 0.000638342\n",
      "[1030]\ttraining's binary_logloss: 0.000635344\n",
      "[1031]\ttraining's binary_logloss: 0.000631368\n",
      "[1032]\ttraining's binary_logloss: 0.00062728\n",
      "[1033]\ttraining's binary_logloss: 0.000624224\n",
      "[1034]\ttraining's binary_logloss: 0.000621362\n",
      "[1035]\ttraining's binary_logloss: 0.000618327\n",
      "[1036]\ttraining's binary_logloss: 0.000615863\n",
      "[1037]\ttraining's binary_logloss: 0.000613209\n",
      "[1038]\ttraining's binary_logloss: 0.000609447\n",
      "[1039]\ttraining's binary_logloss: 0.000605924\n",
      "[1040]\ttraining's binary_logloss: 0.00060314\n",
      "[1041]\ttraining's binary_logloss: 0.000599547\n",
      "[1042]\ttraining's binary_logloss: 0.000597547\n",
      "[1043]\ttraining's binary_logloss: 0.000594629\n",
      "[1044]\ttraining's binary_logloss: 0.000591481\n",
      "[1045]\ttraining's binary_logloss: 0.000588076\n",
      "[1046]\ttraining's binary_logloss: 0.000585245\n",
      "[1047]\ttraining's binary_logloss: 0.000580585\n",
      "[1048]\ttraining's binary_logloss: 0.000575399\n",
      "[1049]\ttraining's binary_logloss: 0.000572962\n",
      "[1050]\ttraining's binary_logloss: 0.000570856\n",
      "[1051]\ttraining's binary_logloss: 0.000566564\n",
      "[1052]\ttraining's binary_logloss: 0.000563683\n",
      "[1053]\ttraining's binary_logloss: 0.000560189\n",
      "[1054]\ttraining's binary_logloss: 0.000557058\n",
      "[1055]\ttraining's binary_logloss: 0.000553728\n",
      "[1056]\ttraining's binary_logloss: 0.000550936\n",
      "[1057]\ttraining's binary_logloss: 0.000547842\n",
      "[1058]\ttraining's binary_logloss: 0.000543964\n",
      "[1059]\ttraining's binary_logloss: 0.000540653\n",
      "[1060]\ttraining's binary_logloss: 0.000536842\n",
      "[1061]\ttraining's binary_logloss: 0.000532255\n",
      "[1062]\ttraining's binary_logloss: 0.0005301\n",
      "[1063]\ttraining's binary_logloss: 0.000525688\n",
      "[1064]\ttraining's binary_logloss: 0.000521039\n",
      "[1065]\ttraining's binary_logloss: 0.000519229\n",
      "[1066]\ttraining's binary_logloss: 0.000516445\n",
      "[1067]\ttraining's binary_logloss: 0.000512538\n",
      "[1068]\ttraining's binary_logloss: 0.000510316\n",
      "[1069]\ttraining's binary_logloss: 0.000508574\n",
      "[1070]\ttraining's binary_logloss: 0.000505506\n",
      "[1071]\ttraining's binary_logloss: 0.000502866\n",
      "[1072]\ttraining's binary_logloss: 0.000499735\n",
      "[1073]\ttraining's binary_logloss: 0.000497133\n",
      "[1074]\ttraining's binary_logloss: 0.000495042\n",
      "[1075]\ttraining's binary_logloss: 0.000490913\n",
      "[1076]\ttraining's binary_logloss: 0.000486603\n",
      "[1077]\ttraining's binary_logloss: 0.000484552\n",
      "[1078]\ttraining's binary_logloss: 0.000481751\n",
      "[1079]\ttraining's binary_logloss: 0.000480038\n",
      "[1080]\ttraining's binary_logloss: 0.000477834\n",
      "[1081]\ttraining's binary_logloss: 0.000475522\n",
      "[1082]\ttraining's binary_logloss: 0.00047235\n",
      "[1083]\ttraining's binary_logloss: 0.000468901\n",
      "[1084]\ttraining's binary_logloss: 0.000466891\n",
      "[1085]\ttraining's binary_logloss: 0.000464901\n",
      "[1086]\ttraining's binary_logloss: 0.000462414\n",
      "[1087]\ttraining's binary_logloss: 0.000460106\n",
      "[1088]\ttraining's binary_logloss: 0.00045793\n",
      "[1089]\ttraining's binary_logloss: 0.000454685\n",
      "[1090]\ttraining's binary_logloss: 0.000451865\n",
      "[1091]\ttraining's binary_logloss: 0.000448754\n",
      "[1092]\ttraining's binary_logloss: 0.000445734\n",
      "[1093]\ttraining's binary_logloss: 0.000443175\n",
      "[1094]\ttraining's binary_logloss: 0.000441089\n",
      "[1095]\ttraining's binary_logloss: 0.000437762\n",
      "[1096]\ttraining's binary_logloss: 0.000433995\n",
      "[1097]\ttraining's binary_logloss: 0.00043114\n",
      "[1098]\ttraining's binary_logloss: 0.000428529\n",
      "[1099]\ttraining's binary_logloss: 0.000425906\n",
      "[1100]\ttraining's binary_logloss: 0.000423757\n",
      "[1101]\ttraining's binary_logloss: 0.000422252\n",
      "[1102]\ttraining's binary_logloss: 0.000420548\n",
      "[1103]\ttraining's binary_logloss: 0.000417495\n",
      "[1104]\ttraining's binary_logloss: 0.000415602\n",
      "[1105]\ttraining's binary_logloss: 0.000414066\n",
      "[1106]\ttraining's binary_logloss: 0.000411517\n",
      "[1107]\ttraining's binary_logloss: 0.000408759\n",
      "[1108]\ttraining's binary_logloss: 0.000406691\n",
      "[1109]\ttraining's binary_logloss: 0.000404984\n",
      "[1110]\ttraining's binary_logloss: 0.00040256\n",
      "[1111]\ttraining's binary_logloss: 0.000400714\n",
      "[1112]\ttraining's binary_logloss: 0.000398156\n",
      "[1113]\ttraining's binary_logloss: 0.000394755\n",
      "[1114]\ttraining's binary_logloss: 0.00039137\n",
      "[1115]\ttraining's binary_logloss: 0.000388214\n",
      "[1116]\ttraining's binary_logloss: 0.000385907\n",
      "[1117]\ttraining's binary_logloss: 0.000384784\n",
      "[1118]\ttraining's binary_logloss: 0.00038316\n",
      "[1119]\ttraining's binary_logloss: 0.000379763\n",
      "[1120]\ttraining's binary_logloss: 0.000376937\n",
      "[1121]\ttraining's binary_logloss: 0.000375448\n",
      "[1122]\ttraining's binary_logloss: 0.000374306\n",
      "[1123]\ttraining's binary_logloss: 0.000372331\n",
      "[1124]\ttraining's binary_logloss: 0.000370837\n",
      "[1125]\ttraining's binary_logloss: 0.000369341\n",
      "[1126]\ttraining's binary_logloss: 0.000367301\n",
      "[1127]\ttraining's binary_logloss: 0.000365845\n",
      "[1128]\ttraining's binary_logloss: 0.000364833\n",
      "[1129]\ttraining's binary_logloss: 0.000363467\n",
      "[1130]\ttraining's binary_logloss: 0.000362098\n",
      "[1131]\ttraining's binary_logloss: 0.000360098\n",
      "[1132]\ttraining's binary_logloss: 0.000357849\n",
      "[1133]\ttraining's binary_logloss: 0.000354849\n",
      "[1134]\ttraining's binary_logloss: 0.000351872\n",
      "[1135]\ttraining's binary_logloss: 0.000349631\n",
      "[1136]\ttraining's binary_logloss: 0.000347763\n",
      "[1137]\ttraining's binary_logloss: 0.000346191\n",
      "[1138]\ttraining's binary_logloss: 0.000343338\n",
      "[1139]\ttraining's binary_logloss: 0.000340906\n",
      "[1140]\ttraining's binary_logloss: 0.000338139\n",
      "[1141]\ttraining's binary_logloss: 0.000337039\n",
      "[1142]\ttraining's binary_logloss: 0.00033612\n",
      "[1143]\ttraining's binary_logloss: 0.000333692\n",
      "[1144]\ttraining's binary_logloss: 0.000331148\n",
      "[1145]\ttraining's binary_logloss: 0.000328962\n",
      "[1146]\ttraining's binary_logloss: 0.000326526\n",
      "[1147]\ttraining's binary_logloss: 0.000323469\n",
      "[1148]\ttraining's binary_logloss: 0.000320563\n",
      "[1149]\ttraining's binary_logloss: 0.00031819\n",
      "[1150]\ttraining's binary_logloss: 0.000315619\n",
      "[1151]\ttraining's binary_logloss: 0.00031307\n",
      "[1152]\ttraining's binary_logloss: 0.000310906\n",
      "[1153]\ttraining's binary_logloss: 0.000308775\n",
      "[1154]\ttraining's binary_logloss: 0.000306315\n",
      "[1155]\ttraining's binary_logloss: 0.000305067\n",
      "[1156]\ttraining's binary_logloss: 0.000303764\n",
      "[1157]\ttraining's binary_logloss: 0.000301514\n",
      "[1158]\ttraining's binary_logloss: 0.000299248\n",
      "[1159]\ttraining's binary_logloss: 0.000297196\n",
      "[1160]\ttraining's binary_logloss: 0.000295029\n",
      "[1161]\ttraining's binary_logloss: 0.000294094\n",
      "[1162]\ttraining's binary_logloss: 0.000292591\n",
      "[1163]\ttraining's binary_logloss: 0.000291629\n",
      "[1164]\ttraining's binary_logloss: 0.000289663\n",
      "[1165]\ttraining's binary_logloss: 0.000287521\n",
      "[1166]\ttraining's binary_logloss: 0.000285765\n",
      "[1167]\ttraining's binary_logloss: 0.000284791\n",
      "[1168]\ttraining's binary_logloss: 0.000283029\n",
      "[1169]\ttraining's binary_logloss: 0.000281765\n",
      "[1170]\ttraining's binary_logloss: 0.000280968\n",
      "[1171]\ttraining's binary_logloss: 0.000280066\n",
      "[1172]\ttraining's binary_logloss: 0.000279283\n",
      "[1173]\ttraining's binary_logloss: 0.000277822\n",
      "[1174]\ttraining's binary_logloss: 0.000276181\n",
      "[1175]\ttraining's binary_logloss: 0.000274259\n",
      "[1176]\ttraining's binary_logloss: 0.000271939\n",
      "[1177]\ttraining's binary_logloss: 0.000269974\n",
      "[1178]\ttraining's binary_logloss: 0.000268273\n",
      "[1179]\ttraining's binary_logloss: 0.000266555\n",
      "[1180]\ttraining's binary_logloss: 0.000265\n",
      "[1181]\ttraining's binary_logloss: 0.000263966\n",
      "[1182]\ttraining's binary_logloss: 0.000262948\n",
      "[1183]\ttraining's binary_logloss: 0.00026125\n",
      "[1184]\ttraining's binary_logloss: 0.000259638\n",
      "[1185]\ttraining's binary_logloss: 0.000257949\n",
      "[1186]\ttraining's binary_logloss: 0.000256503\n",
      "[1187]\ttraining's binary_logloss: 0.000254707\n",
      "[1188]\ttraining's binary_logloss: 0.000252684\n",
      "[1189]\ttraining's binary_logloss: 0.000251996\n",
      "[1190]\ttraining's binary_logloss: 0.000250974\n",
      "[1191]\ttraining's binary_logloss: 0.000248837\n",
      "[1192]\ttraining's binary_logloss: 0.00024682\n",
      "[1193]\ttraining's binary_logloss: 0.000245997\n",
      "[1194]\ttraining's binary_logloss: 0.000245338\n",
      "[1195]\ttraining's binary_logloss: 0.000243362\n",
      "[1196]\ttraining's binary_logloss: 0.000241701\n",
      "[1197]\ttraining's binary_logloss: 0.000239945\n",
      "[1198]\ttraining's binary_logloss: 0.000238111\n",
      "[1199]\ttraining's binary_logloss: 0.000236627\n",
      "[1200]\ttraining's binary_logloss: 0.000235779\n",
      "[1201]\ttraining's binary_logloss: 0.000234313\n",
      "[1202]\ttraining's binary_logloss: 0.000232923\n",
      "[1203]\ttraining's binary_logloss: 0.000232028\n",
      "[1204]\ttraining's binary_logloss: 0.000230638\n",
      "[1205]\ttraining's binary_logloss: 0.000228575\n",
      "[1206]\ttraining's binary_logloss: 0.000226721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1207]\ttraining's binary_logloss: 0.000226022\n",
      "[1208]\ttraining's binary_logloss: 0.000224856\n",
      "[1209]\ttraining's binary_logloss: 0.000223187\n",
      "[1210]\ttraining's binary_logloss: 0.000221392\n",
      "[1211]\ttraining's binary_logloss: 0.000220283\n",
      "[1212]\ttraining's binary_logloss: 0.000219598\n",
      "[1213]\ttraining's binary_logloss: 0.000218094\n",
      "[1214]\ttraining's binary_logloss: 0.000216936\n",
      "[1215]\ttraining's binary_logloss: 0.000214951\n",
      "[1216]\ttraining's binary_logloss: 0.000213478\n",
      "[1217]\ttraining's binary_logloss: 0.000211924\n",
      "[1218]\ttraining's binary_logloss: 0.00021031\n",
      "[1219]\ttraining's binary_logloss: 0.000209056\n",
      "[1220]\ttraining's binary_logloss: 0.000208011\n",
      "[1221]\ttraining's binary_logloss: 0.000207135\n",
      "[1222]\ttraining's binary_logloss: 0.00020636\n",
      "[1223]\ttraining's binary_logloss: 0.000205743\n",
      "[1224]\ttraining's binary_logloss: 0.000204816\n",
      "[1225]\ttraining's binary_logloss: 0.000203463\n",
      "[1226]\ttraining's binary_logloss: 0.000202777\n",
      "[1227]\ttraining's binary_logloss: 0.000201697\n",
      "[1228]\ttraining's binary_logloss: 0.000200791\n",
      "[1229]\ttraining's binary_logloss: 0.000200001\n",
      "[1230]\ttraining's binary_logloss: 0.000198654\n",
      "[1231]\ttraining's binary_logloss: 0.000196927\n",
      "[1232]\ttraining's binary_logloss: 0.000195336\n",
      "[1233]\ttraining's binary_logloss: 0.000193915\n",
      "[1234]\ttraining's binary_logloss: 0.000192529\n",
      "[1235]\ttraining's binary_logloss: 0.000191223\n",
      "[1236]\ttraining's binary_logloss: 0.000189942\n",
      "[1237]\ttraining's binary_logloss: 0.000188611\n",
      "[1238]\ttraining's binary_logloss: 0.000187285\n",
      "[1239]\ttraining's binary_logloss: 0.000186016\n",
      "[1240]\ttraining's binary_logloss: 0.000184609\n",
      "[1241]\ttraining's binary_logloss: 0.000183533\n",
      "[1242]\ttraining's binary_logloss: 0.000182551\n",
      "[1243]\ttraining's binary_logloss: 0.000181111\n",
      "[1244]\ttraining's binary_logloss: 0.000179633\n",
      "[1245]\ttraining's binary_logloss: 0.000178324\n",
      "[1246]\ttraining's binary_logloss: 0.000176872\n",
      "[1247]\ttraining's binary_logloss: 0.00017557\n",
      "[1248]\ttraining's binary_logloss: 0.000174327\n",
      "[1249]\ttraining's binary_logloss: 0.000173035\n",
      "[1250]\ttraining's binary_logloss: 0.000171817\n",
      "[1251]\ttraining's binary_logloss: 0.000170882\n",
      "[1252]\ttraining's binary_logloss: 0.000169899\n",
      "[1253]\ttraining's binary_logloss: 0.00016871\n",
      "[1254]\ttraining's binary_logloss: 0.000167347\n",
      "[1255]\ttraining's binary_logloss: 0.000166034\n",
      "[1256]\ttraining's binary_logloss: 0.000164765\n",
      "[1257]\ttraining's binary_logloss: 0.000163564\n",
      "[1258]\ttraining's binary_logloss: 0.000162262\n",
      "[1259]\ttraining's binary_logloss: 0.00016155\n",
      "[1260]\ttraining's binary_logloss: 0.000160755\n",
      "[1261]\ttraining's binary_logloss: 0.000160118\n",
      "[1262]\ttraining's binary_logloss: 0.000159306\n",
      "[1263]\ttraining's binary_logloss: 0.000158268\n",
      "[1264]\ttraining's binary_logloss: 0.000157175\n",
      "[1265]\ttraining's binary_logloss: 0.000156171\n",
      "[1266]\ttraining's binary_logloss: 0.000155244\n",
      "[1267]\ttraining's binary_logloss: 0.000154054\n",
      "[1268]\ttraining's binary_logloss: 0.000152967\n",
      "[1269]\ttraining's binary_logloss: 0.000152147\n",
      "[1270]\ttraining's binary_logloss: 0.000151536\n",
      "[1271]\ttraining's binary_logloss: 0.00015062\n",
      "[1272]\ttraining's binary_logloss: 0.000149359\n",
      "[1273]\ttraining's binary_logloss: 0.000148334\n",
      "[1274]\ttraining's binary_logloss: 0.000147295\n",
      "[1275]\ttraining's binary_logloss: 0.00014621\n",
      "[1276]\ttraining's binary_logloss: 0.000145162\n",
      "[1277]\ttraining's binary_logloss: 0.000144302\n",
      "[1278]\ttraining's binary_logloss: 0.000143402\n",
      "[1279]\ttraining's binary_logloss: 0.000142383\n",
      "[1280]\ttraining's binary_logloss: 0.000141432\n",
      "[1281]\ttraining's binary_logloss: 0.000140576\n",
      "[1282]\ttraining's binary_logloss: 0.000139596\n",
      "[1283]\ttraining's binary_logloss: 0.000138767\n",
      "[1284]\ttraining's binary_logloss: 0.000137882\n",
      "[1285]\ttraining's binary_logloss: 0.000137246\n",
      "[1286]\ttraining's binary_logloss: 0.000136723\n",
      "[1287]\ttraining's binary_logloss: 0.000136128\n",
      "[1288]\ttraining's binary_logloss: 0.000135504\n",
      "[1289]\ttraining's binary_logloss: 0.000134607\n",
      "[1290]\ttraining's binary_logloss: 0.000133793\n",
      "[1291]\ttraining's binary_logloss: 0.000133198\n",
      "[1292]\ttraining's binary_logloss: 0.000132243\n",
      "[1293]\ttraining's binary_logloss: 0.000131391\n",
      "[1294]\ttraining's binary_logloss: 0.000130462\n",
      "[1295]\ttraining's binary_logloss: 0.000129585\n",
      "[1296]\ttraining's binary_logloss: 0.000128769\n",
      "[1297]\ttraining's binary_logloss: 0.000127899\n",
      "[1298]\ttraining's binary_logloss: 0.000126954\n",
      "[1299]\ttraining's binary_logloss: 0.000126177\n",
      "[1300]\ttraining's binary_logloss: 0.000125382\n",
      "[1301]\ttraining's binary_logloss: 0.000124563\n",
      "[1302]\ttraining's binary_logloss: 0.00012367\n",
      "[1303]\ttraining's binary_logloss: 0.000122898\n",
      "[1304]\ttraining's binary_logloss: 0.000122289\n",
      "[1305]\ttraining's binary_logloss: 0.000121427\n",
      "[1306]\ttraining's binary_logloss: 0.000120608\n",
      "[1307]\ttraining's binary_logloss: 0.000120054\n",
      "[1308]\ttraining's binary_logloss: 0.000119539\n",
      "[1309]\ttraining's binary_logloss: 0.000118822\n",
      "[1310]\ttraining's binary_logloss: 0.00011813\n",
      "[1311]\ttraining's binary_logloss: 0.000117611\n",
      "[1312]\ttraining's binary_logloss: 0.000117004\n",
      "[1313]\ttraining's binary_logloss: 0.000116557\n",
      "[1314]\ttraining's binary_logloss: 0.000116078\n",
      "[1315]\ttraining's binary_logloss: 0.000115356\n",
      "[1316]\ttraining's binary_logloss: 0.000114677\n",
      "[1317]\ttraining's binary_logloss: 0.000113929\n",
      "[1318]\ttraining's binary_logloss: 0.000113287\n",
      "[1319]\ttraining's binary_logloss: 0.0001126\n",
      "[1320]\ttraining's binary_logloss: 0.000111954\n",
      "[1321]\ttraining's binary_logloss: 0.000111256\n",
      "[1322]\ttraining's binary_logloss: 0.000110536\n",
      "[1323]\ttraining's binary_logloss: 0.000109788\n",
      "[1324]\ttraining's binary_logloss: 0.000109104\n",
      "[1325]\ttraining's binary_logloss: 0.000108508\n",
      "[1326]\ttraining's binary_logloss: 0.000107758\n",
      "[1327]\ttraining's binary_logloss: 0.000107194\n",
      "[1328]\ttraining's binary_logloss: 0.000106593\n",
      "[1329]\ttraining's binary_logloss: 0.000105967\n",
      "[1330]\ttraining's binary_logloss: 0.000105383\n",
      "[1331]\ttraining's binary_logloss: 0.00010472\n",
      "[1332]\ttraining's binary_logloss: 0.000104013\n",
      "[1333]\ttraining's binary_logloss: 0.000103428\n",
      "[1334]\ttraining's binary_logloss: 0.000102854\n",
      "[1335]\ttraining's binary_logloss: 0.000102241\n",
      "[1336]\ttraining's binary_logloss: 0.000101603\n",
      "[1337]\ttraining's binary_logloss: 0.000101044\n",
      "[1338]\ttraining's binary_logloss: 0.00010047\n",
      "[1339]\ttraining's binary_logloss: 9.99145e-05\n",
      "[1340]\ttraining's binary_logloss: 9.93875e-05\n",
      "[1341]\ttraining's binary_logloss: 9.88293e-05\n",
      "[1342]\ttraining's binary_logloss: 9.83084e-05\n",
      "[1343]\ttraining's binary_logloss: 9.77974e-05\n",
      "[1344]\ttraining's binary_logloss: 9.71568e-05\n",
      "[1345]\ttraining's binary_logloss: 9.65591e-05\n",
      "[1346]\ttraining's binary_logloss: 9.59038e-05\n",
      "[1347]\ttraining's binary_logloss: 9.53204e-05\n",
      "[1348]\ttraining's binary_logloss: 9.47553e-05\n",
      "[1349]\ttraining's binary_logloss: 9.42204e-05\n",
      "[1350]\ttraining's binary_logloss: 9.3664e-05\n",
      "[1351]\ttraining's binary_logloss: 9.3162e-05\n",
      "[1352]\ttraining's binary_logloss: 9.2633e-05\n",
      "[1353]\ttraining's binary_logloss: 9.21587e-05\n",
      "[1354]\ttraining's binary_logloss: 9.16596e-05\n",
      "[1355]\ttraining's binary_logloss: 9.11439e-05\n",
      "[1356]\ttraining's binary_logloss: 9.06688e-05\n",
      "[1357]\ttraining's binary_logloss: 9.02081e-05\n",
      "[1358]\ttraining's binary_logloss: 8.97343e-05\n",
      "[1359]\ttraining's binary_logloss: 8.92102e-05\n",
      "[1360]\ttraining's binary_logloss: 8.86366e-05\n",
      "[1361]\ttraining's binary_logloss: 8.81848e-05\n",
      "[1362]\ttraining's binary_logloss: 8.76919e-05\n",
      "[1363]\ttraining's binary_logloss: 8.71918e-05\n",
      "[1364]\ttraining's binary_logloss: 8.67071e-05\n",
      "[1365]\ttraining's binary_logloss: 8.62622e-05\n",
      "[1366]\ttraining's binary_logloss: 8.57444e-05\n",
      "[1367]\ttraining's binary_logloss: 8.52515e-05\n",
      "[1368]\ttraining's binary_logloss: 8.47866e-05\n",
      "[1369]\ttraining's binary_logloss: 8.42567e-05\n",
      "[1370]\ttraining's binary_logloss: 8.37778e-05\n",
      "[1371]\ttraining's binary_logloss: 8.33529e-05\n",
      "[1372]\ttraining's binary_logloss: 8.27982e-05\n",
      "[1373]\ttraining's binary_logloss: 8.23405e-05\n",
      "[1374]\ttraining's binary_logloss: 8.19055e-05\n",
      "[1375]\ttraining's binary_logloss: 8.14791e-05\n",
      "[1376]\ttraining's binary_logloss: 8.10332e-05\n",
      "[1377]\ttraining's binary_logloss: 8.05608e-05\n",
      "[1378]\ttraining's binary_logloss: 8.0071e-05\n",
      "[1379]\ttraining's binary_logloss: 7.96379e-05\n",
      "[1380]\ttraining's binary_logloss: 7.92237e-05\n",
      "[1381]\ttraining's binary_logloss: 7.87763e-05\n",
      "[1382]\ttraining's binary_logloss: 7.83383e-05\n",
      "[1383]\ttraining's binary_logloss: 7.79539e-05\n",
      "[1384]\ttraining's binary_logloss: 7.74489e-05\n",
      "[1385]\ttraining's binary_logloss: 7.70374e-05\n",
      "[1386]\ttraining's binary_logloss: 7.65817e-05\n",
      "[1387]\ttraining's binary_logloss: 7.61365e-05\n",
      "[1388]\ttraining's binary_logloss: 7.56995e-05\n",
      "[1389]\ttraining's binary_logloss: 7.53181e-05\n",
      "[1390]\ttraining's binary_logloss: 7.48752e-05\n",
      "[1391]\ttraining's binary_logloss: 7.44297e-05\n",
      "[1392]\ttraining's binary_logloss: 7.40334e-05\n",
      "[1393]\ttraining's binary_logloss: 7.36333e-05\n",
      "[1394]\ttraining's binary_logloss: 7.32469e-05\n",
      "[1395]\ttraining's binary_logloss: 7.28196e-05\n",
      "[1396]\ttraining's binary_logloss: 7.23966e-05\n",
      "[1397]\ttraining's binary_logloss: 7.20332e-05\n",
      "[1398]\ttraining's binary_logloss: 7.16037e-05\n",
      "[1399]\ttraining's binary_logloss: 7.11814e-05\n",
      "[1400]\ttraining's binary_logloss: 7.08333e-05\n",
      "[1401]\ttraining's binary_logloss: 7.04066e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1402]\ttraining's binary_logloss: 6.99636e-05\n",
      "[1403]\ttraining's binary_logloss: 6.95481e-05\n",
      "[1404]\ttraining's binary_logloss: 6.91949e-05\n",
      "[1405]\ttraining's binary_logloss: 6.88043e-05\n",
      "[1406]\ttraining's binary_logloss: 6.8381e-05\n",
      "[1407]\ttraining's binary_logloss: 6.80552e-05\n",
      "[1408]\ttraining's binary_logloss: 6.76914e-05\n",
      "[1409]\ttraining's binary_logloss: 6.7334e-05\n",
      "[1410]\ttraining's binary_logloss: 6.69918e-05\n",
      "[1411]\ttraining's binary_logloss: 6.66696e-05\n",
      "[1412]\ttraining's binary_logloss: 6.629e-05\n",
      "[1413]\ttraining's binary_logloss: 6.59239e-05\n",
      "[1414]\ttraining's binary_logloss: 6.55501e-05\n",
      "[1415]\ttraining's binary_logloss: 6.51702e-05\n",
      "[1416]\ttraining's binary_logloss: 6.48149e-05\n",
      "[1417]\ttraining's binary_logloss: 6.44228e-05\n",
      "[1418]\ttraining's binary_logloss: 6.40813e-05\n",
      "[1419]\ttraining's binary_logloss: 6.37522e-05\n",
      "[1420]\ttraining's binary_logloss: 6.34546e-05\n",
      "[1421]\ttraining's binary_logloss: 6.31226e-05\n",
      "[1422]\ttraining's binary_logloss: 6.28474e-05\n",
      "[1423]\ttraining's binary_logloss: 6.24691e-05\n",
      "[1424]\ttraining's binary_logloss: 6.21473e-05\n",
      "[1425]\ttraining's binary_logloss: 6.17464e-05\n",
      "[1426]\ttraining's binary_logloss: 6.13633e-05\n",
      "[1427]\ttraining's binary_logloss: 6.09814e-05\n",
      "[1428]\ttraining's binary_logloss: 6.07092e-05\n",
      "[1429]\ttraining's binary_logloss: 6.04166e-05\n",
      "[1430]\ttraining's binary_logloss: 6.01354e-05\n",
      "[1431]\ttraining's binary_logloss: 5.98393e-05\n",
      "[1432]\ttraining's binary_logloss: 5.9536e-05\n",
      "[1433]\ttraining's binary_logloss: 5.92245e-05\n",
      "[1434]\ttraining's binary_logloss: 5.89293e-05\n",
      "[1435]\ttraining's binary_logloss: 5.86183e-05\n",
      "[1436]\ttraining's binary_logloss: 5.82814e-05\n",
      "[1437]\ttraining's binary_logloss: 5.79842e-05\n",
      "[1438]\ttraining's binary_logloss: 5.76587e-05\n",
      "[1439]\ttraining's binary_logloss: 5.73654e-05\n",
      "[1440]\ttraining's binary_logloss: 5.71125e-05\n",
      "[1441]\ttraining's binary_logloss: 5.68128e-05\n",
      "[1442]\ttraining's binary_logloss: 5.65696e-05\n",
      "[1443]\ttraining's binary_logloss: 5.62671e-05\n",
      "[1444]\ttraining's binary_logloss: 5.60011e-05\n",
      "[1445]\ttraining's binary_logloss: 5.57232e-05\n",
      "[1446]\ttraining's binary_logloss: 5.54369e-05\n",
      "[1447]\ttraining's binary_logloss: 5.51322e-05\n",
      "[1448]\ttraining's binary_logloss: 5.48218e-05\n",
      "[1449]\ttraining's binary_logloss: 5.45625e-05\n",
      "[1450]\ttraining's binary_logloss: 5.42932e-05\n",
      "[1451]\ttraining's binary_logloss: 5.39589e-05\n",
      "[1452]\ttraining's binary_logloss: 5.36886e-05\n",
      "[1453]\ttraining's binary_logloss: 5.34193e-05\n",
      "[1454]\ttraining's binary_logloss: 5.31631e-05\n",
      "[1455]\ttraining's binary_logloss: 5.2905e-05\n",
      "[1456]\ttraining's binary_logloss: 5.26062e-05\n",
      "[1457]\ttraining's binary_logloss: 5.22907e-05\n",
      "[1458]\ttraining's binary_logloss: 5.20029e-05\n",
      "[1459]\ttraining's binary_logloss: 5.17252e-05\n",
      "[1460]\ttraining's binary_logloss: 5.14618e-05\n",
      "[1461]\ttraining's binary_logloss: 5.1231e-05\n",
      "[1462]\ttraining's binary_logloss: 5.09568e-05\n",
      "[1463]\ttraining's binary_logloss: 5.06942e-05\n",
      "[1464]\ttraining's binary_logloss: 5.04507e-05\n",
      "[1465]\ttraining's binary_logloss: 5.02237e-05\n",
      "[1466]\ttraining's binary_logloss: 4.99726e-05\n",
      "[1467]\ttraining's binary_logloss: 4.97172e-05\n",
      "[1468]\ttraining's binary_logloss: 4.94322e-05\n",
      "[1469]\ttraining's binary_logloss: 4.92017e-05\n",
      "[1470]\ttraining's binary_logloss: 4.89546e-05\n",
      "[1471]\ttraining's binary_logloss: 4.87102e-05\n",
      "[1472]\ttraining's binary_logloss: 4.85057e-05\n",
      "[1473]\ttraining's binary_logloss: 4.82558e-05\n",
      "[1474]\ttraining's binary_logloss: 4.80303e-05\n",
      "[1475]\ttraining's binary_logloss: 4.78035e-05\n",
      "[1476]\ttraining's binary_logloss: 4.75528e-05\n",
      "[1477]\ttraining's binary_logloss: 4.72814e-05\n",
      "[1478]\ttraining's binary_logloss: 4.70007e-05\n",
      "[1479]\ttraining's binary_logloss: 4.67942e-05\n",
      "[1480]\ttraining's binary_logloss: 4.65571e-05\n",
      "[1481]\ttraining's binary_logloss: 4.63469e-05\n",
      "[1482]\ttraining's binary_logloss: 4.60945e-05\n",
      "[1483]\ttraining's binary_logloss: 4.58839e-05\n",
      "[1484]\ttraining's binary_logloss: 4.56566e-05\n",
      "[1485]\ttraining's binary_logloss: 4.54447e-05\n",
      "[1486]\ttraining's binary_logloss: 4.52163e-05\n",
      "[1487]\ttraining's binary_logloss: 4.50111e-05\n",
      "[1488]\ttraining's binary_logloss: 4.4799e-05\n",
      "[1489]\ttraining's binary_logloss: 4.45948e-05\n",
      "[1490]\ttraining's binary_logloss: 4.43662e-05\n",
      "[1491]\ttraining's binary_logloss: 4.41566e-05\n",
      "[1492]\ttraining's binary_logloss: 4.39549e-05\n",
      "[1493]\ttraining's binary_logloss: 4.37619e-05\n",
      "[1494]\ttraining's binary_logloss: 4.35435e-05\n",
      "[1495]\ttraining's binary_logloss: 4.33518e-05\n",
      "[1496]\ttraining's binary_logloss: 4.31532e-05\n",
      "[1497]\ttraining's binary_logloss: 4.29522e-05\n",
      "[1498]\ttraining's binary_logloss: 4.27403e-05\n",
      "[1499]\ttraining's binary_logloss: 4.25373e-05\n",
      "[1500]\ttraining's binary_logloss: 4.23579e-05\n",
      "[1501]\ttraining's binary_logloss: 4.21765e-05\n",
      "[1502]\ttraining's binary_logloss: 4.19881e-05\n",
      "[1503]\ttraining's binary_logloss: 4.17988e-05\n",
      "[1504]\ttraining's binary_logloss: 4.16216e-05\n",
      "[1505]\ttraining's binary_logloss: 4.1408e-05\n",
      "[1506]\ttraining's binary_logloss: 4.12089e-05\n",
      "[1507]\ttraining's binary_logloss: 4.10426e-05\n",
      "[1508]\ttraining's binary_logloss: 4.08219e-05\n",
      "[1509]\ttraining's binary_logloss: 4.06343e-05\n",
      "[1510]\ttraining's binary_logloss: 4.04452e-05\n",
      "[1511]\ttraining's binary_logloss: 4.02543e-05\n",
      "[1512]\ttraining's binary_logloss: 4.0097e-05\n",
      "[1513]\ttraining's binary_logloss: 3.99012e-05\n",
      "[1514]\ttraining's binary_logloss: 3.96886e-05\n",
      "[1515]\ttraining's binary_logloss: 3.94964e-05\n",
      "[1516]\ttraining's binary_logloss: 3.93003e-05\n",
      "[1517]\ttraining's binary_logloss: 3.91054e-05\n",
      "[1518]\ttraining's binary_logloss: 3.89409e-05\n",
      "[1519]\ttraining's binary_logloss: 3.87234e-05\n",
      "[1520]\ttraining's binary_logloss: 3.8558e-05\n",
      "[1521]\ttraining's binary_logloss: 3.83948e-05\n",
      "[1522]\ttraining's binary_logloss: 3.82155e-05\n",
      "[1523]\ttraining's binary_logloss: 3.80288e-05\n",
      "[1524]\ttraining's binary_logloss: 3.78426e-05\n",
      "[1525]\ttraining's binary_logloss: 3.76552e-05\n",
      "[1526]\ttraining's binary_logloss: 3.74662e-05\n",
      "[1527]\ttraining's binary_logloss: 3.72773e-05\n",
      "[1528]\ttraining's binary_logloss: 3.71037e-05\n",
      "[1529]\ttraining's binary_logloss: 3.69276e-05\n",
      "[1530]\ttraining's binary_logloss: 3.67505e-05\n",
      "[1531]\ttraining's binary_logloss: 3.6569e-05\n",
      "[1532]\ttraining's binary_logloss: 3.64103e-05\n",
      "[1533]\ttraining's binary_logloss: 3.62311e-05\n",
      "[1534]\ttraining's binary_logloss: 3.60579e-05\n",
      "[1535]\ttraining's binary_logloss: 3.58982e-05\n",
      "[1536]\ttraining's binary_logloss: 3.57367e-05\n",
      "[1537]\ttraining's binary_logloss: 3.55725e-05\n",
      "[1538]\ttraining's binary_logloss: 3.54014e-05\n",
      "[1539]\ttraining's binary_logloss: 3.52423e-05\n",
      "[1540]\ttraining's binary_logloss: 3.50881e-05\n",
      "[1541]\ttraining's binary_logloss: 3.49189e-05\n",
      "[1542]\ttraining's binary_logloss: 3.47221e-05\n",
      "[1543]\ttraining's binary_logloss: 3.4579e-05\n",
      "[1544]\ttraining's binary_logloss: 3.44216e-05\n",
      "[1545]\ttraining's binary_logloss: 3.42398e-05\n",
      "[1546]\ttraining's binary_logloss: 3.40846e-05\n",
      "[1547]\ttraining's binary_logloss: 3.39189e-05\n",
      "[1548]\ttraining's binary_logloss: 3.3764e-05\n",
      "[1549]\ttraining's binary_logloss: 3.36279e-05\n",
      "[1550]\ttraining's binary_logloss: 3.34789e-05\n",
      "[1551]\ttraining's binary_logloss: 3.33281e-05\n",
      "[1552]\ttraining's binary_logloss: 3.31731e-05\n",
      "[1553]\ttraining's binary_logloss: 3.30345e-05\n",
      "[1554]\ttraining's binary_logloss: 3.29047e-05\n",
      "[1555]\ttraining's binary_logloss: 3.27438e-05\n",
      "[1556]\ttraining's binary_logloss: 3.26066e-05\n",
      "[1557]\ttraining's binary_logloss: 3.24292e-05\n",
      "[1558]\ttraining's binary_logloss: 3.22649e-05\n",
      "[1559]\ttraining's binary_logloss: 3.21199e-05\n",
      "[1560]\ttraining's binary_logloss: 3.1982e-05\n",
      "[1561]\ttraining's binary_logloss: 3.1838e-05\n",
      "[1562]\ttraining's binary_logloss: 3.17001e-05\n",
      "[1563]\ttraining's binary_logloss: 3.15528e-05\n",
      "[1564]\ttraining's binary_logloss: 3.14059e-05\n",
      "[1565]\ttraining's binary_logloss: 3.12657e-05\n",
      "[1566]\ttraining's binary_logloss: 3.11327e-05\n",
      "[1567]\ttraining's binary_logloss: 3.09947e-05\n",
      "[1568]\ttraining's binary_logloss: 3.08364e-05\n",
      "[1569]\ttraining's binary_logloss: 3.06975e-05\n",
      "[1570]\ttraining's binary_logloss: 3.05726e-05\n",
      "[1571]\ttraining's binary_logloss: 3.04542e-05\n",
      "[1572]\ttraining's binary_logloss: 3.03287e-05\n",
      "[1573]\ttraining's binary_logloss: 3.01901e-05\n",
      "[1574]\ttraining's binary_logloss: 3.00605e-05\n",
      "[1575]\ttraining's binary_logloss: 2.99328e-05\n",
      "[1576]\ttraining's binary_logloss: 2.97925e-05\n",
      "[1577]\ttraining's binary_logloss: 2.96445e-05\n",
      "[1578]\ttraining's binary_logloss: 2.95311e-05\n",
      "[1579]\ttraining's binary_logloss: 2.93994e-05\n",
      "[1580]\ttraining's binary_logloss: 2.92869e-05\n",
      "[1581]\ttraining's binary_logloss: 2.91539e-05\n",
      "[1582]\ttraining's binary_logloss: 2.90398e-05\n",
      "[1583]\ttraining's binary_logloss: 2.89232e-05\n",
      "[1584]\ttraining's binary_logloss: 2.88034e-05\n",
      "[1585]\ttraining's binary_logloss: 2.86647e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1586]\ttraining's binary_logloss: 2.85442e-05\n",
      "[1587]\ttraining's binary_logloss: 2.84278e-05\n",
      "[1588]\ttraining's binary_logloss: 2.83204e-05\n",
      "[1589]\ttraining's binary_logloss: 2.82165e-05\n",
      "[1590]\ttraining's binary_logloss: 2.80916e-05\n",
      "[1591]\ttraining's binary_logloss: 2.79647e-05\n",
      "[1592]\ttraining's binary_logloss: 2.78469e-05\n",
      "[1593]\ttraining's binary_logloss: 2.77338e-05\n",
      "[1594]\ttraining's binary_logloss: 2.76058e-05\n",
      "[1595]\ttraining's binary_logloss: 2.74874e-05\n",
      "[1596]\ttraining's binary_logloss: 2.73679e-05\n",
      "[1597]\ttraining's binary_logloss: 2.7242e-05\n",
      "[1598]\ttraining's binary_logloss: 2.71284e-05\n",
      "[1599]\ttraining's binary_logloss: 2.70151e-05\n",
      "[1600]\ttraining's binary_logloss: 2.6904e-05\n",
      "[1601]\ttraining's binary_logloss: 2.67999e-05\n",
      "[1602]\ttraining's binary_logloss: 2.66951e-05\n",
      "[1603]\ttraining's binary_logloss: 2.65822e-05\n",
      "[1604]\ttraining's binary_logloss: 2.64844e-05\n",
      "[1605]\ttraining's binary_logloss: 2.63776e-05\n",
      "[1606]\ttraining's binary_logloss: 2.62792e-05\n",
      "[1607]\ttraining's binary_logloss: 2.61699e-05\n",
      "[1608]\ttraining's binary_logloss: 2.60569e-05\n",
      "[1609]\ttraining's binary_logloss: 2.59504e-05\n",
      "[1610]\ttraining's binary_logloss: 2.58336e-05\n",
      "[1611]\ttraining's binary_logloss: 2.57367e-05\n",
      "[1612]\ttraining's binary_logloss: 2.56377e-05\n",
      "[1613]\ttraining's binary_logloss: 2.55414e-05\n",
      "[1614]\ttraining's binary_logloss: 2.54428e-05\n",
      "[1615]\ttraining's binary_logloss: 2.53455e-05\n",
      "[1616]\ttraining's binary_logloss: 2.52445e-05\n",
      "[1617]\ttraining's binary_logloss: 2.51516e-05\n",
      "[1618]\ttraining's binary_logloss: 2.50492e-05\n",
      "[1619]\ttraining's binary_logloss: 2.49478e-05\n",
      "[1620]\ttraining's binary_logloss: 2.48384e-05\n",
      "[1621]\ttraining's binary_logloss: 2.47334e-05\n",
      "[1622]\ttraining's binary_logloss: 2.46424e-05\n",
      "[1623]\ttraining's binary_logloss: 2.45476e-05\n",
      "[1624]\ttraining's binary_logloss: 2.44413e-05\n",
      "[1625]\ttraining's binary_logloss: 2.43444e-05\n",
      "[1626]\ttraining's binary_logloss: 2.42542e-05\n",
      "[1627]\ttraining's binary_logloss: 2.41673e-05\n",
      "[1628]\ttraining's binary_logloss: 2.40721e-05\n",
      "[1629]\ttraining's binary_logloss: 2.39838e-05\n",
      "[1630]\ttraining's binary_logloss: 2.38869e-05\n",
      "[1631]\ttraining's binary_logloss: 2.38017e-05\n",
      "[1632]\ttraining's binary_logloss: 2.37192e-05\n",
      "[1633]\ttraining's binary_logloss: 2.36331e-05\n",
      "[1634]\ttraining's binary_logloss: 2.35335e-05\n",
      "[1635]\ttraining's binary_logloss: 2.34482e-05\n",
      "[1636]\ttraining's binary_logloss: 2.33533e-05\n",
      "[1637]\ttraining's binary_logloss: 2.32711e-05\n",
      "[1638]\ttraining's binary_logloss: 2.31759e-05\n",
      "[1639]\ttraining's binary_logloss: 2.30861e-05\n",
      "[1640]\ttraining's binary_logloss: 2.29916e-05\n",
      "[1641]\ttraining's binary_logloss: 2.29121e-05\n",
      "[1642]\ttraining's binary_logloss: 2.2823e-05\n",
      "[1643]\ttraining's binary_logloss: 2.27428e-05\n",
      "[1644]\ttraining's binary_logloss: 2.26556e-05\n",
      "[1645]\ttraining's binary_logloss: 2.2565e-05\n",
      "[1646]\ttraining's binary_logloss: 2.24669e-05\n",
      "[1647]\ttraining's binary_logloss: 2.23722e-05\n",
      "[1648]\ttraining's binary_logloss: 2.22915e-05\n",
      "[1649]\ttraining's binary_logloss: 2.22127e-05\n",
      "[1650]\ttraining's binary_logloss: 2.21204e-05\n",
      "[1651]\ttraining's binary_logloss: 2.2036e-05\n",
      "[1652]\ttraining's binary_logloss: 2.19527e-05\n",
      "[1653]\ttraining's binary_logloss: 2.18794e-05\n",
      "[1654]\ttraining's binary_logloss: 2.17979e-05\n",
      "[1655]\ttraining's binary_logloss: 2.17153e-05\n",
      "[1656]\ttraining's binary_logloss: 2.16331e-05\n",
      "[1657]\ttraining's binary_logloss: 2.15499e-05\n",
      "[1658]\ttraining's binary_logloss: 2.14724e-05\n",
      "[1659]\ttraining's binary_logloss: 2.13989e-05\n",
      "[1660]\ttraining's binary_logloss: 2.1326e-05\n",
      "[1661]\ttraining's binary_logloss: 2.12378e-05\n",
      "[1662]\ttraining's binary_logloss: 2.11605e-05\n",
      "[1663]\ttraining's binary_logloss: 2.10803e-05\n",
      "[1664]\ttraining's binary_logloss: 2.10066e-05\n",
      "[1665]\ttraining's binary_logloss: 2.09326e-05\n",
      "[1666]\ttraining's binary_logloss: 2.08511e-05\n",
      "[1667]\ttraining's binary_logloss: 2.07813e-05\n",
      "[1668]\ttraining's binary_logloss: 2.07012e-05\n",
      "[1669]\ttraining's binary_logloss: 2.06335e-05\n",
      "[1670]\ttraining's binary_logloss: 2.05599e-05\n",
      "[1671]\ttraining's binary_logloss: 2.04809e-05\n",
      "[1672]\ttraining's binary_logloss: 2.04072e-05\n",
      "[1673]\ttraining's binary_logloss: 2.03298e-05\n",
      "[1674]\ttraining's binary_logloss: 2.0254e-05\n",
      "[1675]\ttraining's binary_logloss: 2.01854e-05\n",
      "[1676]\ttraining's binary_logloss: 2.01176e-05\n",
      "[1677]\ttraining's binary_logloss: 2.00482e-05\n",
      "[1678]\ttraining's binary_logloss: 1.99751e-05\n",
      "[1679]\ttraining's binary_logloss: 1.99081e-05\n",
      "[1680]\ttraining's binary_logloss: 1.98435e-05\n",
      "[1681]\ttraining's binary_logloss: 1.9777e-05\n",
      "[1682]\ttraining's binary_logloss: 1.97068e-05\n",
      "[1683]\ttraining's binary_logloss: 1.96432e-05\n",
      "[1684]\ttraining's binary_logloss: 1.95765e-05\n",
      "[1685]\ttraining's binary_logloss: 1.95098e-05\n",
      "[1686]\ttraining's binary_logloss: 1.94491e-05\n",
      "[1687]\ttraining's binary_logloss: 1.93818e-05\n",
      "[1688]\ttraining's binary_logloss: 1.93223e-05\n",
      "[1689]\ttraining's binary_logloss: 1.92574e-05\n",
      "[1690]\ttraining's binary_logloss: 1.91979e-05\n",
      "[1691]\ttraining's binary_logloss: 1.91302e-05\n",
      "[1692]\ttraining's binary_logloss: 1.90662e-05\n",
      "[1693]\ttraining's binary_logloss: 1.90043e-05\n",
      "[1694]\ttraining's binary_logloss: 1.89452e-05\n",
      "[1695]\ttraining's binary_logloss: 1.88842e-05\n",
      "[1696]\ttraining's binary_logloss: 1.8828e-05\n",
      "[1697]\ttraining's binary_logloss: 1.8763e-05\n",
      "[1698]\ttraining's binary_logloss: 1.86956e-05\n",
      "[1699]\ttraining's binary_logloss: 1.86314e-05\n",
      "[1700]\ttraining's binary_logloss: 1.85694e-05\n",
      "[1701]\ttraining's binary_logloss: 1.85074e-05\n",
      "[1702]\ttraining's binary_logloss: 1.84468e-05\n",
      "[1703]\ttraining's binary_logloss: 1.83901e-05\n",
      "[1704]\ttraining's binary_logloss: 1.83254e-05\n",
      "[1705]\ttraining's binary_logloss: 1.82658e-05\n",
      "[1706]\ttraining's binary_logloss: 1.82099e-05\n",
      "[1707]\ttraining's binary_logloss: 1.81453e-05\n",
      "[1708]\ttraining's binary_logloss: 1.80804e-05\n",
      "[1709]\ttraining's binary_logloss: 1.80257e-05\n",
      "[1710]\ttraining's binary_logloss: 1.79766e-05\n",
      "[1711]\ttraining's binary_logloss: 1.79118e-05\n",
      "[1712]\ttraining's binary_logloss: 1.78483e-05\n",
      "[1713]\ttraining's binary_logloss: 1.77811e-05\n",
      "[1714]\ttraining's binary_logloss: 1.7727e-05\n",
      "[1715]\ttraining's binary_logloss: 1.76685e-05\n",
      "[1716]\ttraining's binary_logloss: 1.76175e-05\n",
      "[1717]\ttraining's binary_logloss: 1.75615e-05\n",
      "[1718]\ttraining's binary_logloss: 1.75011e-05\n",
      "[1719]\ttraining's binary_logloss: 1.74513e-05\n",
      "[1720]\ttraining's binary_logloss: 1.7397e-05\n",
      "[1721]\ttraining's binary_logloss: 1.73408e-05\n",
      "[1722]\ttraining's binary_logloss: 1.72889e-05\n",
      "[1723]\ttraining's binary_logloss: 1.7233e-05\n",
      "[1724]\ttraining's binary_logloss: 1.71845e-05\n",
      "[1725]\ttraining's binary_logloss: 1.71305e-05\n",
      "[1726]\ttraining's binary_logloss: 1.70847e-05\n",
      "[1727]\ttraining's binary_logloss: 1.70358e-05\n",
      "[1728]\ttraining's binary_logloss: 1.69832e-05\n",
      "[1729]\ttraining's binary_logloss: 1.69271e-05\n",
      "[1730]\ttraining's binary_logloss: 1.68827e-05\n",
      "[1731]\ttraining's binary_logloss: 1.68337e-05\n",
      "[1732]\ttraining's binary_logloss: 1.67835e-05\n",
      "[1733]\ttraining's binary_logloss: 1.67333e-05\n",
      "[1734]\ttraining's binary_logloss: 1.6685e-05\n",
      "[1735]\ttraining's binary_logloss: 1.66381e-05\n",
      "[1736]\ttraining's binary_logloss: 1.65883e-05\n",
      "[1737]\ttraining's binary_logloss: 1.65453e-05\n",
      "[1738]\ttraining's binary_logloss: 1.64934e-05\n",
      "[1739]\ttraining's binary_logloss: 1.64432e-05\n",
      "[1740]\ttraining's binary_logloss: 1.63944e-05\n",
      "[1741]\ttraining's binary_logloss: 1.63474e-05\n",
      "[1742]\ttraining's binary_logloss: 1.63009e-05\n",
      "[1743]\ttraining's binary_logloss: 1.62522e-05\n",
      "[1744]\ttraining's binary_logloss: 1.62084e-05\n",
      "[1745]\ttraining's binary_logloss: 1.6163e-05\n",
      "[1746]\ttraining's binary_logloss: 1.61156e-05\n",
      "[1747]\ttraining's binary_logloss: 1.607e-05\n",
      "[1748]\ttraining's binary_logloss: 1.6027e-05\n",
      "[1749]\ttraining's binary_logloss: 1.59841e-05\n",
      "[1750]\ttraining's binary_logloss: 1.59386e-05\n",
      "[1751]\ttraining's binary_logloss: 1.58897e-05\n",
      "[1752]\ttraining's binary_logloss: 1.58485e-05\n",
      "[1753]\ttraining's binary_logloss: 1.57995e-05\n",
      "[1754]\ttraining's binary_logloss: 1.5753e-05\n",
      "[1755]\ttraining's binary_logloss: 1.57077e-05\n",
      "[1756]\ttraining's binary_logloss: 1.56574e-05\n",
      "[1757]\ttraining's binary_logloss: 1.56092e-05\n",
      "[1758]\ttraining's binary_logloss: 1.55685e-05\n",
      "[1759]\ttraining's binary_logloss: 1.55245e-05\n",
      "[1760]\ttraining's binary_logloss: 1.54765e-05\n",
      "[1761]\ttraining's binary_logloss: 1.54345e-05\n",
      "[1762]\ttraining's binary_logloss: 1.53934e-05\n",
      "[1763]\ttraining's binary_logloss: 1.53541e-05\n",
      "[1764]\ttraining's binary_logloss: 1.5312e-05\n",
      "[1765]\ttraining's binary_logloss: 1.52659e-05\n",
      "[1766]\ttraining's binary_logloss: 1.52288e-05\n",
      "[1767]\ttraining's binary_logloss: 1.51931e-05\n",
      "[1768]\ttraining's binary_logloss: 1.5154e-05\n",
      "[1769]\ttraining's binary_logloss: 1.51138e-05\n",
      "[1770]\ttraining's binary_logloss: 1.50713e-05\n",
      "[1771]\ttraining's binary_logloss: 1.50295e-05\n",
      "[1772]\ttraining's binary_logloss: 1.49944e-05\n",
      "[1773]\ttraining's binary_logloss: 1.49554e-05\n",
      "[1774]\ttraining's binary_logloss: 1.49149e-05\n",
      "[1775]\ttraining's binary_logloss: 1.48734e-05\n",
      "[1776]\ttraining's binary_logloss: 1.4834e-05\n",
      "[1777]\ttraining's binary_logloss: 1.47945e-05\n",
      "[1778]\ttraining's binary_logloss: 1.47553e-05\n",
      "[1779]\ttraining's binary_logloss: 1.47201e-05\n",
      "[1780]\ttraining's binary_logloss: 1.46813e-05\n",
      "[1781]\ttraining's binary_logloss: 1.4647e-05\n",
      "[1782]\ttraining's binary_logloss: 1.4614e-05\n",
      "[1783]\ttraining's binary_logloss: 1.45782e-05\n",
      "[1784]\ttraining's binary_logloss: 1.45397e-05\n",
      "[1785]\ttraining's binary_logloss: 1.45021e-05\n",
      "[1786]\ttraining's binary_logloss: 1.44668e-05\n",
      "[1787]\ttraining's binary_logloss: 1.44261e-05\n",
      "[1788]\ttraining's binary_logloss: 1.43917e-05\n",
      "[1789]\ttraining's binary_logloss: 1.43557e-05\n",
      "[1790]\ttraining's binary_logloss: 1.43176e-05\n",
      "[1791]\ttraining's binary_logloss: 1.42828e-05\n",
      "[1792]\ttraining's binary_logloss: 1.42485e-05\n",
      "[1793]\ttraining's binary_logloss: 1.4217e-05\n",
      "[1794]\ttraining's binary_logloss: 1.41792e-05\n",
      "[1795]\ttraining's binary_logloss: 1.4143e-05\n",
      "[1796]\ttraining's binary_logloss: 1.41098e-05\n",
      "[1797]\ttraining's binary_logloss: 1.40778e-05\n",
      "[1798]\ttraining's binary_logloss: 1.40455e-05\n",
      "[1799]\ttraining's binary_logloss: 1.40095e-05\n",
      "[1800]\ttraining's binary_logloss: 1.39789e-05\n",
      "[1801]\ttraining's binary_logloss: 1.39464e-05\n",
      "[1802]\ttraining's binary_logloss: 1.39089e-05\n",
      "[1803]\ttraining's binary_logloss: 1.38746e-05\n",
      "[1804]\ttraining's binary_logloss: 1.384e-05\n",
      "[1805]\ttraining's binary_logloss: 1.38119e-05\n",
      "[1806]\ttraining's binary_logloss: 1.37772e-05\n",
      "[1807]\ttraining's binary_logloss: 1.37461e-05\n",
      "[1808]\ttraining's binary_logloss: 1.37168e-05\n",
      "[1809]\ttraining's binary_logloss: 1.36847e-05\n",
      "[1810]\ttraining's binary_logloss: 1.36515e-05\n",
      "[1811]\ttraining's binary_logloss: 1.36169e-05\n",
      "[1812]\ttraining's binary_logloss: 1.35857e-05\n",
      "[1813]\ttraining's binary_logloss: 1.35574e-05\n",
      "[1814]\ttraining's binary_logloss: 1.35255e-05\n",
      "[1815]\ttraining's binary_logloss: 1.34913e-05\n",
      "[1816]\ttraining's binary_logloss: 1.34586e-05\n",
      "[1817]\ttraining's binary_logloss: 1.34261e-05\n",
      "[1818]\ttraining's binary_logloss: 1.33929e-05\n",
      "[1819]\ttraining's binary_logloss: 1.33628e-05\n",
      "[1820]\ttraining's binary_logloss: 1.33263e-05\n",
      "[1821]\ttraining's binary_logloss: 1.32986e-05\n",
      "[1822]\ttraining's binary_logloss: 1.32685e-05\n",
      "[1823]\ttraining's binary_logloss: 1.32369e-05\n",
      "[1824]\ttraining's binary_logloss: 1.32042e-05\n",
      "[1825]\ttraining's binary_logloss: 1.31738e-05\n",
      "[1826]\ttraining's binary_logloss: 1.31443e-05\n",
      "[1827]\ttraining's binary_logloss: 1.3111e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1828]\ttraining's binary_logloss: 1.30811e-05\n",
      "[1829]\ttraining's binary_logloss: 1.30507e-05\n",
      "[1830]\ttraining's binary_logloss: 1.30215e-05\n",
      "[1831]\ttraining's binary_logloss: 1.29946e-05\n",
      "[1832]\ttraining's binary_logloss: 1.29687e-05\n",
      "[1833]\ttraining's binary_logloss: 1.29378e-05\n",
      "[1834]\ttraining's binary_logloss: 1.29093e-05\n",
      "[1835]\ttraining's binary_logloss: 1.28829e-05\n",
      "[1836]\ttraining's binary_logloss: 1.28548e-05\n",
      "[1837]\ttraining's binary_logloss: 1.28232e-05\n",
      "[1838]\ttraining's binary_logloss: 1.27929e-05\n",
      "[1839]\ttraining's binary_logloss: 1.27612e-05\n",
      "[1840]\ttraining's binary_logloss: 1.27349e-05\n",
      "[1841]\ttraining's binary_logloss: 1.27091e-05\n",
      "[1842]\ttraining's binary_logloss: 1.26818e-05\n",
      "[1843]\ttraining's binary_logloss: 1.26575e-05\n",
      "[1844]\ttraining's binary_logloss: 1.263e-05\n",
      "[1845]\ttraining's binary_logloss: 1.26017e-05\n",
      "[1846]\ttraining's binary_logloss: 1.25739e-05\n",
      "[1847]\ttraining's binary_logloss: 1.25449e-05\n",
      "[1848]\ttraining's binary_logloss: 1.252e-05\n",
      "[1849]\ttraining's binary_logloss: 1.24941e-05\n",
      "[1850]\ttraining's binary_logloss: 1.24669e-05\n",
      "[1851]\ttraining's binary_logloss: 1.24394e-05\n",
      "[1852]\ttraining's binary_logloss: 1.24142e-05\n",
      "[1853]\ttraining's binary_logloss: 1.23915e-05\n",
      "[1854]\ttraining's binary_logloss: 1.23662e-05\n",
      "[1855]\ttraining's binary_logloss: 1.2342e-05\n",
      "[1856]\ttraining's binary_logloss: 1.23156e-05\n",
      "[1857]\ttraining's binary_logloss: 1.22873e-05\n",
      "[1858]\ttraining's binary_logloss: 1.22628e-05\n",
      "[1859]\ttraining's binary_logloss: 1.22365e-05\n",
      "[1860]\ttraining's binary_logloss: 1.22106e-05\n",
      "[1861]\ttraining's binary_logloss: 1.21822e-05\n",
      "[1862]\ttraining's binary_logloss: 1.2159e-05\n",
      "[1863]\ttraining's binary_logloss: 1.21355e-05\n",
      "[1864]\ttraining's binary_logloss: 1.21095e-05\n",
      "[1865]\ttraining's binary_logloss: 1.20854e-05\n",
      "[1866]\ttraining's binary_logloss: 1.20619e-05\n",
      "[1867]\ttraining's binary_logloss: 1.20344e-05\n",
      "[1868]\ttraining's binary_logloss: 1.20078e-05\n",
      "[1869]\ttraining's binary_logloss: 1.19824e-05\n",
      "[1870]\ttraining's binary_logloss: 1.19568e-05\n",
      "[1871]\ttraining's binary_logloss: 1.19314e-05\n",
      "[1872]\ttraining's binary_logloss: 1.19098e-05\n",
      "[1873]\ttraining's binary_logloss: 1.18837e-05\n",
      "[1874]\ttraining's binary_logloss: 1.18623e-05\n",
      "[1875]\ttraining's binary_logloss: 1.18398e-05\n",
      "[1876]\ttraining's binary_logloss: 1.18154e-05\n",
      "[1877]\ttraining's binary_logloss: 1.17924e-05\n",
      "[1878]\ttraining's binary_logloss: 1.1769e-05\n",
      "[1879]\ttraining's binary_logloss: 1.17468e-05\n",
      "[1880]\ttraining's binary_logloss: 1.17233e-05\n",
      "[1881]\ttraining's binary_logloss: 1.17002e-05\n",
      "[1882]\ttraining's binary_logloss: 1.16754e-05\n",
      "[1883]\ttraining's binary_logloss: 1.16545e-05\n",
      "[1884]\ttraining's binary_logloss: 1.16312e-05\n",
      "[1885]\ttraining's binary_logloss: 1.16075e-05\n",
      "[1886]\ttraining's binary_logloss: 1.15852e-05\n",
      "[1887]\ttraining's binary_logloss: 1.15642e-05\n",
      "[1888]\ttraining's binary_logloss: 1.15397e-05\n",
      "[1889]\ttraining's binary_logloss: 1.1518e-05\n",
      "[1890]\ttraining's binary_logloss: 1.14943e-05\n",
      "[1891]\ttraining's binary_logloss: 1.1471e-05\n",
      "[1892]\ttraining's binary_logloss: 1.14504e-05\n",
      "[1893]\ttraining's binary_logloss: 1.14316e-05\n",
      "[1894]\ttraining's binary_logloss: 1.14097e-05\n",
      "[1895]\ttraining's binary_logloss: 1.13898e-05\n",
      "[1896]\ttraining's binary_logloss: 1.13703e-05\n",
      "[1897]\ttraining's binary_logloss: 1.13475e-05\n",
      "[1898]\ttraining's binary_logloss: 1.13269e-05\n",
      "[1899]\ttraining's binary_logloss: 1.13017e-05\n",
      "[1900]\ttraining's binary_logloss: 1.12818e-05\n",
      "[1901]\ttraining's binary_logloss: 1.12597e-05\n",
      "[1902]\ttraining's binary_logloss: 1.12432e-05\n",
      "[1903]\ttraining's binary_logloss: 1.12212e-05\n",
      "[1904]\ttraining's binary_logloss: 1.12004e-05\n",
      "[1905]\ttraining's binary_logloss: 1.11813e-05\n",
      "[1906]\ttraining's binary_logloss: 1.11605e-05\n",
      "[1907]\ttraining's binary_logloss: 1.11411e-05\n",
      "[1908]\ttraining's binary_logloss: 1.1122e-05\n",
      "[1909]\ttraining's binary_logloss: 1.11027e-05\n",
      "[1910]\ttraining's binary_logloss: 1.10803e-05\n",
      "[1911]\ttraining's binary_logloss: 1.10598e-05\n",
      "[1912]\ttraining's binary_logloss: 1.10367e-05\n",
      "[1913]\ttraining's binary_logloss: 1.10199e-05\n",
      "[1914]\ttraining's binary_logloss: 1.10007e-05\n",
      "[1915]\ttraining's binary_logloss: 1.0982e-05\n",
      "[1916]\ttraining's binary_logloss: 1.09626e-05\n",
      "[1917]\ttraining's binary_logloss: 1.09401e-05\n",
      "[1918]\ttraining's binary_logloss: 1.09195e-05\n",
      "[1919]\ttraining's binary_logloss: 1.08995e-05\n",
      "[1920]\ttraining's binary_logloss: 1.08822e-05\n",
      "[1921]\ttraining's binary_logloss: 1.08626e-05\n",
      "[1922]\ttraining's binary_logloss: 1.08442e-05\n",
      "[1923]\ttraining's binary_logloss: 1.08231e-05\n",
      "[1924]\ttraining's binary_logloss: 1.08044e-05\n",
      "[1925]\ttraining's binary_logloss: 1.07864e-05\n",
      "[1926]\ttraining's binary_logloss: 1.07688e-05\n",
      "[1927]\ttraining's binary_logloss: 1.07497e-05\n",
      "[1928]\ttraining's binary_logloss: 1.07308e-05\n",
      "[1929]\ttraining's binary_logloss: 1.07101e-05\n",
      "[1930]\ttraining's binary_logloss: 1.06904e-05\n",
      "[1931]\ttraining's binary_logloss: 1.06729e-05\n",
      "[1932]\ttraining's binary_logloss: 1.06529e-05\n",
      "[1933]\ttraining's binary_logloss: 1.06347e-05\n",
      "[1934]\ttraining's binary_logloss: 1.06155e-05\n",
      "[1935]\ttraining's binary_logloss: 1.05946e-05\n",
      "[1936]\ttraining's binary_logloss: 1.0577e-05\n",
      "[1937]\ttraining's binary_logloss: 1.05604e-05\n",
      "[1938]\ttraining's binary_logloss: 1.05426e-05\n",
      "[1939]\ttraining's binary_logloss: 1.05229e-05\n",
      "[1940]\ttraining's binary_logloss: 1.05042e-05\n",
      "[1941]\ttraining's binary_logloss: 1.04863e-05\n",
      "[1942]\ttraining's binary_logloss: 1.04687e-05\n",
      "[1943]\ttraining's binary_logloss: 1.04501e-05\n",
      "[1944]\ttraining's binary_logloss: 1.04315e-05\n",
      "[1945]\ttraining's binary_logloss: 1.04115e-05\n",
      "[1946]\ttraining's binary_logloss: 1.03933e-05\n",
      "[1947]\ttraining's binary_logloss: 1.03743e-05\n",
      "[1948]\ttraining's binary_logloss: 1.03572e-05\n",
      "[1949]\ttraining's binary_logloss: 1.03384e-05\n",
      "[1950]\ttraining's binary_logloss: 1.03229e-05\n",
      "[1951]\ttraining's binary_logloss: 1.03045e-05\n",
      "[1952]\ttraining's binary_logloss: 1.02874e-05\n",
      "[1953]\ttraining's binary_logloss: 1.02721e-05\n",
      "[1954]\ttraining's binary_logloss: 1.02537e-05\n",
      "[1955]\ttraining's binary_logloss: 1.02356e-05\n",
      "[1956]\ttraining's binary_logloss: 1.02194e-05\n",
      "[1957]\ttraining's binary_logloss: 1.02038e-05\n",
      "[1958]\ttraining's binary_logloss: 1.01868e-05\n",
      "[1959]\ttraining's binary_logloss: 1.01698e-05\n",
      "[1960]\ttraining's binary_logloss: 1.01537e-05\n",
      "[1961]\ttraining's binary_logloss: 1.01384e-05\n",
      "[1962]\ttraining's binary_logloss: 1.01223e-05\n",
      "[1963]\ttraining's binary_logloss: 1.01059e-05\n",
      "[1964]\ttraining's binary_logloss: 1.00912e-05\n",
      "[1965]\ttraining's binary_logloss: 1.00776e-05\n",
      "[1966]\ttraining's binary_logloss: 1.00609e-05\n",
      "[1967]\ttraining's binary_logloss: 1.00423e-05\n",
      "[1968]\ttraining's binary_logloss: 1.00246e-05\n",
      "[1969]\ttraining's binary_logloss: 1.00109e-05\n",
      "[1970]\ttraining's binary_logloss: 9.99489e-06\n",
      "[1971]\ttraining's binary_logloss: 9.97779e-06\n",
      "[1972]\ttraining's binary_logloss: 9.96215e-06\n",
      "[1973]\ttraining's binary_logloss: 9.94603e-06\n",
      "[1974]\ttraining's binary_logloss: 9.93039e-06\n",
      "[1975]\ttraining's binary_logloss: 9.91178e-06\n",
      "[1976]\ttraining's binary_logloss: 9.89496e-06\n",
      "[1977]\ttraining's binary_logloss: 9.87976e-06\n",
      "[1978]\ttraining's binary_logloss: 9.86329e-06\n",
      "[1979]\ttraining's binary_logloss: 9.84891e-06\n",
      "[1980]\ttraining's binary_logloss: 9.83206e-06\n",
      "[1981]\ttraining's binary_logloss: 9.81815e-06\n",
      "[1982]\ttraining's binary_logloss: 9.80382e-06\n",
      "[1983]\ttraining's binary_logloss: 9.78869e-06\n",
      "[1984]\ttraining's binary_logloss: 9.77414e-06\n",
      "[1985]\ttraining's binary_logloss: 9.75913e-06\n",
      "[1986]\ttraining's binary_logloss: 9.74459e-06\n",
      "[1987]\ttraining's binary_logloss: 9.72944e-06\n",
      "[1988]\ttraining's binary_logloss: 9.7134e-06\n",
      "[1989]\ttraining's binary_logloss: 9.69693e-06\n",
      "[1990]\ttraining's binary_logloss: 9.68363e-06\n",
      "[1991]\ttraining's binary_logloss: 9.67107e-06\n",
      "[1992]\ttraining's binary_logloss: 9.65616e-06\n",
      "[1993]\ttraining's binary_logloss: 9.64273e-06\n",
      "[1994]\ttraining's binary_logloss: 9.62981e-06\n",
      "[1995]\ttraining's binary_logloss: 9.61639e-06\n",
      "[1996]\ttraining's binary_logloss: 9.60349e-06\n",
      "[1997]\ttraining's binary_logloss: 9.58732e-06\n",
      "[1998]\ttraining's binary_logloss: 9.57183e-06\n",
      "[1999]\ttraining's binary_logloss: 9.5589e-06\n",
      "[2000]\ttraining's binary_logloss: 9.5442e-06\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = lgb.train(\n",
    "    lgbm_params,\n",
    "    lgtrain,\n",
    "    valid_sets=lgtrain,\n",
    "    num_boost_round=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7884536364881524"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_lgb = lgb_clf.predict(X_test)\n",
    "predict_lgb = np.array([0 if i < 0.6 else 1 for i in predict_lgb])\n",
    "roc_auc_score(predict_lgb, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf, 'random_forest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.679963\n",
      "[2]\ttraining's binary_logloss: 0.66497\n",
      "[3]\ttraining's binary_logloss: 0.652721\n",
      "[4]\ttraining's binary_logloss: 0.638789\n",
      "[5]\ttraining's binary_logloss: 0.625434\n",
      "[6]\ttraining's binary_logloss: 0.61472\n",
      "[7]\ttraining's binary_logloss: 0.603808\n",
      "[8]\ttraining's binary_logloss: 0.591721\n",
      "[9]\ttraining's binary_logloss: 0.581847\n",
      "[10]\ttraining's binary_logloss: 0.57042\n",
      "[11]\ttraining's binary_logloss: 0.561189\n",
      "[12]\ttraining's binary_logloss: 0.550441\n",
      "[13]\ttraining's binary_logloss: 0.541623\n",
      "[14]\ttraining's binary_logloss: 0.53153\n",
      "[15]\ttraining's binary_logloss: 0.52316\n",
      "[16]\ttraining's binary_logloss: 0.515254\n",
      "[17]\ttraining's binary_logloss: 0.505888\n",
      "[18]\ttraining's binary_logloss: 0.498422\n",
      "[19]\ttraining's binary_logloss: 0.489725\n",
      "[20]\ttraining's binary_logloss: 0.482526\n",
      "[21]\ttraining's binary_logloss: 0.47419\n",
      "[22]\ttraining's binary_logloss: 0.467509\n",
      "[23]\ttraining's binary_logloss: 0.460875\n",
      "[24]\ttraining's binary_logloss: 0.454472\n",
      "[25]\ttraining's binary_logloss: 0.446948\n",
      "[26]\ttraining's binary_logloss: 0.439619\n",
      "[27]\ttraining's binary_logloss: 0.433498\n",
      "[28]\ttraining's binary_logloss: 0.426549\n",
      "[29]\ttraining's binary_logloss: 0.419785\n",
      "[30]\ttraining's binary_logloss: 0.414263\n",
      "[31]\ttraining's binary_logloss: 0.408809\n",
      "[32]\ttraining's binary_logloss: 0.40361\n",
      "[33]\ttraining's binary_logloss: 0.398344\n",
      "[34]\ttraining's binary_logloss: 0.392252\n",
      "[35]\ttraining's binary_logloss: 0.386275\n",
      "[36]\ttraining's binary_logloss: 0.380373\n",
      "[37]\ttraining's binary_logloss: 0.374821\n",
      "[38]\ttraining's binary_logloss: 0.369349\n",
      "[39]\ttraining's binary_logloss: 0.3649\n",
      "[40]\ttraining's binary_logloss: 0.359667\n",
      "[41]\ttraining's binary_logloss: 0.354524\n",
      "[42]\ttraining's binary_logloss: 0.350275\n",
      "[43]\ttraining's binary_logloss: 0.346366\n",
      "[44]\ttraining's binary_logloss: 0.342267\n",
      "[45]\ttraining's binary_logloss: 0.338377\n",
      "[46]\ttraining's binary_logloss: 0.333706\n",
      "[47]\ttraining's binary_logloss: 0.329126\n",
      "[48]\ttraining's binary_logloss: 0.325375\n",
      "[49]\ttraining's binary_logloss: 0.321066\n",
      "[50]\ttraining's binary_logloss: 0.317551\n",
      "[51]\ttraining's binary_logloss: 0.313404\n",
      "[52]\ttraining's binary_logloss: 0.309235\n",
      "[53]\ttraining's binary_logloss: 0.305869\n",
      "[54]\ttraining's binary_logloss: 0.301895\n",
      "[55]\ttraining's binary_logloss: 0.298002\n",
      "[56]\ttraining's binary_logloss: 0.294753\n",
      "[57]\ttraining's binary_logloss: 0.291059\n",
      "[58]\ttraining's binary_logloss: 0.28797\n",
      "[59]\ttraining's binary_logloss: 0.284929\n",
      "[60]\ttraining's binary_logloss: 0.282025\n",
      "[61]\ttraining's binary_logloss: 0.278468\n",
      "[62]\ttraining's binary_logloss: 0.274933\n",
      "[63]\ttraining's binary_logloss: 0.272195\n",
      "[64]\ttraining's binary_logloss: 0.268885\n",
      "[65]\ttraining's binary_logloss: 0.265655\n",
      "[66]\ttraining's binary_logloss: 0.262983\n",
      "[67]\ttraining's binary_logloss: 0.260381\n",
      "[68]\ttraining's binary_logloss: 0.257138\n",
      "[69]\ttraining's binary_logloss: 0.253977\n",
      "[70]\ttraining's binary_logloss: 0.251412\n",
      "[71]\ttraining's binary_logloss: 0.248524\n",
      "[72]\ttraining's binary_logloss: 0.246123\n",
      "[73]\ttraining's binary_logloss: 0.243222\n",
      "[74]\ttraining's binary_logloss: 0.240436\n",
      "[75]\ttraining's binary_logloss: 0.237646\n",
      "[76]\ttraining's binary_logloss: 0.235419\n",
      "[77]\ttraining's binary_logloss: 0.233128\n",
      "[78]\ttraining's binary_logloss: 0.230896\n",
      "[79]\ttraining's binary_logloss: 0.228234\n",
      "[80]\ttraining's binary_logloss: 0.225676\n",
      "[81]\ttraining's binary_logloss: 0.223547\n",
      "[82]\ttraining's binary_logloss: 0.221389\n",
      "[83]\ttraining's binary_logloss: 0.219321\n",
      "[84]\ttraining's binary_logloss: 0.216957\n",
      "[85]\ttraining's binary_logloss: 0.214964\n",
      "[86]\ttraining's binary_logloss: 0.2126\n",
      "[87]\ttraining's binary_logloss: 0.210673\n",
      "[88]\ttraining's binary_logloss: 0.208848\n",
      "[89]\ttraining's binary_logloss: 0.206566\n",
      "[90]\ttraining's binary_logloss: 0.204684\n",
      "[91]\ttraining's binary_logloss: 0.202782\n",
      "[92]\ttraining's binary_logloss: 0.200945\n",
      "[93]\ttraining's binary_logloss: 0.199153\n",
      "[94]\ttraining's binary_logloss: 0.197372\n",
      "[95]\ttraining's binary_logloss: 0.195579\n",
      "[96]\ttraining's binary_logloss: 0.193489\n",
      "[97]\ttraining's binary_logloss: 0.191461\n",
      "[98]\ttraining's binary_logloss: 0.189404\n",
      "[99]\ttraining's binary_logloss: 0.187745\n",
      "[100]\ttraining's binary_logloss: 0.18577\n",
      "[101]\ttraining's binary_logloss: 0.184144\n",
      "[102]\ttraining's binary_logloss: 0.182228\n",
      "[103]\ttraining's binary_logloss: 0.180646\n",
      "[104]\ttraining's binary_logloss: 0.179066\n",
      "[105]\ttraining's binary_logloss: 0.177547\n",
      "[106]\ttraining's binary_logloss: 0.175685\n",
      "[107]\ttraining's binary_logloss: 0.173863\n",
      "[108]\ttraining's binary_logloss: 0.172411\n",
      "[109]\ttraining's binary_logloss: 0.170898\n",
      "[110]\ttraining's binary_logloss: 0.169154\n",
      "[111]\ttraining's binary_logloss: 0.167372\n",
      "[112]\ttraining's binary_logloss: 0.16566\n",
      "[113]\ttraining's binary_logloss: 0.164063\n",
      "[114]\ttraining's binary_logloss: 0.162583\n",
      "[115]\ttraining's binary_logloss: 0.161207\n",
      "[116]\ttraining's binary_logloss: 0.159556\n",
      "[117]\ttraining's binary_logloss: 0.157945\n",
      "[118]\ttraining's binary_logloss: 0.156649\n",
      "[119]\ttraining's binary_logloss: 0.155091\n",
      "[120]\ttraining's binary_logloss: 0.153802\n",
      "[121]\ttraining's binary_logloss: 0.152265\n",
      "[122]\ttraining's binary_logloss: 0.151015\n",
      "[123]\ttraining's binary_logloss: 0.149507\n",
      "[124]\ttraining's binary_logloss: 0.148255\n",
      "[125]\ttraining's binary_logloss: 0.146797\n",
      "[126]\ttraining's binary_logloss: 0.14555\n",
      "[127]\ttraining's binary_logloss: 0.144185\n",
      "[128]\ttraining's binary_logloss: 0.142939\n",
      "[129]\ttraining's binary_logloss: 0.141812\n",
      "[130]\ttraining's binary_logloss: 0.140409\n",
      "[131]\ttraining's binary_logloss: 0.139231\n",
      "[132]\ttraining's binary_logloss: 0.138025\n",
      "[133]\ttraining's binary_logloss: 0.136891\n",
      "[134]\ttraining's binary_logloss: 0.135781\n",
      "[135]\ttraining's binary_logloss: 0.13452\n",
      "[136]\ttraining's binary_logloss: 0.133225\n",
      "[137]\ttraining's binary_logloss: 0.132128\n",
      "[138]\ttraining's binary_logloss: 0.130994\n",
      "[139]\ttraining's binary_logloss: 0.129713\n",
      "[140]\ttraining's binary_logloss: 0.128477\n",
      "[141]\ttraining's binary_logloss: 0.127455\n",
      "[142]\ttraining's binary_logloss: 0.126277\n",
      "[143]\ttraining's binary_logloss: 0.125246\n",
      "[144]\ttraining's binary_logloss: 0.124189\n",
      "[145]\ttraining's binary_logloss: 0.123137\n",
      "[146]\ttraining's binary_logloss: 0.121966\n",
      "[147]\ttraining's binary_logloss: 0.120761\n",
      "[148]\ttraining's binary_logloss: 0.119799\n",
      "[149]\ttraining's binary_logloss: 0.118851\n",
      "[150]\ttraining's binary_logloss: 0.117906\n",
      "[151]\ttraining's binary_logloss: 0.116812\n",
      "[152]\ttraining's binary_logloss: 0.115737\n",
      "[153]\ttraining's binary_logloss: 0.114804\n",
      "[154]\ttraining's binary_logloss: 0.113885\n",
      "[155]\ttraining's binary_logloss: 0.112927\n",
      "[156]\ttraining's binary_logloss: 0.112013\n",
      "[157]\ttraining's binary_logloss: 0.111113\n",
      "[158]\ttraining's binary_logloss: 0.11007\n",
      "[159]\ttraining's binary_logloss: 0.109017\n",
      "[160]\ttraining's binary_logloss: 0.108137\n",
      "[161]\ttraining's binary_logloss: 0.10711\n",
      "[162]\ttraining's binary_logloss: 0.106263\n",
      "[163]\ttraining's binary_logloss: 0.105385\n",
      "[164]\ttraining's binary_logloss: 0.1044\n",
      "[165]\ttraining's binary_logloss: 0.103551\n",
      "[166]\ttraining's binary_logloss: 0.102634\n",
      "[167]\ttraining's binary_logloss: 0.101702\n",
      "[168]\ttraining's binary_logloss: 0.10087\n",
      "[169]\ttraining's binary_logloss: 0.0999508\n",
      "[170]\ttraining's binary_logloss: 0.0990197\n",
      "[171]\ttraining's binary_logloss: 0.098245\n",
      "[172]\ttraining's binary_logloss: 0.0975026\n",
      "[173]\ttraining's binary_logloss: 0.0966415\n",
      "[174]\ttraining's binary_logloss: 0.0957594\n",
      "[175]\ttraining's binary_logloss: 0.0949628\n",
      "[176]\ttraining's binary_logloss: 0.0942145\n",
      "[177]\ttraining's binary_logloss: 0.0933526\n",
      "[178]\ttraining's binary_logloss: 0.092574\n",
      "[179]\ttraining's binary_logloss: 0.0918334\n",
      "[180]\ttraining's binary_logloss: 0.0909988\n",
      "[181]\ttraining's binary_logloss: 0.0901212\n",
      "[182]\ttraining's binary_logloss: 0.0892825\n",
      "[183]\ttraining's binary_logloss: 0.0884927\n",
      "[184]\ttraining's binary_logloss: 0.0877016\n",
      "[185]\ttraining's binary_logloss: 0.0870071\n",
      "[186]\ttraining's binary_logloss: 0.0862312\n",
      "[187]\ttraining's binary_logloss: 0.0855052\n",
      "[188]\ttraining's binary_logloss: 0.0847689\n",
      "[189]\ttraining's binary_logloss: 0.0840466\n",
      "[190]\ttraining's binary_logloss: 0.0834341\n",
      "[191]\ttraining's binary_logloss: 0.0826686\n",
      "[192]\ttraining's binary_logloss: 0.0819852\n",
      "[193]\ttraining's binary_logloss: 0.0812484\n",
      "[194]\ttraining's binary_logloss: 0.0805737\n",
      "[195]\ttraining's binary_logloss: 0.0798818\n",
      "[196]\ttraining's binary_logloss: 0.0791462\n",
      "[197]\ttraining's binary_logloss: 0.0785112\n",
      "[198]\ttraining's binary_logloss: 0.0778671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[199]\ttraining's binary_logloss: 0.0772638\n",
      "[200]\ttraining's binary_logloss: 0.0766379\n",
      "[201]\ttraining's binary_logloss: 0.0759774\n",
      "[202]\ttraining's binary_logloss: 0.0753103\n",
      "[203]\ttraining's binary_logloss: 0.0747256\n",
      "[204]\ttraining's binary_logloss: 0.0741488\n",
      "[205]\ttraining's binary_logloss: 0.0734999\n",
      "[206]\ttraining's binary_logloss: 0.0729097\n",
      "[207]\ttraining's binary_logloss: 0.07227\n",
      "[208]\ttraining's binary_logloss: 0.0715998\n",
      "[209]\ttraining's binary_logloss: 0.0709609\n",
      "[210]\ttraining's binary_logloss: 0.0703132\n",
      "[211]\ttraining's binary_logloss: 0.0697548\n",
      "[212]\ttraining's binary_logloss: 0.0691784\n",
      "[213]\ttraining's binary_logloss: 0.0685933\n",
      "[214]\ttraining's binary_logloss: 0.0680614\n",
      "[215]\ttraining's binary_logloss: 0.0674941\n",
      "[216]\ttraining's binary_logloss: 0.0669178\n",
      "[217]\ttraining's binary_logloss: 0.066328\n",
      "[218]\ttraining's binary_logloss: 0.0658082\n",
      "[219]\ttraining's binary_logloss: 0.0653198\n",
      "[220]\ttraining's binary_logloss: 0.0647656\n",
      "[221]\ttraining's binary_logloss: 0.0642212\n",
      "[222]\ttraining's binary_logloss: 0.0636756\n",
      "[223]\ttraining's binary_logloss: 0.0631491\n",
      "[224]\ttraining's binary_logloss: 0.062638\n",
      "[225]\ttraining's binary_logloss: 0.0621118\n",
      "[226]\ttraining's binary_logloss: 0.0616183\n",
      "[227]\ttraining's binary_logloss: 0.0611019\n",
      "[228]\ttraining's binary_logloss: 0.0606229\n",
      "[229]\ttraining's binary_logloss: 0.0600992\n",
      "[230]\ttraining's binary_logloss: 0.0596143\n",
      "[231]\ttraining's binary_logloss: 0.0591266\n",
      "[232]\ttraining's binary_logloss: 0.0586705\n",
      "[233]\ttraining's binary_logloss: 0.0581841\n",
      "[234]\ttraining's binary_logloss: 0.0577083\n",
      "[235]\ttraining's binary_logloss: 0.0572214\n",
      "[236]\ttraining's binary_logloss: 0.056758\n",
      "[237]\ttraining's binary_logloss: 0.0562983\n",
      "[238]\ttraining's binary_logloss: 0.0558459\n",
      "[239]\ttraining's binary_logloss: 0.0553963\n",
      "[240]\ttraining's binary_logloss: 0.0549271\n",
      "[241]\ttraining's binary_logloss: 0.0544738\n",
      "[242]\ttraining's binary_logloss: 0.0540053\n",
      "[243]\ttraining's binary_logloss: 0.0535628\n",
      "[244]\ttraining's binary_logloss: 0.0531533\n",
      "[245]\ttraining's binary_logloss: 0.0527112\n",
      "[246]\ttraining's binary_logloss: 0.0522844\n",
      "[247]\ttraining's binary_logloss: 0.0518874\n",
      "[248]\ttraining's binary_logloss: 0.0514647\n",
      "[249]\ttraining's binary_logloss: 0.0510556\n",
      "[250]\ttraining's binary_logloss: 0.0506682\n",
      "[251]\ttraining's binary_logloss: 0.0502696\n",
      "[252]\ttraining's binary_logloss: 0.0498742\n",
      "[253]\ttraining's binary_logloss: 0.0494613\n",
      "[254]\ttraining's binary_logloss: 0.0490746\n",
      "[255]\ttraining's binary_logloss: 0.048682\n",
      "[256]\ttraining's binary_logloss: 0.0482955\n",
      "[257]\ttraining's binary_logloss: 0.0479037\n",
      "[258]\ttraining's binary_logloss: 0.0475096\n",
      "[259]\ttraining's binary_logloss: 0.0471576\n",
      "[260]\ttraining's binary_logloss: 0.0467778\n",
      "[261]\ttraining's binary_logloss: 0.0464054\n",
      "[262]\ttraining's binary_logloss: 0.0460471\n",
      "[263]\ttraining's binary_logloss: 0.045672\n",
      "[264]\ttraining's binary_logloss: 0.045319\n",
      "[265]\ttraining's binary_logloss: 0.0449705\n",
      "[266]\ttraining's binary_logloss: 0.0446228\n",
      "[267]\ttraining's binary_logloss: 0.044261\n",
      "[268]\ttraining's binary_logloss: 0.0438791\n",
      "[269]\ttraining's binary_logloss: 0.0435181\n",
      "[270]\ttraining's binary_logloss: 0.0431746\n",
      "[271]\ttraining's binary_logloss: 0.0428168\n",
      "[272]\ttraining's binary_logloss: 0.0424875\n",
      "[273]\ttraining's binary_logloss: 0.0421553\n",
      "[274]\ttraining's binary_logloss: 0.0418083\n",
      "[275]\ttraining's binary_logloss: 0.041475\n",
      "[276]\ttraining's binary_logloss: 0.0411459\n",
      "[277]\ttraining's binary_logloss: 0.0408344\n",
      "[278]\ttraining's binary_logloss: 0.040494\n",
      "[279]\ttraining's binary_logloss: 0.0401883\n",
      "[280]\ttraining's binary_logloss: 0.0398791\n",
      "[281]\ttraining's binary_logloss: 0.0395616\n",
      "[282]\ttraining's binary_logloss: 0.0392493\n",
      "[283]\ttraining's binary_logloss: 0.0389341\n",
      "[284]\ttraining's binary_logloss: 0.0386259\n",
      "[285]\ttraining's binary_logloss: 0.038319\n",
      "[286]\ttraining's binary_logloss: 0.0380191\n",
      "[287]\ttraining's binary_logloss: 0.0377088\n",
      "[288]\ttraining's binary_logloss: 0.0374307\n",
      "[289]\ttraining's binary_logloss: 0.0371431\n",
      "[290]\ttraining's binary_logloss: 0.0368473\n",
      "[291]\ttraining's binary_logloss: 0.0365469\n",
      "[292]\ttraining's binary_logloss: 0.036274\n",
      "[293]\ttraining's binary_logloss: 0.0359971\n",
      "[294]\ttraining's binary_logloss: 0.0357139\n",
      "[295]\ttraining's binary_logloss: 0.0354357\n",
      "[296]\ttraining's binary_logloss: 0.0351663\n",
      "[297]\ttraining's binary_logloss: 0.0348798\n",
      "[298]\ttraining's binary_logloss: 0.0346154\n",
      "[299]\ttraining's binary_logloss: 0.0343329\n",
      "[300]\ttraining's binary_logloss: 0.0340559\n",
      "[301]\ttraining's binary_logloss: 0.0337888\n",
      "[302]\ttraining's binary_logloss: 0.0335231\n",
      "[303]\ttraining's binary_logloss: 0.0332643\n",
      "[304]\ttraining's binary_logloss: 0.0330167\n",
      "[305]\ttraining's binary_logloss: 0.0327656\n",
      "[306]\ttraining's binary_logloss: 0.0325011\n",
      "[307]\ttraining's binary_logloss: 0.0322418\n",
      "[308]\ttraining's binary_logloss: 0.031996\n",
      "[309]\ttraining's binary_logloss: 0.0317577\n",
      "[310]\ttraining's binary_logloss: 0.0315155\n",
      "[311]\ttraining's binary_logloss: 0.0312587\n",
      "[312]\ttraining's binary_logloss: 0.0310052\n",
      "[313]\ttraining's binary_logloss: 0.0307574\n",
      "[314]\ttraining's binary_logloss: 0.0305268\n",
      "[315]\ttraining's binary_logloss: 0.030294\n",
      "[316]\ttraining's binary_logloss: 0.0300643\n",
      "[317]\ttraining's binary_logloss: 0.0298353\n",
      "[318]\ttraining's binary_logloss: 0.0296069\n",
      "[319]\ttraining's binary_logloss: 0.0293748\n",
      "[320]\ttraining's binary_logloss: 0.029155\n",
      "[321]\ttraining's binary_logloss: 0.0289416\n",
      "[322]\ttraining's binary_logloss: 0.0287221\n",
      "[323]\ttraining's binary_logloss: 0.0284949\n",
      "[324]\ttraining's binary_logloss: 0.0282682\n",
      "[325]\ttraining's binary_logloss: 0.0280631\n",
      "[326]\ttraining's binary_logloss: 0.0278447\n",
      "[327]\ttraining's binary_logloss: 0.0276368\n",
      "[328]\ttraining's binary_logloss: 0.027427\n",
      "[329]\ttraining's binary_logloss: 0.0272156\n",
      "[330]\ttraining's binary_logloss: 0.027004\n",
      "[331]\ttraining's binary_logloss: 0.0267961\n",
      "[332]\ttraining's binary_logloss: 0.0265897\n",
      "[333]\ttraining's binary_logloss: 0.0263855\n",
      "[334]\ttraining's binary_logloss: 0.0261838\n",
      "[335]\ttraining's binary_logloss: 0.025981\n",
      "[336]\ttraining's binary_logloss: 0.0257806\n",
      "[337]\ttraining's binary_logloss: 0.0255857\n",
      "[338]\ttraining's binary_logloss: 0.0253861\n",
      "[339]\ttraining's binary_logloss: 0.0251884\n",
      "[340]\ttraining's binary_logloss: 0.0249973\n",
      "[341]\ttraining's binary_logloss: 0.0248062\n",
      "[342]\ttraining's binary_logloss: 0.0246153\n",
      "[343]\ttraining's binary_logloss: 0.0244462\n",
      "[344]\ttraining's binary_logloss: 0.0242738\n",
      "[345]\ttraining's binary_logloss: 0.0240907\n",
      "[346]\ttraining's binary_logloss: 0.0239012\n",
      "[347]\ttraining's binary_logloss: 0.02373\n",
      "[348]\ttraining's binary_logloss: 0.0235527\n",
      "[349]\ttraining's binary_logloss: 0.0233665\n",
      "[350]\ttraining's binary_logloss: 0.0231985\n",
      "[351]\ttraining's binary_logloss: 0.0230255\n",
      "[352]\ttraining's binary_logloss: 0.0228425\n",
      "[353]\ttraining's binary_logloss: 0.0226706\n",
      "[354]\ttraining's binary_logloss: 0.0224954\n",
      "[355]\ttraining's binary_logloss: 0.022318\n",
      "[356]\ttraining's binary_logloss: 0.0221549\n",
      "[357]\ttraining's binary_logloss: 0.0219782\n",
      "[358]\ttraining's binary_logloss: 0.021806\n",
      "[359]\ttraining's binary_logloss: 0.0216314\n",
      "[360]\ttraining's binary_logloss: 0.0214707\n",
      "[361]\ttraining's binary_logloss: 0.0213098\n",
      "[362]\ttraining's binary_logloss: 0.0211541\n",
      "[363]\ttraining's binary_logloss: 0.020992\n",
      "[364]\ttraining's binary_logloss: 0.0208415\n",
      "[365]\ttraining's binary_logloss: 0.02068\n",
      "[366]\ttraining's binary_logloss: 0.0205189\n",
      "[367]\ttraining's binary_logloss: 0.0203626\n",
      "[368]\ttraining's binary_logloss: 0.0202103\n",
      "[369]\ttraining's binary_logloss: 0.0200436\n",
      "[370]\ttraining's binary_logloss: 0.0198875\n",
      "[371]\ttraining's binary_logloss: 0.0197482\n",
      "[372]\ttraining's binary_logloss: 0.0195942\n",
      "[373]\ttraining's binary_logloss: 0.0194506\n",
      "[374]\ttraining's binary_logloss: 0.0193044\n",
      "[375]\ttraining's binary_logloss: 0.019162\n",
      "[376]\ttraining's binary_logloss: 0.0190129\n",
      "[377]\ttraining's binary_logloss: 0.0188638\n",
      "[378]\ttraining's binary_logloss: 0.0187253\n",
      "[379]\ttraining's binary_logloss: 0.0185813\n",
      "[380]\ttraining's binary_logloss: 0.0184323\n",
      "[381]\ttraining's binary_logloss: 0.0182838\n",
      "[382]\ttraining's binary_logloss: 0.0181414\n",
      "[383]\ttraining's binary_logloss: 0.0180054\n",
      "[384]\ttraining's binary_logloss: 0.0178645\n",
      "[385]\ttraining's binary_logloss: 0.0177298\n",
      "[386]\ttraining's binary_logloss: 0.0175903\n",
      "[387]\ttraining's binary_logloss: 0.0174592\n",
      "[388]\ttraining's binary_logloss: 0.0173305\n",
      "[389]\ttraining's binary_logloss: 0.0171948\n",
      "[390]\ttraining's binary_logloss: 0.0170689\n",
      "[391]\ttraining's binary_logloss: 0.016942\n",
      "[392]\ttraining's binary_logloss: 0.0168076\n",
      "[393]\ttraining's binary_logloss: 0.0166851\n",
      "[394]\ttraining's binary_logloss: 0.0165552\n",
      "[395]\ttraining's binary_logloss: 0.0164301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[396]\ttraining's binary_logloss: 0.0163086\n",
      "[397]\ttraining's binary_logloss: 0.0161884\n",
      "[398]\ttraining's binary_logloss: 0.0160625\n",
      "[399]\ttraining's binary_logloss: 0.0159455\n",
      "[400]\ttraining's binary_logloss: 0.0158206\n",
      "[401]\ttraining's binary_logloss: 0.0157\n",
      "[402]\ttraining's binary_logloss: 0.0155789\n",
      "[403]\ttraining's binary_logloss: 0.0154607\n",
      "[404]\ttraining's binary_logloss: 0.0153426\n",
      "[405]\ttraining's binary_logloss: 0.0152259\n",
      "[406]\ttraining's binary_logloss: 0.0151091\n",
      "[407]\ttraining's binary_logloss: 0.0149929\n",
      "[408]\ttraining's binary_logloss: 0.0148796\n",
      "[409]\ttraining's binary_logloss: 0.0147623\n",
      "[410]\ttraining's binary_logloss: 0.0146502\n",
      "[411]\ttraining's binary_logloss: 0.0145413\n",
      "[412]\ttraining's binary_logloss: 0.0144362\n",
      "[413]\ttraining's binary_logloss: 0.0143286\n",
      "[414]\ttraining's binary_logloss: 0.0142198\n",
      "[415]\ttraining's binary_logloss: 0.0141239\n",
      "[416]\ttraining's binary_logloss: 0.0140186\n",
      "[417]\ttraining's binary_logloss: 0.0139128\n",
      "[418]\ttraining's binary_logloss: 0.0138017\n",
      "[419]\ttraining's binary_logloss: 0.0137046\n",
      "[420]\ttraining's binary_logloss: 0.0136069\n",
      "[421]\ttraining's binary_logloss: 0.0135029\n",
      "[422]\ttraining's binary_logloss: 0.0134028\n",
      "[423]\ttraining's binary_logloss: 0.0132999\n",
      "[424]\ttraining's binary_logloss: 0.0131975\n",
      "[425]\ttraining's binary_logloss: 0.0130979\n",
      "[426]\ttraining's binary_logloss: 0.0129995\n",
      "[427]\ttraining's binary_logloss: 0.012904\n",
      "[428]\ttraining's binary_logloss: 0.0128033\n",
      "[429]\ttraining's binary_logloss: 0.0127136\n",
      "[430]\ttraining's binary_logloss: 0.0126146\n",
      "[431]\ttraining's binary_logloss: 0.0125212\n",
      "[432]\ttraining's binary_logloss: 0.0124241\n",
      "[433]\ttraining's binary_logloss: 0.0123305\n",
      "[434]\ttraining's binary_logloss: 0.0122348\n",
      "[435]\ttraining's binary_logloss: 0.0121236\n",
      "[436]\ttraining's binary_logloss: 0.012016\n",
      "[437]\ttraining's binary_logloss: 0.011919\n",
      "[438]\ttraining's binary_logloss: 0.0118206\n",
      "[439]\ttraining's binary_logloss: 0.0117187\n",
      "[440]\ttraining's binary_logloss: 0.0116259\n",
      "[441]\ttraining's binary_logloss: 0.0115359\n",
      "[442]\ttraining's binary_logloss: 0.0114464\n",
      "[443]\ttraining's binary_logloss: 0.0113553\n",
      "[444]\ttraining's binary_logloss: 0.011261\n",
      "[445]\ttraining's binary_logloss: 0.0111769\n",
      "[446]\ttraining's binary_logloss: 0.0110875\n",
      "[447]\ttraining's binary_logloss: 0.0109997\n",
      "[448]\ttraining's binary_logloss: 0.0109131\n",
      "[449]\ttraining's binary_logloss: 0.0108244\n",
      "[450]\ttraining's binary_logloss: 0.0107454\n",
      "[451]\ttraining's binary_logloss: 0.0106594\n",
      "[452]\ttraining's binary_logloss: 0.0105764\n",
      "[453]\ttraining's binary_logloss: 0.010495\n",
      "[454]\ttraining's binary_logloss: 0.010414\n",
      "[455]\ttraining's binary_logloss: 0.0103356\n",
      "[456]\ttraining's binary_logloss: 0.010256\n",
      "[457]\ttraining's binary_logloss: 0.0101826\n",
      "[458]\ttraining's binary_logloss: 0.0101069\n",
      "[459]\ttraining's binary_logloss: 0.0100338\n",
      "[460]\ttraining's binary_logloss: 0.00995369\n",
      "[461]\ttraining's binary_logloss: 0.00987729\n",
      "[462]\ttraining's binary_logloss: 0.00979927\n",
      "[463]\ttraining's binary_logloss: 0.00972719\n",
      "[464]\ttraining's binary_logloss: 0.00965655\n",
      "[465]\ttraining's binary_logloss: 0.00958958\n",
      "[466]\ttraining's binary_logloss: 0.00951833\n",
      "[467]\ttraining's binary_logloss: 0.00944965\n",
      "[468]\ttraining's binary_logloss: 0.0093761\n",
      "[469]\ttraining's binary_logloss: 0.00930542\n",
      "[470]\ttraining's binary_logloss: 0.00923198\n",
      "[471]\ttraining's binary_logloss: 0.00916088\n",
      "[472]\ttraining's binary_logloss: 0.00908771\n",
      "[473]\ttraining's binary_logloss: 0.00901988\n",
      "[474]\ttraining's binary_logloss: 0.00895402\n",
      "[475]\ttraining's binary_logloss: 0.00888605\n",
      "[476]\ttraining's binary_logloss: 0.00881833\n",
      "[477]\ttraining's binary_logloss: 0.00875457\n",
      "[478]\ttraining's binary_logloss: 0.00868633\n",
      "[479]\ttraining's binary_logloss: 0.00862282\n",
      "[480]\ttraining's binary_logloss: 0.0085609\n",
      "[481]\ttraining's binary_logloss: 0.00849696\n",
      "[482]\ttraining's binary_logloss: 0.00843481\n",
      "[483]\ttraining's binary_logloss: 0.00837361\n",
      "[484]\ttraining's binary_logloss: 0.00830722\n",
      "[485]\ttraining's binary_logloss: 0.00824393\n",
      "[486]\ttraining's binary_logloss: 0.0081838\n",
      "[487]\ttraining's binary_logloss: 0.00812343\n",
      "[488]\ttraining's binary_logloss: 0.00806065\n",
      "[489]\ttraining's binary_logloss: 0.00799721\n",
      "[490]\ttraining's binary_logloss: 0.00793789\n",
      "[491]\ttraining's binary_logloss: 0.00787337\n",
      "[492]\ttraining's binary_logloss: 0.00781241\n",
      "[493]\ttraining's binary_logloss: 0.00775038\n",
      "[494]\ttraining's binary_logloss: 0.00769436\n",
      "[495]\ttraining's binary_logloss: 0.00763446\n",
      "[496]\ttraining's binary_logloss: 0.00757692\n",
      "[497]\ttraining's binary_logloss: 0.0075195\n",
      "[498]\ttraining's binary_logloss: 0.00746318\n",
      "[499]\ttraining's binary_logloss: 0.00740737\n",
      "[500]\ttraining's binary_logloss: 0.00735041\n",
      "[501]\ttraining's binary_logloss: 0.00729884\n",
      "[502]\ttraining's binary_logloss: 0.00724389\n",
      "[503]\ttraining's binary_logloss: 0.00719009\n",
      "[504]\ttraining's binary_logloss: 0.00713717\n",
      "[505]\ttraining's binary_logloss: 0.00708024\n",
      "[506]\ttraining's binary_logloss: 0.00702735\n",
      "[507]\ttraining's binary_logloss: 0.00697376\n",
      "[508]\ttraining's binary_logloss: 0.00692056\n",
      "[509]\ttraining's binary_logloss: 0.00686662\n",
      "[510]\ttraining's binary_logloss: 0.00681365\n",
      "[511]\ttraining's binary_logloss: 0.00676248\n",
      "[512]\ttraining's binary_logloss: 0.00671352\n",
      "[513]\ttraining's binary_logloss: 0.00665958\n",
      "[514]\ttraining's binary_logloss: 0.0066081\n",
      "[515]\ttraining's binary_logloss: 0.00656117\n",
      "[516]\ttraining's binary_logloss: 0.00651347\n",
      "[517]\ttraining's binary_logloss: 0.00646572\n",
      "[518]\ttraining's binary_logloss: 0.00641729\n",
      "[519]\ttraining's binary_logloss: 0.00637126\n",
      "[520]\ttraining's binary_logloss: 0.00632733\n",
      "[521]\ttraining's binary_logloss: 0.00628047\n",
      "[522]\ttraining's binary_logloss: 0.00623394\n",
      "[523]\ttraining's binary_logloss: 0.00618545\n",
      "[524]\ttraining's binary_logloss: 0.00614251\n",
      "[525]\ttraining's binary_logloss: 0.00609624\n",
      "[526]\ttraining's binary_logloss: 0.00605199\n",
      "[527]\ttraining's binary_logloss: 0.00600674\n",
      "[528]\ttraining's binary_logloss: 0.00595805\n",
      "[529]\ttraining's binary_logloss: 0.00591459\n",
      "[530]\ttraining's binary_logloss: 0.00587135\n",
      "[531]\ttraining's binary_logloss: 0.0058292\n",
      "[532]\ttraining's binary_logloss: 0.00578771\n",
      "[533]\ttraining's binary_logloss: 0.00574617\n",
      "[534]\ttraining's binary_logloss: 0.00570553\n",
      "[535]\ttraining's binary_logloss: 0.00566361\n",
      "[536]\ttraining's binary_logloss: 0.00562273\n",
      "[537]\ttraining's binary_logloss: 0.00558305\n",
      "[538]\ttraining's binary_logloss: 0.00554141\n",
      "[539]\ttraining's binary_logloss: 0.0055018\n",
      "[540]\ttraining's binary_logloss: 0.00546259\n",
      "[541]\ttraining's binary_logloss: 0.00542238\n",
      "[542]\ttraining's binary_logloss: 0.00538263\n",
      "[543]\ttraining's binary_logloss: 0.00534271\n",
      "[544]\ttraining's binary_logloss: 0.00530291\n",
      "[545]\ttraining's binary_logloss: 0.0052648\n",
      "[546]\ttraining's binary_logloss: 0.00522638\n",
      "[547]\ttraining's binary_logloss: 0.00518853\n",
      "[548]\ttraining's binary_logloss: 0.00515006\n",
      "[549]\ttraining's binary_logloss: 0.00511013\n",
      "[550]\ttraining's binary_logloss: 0.00507613\n",
      "[551]\ttraining's binary_logloss: 0.0050393\n",
      "[552]\ttraining's binary_logloss: 0.00500306\n",
      "[553]\ttraining's binary_logloss: 0.00496487\n",
      "[554]\ttraining's binary_logloss: 0.00492896\n",
      "[555]\ttraining's binary_logloss: 0.00489539\n",
      "[556]\ttraining's binary_logloss: 0.00486115\n",
      "[557]\ttraining's binary_logloss: 0.00482578\n",
      "[558]\ttraining's binary_logloss: 0.00479116\n",
      "[559]\ttraining's binary_logloss: 0.00475699\n",
      "[560]\ttraining's binary_logloss: 0.00472517\n",
      "[561]\ttraining's binary_logloss: 0.00468991\n",
      "[562]\ttraining's binary_logloss: 0.00465603\n",
      "[563]\ttraining's binary_logloss: 0.0046219\n",
      "[564]\ttraining's binary_logloss: 0.00458762\n",
      "[565]\ttraining's binary_logloss: 0.00455125\n",
      "[566]\ttraining's binary_logloss: 0.00451594\n",
      "[567]\ttraining's binary_logloss: 0.00448456\n",
      "[568]\ttraining's binary_logloss: 0.00445117\n",
      "[569]\ttraining's binary_logloss: 0.00441999\n",
      "[570]\ttraining's binary_logloss: 0.00439001\n",
      "[571]\ttraining's binary_logloss: 0.00435911\n",
      "[572]\ttraining's binary_logloss: 0.00432921\n",
      "[573]\ttraining's binary_logloss: 0.00429818\n",
      "[574]\ttraining's binary_logloss: 0.00426774\n",
      "[575]\ttraining's binary_logloss: 0.00423699\n",
      "[576]\ttraining's binary_logloss: 0.00420747\n",
      "[577]\ttraining's binary_logloss: 0.00417603\n",
      "[578]\ttraining's binary_logloss: 0.00414608\n",
      "[579]\ttraining's binary_logloss: 0.00411793\n",
      "[580]\ttraining's binary_logloss: 0.00409056\n",
      "[581]\ttraining's binary_logloss: 0.00406136\n",
      "[582]\ttraining's binary_logloss: 0.00403054\n",
      "[583]\ttraining's binary_logloss: 0.004\n",
      "[584]\ttraining's binary_logloss: 0.00397183\n",
      "[585]\ttraining's binary_logloss: 0.00394187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[586]\ttraining's binary_logloss: 0.00391371\n",
      "[587]\ttraining's binary_logloss: 0.00388607\n",
      "[588]\ttraining's binary_logloss: 0.00385704\n",
      "[589]\ttraining's binary_logloss: 0.00382918\n",
      "[590]\ttraining's binary_logloss: 0.0038032\n",
      "[591]\ttraining's binary_logloss: 0.00377537\n",
      "[592]\ttraining's binary_logloss: 0.00374882\n",
      "[593]\ttraining's binary_logloss: 0.00372338\n",
      "[594]\ttraining's binary_logloss: 0.00369763\n",
      "[595]\ttraining's binary_logloss: 0.00367219\n",
      "[596]\ttraining's binary_logloss: 0.00364397\n",
      "[597]\ttraining's binary_logloss: 0.00361821\n",
      "[598]\ttraining's binary_logloss: 0.00359339\n",
      "[599]\ttraining's binary_logloss: 0.0035683\n",
      "[600]\ttraining's binary_logloss: 0.00354372\n",
      "[601]\ttraining's binary_logloss: 0.00351886\n",
      "[602]\ttraining's binary_logloss: 0.00349407\n",
      "[603]\ttraining's binary_logloss: 0.00346782\n",
      "[604]\ttraining's binary_logloss: 0.00344381\n",
      "[605]\ttraining's binary_logloss: 0.0034181\n",
      "[606]\ttraining's binary_logloss: 0.0033936\n",
      "[607]\ttraining's binary_logloss: 0.00337161\n",
      "[608]\ttraining's binary_logloss: 0.00334883\n",
      "[609]\ttraining's binary_logloss: 0.00332562\n",
      "[610]\ttraining's binary_logloss: 0.00330163\n",
      "[611]\ttraining's binary_logloss: 0.00327795\n",
      "[612]\ttraining's binary_logloss: 0.00325575\n",
      "[613]\ttraining's binary_logloss: 0.00323257\n",
      "[614]\ttraining's binary_logloss: 0.00320936\n",
      "[615]\ttraining's binary_logloss: 0.00318666\n",
      "[616]\ttraining's binary_logloss: 0.00316347\n",
      "[617]\ttraining's binary_logloss: 0.00314352\n",
      "[618]\ttraining's binary_logloss: 0.00312075\n",
      "[619]\ttraining's binary_logloss: 0.00310003\n",
      "[620]\ttraining's binary_logloss: 0.00307929\n",
      "[621]\ttraining's binary_logloss: 0.00305845\n",
      "[622]\ttraining's binary_logloss: 0.00303691\n",
      "[623]\ttraining's binary_logloss: 0.00301574\n",
      "[624]\ttraining's binary_logloss: 0.00299553\n",
      "[625]\ttraining's binary_logloss: 0.00297517\n",
      "[626]\ttraining's binary_logloss: 0.00295558\n",
      "[627]\ttraining's binary_logloss: 0.0029367\n",
      "[628]\ttraining's binary_logloss: 0.00291707\n",
      "[629]\ttraining's binary_logloss: 0.00289714\n",
      "[630]\ttraining's binary_logloss: 0.00287716\n",
      "[631]\ttraining's binary_logloss: 0.00285588\n",
      "[632]\ttraining's binary_logloss: 0.00283613\n",
      "[633]\ttraining's binary_logloss: 0.00281519\n",
      "[634]\ttraining's binary_logloss: 0.00279638\n",
      "[635]\ttraining's binary_logloss: 0.00277866\n",
      "[636]\ttraining's binary_logloss: 0.00276052\n",
      "[637]\ttraining's binary_logloss: 0.00274038\n",
      "[638]\ttraining's binary_logloss: 0.0027219\n",
      "[639]\ttraining's binary_logloss: 0.00270207\n",
      "[640]\ttraining's binary_logloss: 0.00268275\n",
      "[641]\ttraining's binary_logloss: 0.00266509\n",
      "[642]\ttraining's binary_logloss: 0.00264655\n",
      "[643]\ttraining's binary_logloss: 0.00262658\n",
      "[644]\ttraining's binary_logloss: 0.00260756\n",
      "[645]\ttraining's binary_logloss: 0.00258937\n",
      "[646]\ttraining's binary_logloss: 0.00257311\n",
      "[647]\ttraining's binary_logloss: 0.00255476\n",
      "[648]\ttraining's binary_logloss: 0.0025377\n",
      "[649]\ttraining's binary_logloss: 0.00252215\n",
      "[650]\ttraining's binary_logloss: 0.0025045\n",
      "[651]\ttraining's binary_logloss: 0.00248768\n",
      "[652]\ttraining's binary_logloss: 0.00247063\n",
      "[653]\ttraining's binary_logloss: 0.00245304\n",
      "[654]\ttraining's binary_logloss: 0.00243707\n",
      "[655]\ttraining's binary_logloss: 0.00242079\n",
      "[656]\ttraining's binary_logloss: 0.00240528\n",
      "[657]\ttraining's binary_logloss: 0.0023891\n",
      "[658]\ttraining's binary_logloss: 0.00237327\n",
      "[659]\ttraining's binary_logloss: 0.0023567\n",
      "[660]\ttraining's binary_logloss: 0.00234169\n",
      "[661]\ttraining's binary_logloss: 0.00232692\n",
      "[662]\ttraining's binary_logloss: 0.00231262\n",
      "[663]\ttraining's binary_logloss: 0.00229565\n",
      "[664]\ttraining's binary_logloss: 0.00228168\n",
      "[665]\ttraining's binary_logloss: 0.00226674\n",
      "[666]\ttraining's binary_logloss: 0.00225148\n",
      "[667]\ttraining's binary_logloss: 0.00223721\n",
      "[668]\ttraining's binary_logloss: 0.00222364\n",
      "[669]\ttraining's binary_logloss: 0.00220935\n",
      "[670]\ttraining's binary_logloss: 0.00219494\n",
      "[671]\ttraining's binary_logloss: 0.00218134\n",
      "[672]\ttraining's binary_logloss: 0.00216819\n",
      "[673]\ttraining's binary_logloss: 0.00215447\n",
      "[674]\ttraining's binary_logloss: 0.00213859\n",
      "[675]\ttraining's binary_logloss: 0.00212494\n",
      "[676]\ttraining's binary_logloss: 0.00211093\n",
      "[677]\ttraining's binary_logloss: 0.00209729\n",
      "[678]\ttraining's binary_logloss: 0.00208409\n",
      "[679]\ttraining's binary_logloss: 0.00207003\n",
      "[680]\ttraining's binary_logloss: 0.00205742\n",
      "[681]\ttraining's binary_logloss: 0.00204289\n",
      "[682]\ttraining's binary_logloss: 0.0020299\n",
      "[683]\ttraining's binary_logloss: 0.00201553\n",
      "[684]\ttraining's binary_logloss: 0.00200205\n",
      "[685]\ttraining's binary_logloss: 0.00198994\n",
      "[686]\ttraining's binary_logloss: 0.00197767\n",
      "[687]\ttraining's binary_logloss: 0.0019655\n",
      "[688]\ttraining's binary_logloss: 0.00195309\n",
      "[689]\ttraining's binary_logloss: 0.00193957\n",
      "[690]\ttraining's binary_logloss: 0.00192792\n",
      "[691]\ttraining's binary_logloss: 0.00191631\n",
      "[692]\ttraining's binary_logloss: 0.00190319\n",
      "[693]\ttraining's binary_logloss: 0.00189036\n",
      "[694]\ttraining's binary_logloss: 0.00187844\n",
      "[695]\ttraining's binary_logloss: 0.00186557\n",
      "[696]\ttraining's binary_logloss: 0.00185324\n",
      "[697]\ttraining's binary_logloss: 0.00184265\n",
      "[698]\ttraining's binary_logloss: 0.00183193\n",
      "[699]\ttraining's binary_logloss: 0.00182106\n",
      "[700]\ttraining's binary_logloss: 0.00180977\n",
      "[701]\ttraining's binary_logloss: 0.001799\n",
      "[702]\ttraining's binary_logloss: 0.00178826\n",
      "[703]\ttraining's binary_logloss: 0.00177617\n",
      "[704]\ttraining's binary_logloss: 0.0017648\n",
      "[705]\ttraining's binary_logloss: 0.00175166\n",
      "[706]\ttraining's binary_logloss: 0.00174199\n",
      "[707]\ttraining's binary_logloss: 0.00173185\n",
      "[708]\ttraining's binary_logloss: 0.00172026\n",
      "[709]\ttraining's binary_logloss: 0.00171021\n",
      "[710]\ttraining's binary_logloss: 0.00169997\n",
      "[711]\ttraining's binary_logloss: 0.00166088\n",
      "[712]\ttraining's binary_logloss: 0.00162726\n",
      "[713]\ttraining's binary_logloss: 0.00160026\n",
      "[714]\ttraining's binary_logloss: 0.00157917\n",
      "[715]\ttraining's binary_logloss: 0.00155891\n",
      "[716]\ttraining's binary_logloss: 0.00153742\n",
      "[717]\ttraining's binary_logloss: 0.00151925\n",
      "[718]\ttraining's binary_logloss: 0.00150183\n",
      "[719]\ttraining's binary_logloss: 0.0014864\n",
      "[720]\ttraining's binary_logloss: 0.00147098\n",
      "[721]\ttraining's binary_logloss: 0.00145558\n",
      "[722]\ttraining's binary_logloss: 0.001442\n",
      "[723]\ttraining's binary_logloss: 0.00142807\n",
      "[724]\ttraining's binary_logloss: 0.00141392\n",
      "[725]\ttraining's binary_logloss: 0.00140134\n",
      "[726]\ttraining's binary_logloss: 0.00138849\n",
      "[727]\ttraining's binary_logloss: 0.00137657\n",
      "[728]\ttraining's binary_logloss: 0.00136481\n",
      "[729]\ttraining's binary_logloss: 0.00135335\n",
      "[730]\ttraining's binary_logloss: 0.00134117\n",
      "[731]\ttraining's binary_logloss: 0.00132954\n",
      "[732]\ttraining's binary_logloss: 0.00131801\n",
      "[733]\ttraining's binary_logloss: 0.00130696\n",
      "[734]\ttraining's binary_logloss: 0.00129615\n",
      "[735]\ttraining's binary_logloss: 0.00128503\n",
      "[736]\ttraining's binary_logloss: 0.00127396\n",
      "[737]\ttraining's binary_logloss: 0.00126359\n",
      "[738]\ttraining's binary_logloss: 0.00125352\n",
      "[739]\ttraining's binary_logloss: 0.00124338\n",
      "[740]\ttraining's binary_logloss: 0.00123319\n",
      "[741]\ttraining's binary_logloss: 0.00122344\n",
      "[742]\ttraining's binary_logloss: 0.00121384\n",
      "[743]\ttraining's binary_logloss: 0.00120416\n",
      "[744]\ttraining's binary_logloss: 0.00119492\n",
      "[745]\ttraining's binary_logloss: 0.0011856\n",
      "[746]\ttraining's binary_logloss: 0.00117625\n",
      "[747]\ttraining's binary_logloss: 0.00116676\n",
      "[748]\ttraining's binary_logloss: 0.00115759\n",
      "[749]\ttraining's binary_logloss: 0.00114864\n",
      "[750]\ttraining's binary_logloss: 0.00114002\n",
      "[751]\ttraining's binary_logloss: 0.00113149\n",
      "[752]\ttraining's binary_logloss: 0.00112303\n",
      "[753]\ttraining's binary_logloss: 0.00111437\n",
      "[754]\ttraining's binary_logloss: 0.00110509\n",
      "[755]\ttraining's binary_logloss: 0.00109621\n",
      "[756]\ttraining's binary_logloss: 0.00108805\n",
      "[757]\ttraining's binary_logloss: 0.0010797\n",
      "[758]\ttraining's binary_logloss: 0.00107133\n",
      "[759]\ttraining's binary_logloss: 0.00106305\n",
      "[760]\ttraining's binary_logloss: 0.00105497\n",
      "[761]\ttraining's binary_logloss: 0.0010466\n",
      "[762]\ttraining's binary_logloss: 0.0010383\n",
      "[763]\ttraining's binary_logloss: 0.00103005\n",
      "[764]\ttraining's binary_logloss: 0.00102244\n",
      "[765]\ttraining's binary_logloss: 0.00101468\n",
      "[766]\ttraining's binary_logloss: 0.00100691\n",
      "[767]\ttraining's binary_logloss: 0.000999504\n",
      "[768]\ttraining's binary_logloss: 0.000991858\n",
      "[769]\ttraining's binary_logloss: 0.000984214\n",
      "[770]\ttraining's binary_logloss: 0.000976777\n",
      "[771]\ttraining's binary_logloss: 0.000968783\n",
      "[772]\ttraining's binary_logloss: 0.000961577\n",
      "[773]\ttraining's binary_logloss: 0.000954919\n",
      "[774]\ttraining's binary_logloss: 0.000947551\n",
      "[775]\ttraining's binary_logloss: 0.000939862\n",
      "[776]\ttraining's binary_logloss: 0.000932297\n",
      "[777]\ttraining's binary_logloss: 0.000924699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[778]\ttraining's binary_logloss: 0.000917744\n",
      "[779]\ttraining's binary_logloss: 0.000911321\n",
      "[780]\ttraining's binary_logloss: 0.000904474\n",
      "[781]\ttraining's binary_logloss: 0.000897863\n",
      "[782]\ttraining's binary_logloss: 0.000891265\n",
      "[783]\ttraining's binary_logloss: 0.000884333\n",
      "[784]\ttraining's binary_logloss: 0.000877636\n",
      "[785]\ttraining's binary_logloss: 0.000871198\n",
      "[786]\ttraining's binary_logloss: 0.000864699\n",
      "[787]\ttraining's binary_logloss: 0.000857901\n",
      "[788]\ttraining's binary_logloss: 0.000851647\n",
      "[789]\ttraining's binary_logloss: 0.000845216\n",
      "[790]\ttraining's binary_logloss: 0.000838978\n",
      "[791]\ttraining's binary_logloss: 0.000832331\n",
      "[792]\ttraining's binary_logloss: 0.000826494\n",
      "[793]\ttraining's binary_logloss: 0.000820733\n",
      "[794]\ttraining's binary_logloss: 0.000814784\n",
      "[795]\ttraining's binary_logloss: 0.000808437\n",
      "[796]\ttraining's binary_logloss: 0.000802418\n",
      "[797]\ttraining's binary_logloss: 0.000796565\n",
      "[798]\ttraining's binary_logloss: 0.000790911\n",
      "[799]\ttraining's binary_logloss: 0.000784638\n",
      "[800]\ttraining's binary_logloss: 0.000778713\n",
      "[801]\ttraining's binary_logloss: 0.000772973\n",
      "[802]\ttraining's binary_logloss: 0.00076701\n",
      "[803]\ttraining's binary_logloss: 0.000761176\n",
      "[804]\ttraining's binary_logloss: 0.000755599\n",
      "[805]\ttraining's binary_logloss: 0.000749759\n",
      "[806]\ttraining's binary_logloss: 0.000744452\n",
      "[807]\ttraining's binary_logloss: 0.000739323\n",
      "[808]\ttraining's binary_logloss: 0.00073385\n",
      "[809]\ttraining's binary_logloss: 0.000728736\n",
      "[810]\ttraining's binary_logloss: 0.000722985\n",
      "[811]\ttraining's binary_logloss: 0.000718112\n",
      "[812]\ttraining's binary_logloss: 0.00071334\n",
      "[813]\ttraining's binary_logloss: 0.000708243\n",
      "[814]\ttraining's binary_logloss: 0.000702684\n",
      "[815]\ttraining's binary_logloss: 0.000697325\n",
      "[816]\ttraining's binary_logloss: 0.000692405\n",
      "[817]\ttraining's binary_logloss: 0.000687453\n",
      "[818]\ttraining's binary_logloss: 0.000682462\n",
      "[819]\ttraining's binary_logloss: 0.000677327\n",
      "[820]\ttraining's binary_logloss: 0.000672635\n",
      "[821]\ttraining's binary_logloss: 0.000667608\n",
      "[822]\ttraining's binary_logloss: 0.00066288\n",
      "[823]\ttraining's binary_logloss: 0.000658221\n",
      "[824]\ttraining's binary_logloss: 0.00065338\n",
      "[825]\ttraining's binary_logloss: 0.00064861\n",
      "[826]\ttraining's binary_logloss: 0.000644019\n",
      "[827]\ttraining's binary_logloss: 0.000639143\n",
      "[828]\ttraining's binary_logloss: 0.000634421\n",
      "[829]\ttraining's binary_logloss: 0.000630201\n",
      "[830]\ttraining's binary_logloss: 0.000625477\n",
      "[831]\ttraining's binary_logloss: 0.000620447\n",
      "[832]\ttraining's binary_logloss: 0.000616003\n",
      "[833]\ttraining's binary_logloss: 0.000611747\n",
      "[834]\ttraining's binary_logloss: 0.000607026\n",
      "[835]\ttraining's binary_logloss: 0.000602484\n",
      "[836]\ttraining's binary_logloss: 0.000598051\n",
      "[837]\ttraining's binary_logloss: 0.000593345\n",
      "[838]\ttraining's binary_logloss: 0.000589302\n",
      "[839]\ttraining's binary_logloss: 0.000585161\n",
      "[840]\ttraining's binary_logloss: 0.000580567\n",
      "[841]\ttraining's binary_logloss: 0.000576252\n",
      "[842]\ttraining's binary_logloss: 0.000571955\n",
      "[843]\ttraining's binary_logloss: 0.000567972\n",
      "[844]\ttraining's binary_logloss: 0.000564017\n",
      "[845]\ttraining's binary_logloss: 0.00055966\n",
      "[846]\ttraining's binary_logloss: 0.000555725\n",
      "[847]\ttraining's binary_logloss: 0.000551606\n",
      "[848]\ttraining's binary_logloss: 0.000547293\n",
      "[849]\ttraining's binary_logloss: 0.000543114\n",
      "[850]\ttraining's binary_logloss: 0.000539148\n",
      "[851]\ttraining's binary_logloss: 0.000535376\n",
      "[852]\ttraining's binary_logloss: 0.00053135\n",
      "[853]\ttraining's binary_logloss: 0.000527699\n",
      "[854]\ttraining's binary_logloss: 0.000523941\n",
      "[855]\ttraining's binary_logloss: 0.000519949\n",
      "[856]\ttraining's binary_logloss: 0.000515916\n",
      "[857]\ttraining's binary_logloss: 0.000511905\n",
      "[858]\ttraining's binary_logloss: 0.000507825\n",
      "[859]\ttraining's binary_logloss: 0.000504474\n",
      "[860]\ttraining's binary_logloss: 0.0005009\n",
      "[861]\ttraining's binary_logloss: 0.000497022\n",
      "[862]\ttraining's binary_logloss: 0.000493305\n",
      "[863]\ttraining's binary_logloss: 0.000490132\n",
      "[864]\ttraining's binary_logloss: 0.00048681\n",
      "[865]\ttraining's binary_logloss: 0.000483234\n",
      "[866]\ttraining's binary_logloss: 0.00048003\n",
      "[867]\ttraining's binary_logloss: 0.000476749\n",
      "[868]\ttraining's binary_logloss: 0.000473258\n",
      "[869]\ttraining's binary_logloss: 0.000469671\n",
      "[870]\ttraining's binary_logloss: 0.000466161\n",
      "[871]\ttraining's binary_logloss: 0.000462991\n",
      "[872]\ttraining's binary_logloss: 0.00045941\n",
      "[873]\ttraining's binary_logloss: 0.000456185\n",
      "[874]\ttraining's binary_logloss: 0.000452731\n",
      "[875]\ttraining's binary_logloss: 0.000449778\n",
      "[876]\ttraining's binary_logloss: 0.000446368\n",
      "[877]\ttraining's binary_logloss: 0.000443031\n",
      "[878]\ttraining's binary_logloss: 0.000440004\n",
      "[879]\ttraining's binary_logloss: 0.000436703\n",
      "[880]\ttraining's binary_logloss: 0.000433447\n",
      "[881]\ttraining's binary_logloss: 0.000430577\n",
      "[882]\ttraining's binary_logloss: 0.000427592\n",
      "[883]\ttraining's binary_logloss: 0.00042445\n",
      "[884]\ttraining's binary_logloss: 0.000420946\n",
      "[885]\ttraining's binary_logloss: 0.000417693\n",
      "[886]\ttraining's binary_logloss: 0.000414996\n",
      "[887]\ttraining's binary_logloss: 0.000412251\n",
      "[888]\ttraining's binary_logloss: 0.000409453\n",
      "[889]\ttraining's binary_logloss: 0.000406656\n",
      "[890]\ttraining's binary_logloss: 0.000403647\n",
      "[891]\ttraining's binary_logloss: 0.00040048\n",
      "[892]\ttraining's binary_logloss: 0.000397256\n",
      "[893]\ttraining's binary_logloss: 0.00039452\n",
      "[894]\ttraining's binary_logloss: 0.000391409\n",
      "[895]\ttraining's binary_logloss: 0.000388487\n",
      "[896]\ttraining's binary_logloss: 0.000385862\n",
      "[897]\ttraining's binary_logloss: 0.000383004\n",
      "[898]\ttraining's binary_logloss: 0.000380455\n",
      "[899]\ttraining's binary_logloss: 0.000377607\n",
      "[900]\ttraining's binary_logloss: 0.000375149\n",
      "[901]\ttraining's binary_logloss: 0.000372606\n",
      "[902]\ttraining's binary_logloss: 0.000370192\n",
      "[903]\ttraining's binary_logloss: 0.000367834\n",
      "[904]\ttraining's binary_logloss: 0.000365632\n",
      "[905]\ttraining's binary_logloss: 0.000363218\n",
      "[906]\ttraining's binary_logloss: 0.00036048\n",
      "[907]\ttraining's binary_logloss: 0.000358135\n",
      "[908]\ttraining's binary_logloss: 0.000355512\n",
      "[909]\ttraining's binary_logloss: 0.000353182\n",
      "[910]\ttraining's binary_logloss: 0.00035043\n",
      "[911]\ttraining's binary_logloss: 0.000347701\n",
      "[912]\ttraining's binary_logloss: 0.000345516\n",
      "[913]\ttraining's binary_logloss: 0.000342875\n",
      "[914]\ttraining's binary_logloss: 0.000340628\n",
      "[915]\ttraining's binary_logloss: 0.000338504\n",
      "[916]\ttraining's binary_logloss: 0.000336038\n",
      "[917]\ttraining's binary_logloss: 0.000333332\n",
      "[918]\ttraining's binary_logloss: 0.000331141\n",
      "[919]\ttraining's binary_logloss: 0.000329207\n",
      "[920]\ttraining's binary_logloss: 0.000326972\n",
      "[921]\ttraining's binary_logloss: 0.000324642\n",
      "[922]\ttraining's binary_logloss: 0.000322146\n",
      "[923]\ttraining's binary_logloss: 0.000319782\n",
      "[924]\ttraining's binary_logloss: 0.000317598\n",
      "[925]\ttraining's binary_logloss: 0.000315179\n",
      "[926]\ttraining's binary_logloss: 0.000313192\n",
      "[927]\ttraining's binary_logloss: 0.000311033\n",
      "[928]\ttraining's binary_logloss: 0.000308732\n",
      "[929]\ttraining's binary_logloss: 0.000306521\n",
      "[930]\ttraining's binary_logloss: 0.000304546\n",
      "[931]\ttraining's binary_logloss: 0.00030266\n",
      "[932]\ttraining's binary_logloss: 0.000300747\n",
      "[933]\ttraining's binary_logloss: 0.000298449\n",
      "[934]\ttraining's binary_logloss: 0.000296555\n",
      "[935]\ttraining's binary_logloss: 0.000294369\n",
      "[936]\ttraining's binary_logloss: 0.000292591\n",
      "[937]\ttraining's binary_logloss: 0.000290401\n",
      "[938]\ttraining's binary_logloss: 0.000288247\n",
      "[939]\ttraining's binary_logloss: 0.000286485\n",
      "[940]\ttraining's binary_logloss: 0.000284362\n",
      "[941]\ttraining's binary_logloss: 0.000282199\n",
      "[942]\ttraining's binary_logloss: 0.000280158\n",
      "[943]\ttraining's binary_logloss: 0.00027857\n",
      "[944]\ttraining's binary_logloss: 0.000276653\n",
      "[945]\ttraining's binary_logloss: 0.000274936\n",
      "[946]\ttraining's binary_logloss: 0.000272895\n",
      "[947]\ttraining's binary_logloss: 0.00027124\n",
      "[948]\ttraining's binary_logloss: 0.000269126\n",
      "[949]\ttraining's binary_logloss: 0.000267523\n",
      "[950]\ttraining's binary_logloss: 0.000265377\n",
      "[951]\ttraining's binary_logloss: 0.000263492\n",
      "[952]\ttraining's binary_logloss: 0.000261398\n",
      "[953]\ttraining's binary_logloss: 0.000259519\n",
      "[954]\ttraining's binary_logloss: 0.00025756\n",
      "[955]\ttraining's binary_logloss: 0.000255683\n",
      "[956]\ttraining's binary_logloss: 0.000253662\n",
      "[957]\ttraining's binary_logloss: 0.000252104\n",
      "[958]\ttraining's binary_logloss: 0.000250617\n",
      "[959]\ttraining's binary_logloss: 0.000249074\n",
      "[960]\ttraining's binary_logloss: 0.000247431\n",
      "[961]\ttraining's binary_logloss: 0.000245759\n",
      "[962]\ttraining's binary_logloss: 0.000244181\n",
      "[963]\ttraining's binary_logloss: 0.000242473\n",
      "[964]\ttraining's binary_logloss: 0.000240642\n",
      "[965]\ttraining's binary_logloss: 0.000238839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[966]\ttraining's binary_logloss: 0.000237133\n",
      "[967]\ttraining's binary_logloss: 0.000235747\n",
      "[968]\ttraining's binary_logloss: 0.000234227\n",
      "[969]\ttraining's binary_logloss: 0.000232402\n",
      "[970]\ttraining's binary_logloss: 0.000231023\n",
      "[971]\ttraining's binary_logloss: 0.000229196\n",
      "[972]\ttraining's binary_logloss: 0.000227612\n",
      "[973]\ttraining's binary_logloss: 0.00022639\n",
      "[974]\ttraining's binary_logloss: 0.000225063\n",
      "[975]\ttraining's binary_logloss: 0.000223813\n",
      "[976]\ttraining's binary_logloss: 0.000222086\n",
      "[977]\ttraining's binary_logloss: 0.000220834\n",
      "[978]\ttraining's binary_logloss: 0.000219167\n",
      "[979]\ttraining's binary_logloss: 0.000217519\n",
      "[980]\ttraining's binary_logloss: 0.000216224\n",
      "[981]\ttraining's binary_logloss: 0.000214986\n",
      "[982]\ttraining's binary_logloss: 0.000213927\n",
      "[983]\ttraining's binary_logloss: 0.000212762\n",
      "[984]\ttraining's binary_logloss: 0.000211161\n",
      "[985]\ttraining's binary_logloss: 0.000209501\n",
      "[986]\ttraining's binary_logloss: 0.000207771\n",
      "[987]\ttraining's binary_logloss: 0.000206628\n",
      "[988]\ttraining's binary_logloss: 0.000205247\n",
      "[989]\ttraining's binary_logloss: 0.000203633\n",
      "[990]\ttraining's binary_logloss: 0.000202256\n",
      "[991]\ttraining's binary_logloss: 0.000201047\n",
      "[992]\ttraining's binary_logloss: 0.000199609\n",
      "[993]\ttraining's binary_logloss: 0.000198428\n",
      "[994]\ttraining's binary_logloss: 0.000196885\n",
      "[995]\ttraining's binary_logloss: 0.000195703\n",
      "[996]\ttraining's binary_logloss: 0.000194197\n",
      "[997]\ttraining's binary_logloss: 0.000193169\n",
      "[998]\ttraining's binary_logloss: 0.000192135\n",
      "[999]\ttraining's binary_logloss: 0.000191064\n",
      "[1000]\ttraining's binary_logloss: 0.00018982\n",
      "[1001]\ttraining's binary_logloss: 0.000188895\n",
      "[1002]\ttraining's binary_logloss: 0.000187462\n",
      "[1003]\ttraining's binary_logloss: 0.000185962\n",
      "[1004]\ttraining's binary_logloss: 0.000184683\n",
      "[1005]\ttraining's binary_logloss: 0.000183597\n",
      "[1006]\ttraining's binary_logloss: 0.00018222\n",
      "[1007]\ttraining's binary_logloss: 0.000180717\n",
      "[1008]\ttraining's binary_logloss: 0.000179688\n",
      "[1009]\ttraining's binary_logloss: 0.000178289\n",
      "[1010]\ttraining's binary_logloss: 0.000177166\n",
      "[1011]\ttraining's binary_logloss: 0.000176184\n",
      "[1012]\ttraining's binary_logloss: 0.000174946\n",
      "[1013]\ttraining's binary_logloss: 0.000173952\n",
      "[1014]\ttraining's binary_logloss: 0.000172987\n",
      "[1015]\ttraining's binary_logloss: 0.000172078\n",
      "[1016]\ttraining's binary_logloss: 0.000170934\n",
      "[1017]\ttraining's binary_logloss: 0.000169576\n",
      "[1018]\ttraining's binary_logloss: 0.00016877\n",
      "[1019]\ttraining's binary_logloss: 0.000167523\n",
      "[1020]\ttraining's binary_logloss: 0.000166785\n",
      "[1021]\ttraining's binary_logloss: 0.000165559\n",
      "[1022]\ttraining's binary_logloss: 0.000164763\n",
      "[1023]\ttraining's binary_logloss: 0.000163813\n",
      "[1024]\ttraining's binary_logloss: 0.000162712\n",
      "[1025]\ttraining's binary_logloss: 0.000161927\n",
      "[1026]\ttraining's binary_logloss: 0.000161059\n",
      "[1027]\ttraining's binary_logloss: 0.000160241\n",
      "[1028]\ttraining's binary_logloss: 0.000159293\n",
      "[1029]\ttraining's binary_logloss: 0.00015809\n",
      "[1030]\ttraining's binary_logloss: 0.000157465\n",
      "[1031]\ttraining's binary_logloss: 0.000156185\n",
      "[1032]\ttraining's binary_logloss: 0.000155452\n",
      "[1033]\ttraining's binary_logloss: 0.000154567\n",
      "[1034]\ttraining's binary_logloss: 0.000153342\n",
      "[1035]\ttraining's binary_logloss: 0.000152744\n",
      "[1036]\ttraining's binary_logloss: 0.000151865\n",
      "[1037]\ttraining's binary_logloss: 0.000150617\n",
      "[1038]\ttraining's binary_logloss: 0.000149472\n",
      "[1039]\ttraining's binary_logloss: 0.000148805\n",
      "[1040]\ttraining's binary_logloss: 0.000147942\n",
      "[1041]\ttraining's binary_logloss: 0.00014698\n",
      "[1042]\ttraining's binary_logloss: 0.000146404\n",
      "[1043]\ttraining's binary_logloss: 0.000145496\n",
      "[1044]\ttraining's binary_logloss: 0.000144661\n",
      "[1045]\ttraining's binary_logloss: 0.000143821\n",
      "[1046]\ttraining's binary_logloss: 0.000143189\n",
      "[1047]\ttraining's binary_logloss: 0.000142133\n",
      "[1048]\ttraining's binary_logloss: 0.000141208\n",
      "[1049]\ttraining's binary_logloss: 0.000140313\n",
      "[1050]\ttraining's binary_logloss: 0.000139267\n",
      "[1051]\ttraining's binary_logloss: 0.000138726\n",
      "[1052]\ttraining's binary_logloss: 0.000137814\n",
      "[1053]\ttraining's binary_logloss: 0.000137177\n",
      "[1054]\ttraining's binary_logloss: 0.000136201\n",
      "[1055]\ttraining's binary_logloss: 0.000135274\n",
      "[1056]\ttraining's binary_logloss: 0.00013419\n",
      "[1057]\ttraining's binary_logloss: 0.000133687\n",
      "[1058]\ttraining's binary_logloss: 0.000132644\n",
      "[1059]\ttraining's binary_logloss: 0.000131979\n",
      "[1060]\ttraining's binary_logloss: 0.000130848\n",
      "[1061]\ttraining's binary_logloss: 0.000129722\n",
      "[1062]\ttraining's binary_logloss: 0.000129292\n",
      "[1063]\ttraining's binary_logloss: 0.0001285\n",
      "[1064]\ttraining's binary_logloss: 0.000128057\n",
      "[1065]\ttraining's binary_logloss: 0.00012717\n",
      "[1066]\ttraining's binary_logloss: 0.00012671\n",
      "[1067]\ttraining's binary_logloss: 0.000126249\n",
      "[1068]\ttraining's binary_logloss: 0.000125332\n",
      "[1069]\ttraining's binary_logloss: 0.000124886\n",
      "[1070]\ttraining's binary_logloss: 0.000124504\n",
      "[1071]\ttraining's binary_logloss: 0.000124019\n",
      "[1072]\ttraining's binary_logloss: 0.000123596\n",
      "[1073]\ttraining's binary_logloss: 0.000123159\n",
      "[1074]\ttraining's binary_logloss: 0.000122693\n",
      "[1075]\ttraining's binary_logloss: 0.000121662\n",
      "[1076]\ttraining's binary_logloss: 0.000120922\n",
      "[1077]\ttraining's binary_logloss: 0.000120465\n",
      "[1078]\ttraining's binary_logloss: 0.00011936\n",
      "[1079]\ttraining's binary_logloss: 0.00011844\n",
      "[1080]\ttraining's binary_logloss: 0.000117949\n",
      "[1081]\ttraining's binary_logloss: 0.000117229\n",
      "[1082]\ttraining's binary_logloss: 0.000116888\n",
      "[1083]\ttraining's binary_logloss: 0.000115975\n",
      "[1084]\ttraining's binary_logloss: 0.00011557\n",
      "[1085]\ttraining's binary_logloss: 0.000115255\n",
      "[1086]\ttraining's binary_logloss: 0.000114934\n",
      "[1087]\ttraining's binary_logloss: 0.000114685\n",
      "[1088]\ttraining's binary_logloss: 0.000113702\n",
      "[1089]\ttraining's binary_logloss: 0.000112856\n",
      "[1090]\ttraining's binary_logloss: 0.000111809\n",
      "[1091]\ttraining's binary_logloss: 0.000111122\n",
      "[1092]\ttraining's binary_logloss: 0.000110345\n",
      "[1093]\ttraining's binary_logloss: 0.000109413\n",
      "[1094]\ttraining's binary_logloss: 0.000108638\n",
      "[1095]\ttraining's binary_logloss: 0.000107685\n",
      "[1096]\ttraining's binary_logloss: 0.000107159\n",
      "[1097]\ttraining's binary_logloss: 0.000106354\n",
      "[1098]\ttraining's binary_logloss: 0.000105567\n",
      "[1099]\ttraining's binary_logloss: 0.000104773\n",
      "[1100]\ttraining's binary_logloss: 0.000104478\n",
      "[1101]\ttraining's binary_logloss: 0.000103536\n",
      "[1102]\ttraining's binary_logloss: 0.000103195\n",
      "[1103]\ttraining's binary_logloss: 0.000102459\n",
      "[1104]\ttraining's binary_logloss: 0.000101619\n",
      "[1105]\ttraining's binary_logloss: 0.000101226\n",
      "[1106]\ttraining's binary_logloss: 0.000100339\n",
      "[1107]\ttraining's binary_logloss: 0.000100077\n",
      "[1108]\ttraining's binary_logloss: 9.94696e-05\n",
      "[1109]\ttraining's binary_logloss: 9.87492e-05\n",
      "[1110]\ttraining's binary_logloss: 9.78944e-05\n",
      "[1111]\ttraining's binary_logloss: 9.75052e-05\n",
      "[1112]\ttraining's binary_logloss: 9.70236e-05\n",
      "[1113]\ttraining's binary_logloss: 9.61892e-05\n",
      "[1114]\ttraining's binary_logloss: 9.56606e-05\n",
      "[1115]\ttraining's binary_logloss: 9.48396e-05\n",
      "[1116]\ttraining's binary_logloss: 9.40722e-05\n",
      "[1117]\ttraining's binary_logloss: 9.34058e-05\n",
      "[1118]\ttraining's binary_logloss: 9.255e-05\n",
      "[1119]\ttraining's binary_logloss: 9.18932e-05\n",
      "[1120]\ttraining's binary_logloss: 9.14164e-05\n",
      "[1121]\ttraining's binary_logloss: 9.1085e-05\n",
      "[1122]\ttraining's binary_logloss: 9.09619e-05\n",
      "[1123]\ttraining's binary_logloss: 9.08088e-05\n",
      "[1124]\ttraining's binary_logloss: 9.01153e-05\n",
      "[1125]\ttraining's binary_logloss: 8.94244e-05\n",
      "[1126]\ttraining's binary_logloss: 8.87134e-05\n",
      "[1127]\ttraining's binary_logloss: 8.85982e-05\n",
      "[1128]\ttraining's binary_logloss: 8.84456e-05\n",
      "[1129]\ttraining's binary_logloss: 8.76789e-05\n",
      "[1130]\ttraining's binary_logloss: 8.68932e-05\n",
      "[1131]\ttraining's binary_logloss: 8.61358e-05\n",
      "[1132]\ttraining's binary_logloss: 8.53242e-05\n",
      "[1133]\ttraining's binary_logloss: 8.46742e-05\n",
      "[1134]\ttraining's binary_logloss: 8.39233e-05\n",
      "[1135]\ttraining's binary_logloss: 8.34557e-05\n",
      "[1136]\ttraining's binary_logloss: 8.29668e-05\n",
      "[1137]\ttraining's binary_logloss: 8.2726e-05\n",
      "[1138]\ttraining's binary_logloss: 8.19687e-05\n",
      "[1139]\ttraining's binary_logloss: 8.12392e-05\n",
      "[1140]\ttraining's binary_logloss: 8.10243e-05\n",
      "[1141]\ttraining's binary_logloss: 8.07194e-05\n",
      "[1142]\ttraining's binary_logloss: 8.01353e-05\n",
      "[1143]\ttraining's binary_logloss: 7.98742e-05\n",
      "[1144]\ttraining's binary_logloss: 7.90943e-05\n",
      "[1145]\ttraining's binary_logloss: 7.81338e-05\n",
      "[1146]\ttraining's binary_logloss: 7.72333e-05\n",
      "[1147]\ttraining's binary_logloss: 7.62974e-05\n",
      "[1148]\ttraining's binary_logloss: 7.54405e-05\n",
      "[1149]\ttraining's binary_logloss: 7.45554e-05\n",
      "[1150]\ttraining's binary_logloss: 7.3704e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1151]\ttraining's binary_logloss: 7.28559e-05\n",
      "[1152]\ttraining's binary_logloss: 7.2054e-05\n",
      "[1153]\ttraining's binary_logloss: 7.12271e-05\n",
      "[1154]\ttraining's binary_logloss: 7.04427e-05\n",
      "[1155]\ttraining's binary_logloss: 6.96573e-05\n",
      "[1156]\ttraining's binary_logloss: 6.8886e-05\n",
      "[1157]\ttraining's binary_logloss: 6.81261e-05\n",
      "[1158]\ttraining's binary_logloss: 6.74114e-05\n",
      "[1159]\ttraining's binary_logloss: 6.67075e-05\n",
      "[1160]\ttraining's binary_logloss: 6.60037e-05\n",
      "[1161]\ttraining's binary_logloss: 6.53071e-05\n",
      "[1162]\ttraining's binary_logloss: 6.46151e-05\n",
      "[1163]\ttraining's binary_logloss: 6.39462e-05\n",
      "[1164]\ttraining's binary_logloss: 6.32633e-05\n",
      "[1165]\ttraining's binary_logloss: 6.25969e-05\n",
      "[1166]\ttraining's binary_logloss: 6.19462e-05\n",
      "[1167]\ttraining's binary_logloss: 6.13293e-05\n",
      "[1168]\ttraining's binary_logloss: 6.06975e-05\n",
      "[1169]\ttraining's binary_logloss: 6.00733e-05\n",
      "[1170]\ttraining's binary_logloss: 5.94693e-05\n",
      "[1171]\ttraining's binary_logloss: 5.88608e-05\n",
      "[1172]\ttraining's binary_logloss: 5.82693e-05\n",
      "[1173]\ttraining's binary_logloss: 5.76909e-05\n",
      "[1174]\ttraining's binary_logloss: 5.71327e-05\n",
      "[1175]\ttraining's binary_logloss: 5.65633e-05\n",
      "[1176]\ttraining's binary_logloss: 5.60328e-05\n",
      "[1177]\ttraining's binary_logloss: 5.55119e-05\n",
      "[1178]\ttraining's binary_logloss: 5.49711e-05\n",
      "[1179]\ttraining's binary_logloss: 5.44623e-05\n",
      "[1180]\ttraining's binary_logloss: 5.39478e-05\n",
      "[1181]\ttraining's binary_logloss: 5.34326e-05\n",
      "[1182]\ttraining's binary_logloss: 5.29374e-05\n",
      "[1183]\ttraining's binary_logloss: 5.24521e-05\n",
      "[1184]\ttraining's binary_logloss: 5.19486e-05\n",
      "[1185]\ttraining's binary_logloss: 5.14775e-05\n",
      "[1186]\ttraining's binary_logloss: 5.10039e-05\n",
      "[1187]\ttraining's binary_logloss: 5.05449e-05\n",
      "[1188]\ttraining's binary_logloss: 5.00768e-05\n",
      "[1189]\ttraining's binary_logloss: 4.96186e-05\n",
      "[1190]\ttraining's binary_logloss: 4.91684e-05\n",
      "[1191]\ttraining's binary_logloss: 4.87261e-05\n",
      "[1192]\ttraining's binary_logloss: 4.82923e-05\n",
      "[1193]\ttraining's binary_logloss: 4.78685e-05\n",
      "[1194]\ttraining's binary_logloss: 4.74448e-05\n",
      "[1195]\ttraining's binary_logloss: 4.70299e-05\n",
      "[1196]\ttraining's binary_logloss: 4.66172e-05\n",
      "[1197]\ttraining's binary_logloss: 4.6212e-05\n",
      "[1198]\ttraining's binary_logloss: 4.57995e-05\n",
      "[1199]\ttraining's binary_logloss: 4.54102e-05\n",
      "[1200]\ttraining's binary_logloss: 4.50222e-05\n",
      "[1201]\ttraining's binary_logloss: 4.46512e-05\n",
      "[1202]\ttraining's binary_logloss: 4.42796e-05\n",
      "[1203]\ttraining's binary_logloss: 4.39024e-05\n",
      "[1204]\ttraining's binary_logloss: 4.35465e-05\n",
      "[1205]\ttraining's binary_logloss: 4.31735e-05\n",
      "[1206]\ttraining's binary_logloss: 4.28058e-05\n",
      "[1207]\ttraining's binary_logloss: 4.24326e-05\n",
      "[1208]\ttraining's binary_logloss: 4.20718e-05\n",
      "[1209]\ttraining's binary_logloss: 4.17269e-05\n",
      "[1210]\ttraining's binary_logloss: 4.13774e-05\n",
      "[1211]\ttraining's binary_logloss: 4.10528e-05\n",
      "[1212]\ttraining's binary_logloss: 4.07227e-05\n",
      "[1213]\ttraining's binary_logloss: 4.03887e-05\n",
      "[1214]\ttraining's binary_logloss: 4.00509e-05\n",
      "[1215]\ttraining's binary_logloss: 3.97292e-05\n",
      "[1216]\ttraining's binary_logloss: 3.94052e-05\n",
      "[1217]\ttraining's binary_logloss: 3.90771e-05\n",
      "[1218]\ttraining's binary_logloss: 3.876e-05\n",
      "[1219]\ttraining's binary_logloss: 3.84541e-05\n",
      "[1220]\ttraining's binary_logloss: 3.81625e-05\n",
      "[1221]\ttraining's binary_logloss: 3.7872e-05\n",
      "[1222]\ttraining's binary_logloss: 3.75833e-05\n",
      "[1223]\ttraining's binary_logloss: 3.72891e-05\n",
      "[1224]\ttraining's binary_logloss: 3.69994e-05\n",
      "[1225]\ttraining's binary_logloss: 3.67186e-05\n",
      "[1226]\ttraining's binary_logloss: 3.64322e-05\n",
      "[1227]\ttraining's binary_logloss: 3.61573e-05\n",
      "[1228]\ttraining's binary_logloss: 3.58792e-05\n",
      "[1229]\ttraining's binary_logloss: 3.56231e-05\n",
      "[1230]\ttraining's binary_logloss: 3.53477e-05\n",
      "[1231]\ttraining's binary_logloss: 3.50716e-05\n",
      "[1232]\ttraining's binary_logloss: 3.48179e-05\n",
      "[1233]\ttraining's binary_logloss: 3.45483e-05\n",
      "[1234]\ttraining's binary_logloss: 3.42866e-05\n",
      "[1235]\ttraining's binary_logloss: 3.40284e-05\n",
      "[1236]\ttraining's binary_logloss: 3.37778e-05\n",
      "[1237]\ttraining's binary_logloss: 3.35366e-05\n",
      "[1238]\ttraining's binary_logloss: 3.32917e-05\n",
      "[1239]\ttraining's binary_logloss: 3.30542e-05\n",
      "[1240]\ttraining's binary_logloss: 3.2814e-05\n",
      "[1241]\ttraining's binary_logloss: 3.25822e-05\n",
      "[1242]\ttraining's binary_logloss: 3.23505e-05\n",
      "[1243]\ttraining's binary_logloss: 3.21223e-05\n",
      "[1244]\ttraining's binary_logloss: 3.18993e-05\n",
      "[1245]\ttraining's binary_logloss: 3.16738e-05\n",
      "[1246]\ttraining's binary_logloss: 3.14519e-05\n",
      "[1247]\ttraining's binary_logloss: 3.12348e-05\n",
      "[1248]\ttraining's binary_logloss: 3.10037e-05\n",
      "[1249]\ttraining's binary_logloss: 3.07882e-05\n",
      "[1250]\ttraining's binary_logloss: 3.05747e-05\n",
      "[1251]\ttraining's binary_logloss: 3.03741e-05\n",
      "[1252]\ttraining's binary_logloss: 3.01624e-05\n",
      "[1253]\ttraining's binary_logloss: 2.99561e-05\n",
      "[1254]\ttraining's binary_logloss: 2.97473e-05\n",
      "[1255]\ttraining's binary_logloss: 2.95527e-05\n",
      "[1256]\ttraining's binary_logloss: 2.93546e-05\n",
      "[1257]\ttraining's binary_logloss: 2.91539e-05\n",
      "[1258]\ttraining's binary_logloss: 2.89582e-05\n",
      "[1259]\ttraining's binary_logloss: 2.8763e-05\n",
      "[1260]\ttraining's binary_logloss: 2.85671e-05\n",
      "[1261]\ttraining's binary_logloss: 2.83706e-05\n",
      "[1262]\ttraining's binary_logloss: 2.81781e-05\n",
      "[1263]\ttraining's binary_logloss: 2.79929e-05\n",
      "[1264]\ttraining's binary_logloss: 2.78064e-05\n",
      "[1265]\ttraining's binary_logloss: 2.76251e-05\n",
      "[1266]\ttraining's binary_logloss: 2.74473e-05\n",
      "[1267]\ttraining's binary_logloss: 2.72797e-05\n",
      "[1268]\ttraining's binary_logloss: 2.71134e-05\n",
      "[1269]\ttraining's binary_logloss: 2.69423e-05\n",
      "[1270]\ttraining's binary_logloss: 2.67797e-05\n",
      "[1271]\ttraining's binary_logloss: 2.661e-05\n",
      "[1272]\ttraining's binary_logloss: 2.64562e-05\n",
      "[1273]\ttraining's binary_logloss: 2.63018e-05\n",
      "[1274]\ttraining's binary_logloss: 2.61436e-05\n",
      "[1275]\ttraining's binary_logloss: 2.59879e-05\n",
      "[1276]\ttraining's binary_logloss: 2.58372e-05\n",
      "[1277]\ttraining's binary_logloss: 2.56866e-05\n",
      "[1278]\ttraining's binary_logloss: 2.55236e-05\n",
      "[1279]\ttraining's binary_logloss: 2.53639e-05\n",
      "[1280]\ttraining's binary_logloss: 2.52121e-05\n",
      "[1281]\ttraining's binary_logloss: 2.5061e-05\n",
      "[1282]\ttraining's binary_logloss: 2.49033e-05\n",
      "[1283]\ttraining's binary_logloss: 2.47616e-05\n",
      "[1284]\ttraining's binary_logloss: 2.46235e-05\n",
      "[1285]\ttraining's binary_logloss: 2.44777e-05\n",
      "[1286]\ttraining's binary_logloss: 2.43309e-05\n",
      "[1287]\ttraining's binary_logloss: 2.41817e-05\n",
      "[1288]\ttraining's binary_logloss: 2.40528e-05\n",
      "[1289]\ttraining's binary_logloss: 2.39145e-05\n",
      "[1290]\ttraining's binary_logloss: 2.37849e-05\n",
      "[1291]\ttraining's binary_logloss: 2.36493e-05\n",
      "[1292]\ttraining's binary_logloss: 2.3519e-05\n",
      "[1293]\ttraining's binary_logloss: 2.33854e-05\n",
      "[1294]\ttraining's binary_logloss: 2.32665e-05\n",
      "[1295]\ttraining's binary_logloss: 2.31447e-05\n",
      "[1296]\ttraining's binary_logloss: 2.3013e-05\n",
      "[1297]\ttraining's binary_logloss: 2.28851e-05\n",
      "[1298]\ttraining's binary_logloss: 2.27509e-05\n",
      "[1299]\ttraining's binary_logloss: 2.26296e-05\n",
      "[1300]\ttraining's binary_logloss: 2.25037e-05\n",
      "[1301]\ttraining's binary_logloss: 2.23764e-05\n",
      "[1302]\ttraining's binary_logloss: 2.22659e-05\n",
      "[1303]\ttraining's binary_logloss: 2.21418e-05\n",
      "[1304]\ttraining's binary_logloss: 2.20267e-05\n",
      "[1305]\ttraining's binary_logloss: 2.19073e-05\n",
      "[1306]\ttraining's binary_logloss: 2.17926e-05\n",
      "[1307]\ttraining's binary_logloss: 2.16764e-05\n",
      "[1308]\ttraining's binary_logloss: 2.15645e-05\n",
      "[1309]\ttraining's binary_logloss: 2.14488e-05\n",
      "[1310]\ttraining's binary_logloss: 2.13384e-05\n",
      "[1311]\ttraining's binary_logloss: 2.12276e-05\n",
      "[1312]\ttraining's binary_logloss: 2.11203e-05\n",
      "[1313]\ttraining's binary_logloss: 2.10126e-05\n",
      "[1314]\ttraining's binary_logloss: 2.09052e-05\n",
      "[1315]\ttraining's binary_logloss: 2.07993e-05\n",
      "[1316]\ttraining's binary_logloss: 2.06886e-05\n",
      "[1317]\ttraining's binary_logloss: 2.05921e-05\n",
      "[1318]\ttraining's binary_logloss: 2.04903e-05\n",
      "[1319]\ttraining's binary_logloss: 2.03921e-05\n",
      "[1320]\ttraining's binary_logloss: 2.02983e-05\n",
      "[1321]\ttraining's binary_logloss: 2.01997e-05\n",
      "[1322]\ttraining's binary_logloss: 2.0098e-05\n",
      "[1323]\ttraining's binary_logloss: 2.00032e-05\n",
      "[1324]\ttraining's binary_logloss: 1.99097e-05\n",
      "[1325]\ttraining's binary_logloss: 1.98212e-05\n",
      "[1326]\ttraining's binary_logloss: 1.9731e-05\n",
      "[1327]\ttraining's binary_logloss: 1.96319e-05\n",
      "[1328]\ttraining's binary_logloss: 1.95388e-05\n",
      "[1329]\ttraining's binary_logloss: 1.94495e-05\n",
      "[1330]\ttraining's binary_logloss: 1.93583e-05\n",
      "[1331]\ttraining's binary_logloss: 1.92669e-05\n",
      "[1332]\ttraining's binary_logloss: 1.91781e-05\n",
      "[1333]\ttraining's binary_logloss: 1.90877e-05\n",
      "[1334]\ttraining's binary_logloss: 1.89895e-05\n",
      "[1335]\ttraining's binary_logloss: 1.89035e-05\n",
      "[1336]\ttraining's binary_logloss: 1.88156e-05\n",
      "[1337]\ttraining's binary_logloss: 1.87276e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1338]\ttraining's binary_logloss: 1.86435e-05\n",
      "[1339]\ttraining's binary_logloss: 1.85559e-05\n",
      "[1340]\ttraining's binary_logloss: 1.84692e-05\n",
      "[1341]\ttraining's binary_logloss: 1.83826e-05\n",
      "[1342]\ttraining's binary_logloss: 1.83039e-05\n",
      "[1343]\ttraining's binary_logloss: 1.82201e-05\n",
      "[1344]\ttraining's binary_logloss: 1.81407e-05\n",
      "[1345]\ttraining's binary_logloss: 1.80676e-05\n",
      "[1346]\ttraining's binary_logloss: 1.79917e-05\n",
      "[1347]\ttraining's binary_logloss: 1.79126e-05\n",
      "[1348]\ttraining's binary_logloss: 1.7833e-05\n",
      "[1349]\ttraining's binary_logloss: 1.77569e-05\n",
      "[1350]\ttraining's binary_logloss: 1.7679e-05\n",
      "[1351]\ttraining's binary_logloss: 1.75983e-05\n",
      "[1352]\ttraining's binary_logloss: 1.75279e-05\n",
      "[1353]\ttraining's binary_logloss: 1.74535e-05\n",
      "[1354]\ttraining's binary_logloss: 1.73776e-05\n",
      "[1355]\ttraining's binary_logloss: 1.7304e-05\n",
      "[1356]\ttraining's binary_logloss: 1.7228e-05\n",
      "[1357]\ttraining's binary_logloss: 1.71516e-05\n",
      "[1358]\ttraining's binary_logloss: 1.70838e-05\n",
      "[1359]\ttraining's binary_logloss: 1.70124e-05\n",
      "[1360]\ttraining's binary_logloss: 1.69455e-05\n",
      "[1361]\ttraining's binary_logloss: 1.68737e-05\n",
      "[1362]\ttraining's binary_logloss: 1.68054e-05\n",
      "[1363]\ttraining's binary_logloss: 1.67347e-05\n",
      "[1364]\ttraining's binary_logloss: 1.66698e-05\n",
      "[1365]\ttraining's binary_logloss: 1.66012e-05\n",
      "[1366]\ttraining's binary_logloss: 1.6537e-05\n",
      "[1367]\ttraining's binary_logloss: 1.647e-05\n",
      "[1368]\ttraining's binary_logloss: 1.64028e-05\n",
      "[1369]\ttraining's binary_logloss: 1.6338e-05\n",
      "[1370]\ttraining's binary_logloss: 1.62793e-05\n",
      "[1371]\ttraining's binary_logloss: 1.6217e-05\n",
      "[1372]\ttraining's binary_logloss: 1.61536e-05\n",
      "[1373]\ttraining's binary_logloss: 1.6096e-05\n",
      "[1374]\ttraining's binary_logloss: 1.60369e-05\n",
      "[1375]\ttraining's binary_logloss: 1.59726e-05\n",
      "[1376]\ttraining's binary_logloss: 1.59109e-05\n",
      "[1377]\ttraining's binary_logloss: 1.58473e-05\n",
      "[1378]\ttraining's binary_logloss: 1.57877e-05\n",
      "[1379]\ttraining's binary_logloss: 1.57238e-05\n",
      "[1380]\ttraining's binary_logloss: 1.56654e-05\n",
      "[1381]\ttraining's binary_logloss: 1.5609e-05\n",
      "[1382]\ttraining's binary_logloss: 1.55519e-05\n",
      "[1383]\ttraining's binary_logloss: 1.54921e-05\n",
      "[1384]\ttraining's binary_logloss: 1.54309e-05\n",
      "[1385]\ttraining's binary_logloss: 1.53776e-05\n",
      "[1386]\ttraining's binary_logloss: 1.53218e-05\n",
      "[1387]\ttraining's binary_logloss: 1.52696e-05\n",
      "[1388]\ttraining's binary_logloss: 1.52132e-05\n",
      "[1389]\ttraining's binary_logloss: 1.51575e-05\n",
      "[1390]\ttraining's binary_logloss: 1.51024e-05\n",
      "[1391]\ttraining's binary_logloss: 1.50449e-05\n",
      "[1392]\ttraining's binary_logloss: 1.49938e-05\n",
      "[1393]\ttraining's binary_logloss: 1.49397e-05\n",
      "[1394]\ttraining's binary_logloss: 1.48891e-05\n",
      "[1395]\ttraining's binary_logloss: 1.48321e-05\n",
      "[1396]\ttraining's binary_logloss: 1.4779e-05\n",
      "[1397]\ttraining's binary_logloss: 1.47245e-05\n",
      "[1398]\ttraining's binary_logloss: 1.46761e-05\n",
      "[1399]\ttraining's binary_logloss: 1.46259e-05\n",
      "[1400]\ttraining's binary_logloss: 1.45793e-05\n",
      "[1401]\ttraining's binary_logloss: 1.45257e-05\n",
      "[1402]\ttraining's binary_logloss: 1.44805e-05\n",
      "[1403]\ttraining's binary_logloss: 1.44329e-05\n",
      "[1404]\ttraining's binary_logloss: 1.4388e-05\n",
      "[1405]\ttraining's binary_logloss: 1.43355e-05\n",
      "[1406]\ttraining's binary_logloss: 1.42881e-05\n",
      "[1407]\ttraining's binary_logloss: 1.42388e-05\n",
      "[1408]\ttraining's binary_logloss: 1.41909e-05\n",
      "[1409]\ttraining's binary_logloss: 1.41407e-05\n",
      "[1410]\ttraining's binary_logloss: 1.40901e-05\n",
      "[1411]\ttraining's binary_logloss: 1.4044e-05\n",
      "[1412]\ttraining's binary_logloss: 1.39983e-05\n",
      "[1413]\ttraining's binary_logloss: 1.39502e-05\n",
      "[1414]\ttraining's binary_logloss: 1.39024e-05\n",
      "[1415]\ttraining's binary_logloss: 1.38534e-05\n",
      "[1416]\ttraining's binary_logloss: 1.38029e-05\n",
      "[1417]\ttraining's binary_logloss: 1.37555e-05\n",
      "[1418]\ttraining's binary_logloss: 1.3713e-05\n",
      "[1419]\ttraining's binary_logloss: 1.36651e-05\n",
      "[1420]\ttraining's binary_logloss: 1.36224e-05\n",
      "[1421]\ttraining's binary_logloss: 1.35761e-05\n",
      "[1422]\ttraining's binary_logloss: 1.3531e-05\n",
      "[1423]\ttraining's binary_logloss: 1.34861e-05\n",
      "[1424]\ttraining's binary_logloss: 1.34398e-05\n",
      "[1425]\ttraining's binary_logloss: 1.33944e-05\n",
      "[1426]\ttraining's binary_logloss: 1.33511e-05\n",
      "[1427]\ttraining's binary_logloss: 1.33145e-05\n",
      "[1428]\ttraining's binary_logloss: 1.32737e-05\n",
      "[1429]\ttraining's binary_logloss: 1.32291e-05\n",
      "[1430]\ttraining's binary_logloss: 1.31843e-05\n",
      "[1431]\ttraining's binary_logloss: 1.31435e-05\n",
      "[1432]\ttraining's binary_logloss: 1.31031e-05\n",
      "[1433]\ttraining's binary_logloss: 1.30649e-05\n",
      "[1434]\ttraining's binary_logloss: 1.30255e-05\n",
      "[1435]\ttraining's binary_logloss: 1.29857e-05\n",
      "[1436]\ttraining's binary_logloss: 1.29426e-05\n",
      "[1437]\ttraining's binary_logloss: 1.29037e-05\n",
      "[1438]\ttraining's binary_logloss: 1.28671e-05\n",
      "[1439]\ttraining's binary_logloss: 1.28315e-05\n",
      "[1440]\ttraining's binary_logloss: 1.27924e-05\n",
      "[1441]\ttraining's binary_logloss: 1.27492e-05\n",
      "[1442]\ttraining's binary_logloss: 1.27086e-05\n",
      "[1443]\ttraining's binary_logloss: 1.2669e-05\n",
      "[1444]\ttraining's binary_logloss: 1.26303e-05\n",
      "[1445]\ttraining's binary_logloss: 1.25942e-05\n",
      "[1446]\ttraining's binary_logloss: 1.25575e-05\n",
      "[1447]\ttraining's binary_logloss: 1.25217e-05\n",
      "[1448]\ttraining's binary_logloss: 1.24827e-05\n",
      "[1449]\ttraining's binary_logloss: 1.24472e-05\n",
      "[1450]\ttraining's binary_logloss: 1.24043e-05\n",
      "[1451]\ttraining's binary_logloss: 1.23675e-05\n",
      "[1452]\ttraining's binary_logloss: 1.23307e-05\n",
      "[1453]\ttraining's binary_logloss: 1.22912e-05\n",
      "[1454]\ttraining's binary_logloss: 1.22494e-05\n",
      "[1455]\ttraining's binary_logloss: 1.22072e-05\n",
      "[1456]\ttraining's binary_logloss: 1.21707e-05\n",
      "[1457]\ttraining's binary_logloss: 1.21332e-05\n",
      "[1458]\ttraining's binary_logloss: 1.20931e-05\n",
      "[1459]\ttraining's binary_logloss: 1.20585e-05\n",
      "[1460]\ttraining's binary_logloss: 1.20199e-05\n",
      "[1461]\ttraining's binary_logloss: 1.1983e-05\n",
      "[1462]\ttraining's binary_logloss: 1.19463e-05\n",
      "[1463]\ttraining's binary_logloss: 1.19099e-05\n",
      "[1464]\ttraining's binary_logloss: 1.18742e-05\n",
      "[1465]\ttraining's binary_logloss: 1.18408e-05\n",
      "[1466]\ttraining's binary_logloss: 1.18044e-05\n",
      "[1467]\ttraining's binary_logloss: 1.17701e-05\n",
      "[1468]\ttraining's binary_logloss: 1.1734e-05\n",
      "[1469]\ttraining's binary_logloss: 1.16993e-05\n",
      "[1470]\ttraining's binary_logloss: 1.16653e-05\n",
      "[1471]\ttraining's binary_logloss: 1.16315e-05\n",
      "[1472]\ttraining's binary_logloss: 1.15981e-05\n",
      "[1473]\ttraining's binary_logloss: 1.15657e-05\n",
      "[1474]\ttraining's binary_logloss: 1.15332e-05\n",
      "[1475]\ttraining's binary_logloss: 1.15009e-05\n",
      "[1476]\ttraining's binary_logloss: 1.147e-05\n",
      "[1477]\ttraining's binary_logloss: 1.14349e-05\n",
      "[1478]\ttraining's binary_logloss: 1.14017e-05\n",
      "[1479]\ttraining's binary_logloss: 1.13664e-05\n",
      "[1480]\ttraining's binary_logloss: 1.13333e-05\n",
      "[1481]\ttraining's binary_logloss: 1.12997e-05\n",
      "[1482]\ttraining's binary_logloss: 1.12624e-05\n",
      "[1483]\ttraining's binary_logloss: 1.12303e-05\n",
      "[1484]\ttraining's binary_logloss: 1.11964e-05\n",
      "[1485]\ttraining's binary_logloss: 1.11645e-05\n",
      "[1486]\ttraining's binary_logloss: 1.11326e-05\n",
      "[1487]\ttraining's binary_logloss: 1.11021e-05\n",
      "[1488]\ttraining's binary_logloss: 1.10721e-05\n",
      "[1489]\ttraining's binary_logloss: 1.10407e-05\n",
      "[1490]\ttraining's binary_logloss: 1.1012e-05\n",
      "[1491]\ttraining's binary_logloss: 1.09824e-05\n",
      "[1492]\ttraining's binary_logloss: 1.09542e-05\n",
      "[1493]\ttraining's binary_logloss: 1.09251e-05\n",
      "[1494]\ttraining's binary_logloss: 1.08937e-05\n",
      "[1495]\ttraining's binary_logloss: 1.08635e-05\n",
      "[1496]\ttraining's binary_logloss: 1.08351e-05\n",
      "[1497]\ttraining's binary_logloss: 1.08041e-05\n",
      "[1498]\ttraining's binary_logloss: 1.0777e-05\n",
      "[1499]\ttraining's binary_logloss: 1.07495e-05\n",
      "[1500]\ttraining's binary_logloss: 1.07218e-05\n",
      "[1501]\ttraining's binary_logloss: 1.06933e-05\n",
      "[1502]\ttraining's binary_logloss: 1.06666e-05\n",
      "[1503]\ttraining's binary_logloss: 1.0641e-05\n",
      "[1504]\ttraining's binary_logloss: 1.06126e-05\n",
      "[1505]\ttraining's binary_logloss: 1.05858e-05\n",
      "[1506]\ttraining's binary_logloss: 1.05586e-05\n",
      "[1507]\ttraining's binary_logloss: 1.05323e-05\n",
      "[1508]\ttraining's binary_logloss: 1.05065e-05\n",
      "[1509]\ttraining's binary_logloss: 1.04786e-05\n",
      "[1510]\ttraining's binary_logloss: 1.04551e-05\n",
      "[1511]\ttraining's binary_logloss: 1.04279e-05\n",
      "[1512]\ttraining's binary_logloss: 1.04012e-05\n",
      "[1513]\ttraining's binary_logloss: 1.03738e-05\n",
      "[1514]\ttraining's binary_logloss: 1.0347e-05\n",
      "[1515]\ttraining's binary_logloss: 1.03201e-05\n",
      "[1516]\ttraining's binary_logloss: 1.02923e-05\n",
      "[1517]\ttraining's binary_logloss: 1.0265e-05\n",
      "[1518]\ttraining's binary_logloss: 1.02366e-05\n",
      "[1519]\ttraining's binary_logloss: 1.02108e-05\n",
      "[1520]\ttraining's binary_logloss: 1.01859e-05\n",
      "[1521]\ttraining's binary_logloss: 1.01615e-05\n",
      "[1522]\ttraining's binary_logloss: 1.01358e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1523]\ttraining's binary_logloss: 1.01089e-05\n",
      "[1524]\ttraining's binary_logloss: 1.00826e-05\n",
      "[1525]\ttraining's binary_logloss: 1.00551e-05\n",
      "[1526]\ttraining's binary_logloss: 1.0032e-05\n",
      "[1527]\ttraining's binary_logloss: 1.00089e-05\n",
      "[1528]\ttraining's binary_logloss: 9.98494e-06\n",
      "[1529]\ttraining's binary_logloss: 9.961e-06\n",
      "[1530]\ttraining's binary_logloss: 9.93624e-06\n",
      "[1531]\ttraining's binary_logloss: 9.91411e-06\n",
      "[1532]\ttraining's binary_logloss: 9.89048e-06\n",
      "[1533]\ttraining's binary_logloss: 9.86731e-06\n",
      "[1534]\ttraining's binary_logloss: 9.84421e-06\n",
      "[1535]\ttraining's binary_logloss: 9.82192e-06\n",
      "[1536]\ttraining's binary_logloss: 9.79646e-06\n",
      "[1537]\ttraining's binary_logloss: 9.77435e-06\n",
      "[1538]\ttraining's binary_logloss: 9.75123e-06\n",
      "[1539]\ttraining's binary_logloss: 9.72864e-06\n",
      "[1540]\ttraining's binary_logloss: 9.70609e-06\n",
      "[1541]\ttraining's binary_logloss: 9.68156e-06\n",
      "[1542]\ttraining's binary_logloss: 9.65961e-06\n",
      "[1543]\ttraining's binary_logloss: 9.63833e-06\n",
      "[1544]\ttraining's binary_logloss: 9.61808e-06\n",
      "[1545]\ttraining's binary_logloss: 9.59662e-06\n",
      "[1546]\ttraining's binary_logloss: 9.57293e-06\n",
      "[1547]\ttraining's binary_logloss: 9.5495e-06\n",
      "[1548]\ttraining's binary_logloss: 9.52765e-06\n",
      "[1549]\ttraining's binary_logloss: 9.50714e-06\n",
      "[1550]\ttraining's binary_logloss: 9.48744e-06\n",
      "[1551]\ttraining's binary_logloss: 9.46827e-06\n",
      "[1552]\ttraining's binary_logloss: 9.44662e-06\n",
      "[1553]\ttraining's binary_logloss: 9.42582e-06\n",
      "[1554]\ttraining's binary_logloss: 9.40259e-06\n",
      "[1555]\ttraining's binary_logloss: 9.38044e-06\n",
      "[1556]\ttraining's binary_logloss: 9.3574e-06\n",
      "[1557]\ttraining's binary_logloss: 9.33604e-06\n",
      "[1558]\ttraining's binary_logloss: 9.31287e-06\n",
      "[1559]\ttraining's binary_logloss: 9.29365e-06\n",
      "[1560]\ttraining's binary_logloss: 9.27472e-06\n",
      "[1561]\ttraining's binary_logloss: 9.2571e-06\n",
      "[1562]\ttraining's binary_logloss: 9.23868e-06\n",
      "[1563]\ttraining's binary_logloss: 9.2169e-06\n",
      "[1564]\ttraining's binary_logloss: 9.19652e-06\n",
      "[1565]\ttraining's binary_logloss: 9.17515e-06\n",
      "[1566]\ttraining's binary_logloss: 9.15703e-06\n",
      "[1567]\ttraining's binary_logloss: 9.13912e-06\n",
      "[1568]\ttraining's binary_logloss: 9.12025e-06\n",
      "[1569]\ttraining's binary_logloss: 9.10297e-06\n",
      "[1570]\ttraining's binary_logloss: 9.08436e-06\n",
      "[1571]\ttraining's binary_logloss: 9.0654e-06\n",
      "[1572]\ttraining's binary_logloss: 9.04566e-06\n",
      "[1573]\ttraining's binary_logloss: 9.02581e-06\n",
      "[1574]\ttraining's binary_logloss: 9.00657e-06\n",
      "[1575]\ttraining's binary_logloss: 8.98714e-06\n",
      "[1576]\ttraining's binary_logloss: 8.96817e-06\n",
      "[1577]\ttraining's binary_logloss: 8.94909e-06\n",
      "[1578]\ttraining's binary_logloss: 8.92942e-06\n",
      "[1579]\ttraining's binary_logloss: 8.90936e-06\n",
      "[1580]\ttraining's binary_logloss: 8.89107e-06\n",
      "[1581]\ttraining's binary_logloss: 8.87195e-06\n",
      "[1582]\ttraining's binary_logloss: 8.85173e-06\n",
      "[1583]\ttraining's binary_logloss: 8.83328e-06\n",
      "[1584]\ttraining's binary_logloss: 8.81421e-06\n",
      "[1585]\ttraining's binary_logloss: 8.79501e-06\n",
      "[1586]\ttraining's binary_logloss: 8.77643e-06\n",
      "[1587]\ttraining's binary_logloss: 8.75849e-06\n",
      "[1588]\ttraining's binary_logloss: 8.74042e-06\n",
      "[1589]\ttraining's binary_logloss: 8.72356e-06\n",
      "[1590]\ttraining's binary_logloss: 8.70341e-06\n",
      "[1591]\ttraining's binary_logloss: 8.68685e-06\n",
      "[1592]\ttraining's binary_logloss: 8.66925e-06\n",
      "[1593]\ttraining's binary_logloss: 8.65285e-06\n",
      "[1594]\ttraining's binary_logloss: 8.63464e-06\n",
      "[1595]\ttraining's binary_logloss: 8.61848e-06\n",
      "[1596]\ttraining's binary_logloss: 8.59951e-06\n",
      "[1597]\ttraining's binary_logloss: 8.58142e-06\n",
      "[1598]\ttraining's binary_logloss: 8.56457e-06\n",
      "[1599]\ttraining's binary_logloss: 8.54725e-06\n",
      "[1600]\ttraining's binary_logloss: 8.53093e-06\n",
      "[1601]\ttraining's binary_logloss: 8.5148e-06\n",
      "[1602]\ttraining's binary_logloss: 8.49755e-06\n",
      "[1603]\ttraining's binary_logloss: 8.48037e-06\n",
      "[1604]\ttraining's binary_logloss: 8.46246e-06\n",
      "[1605]\ttraining's binary_logloss: 8.44324e-06\n",
      "[1606]\ttraining's binary_logloss: 8.42817e-06\n",
      "[1607]\ttraining's binary_logloss: 8.41263e-06\n",
      "[1608]\ttraining's binary_logloss: 8.39621e-06\n",
      "[1609]\ttraining's binary_logloss: 8.37881e-06\n",
      "[1610]\ttraining's binary_logloss: 8.3642e-06\n",
      "[1611]\ttraining's binary_logloss: 8.34741e-06\n",
      "[1612]\ttraining's binary_logloss: 8.33129e-06\n",
      "[1613]\ttraining's binary_logloss: 8.31666e-06\n",
      "[1614]\ttraining's binary_logloss: 8.29986e-06\n",
      "[1615]\ttraining's binary_logloss: 8.28339e-06\n",
      "[1616]\ttraining's binary_logloss: 8.2688e-06\n",
      "[1617]\ttraining's binary_logloss: 8.25168e-06\n",
      "[1618]\ttraining's binary_logloss: 8.23588e-06\n",
      "[1619]\ttraining's binary_logloss: 8.21992e-06\n",
      "[1620]\ttraining's binary_logloss: 8.20301e-06\n",
      "[1621]\ttraining's binary_logloss: 8.18708e-06\n",
      "[1622]\ttraining's binary_logloss: 8.17177e-06\n",
      "[1623]\ttraining's binary_logloss: 8.15503e-06\n",
      "[1624]\ttraining's binary_logloss: 8.13854e-06\n",
      "[1625]\ttraining's binary_logloss: 8.12256e-06\n",
      "[1626]\ttraining's binary_logloss: 8.1072e-06\n",
      "[1627]\ttraining's binary_logloss: 8.09416e-06\n",
      "[1628]\ttraining's binary_logloss: 8.07898e-06\n",
      "[1629]\ttraining's binary_logloss: 8.06525e-06\n",
      "[1630]\ttraining's binary_logloss: 8.05051e-06\n",
      "[1631]\ttraining's binary_logloss: 8.03322e-06\n",
      "[1632]\ttraining's binary_logloss: 8.01646e-06\n",
      "[1633]\ttraining's binary_logloss: 8.00107e-06\n",
      "[1634]\ttraining's binary_logloss: 7.98582e-06\n",
      "[1635]\ttraining's binary_logloss: 7.9719e-06\n",
      "[1636]\ttraining's binary_logloss: 7.95781e-06\n",
      "[1637]\ttraining's binary_logloss: 7.94379e-06\n",
      "[1638]\ttraining's binary_logloss: 7.92873e-06\n",
      "[1639]\ttraining's binary_logloss: 7.91572e-06\n",
      "[1640]\ttraining's binary_logloss: 7.90109e-06\n",
      "[1641]\ttraining's binary_logloss: 7.88629e-06\n",
      "[1642]\ttraining's binary_logloss: 7.8723e-06\n",
      "[1643]\ttraining's binary_logloss: 7.85922e-06\n",
      "[1644]\ttraining's binary_logloss: 7.8444e-06\n",
      "[1645]\ttraining's binary_logloss: 7.83017e-06\n",
      "[1646]\ttraining's binary_logloss: 7.81588e-06\n",
      "[1647]\ttraining's binary_logloss: 7.80182e-06\n",
      "[1648]\ttraining's binary_logloss: 7.78755e-06\n",
      "[1649]\ttraining's binary_logloss: 7.77367e-06\n",
      "[1650]\ttraining's binary_logloss: 7.75826e-06\n",
      "[1651]\ttraining's binary_logloss: 7.74267e-06\n",
      "[1652]\ttraining's binary_logloss: 7.72907e-06\n",
      "[1653]\ttraining's binary_logloss: 7.71523e-06\n",
      "[1654]\ttraining's binary_logloss: 7.7011e-06\n",
      "[1655]\ttraining's binary_logloss: 7.68684e-06\n",
      "[1656]\ttraining's binary_logloss: 7.67276e-06\n",
      "[1657]\ttraining's binary_logloss: 7.65796e-06\n",
      "[1658]\ttraining's binary_logloss: 7.644e-06\n",
      "[1659]\ttraining's binary_logloss: 7.63152e-06\n",
      "[1660]\ttraining's binary_logloss: 7.61918e-06\n",
      "[1661]\ttraining's binary_logloss: 7.60553e-06\n",
      "[1662]\ttraining's binary_logloss: 7.59404e-06\n",
      "[1663]\ttraining's binary_logloss: 7.58126e-06\n",
      "[1664]\ttraining's binary_logloss: 7.56798e-06\n",
      "[1665]\ttraining's binary_logloss: 7.55492e-06\n",
      "[1666]\ttraining's binary_logloss: 7.54147e-06\n",
      "[1667]\ttraining's binary_logloss: 7.52778e-06\n",
      "[1668]\ttraining's binary_logloss: 7.51541e-06\n",
      "[1669]\ttraining's binary_logloss: 7.50255e-06\n",
      "[1670]\ttraining's binary_logloss: 7.48862e-06\n",
      "[1671]\ttraining's binary_logloss: 7.47625e-06\n",
      "[1672]\ttraining's binary_logloss: 7.46257e-06\n",
      "[1673]\ttraining's binary_logloss: 7.45062e-06\n",
      "[1674]\ttraining's binary_logloss: 7.43809e-06\n",
      "[1675]\ttraining's binary_logloss: 7.42562e-06\n",
      "[1676]\ttraining's binary_logloss: 7.41285e-06\n",
      "[1677]\ttraining's binary_logloss: 7.40046e-06\n",
      "[1678]\ttraining's binary_logloss: 7.38678e-06\n",
      "[1679]\ttraining's binary_logloss: 7.37308e-06\n",
      "[1680]\ttraining's binary_logloss: 7.36098e-06\n",
      "[1681]\ttraining's binary_logloss: 7.34919e-06\n",
      "[1682]\ttraining's binary_logloss: 7.33698e-06\n",
      "[1683]\ttraining's binary_logloss: 7.32545e-06\n",
      "[1684]\ttraining's binary_logloss: 7.31138e-06\n",
      "[1685]\ttraining's binary_logloss: 7.29892e-06\n",
      "[1686]\ttraining's binary_logloss: 7.28662e-06\n",
      "[1687]\ttraining's binary_logloss: 7.27482e-06\n",
      "[1688]\ttraining's binary_logloss: 7.2615e-06\n",
      "[1689]\ttraining's binary_logloss: 7.25017e-06\n",
      "[1690]\ttraining's binary_logloss: 7.23756e-06\n",
      "[1691]\ttraining's binary_logloss: 7.22688e-06\n",
      "[1692]\ttraining's binary_logloss: 7.21594e-06\n",
      "[1693]\ttraining's binary_logloss: 7.20541e-06\n",
      "[1694]\ttraining's binary_logloss: 7.19251e-06\n",
      "[1695]\ttraining's binary_logloss: 7.18094e-06\n",
      "[1696]\ttraining's binary_logloss: 7.16984e-06\n",
      "[1697]\ttraining's binary_logloss: 7.15763e-06\n",
      "[1698]\ttraining's binary_logloss: 7.14585e-06\n",
      "[1699]\ttraining's binary_logloss: 7.13356e-06\n",
      "[1700]\ttraining's binary_logloss: 7.12143e-06\n",
      "[1701]\ttraining's binary_logloss: 7.10916e-06\n",
      "[1702]\ttraining's binary_logloss: 7.09756e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1703]\ttraining's binary_logloss: 7.0865e-06\n",
      "[1704]\ttraining's binary_logloss: 7.07601e-06\n",
      "[1705]\ttraining's binary_logloss: 7.06373e-06\n",
      "[1706]\ttraining's binary_logloss: 7.05289e-06\n",
      "[1707]\ttraining's binary_logloss: 7.04251e-06\n",
      "[1708]\ttraining's binary_logloss: 7.03189e-06\n",
      "[1709]\ttraining's binary_logloss: 7.02024e-06\n",
      "[1710]\ttraining's binary_logloss: 7.00908e-06\n",
      "[1711]\ttraining's binary_logloss: 6.99807e-06\n",
      "[1712]\ttraining's binary_logloss: 6.98759e-06\n",
      "[1713]\ttraining's binary_logloss: 6.97678e-06\n",
      "[1714]\ttraining's binary_logloss: 6.96561e-06\n",
      "[1715]\ttraining's binary_logloss: 6.95475e-06\n",
      "[1716]\ttraining's binary_logloss: 6.94468e-06\n",
      "[1717]\ttraining's binary_logloss: 6.93301e-06\n",
      "[1718]\ttraining's binary_logloss: 6.92261e-06\n",
      "[1719]\ttraining's binary_logloss: 6.91172e-06\n",
      "[1720]\ttraining's binary_logloss: 6.90023e-06\n",
      "[1721]\ttraining's binary_logloss: 6.8906e-06\n",
      "[1722]\ttraining's binary_logloss: 6.88054e-06\n",
      "[1723]\ttraining's binary_logloss: 6.8698e-06\n",
      "[1724]\ttraining's binary_logloss: 6.85886e-06\n",
      "[1725]\ttraining's binary_logloss: 6.84741e-06\n",
      "[1726]\ttraining's binary_logloss: 6.83575e-06\n",
      "[1727]\ttraining's binary_logloss: 6.82454e-06\n",
      "[1728]\ttraining's binary_logloss: 6.8146e-06\n",
      "[1729]\ttraining's binary_logloss: 6.80454e-06\n",
      "[1730]\ttraining's binary_logloss: 6.79422e-06\n",
      "[1731]\ttraining's binary_logloss: 6.78403e-06\n",
      "[1732]\ttraining's binary_logloss: 6.77386e-06\n",
      "[1733]\ttraining's binary_logloss: 6.76284e-06\n",
      "[1734]\ttraining's binary_logloss: 6.75246e-06\n",
      "[1735]\ttraining's binary_logloss: 6.74308e-06\n",
      "[1736]\ttraining's binary_logloss: 6.73361e-06\n",
      "[1737]\ttraining's binary_logloss: 6.7242e-06\n",
      "[1738]\ttraining's binary_logloss: 6.71368e-06\n",
      "[1739]\ttraining's binary_logloss: 6.70389e-06\n",
      "[1740]\ttraining's binary_logloss: 6.69408e-06\n",
      "[1741]\ttraining's binary_logloss: 6.68482e-06\n",
      "[1742]\ttraining's binary_logloss: 6.67537e-06\n",
      "[1743]\ttraining's binary_logloss: 6.66578e-06\n",
      "[1744]\ttraining's binary_logloss: 6.65654e-06\n",
      "[1745]\ttraining's binary_logloss: 6.64629e-06\n",
      "[1746]\ttraining's binary_logloss: 6.638e-06\n",
      "[1747]\ttraining's binary_logloss: 6.62828e-06\n",
      "[1748]\ttraining's binary_logloss: 6.61887e-06\n",
      "[1749]\ttraining's binary_logloss: 6.60843e-06\n",
      "[1750]\ttraining's binary_logloss: 6.59889e-06\n",
      "[1751]\ttraining's binary_logloss: 6.58881e-06\n",
      "[1752]\ttraining's binary_logloss: 6.57878e-06\n",
      "[1753]\ttraining's binary_logloss: 6.5688e-06\n",
      "[1754]\ttraining's binary_logloss: 6.55866e-06\n",
      "[1755]\ttraining's binary_logloss: 6.54962e-06\n",
      "[1756]\ttraining's binary_logloss: 6.53998e-06\n",
      "[1757]\ttraining's binary_logloss: 6.52985e-06\n",
      "[1758]\ttraining's binary_logloss: 6.52068e-06\n",
      "[1759]\ttraining's binary_logloss: 6.51152e-06\n",
      "[1760]\ttraining's binary_logloss: 6.503e-06\n",
      "[1761]\ttraining's binary_logloss: 6.49335e-06\n",
      "[1762]\ttraining's binary_logloss: 6.48393e-06\n",
      "[1763]\ttraining's binary_logloss: 6.4747e-06\n",
      "[1764]\ttraining's binary_logloss: 6.46505e-06\n",
      "[1765]\ttraining's binary_logloss: 6.45512e-06\n",
      "[1766]\ttraining's binary_logloss: 6.44587e-06\n",
      "[1767]\ttraining's binary_logloss: 6.43646e-06\n",
      "[1768]\ttraining's binary_logloss: 6.42635e-06\n",
      "[1769]\ttraining's binary_logloss: 6.41704e-06\n",
      "[1770]\ttraining's binary_logloss: 6.40702e-06\n",
      "[1771]\ttraining's binary_logloss: 6.39819e-06\n",
      "[1772]\ttraining's binary_logloss: 6.38944e-06\n",
      "[1773]\ttraining's binary_logloss: 6.38073e-06\n",
      "[1774]\ttraining's binary_logloss: 6.37071e-06\n",
      "[1775]\ttraining's binary_logloss: 6.36173e-06\n",
      "[1776]\ttraining's binary_logloss: 6.35259e-06\n",
      "[1777]\ttraining's binary_logloss: 6.34316e-06\n",
      "[1778]\ttraining's binary_logloss: 6.33327e-06\n",
      "[1779]\ttraining's binary_logloss: 6.32398e-06\n",
      "[1780]\ttraining's binary_logloss: 6.31455e-06\n",
      "[1781]\ttraining's binary_logloss: 6.30545e-06\n",
      "[1782]\ttraining's binary_logloss: 6.29622e-06\n",
      "[1783]\ttraining's binary_logloss: 6.28821e-06\n",
      "[1784]\ttraining's binary_logloss: 6.28006e-06\n",
      "[1785]\ttraining's binary_logloss: 6.27058e-06\n",
      "[1786]\ttraining's binary_logloss: 6.26233e-06\n",
      "[1787]\ttraining's binary_logloss: 6.25469e-06\n",
      "[1788]\ttraining's binary_logloss: 6.24597e-06\n",
      "[1789]\ttraining's binary_logloss: 6.23619e-06\n",
      "[1790]\ttraining's binary_logloss: 6.22863e-06\n",
      "[1791]\ttraining's binary_logloss: 6.22071e-06\n",
      "[1792]\ttraining's binary_logloss: 6.21224e-06\n",
      "[1793]\ttraining's binary_logloss: 6.20312e-06\n",
      "[1794]\ttraining's binary_logloss: 6.19469e-06\n",
      "[1795]\ttraining's binary_logloss: 6.18594e-06\n",
      "[1796]\ttraining's binary_logloss: 6.17836e-06\n",
      "[1797]\ttraining's binary_logloss: 6.16908e-06\n",
      "[1798]\ttraining's binary_logloss: 6.16211e-06\n",
      "[1799]\ttraining's binary_logloss: 6.15432e-06\n",
      "[1800]\ttraining's binary_logloss: 6.14582e-06\n",
      "[1801]\ttraining's binary_logloss: 6.13757e-06\n",
      "[1802]\ttraining's binary_logloss: 6.12916e-06\n",
      "[1803]\ttraining's binary_logloss: 6.12135e-06\n",
      "[1804]\ttraining's binary_logloss: 6.11381e-06\n",
      "[1805]\ttraining's binary_logloss: 6.10483e-06\n",
      "[1806]\ttraining's binary_logloss: 6.09708e-06\n",
      "[1807]\ttraining's binary_logloss: 6.0887e-06\n",
      "[1808]\ttraining's binary_logloss: 6.08122e-06\n",
      "[1809]\ttraining's binary_logloss: 6.07299e-06\n",
      "[1810]\ttraining's binary_logloss: 6.06526e-06\n",
      "[1811]\ttraining's binary_logloss: 6.05724e-06\n",
      "[1812]\ttraining's binary_logloss: 6.04951e-06\n",
      "[1813]\ttraining's binary_logloss: 6.04165e-06\n",
      "[1814]\ttraining's binary_logloss: 6.03403e-06\n",
      "[1815]\ttraining's binary_logloss: 6.02648e-06\n",
      "[1816]\ttraining's binary_logloss: 6.01869e-06\n",
      "[1817]\ttraining's binary_logloss: 6.01148e-06\n",
      "[1818]\ttraining's binary_logloss: 6.0038e-06\n",
      "[1819]\ttraining's binary_logloss: 5.99748e-06\n",
      "[1820]\ttraining's binary_logloss: 5.98949e-06\n",
      "[1821]\ttraining's binary_logloss: 5.98137e-06\n",
      "[1822]\ttraining's binary_logloss: 5.97379e-06\n",
      "[1823]\ttraining's binary_logloss: 5.96659e-06\n",
      "[1824]\ttraining's binary_logloss: 5.95916e-06\n",
      "[1825]\ttraining's binary_logloss: 5.95171e-06\n",
      "[1826]\ttraining's binary_logloss: 5.94384e-06\n",
      "[1827]\ttraining's binary_logloss: 5.93598e-06\n",
      "[1828]\ttraining's binary_logloss: 5.92839e-06\n",
      "[1829]\ttraining's binary_logloss: 5.9204e-06\n",
      "[1830]\ttraining's binary_logloss: 5.91266e-06\n",
      "[1831]\ttraining's binary_logloss: 5.9055e-06\n",
      "[1832]\ttraining's binary_logloss: 5.898e-06\n",
      "[1833]\ttraining's binary_logloss: 5.88979e-06\n",
      "[1834]\ttraining's binary_logloss: 5.88177e-06\n",
      "[1835]\ttraining's binary_logloss: 5.87418e-06\n",
      "[1836]\ttraining's binary_logloss: 5.86667e-06\n",
      "[1837]\ttraining's binary_logloss: 5.85835e-06\n",
      "[1838]\ttraining's binary_logloss: 5.85056e-06\n",
      "[1839]\ttraining's binary_logloss: 5.84375e-06\n",
      "[1840]\ttraining's binary_logloss: 5.83696e-06\n",
      "[1841]\ttraining's binary_logloss: 5.82892e-06\n",
      "[1842]\ttraining's binary_logloss: 5.82128e-06\n",
      "[1843]\ttraining's binary_logloss: 5.81338e-06\n",
      "[1844]\ttraining's binary_logloss: 5.80591e-06\n",
      "[1845]\ttraining's binary_logloss: 5.7984e-06\n",
      "[1846]\ttraining's binary_logloss: 5.79109e-06\n",
      "[1847]\ttraining's binary_logloss: 5.78436e-06\n",
      "[1848]\ttraining's binary_logloss: 5.77714e-06\n",
      "[1849]\ttraining's binary_logloss: 5.77076e-06\n",
      "[1850]\ttraining's binary_logloss: 5.76374e-06\n",
      "[1851]\ttraining's binary_logloss: 5.7564e-06\n",
      "[1852]\ttraining's binary_logloss: 5.74997e-06\n",
      "[1853]\ttraining's binary_logloss: 5.74345e-06\n",
      "[1854]\ttraining's binary_logloss: 5.73751e-06\n",
      "[1855]\ttraining's binary_logloss: 5.72982e-06\n",
      "[1856]\ttraining's binary_logloss: 5.72254e-06\n",
      "[1857]\ttraining's binary_logloss: 5.71612e-06\n",
      "[1858]\ttraining's binary_logloss: 5.70851e-06\n",
      "[1859]\ttraining's binary_logloss: 5.70109e-06\n",
      "[1860]\ttraining's binary_logloss: 5.69381e-06\n",
      "[1861]\ttraining's binary_logloss: 5.68674e-06\n",
      "[1862]\ttraining's binary_logloss: 5.68029e-06\n",
      "[1863]\ttraining's binary_logloss: 5.67409e-06\n",
      "[1864]\ttraining's binary_logloss: 5.66721e-06\n",
      "[1865]\ttraining's binary_logloss: 5.66045e-06\n",
      "[1866]\ttraining's binary_logloss: 5.65272e-06\n",
      "[1867]\ttraining's binary_logloss: 5.64559e-06\n",
      "[1868]\ttraining's binary_logloss: 5.63835e-06\n",
      "[1869]\ttraining's binary_logloss: 5.6316e-06\n",
      "[1870]\ttraining's binary_logloss: 5.62524e-06\n",
      "[1871]\ttraining's binary_logloss: 5.61919e-06\n",
      "[1872]\ttraining's binary_logloss: 5.61278e-06\n",
      "[1873]\ttraining's binary_logloss: 5.60641e-06\n",
      "[1874]\ttraining's binary_logloss: 5.60006e-06\n",
      "[1875]\ttraining's binary_logloss: 5.59301e-06\n",
      "[1876]\ttraining's binary_logloss: 5.58651e-06\n",
      "[1877]\ttraining's binary_logloss: 5.57962e-06\n",
      "[1878]\ttraining's binary_logloss: 5.57232e-06\n",
      "[1879]\ttraining's binary_logloss: 5.56543e-06\n",
      "[1880]\ttraining's binary_logloss: 5.5586e-06\n",
      "[1881]\ttraining's binary_logloss: 5.55192e-06\n",
      "[1882]\ttraining's binary_logloss: 5.54491e-06\n",
      "[1883]\ttraining's binary_logloss: 5.53811e-06\n",
      "[1884]\ttraining's binary_logloss: 5.53191e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1885]\ttraining's binary_logloss: 5.52485e-06\n",
      "[1886]\ttraining's binary_logloss: 5.51804e-06\n",
      "[1887]\ttraining's binary_logloss: 5.51168e-06\n",
      "[1888]\ttraining's binary_logloss: 5.50587e-06\n",
      "[1889]\ttraining's binary_logloss: 5.49901e-06\n",
      "[1890]\ttraining's binary_logloss: 5.49267e-06\n",
      "[1891]\ttraining's binary_logloss: 5.48657e-06\n",
      "[1892]\ttraining's binary_logloss: 5.47892e-06\n",
      "[1893]\ttraining's binary_logloss: 5.47216e-06\n",
      "[1894]\ttraining's binary_logloss: 5.466e-06\n",
      "[1895]\ttraining's binary_logloss: 5.4598e-06\n",
      "[1896]\ttraining's binary_logloss: 5.45356e-06\n",
      "[1897]\ttraining's binary_logloss: 5.44636e-06\n",
      "[1898]\ttraining's binary_logloss: 5.43952e-06\n",
      "[1899]\ttraining's binary_logloss: 5.43297e-06\n",
      "[1900]\ttraining's binary_logloss: 5.42741e-06\n",
      "[1901]\ttraining's binary_logloss: 5.42125e-06\n",
      "[1902]\ttraining's binary_logloss: 5.4146e-06\n",
      "[1903]\ttraining's binary_logloss: 5.40882e-06\n",
      "[1904]\ttraining's binary_logloss: 5.40225e-06\n",
      "[1905]\ttraining's binary_logloss: 5.39626e-06\n",
      "[1906]\ttraining's binary_logloss: 5.39025e-06\n",
      "[1907]\ttraining's binary_logloss: 5.38434e-06\n",
      "[1908]\ttraining's binary_logloss: 5.37813e-06\n",
      "[1909]\ttraining's binary_logloss: 5.37191e-06\n",
      "[1910]\ttraining's binary_logloss: 5.36511e-06\n",
      "[1911]\ttraining's binary_logloss: 5.35761e-06\n",
      "[1912]\ttraining's binary_logloss: 5.35133e-06\n",
      "[1913]\ttraining's binary_logloss: 5.34519e-06\n",
      "[1914]\ttraining's binary_logloss: 5.33917e-06\n",
      "[1915]\ttraining's binary_logloss: 5.33341e-06\n",
      "[1916]\ttraining's binary_logloss: 5.32793e-06\n",
      "[1917]\ttraining's binary_logloss: 5.32176e-06\n",
      "[1918]\ttraining's binary_logloss: 5.31614e-06\n",
      "[1919]\ttraining's binary_logloss: 5.30983e-06\n",
      "[1920]\ttraining's binary_logloss: 5.30381e-06\n",
      "[1921]\ttraining's binary_logloss: 5.29804e-06\n",
      "[1922]\ttraining's binary_logloss: 5.29266e-06\n",
      "[1923]\ttraining's binary_logloss: 5.28709e-06\n",
      "[1924]\ttraining's binary_logloss: 5.28136e-06\n",
      "[1925]\ttraining's binary_logloss: 5.27549e-06\n",
      "[1926]\ttraining's binary_logloss: 5.26938e-06\n",
      "[1927]\ttraining's binary_logloss: 5.26373e-06\n",
      "[1928]\ttraining's binary_logloss: 5.25777e-06\n",
      "[1929]\ttraining's binary_logloss: 5.25205e-06\n",
      "[1930]\ttraining's binary_logloss: 5.24599e-06\n",
      "[1931]\ttraining's binary_logloss: 5.24066e-06\n",
      "[1932]\ttraining's binary_logloss: 5.23468e-06\n",
      "[1933]\ttraining's binary_logloss: 5.22822e-06\n",
      "[1934]\ttraining's binary_logloss: 5.2224e-06\n",
      "[1935]\ttraining's binary_logloss: 5.21638e-06\n",
      "[1936]\ttraining's binary_logloss: 5.21085e-06\n",
      "[1937]\ttraining's binary_logloss: 5.20547e-06\n",
      "[1938]\ttraining's binary_logloss: 5.19981e-06\n",
      "[1939]\ttraining's binary_logloss: 5.19434e-06\n",
      "[1940]\ttraining's binary_logloss: 5.18847e-06\n",
      "[1941]\ttraining's binary_logloss: 5.18245e-06\n",
      "[1942]\ttraining's binary_logloss: 5.17639e-06\n",
      "[1943]\ttraining's binary_logloss: 5.1712e-06\n",
      "[1944]\ttraining's binary_logloss: 5.16446e-06\n",
      "[1945]\ttraining's binary_logloss: 5.15829e-06\n",
      "[1946]\ttraining's binary_logloss: 5.15281e-06\n",
      "[1947]\ttraining's binary_logloss: 5.14727e-06\n",
      "[1948]\ttraining's binary_logloss: 5.1425e-06\n",
      "[1949]\ttraining's binary_logloss: 5.13792e-06\n",
      "[1950]\ttraining's binary_logloss: 5.13326e-06\n",
      "[1951]\ttraining's binary_logloss: 5.12788e-06\n",
      "[1952]\ttraining's binary_logloss: 5.12316e-06\n",
      "[1953]\ttraining's binary_logloss: 5.11806e-06\n",
      "[1954]\ttraining's binary_logloss: 5.11309e-06\n",
      "[1955]\ttraining's binary_logloss: 5.10749e-06\n",
      "[1956]\ttraining's binary_logloss: 5.10194e-06\n",
      "[1957]\ttraining's binary_logloss: 5.09701e-06\n",
      "[1958]\ttraining's binary_logloss: 5.09173e-06\n",
      "[1959]\ttraining's binary_logloss: 5.08641e-06\n",
      "[1960]\ttraining's binary_logloss: 5.0806e-06\n",
      "[1961]\ttraining's binary_logloss: 5.07532e-06\n",
      "[1962]\ttraining's binary_logloss: 5.06982e-06\n",
      "[1963]\ttraining's binary_logloss: 5.06381e-06\n",
      "[1964]\ttraining's binary_logloss: 5.05772e-06\n",
      "[1965]\ttraining's binary_logloss: 5.05202e-06\n",
      "[1966]\ttraining's binary_logloss: 5.04662e-06\n",
      "[1967]\ttraining's binary_logloss: 5.04113e-06\n",
      "[1968]\ttraining's binary_logloss: 5.03587e-06\n",
      "[1969]\ttraining's binary_logloss: 5.03049e-06\n",
      "[1970]\ttraining's binary_logloss: 5.02537e-06\n",
      "[1971]\ttraining's binary_logloss: 5.01967e-06\n",
      "[1972]\ttraining's binary_logloss: 5.01496e-06\n",
      "[1973]\ttraining's binary_logloss: 5.00959e-06\n",
      "[1974]\ttraining's binary_logloss: 5.00479e-06\n",
      "[1975]\ttraining's binary_logloss: 4.99947e-06\n",
      "[1976]\ttraining's binary_logloss: 4.99412e-06\n",
      "[1977]\ttraining's binary_logloss: 4.98893e-06\n",
      "[1978]\ttraining's binary_logloss: 4.98344e-06\n",
      "[1979]\ttraining's binary_logloss: 4.97827e-06\n",
      "[1980]\ttraining's binary_logloss: 4.9735e-06\n",
      "[1981]\ttraining's binary_logloss: 4.96911e-06\n",
      "[1982]\ttraining's binary_logloss: 4.964e-06\n",
      "[1983]\ttraining's binary_logloss: 4.95876e-06\n",
      "[1984]\ttraining's binary_logloss: 4.95298e-06\n",
      "[1985]\ttraining's binary_logloss: 4.94838e-06\n",
      "[1986]\ttraining's binary_logloss: 4.94294e-06\n",
      "[1987]\ttraining's binary_logloss: 4.93774e-06\n",
      "[1988]\ttraining's binary_logloss: 4.93282e-06\n",
      "[1989]\ttraining's binary_logloss: 4.92834e-06\n",
      "[1990]\ttraining's binary_logloss: 4.92286e-06\n",
      "[1991]\ttraining's binary_logloss: 4.91781e-06\n",
      "[1992]\ttraining's binary_logloss: 4.91314e-06\n",
      "[1993]\ttraining's binary_logloss: 4.90819e-06\n",
      "[1994]\ttraining's binary_logloss: 4.90324e-06\n",
      "[1995]\ttraining's binary_logloss: 4.89736e-06\n",
      "[1996]\ttraining's binary_logloss: 4.89241e-06\n",
      "[1997]\ttraining's binary_logloss: 4.88727e-06\n",
      "[1998]\ttraining's binary_logloss: 4.88254e-06\n",
      "[1999]\ttraining's binary_logloss: 4.87814e-06\n",
      "[2000]\ttraining's binary_logloss: 4.87306e-06\n"
     ]
    }
   ],
   "source": [
    "# deploy model\n",
    "lgtrain = lgb.Dataset(X_res, y_res)\n",
    "\n",
    "final_lgb = lgb.train(\n",
    "    lgbm_params,\n",
    "    lgtrain,\n",
    "    valid_sets=lgtrain,\n",
    "    num_boost_round=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the final model to the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "preprocess = DataPreprocess(label_encoder)\n",
    "processed_payment_test = preprocess.preprocess_payment(payment_test)\n",
    "billing_test = preprocess.initialize_billing(billing_test)\n",
    "processed_billing_test = preprocess.preprocess_billing(billing_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test = preprocess.merge(processed_payment_test, processed_billing_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in transaction_col:\n",
    "    replace_value = processed_test[processed_test[col].notna()][col].mean()\n",
    "    processed_test[col] = processed_test[col].fillna(replace_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test = processed_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_01_month</th>\n",
       "      <th>transaction_02_month</th>\n",
       "      <th>transaction_03_month</th>\n",
       "      <th>transaction_04_month</th>\n",
       "      <th>transaction_05_month</th>\n",
       "      <th>transaction_06_month</th>\n",
       "      <th>transaction_07_month</th>\n",
       "      <th>transaction_08_month</th>\n",
       "      <th>transaction_09_month</th>\n",
       "      <th>transaction_10_month</th>\n",
       "      <th>...</th>\n",
       "      <th>cash_balance_06_month</th>\n",
       "      <th>cash_balance_07_month</th>\n",
       "      <th>cash_balance_08_month</th>\n",
       "      <th>cash_balance_09_month</th>\n",
       "      <th>cash_balance_10_month</th>\n",
       "      <th>cash_balance_11_month</th>\n",
       "      <th>cash_balance_12_month</th>\n",
       "      <th>MaxDelqCycle</th>\n",
       "      <th>AvgDelqCycle</th>\n",
       "      <th>LateCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10074849</th>\n",
       "      <td>411.00</td>\n",
       "      <td>340.26</td>\n",
       "      <td>993.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>906.38</td>\n",
       "      <td>363.00</td>\n",
       "      <td>915.54</td>\n",
       "      <td>609.50</td>\n",
       "      <td>626.85</td>\n",
       "      <td>396.93</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10086539</th>\n",
       "      <td>0.00</td>\n",
       "      <td>556.92</td>\n",
       "      <td>832.00</td>\n",
       "      <td>642.0</td>\n",
       "      <td>661.26</td>\n",
       "      <td>1880.00</td>\n",
       "      <td>950.86</td>\n",
       "      <td>1591.00</td>\n",
       "      <td>1048.60</td>\n",
       "      <td>500.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10140908</th>\n",
       "      <td>214.10</td>\n",
       "      <td>88.36</td>\n",
       "      <td>200.00</td>\n",
       "      <td>206.0</td>\n",
       "      <td>239.99</td>\n",
       "      <td>160.50</td>\n",
       "      <td>418.00</td>\n",
       "      <td>428.72</td>\n",
       "      <td>202.00</td>\n",
       "      <td>163.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10147994</th>\n",
       "      <td>38.11</td>\n",
       "      <td>39.52</td>\n",
       "      <td>218.40</td>\n",
       "      <td>227.9</td>\n",
       "      <td>224.70</td>\n",
       "      <td>229.69</td>\n",
       "      <td>226.00</td>\n",
       "      <td>504.29</td>\n",
       "      <td>4.24</td>\n",
       "      <td>256.20</td>\n",
       "      <td>...</td>\n",
       "      <td>17.85</td>\n",
       "      <td>55.12</td>\n",
       "      <td>28.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10152808</th>\n",
       "      <td>420.00</td>\n",
       "      <td>1030.00</td>\n",
       "      <td>510.00</td>\n",
       "      <td>423.3</td>\n",
       "      <td>877.50</td>\n",
       "      <td>1157.44</td>\n",
       "      <td>709.00</td>\n",
       "      <td>995.00</td>\n",
       "      <td>1015.00</td>\n",
       "      <td>515.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          transaction_01_month  transaction_02_month  transaction_03_month  \\\n",
       "ID_CPTE                                                                      \n",
       "10074849                411.00                340.26                993.92   \n",
       "10086539                  0.00                556.92                832.00   \n",
       "10140908                214.10                 88.36                200.00   \n",
       "10147994                 38.11                 39.52                218.40   \n",
       "10152808                420.00               1030.00                510.00   \n",
       "\n",
       "          transaction_04_month  transaction_05_month  transaction_06_month  \\\n",
       "ID_CPTE                                                                      \n",
       "10074849                   0.0                906.38                363.00   \n",
       "10086539                 642.0                661.26               1880.00   \n",
       "10140908                 206.0                239.99                160.50   \n",
       "10147994                 227.9                224.70                229.69   \n",
       "10152808                 423.3                877.50               1157.44   \n",
       "\n",
       "          transaction_07_month  transaction_08_month  transaction_09_month  \\\n",
       "ID_CPTE                                                                      \n",
       "10074849                915.54                609.50                626.85   \n",
       "10086539                950.86               1591.00               1048.60   \n",
       "10140908                418.00                428.72                202.00   \n",
       "10147994                226.00                504.29                  4.24   \n",
       "10152808                709.00                995.00               1015.00   \n",
       "\n",
       "          transaction_10_month    ...      cash_balance_06_month  \\\n",
       "ID_CPTE                           ...                              \n",
       "10074849                396.93    ...                       0.00   \n",
       "10086539                500.00    ...                       0.00   \n",
       "10140908                163.20    ...                       1.03   \n",
       "10147994                256.20    ...                      17.85   \n",
       "10152808                515.00    ...                       0.00   \n",
       "\n",
       "          cash_balance_07_month  cash_balance_08_month  cash_balance_09_month  \\\n",
       "ID_CPTE                                                                         \n",
       "10074849                   0.00                   0.00                    0.0   \n",
       "10086539                   0.00                   0.00                    0.0   \n",
       "10140908                   0.00                   0.00                    0.0   \n",
       "10147994                  55.12                  28.35                    0.0   \n",
       "10152808                   0.00                   0.00                    0.0   \n",
       "\n",
       "          cash_balance_10_month  cash_balance_11_month  cash_balance_12_month  \\\n",
       "ID_CPTE                                                                         \n",
       "10074849                   0.00                   0.00                    0.0   \n",
       "10086539                   0.00                   0.00                    0.0   \n",
       "10140908                   3.06                   2.04                    0.0   \n",
       "10147994                   0.00                   0.00                    0.0   \n",
       "10152808                   0.00                   0.00                    0.0   \n",
       "\n",
       "          MaxDelqCycle  AvgDelqCycle  LateCount  \n",
       "ID_CPTE                                          \n",
       "10074849             0           0.0          0  \n",
       "10086539             0           0.0          0  \n",
       "10140908             2           1.0         12  \n",
       "10147994             0           0.0         10  \n",
       "10152808             0           0.0         12  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(processed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp = normalize(X_test[:, :-3])\n",
    "X_test = np.hstack((X_tmp, X_test[:, -3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5100, 40)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lgb = rf.predict(X_test)\n",
    "#predict_lgb = np.array([0 if i < 0.6 else 1 for i in predict_lgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test['Default'] = predict_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = processed_test.reset_index()[['ID_CPTE', 'Default']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../raw_data/performance_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71424379</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64887111</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69431075</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31823308</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39407834</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE PERIODID_MY  Default\n",
       "0  71424379  2014-12-01      NaN\n",
       "1  64887111  2015-12-01      NaN\n",
       "2  69431075  2014-12-01      NaN\n",
       "3  31823308  2016-12-01      NaN\n",
       "4  39407834  2012-12-01      NaN"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10074849</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10086539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10140908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10147994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10152808</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  Default\n",
       "0  10074849        0\n",
       "1  10086539        0\n",
       "2  10140908        0\n",
       "3  10147994        0\n",
       "4  10152808        0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission[['ID_CPTE', 'Default']].merge(results, on='ID_CPTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission[['ID_CPTE', 'Default_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission.rename(columns={'Default_y': 'Default'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71424379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64887111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69431075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31823308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39407834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  Default\n",
       "0  71424379        0\n",
       "1  64887111        0\n",
       "2  69431075        0\n",
       "3  31823308        0\n",
       "4  39407834        0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71424379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64887111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69431075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31823308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39407834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  Default\n",
       "0  71424379        0\n",
       "1  64887111        0\n",
       "2  69431075        0\n",
       "3  31823308        0\n",
       "4  39407834        0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5100"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71424379</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64887111</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69431075</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31823308</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39407834</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE PERIODID_MY  Default\n",
       "0  71424379  2014-12-01      NaN\n",
       "1  64887111  2015-12-01      NaN\n",
       "2  69431075  2014-12-01      NaN\n",
       "3  31823308  2016-12-01      NaN\n",
       "4  39407834  2012-12-01      NaN"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
