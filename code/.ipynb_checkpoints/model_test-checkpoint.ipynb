{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Test(Logistic regression, random forest, LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the relevant computational modules\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd #data processing\n",
    "import numpy as np #linear algebra\n",
    "\n",
    "# Models Packages\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Gradient Boosting\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Basic Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "# Oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# visualization \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "transaction_training = pd.read_csv('../raw_data/transactions_train.csv')\n",
    "payment_training = pd.read_csv('../raw_data/paiements_train.csv')\n",
    "billing_training = pd.read_csv('../raw_data/facturation_train.csv')\n",
    "performance_training = pd.read_csv('../raw_data/performance_train.csv')\n",
    "\n",
    "\n",
    "transaction_test = pd.read_csv('../raw_data/transactions_test.csv')\n",
    "payment_test = pd.read_csv('../raw_data/paiements_test.csv')\n",
    "billing_test = pd.read_csv('../raw_data/facturation_test.csv')\n",
    "performance_test = pd.read_csv('../raw_data/performance_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>TRANSACTION_AMT</th>\n",
       "      <th>TRANSACTION_DTTM</th>\n",
       "      <th>PAYMENT_REVERSAL_XFLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99690111</td>\n",
       "      <td>208.0</td>\n",
       "      <td>2015-04-26 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99690111</td>\n",
       "      <td>176.8</td>\n",
       "      <td>2015-05-28 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99690111</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2015-03-27 04:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99690111</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2015-04-02 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99690111</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2015-11-24 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  TRANSACTION_AMT     TRANSACTION_DTTM PAYMENT_REVERSAL_XFLG\n",
       "0  99690111            208.0  2015-04-26 00:00:00                     Q\n",
       "1  99690111            176.8  2015-05-28 00:00:00                     Q\n",
       "2  99690111            200.0  2015-03-27 04:00:00                     Q\n",
       "3  99690111             80.8  2015-04-02 00:00:00                     Q\n",
       "4  99690111            250.0  2015-11-24 00:00:00                     Q"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payment_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>StatementDate</th>\n",
       "      <th>CurrentTotalBalance</th>\n",
       "      <th>CashBalance</th>\n",
       "      <th>CreditLimit</th>\n",
       "      <th>DelqCycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>2015-05-03</td>\n",
       "      <td>8497.84</td>\n",
       "      <td>4293.12</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>2014-11-03</td>\n",
       "      <td>866.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>2015-05-31</td>\n",
       "      <td>10790.95</td>\n",
       "      <td>5224.44</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>2015-10-04</td>\n",
       "      <td>12388.46</td>\n",
       "      <td>4786.08</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>2015-11-02</td>\n",
       "      <td>12746.50</td>\n",
       "      <td>4818.48</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE PERIODID_MY StatementDate  CurrentTotalBalance  CashBalance  \\\n",
       "0  99690111  2015-05-01    2015-05-03              8497.84      4293.12   \n",
       "1  99690111  2014-11-01    2014-11-03               866.00         0.00   \n",
       "2  99690111  2015-06-01    2015-05-31             10790.95      5224.44   \n",
       "3  99690111  2015-10-01    2015-10-04             12388.46      4786.08   \n",
       "4  99690111  2015-11-01    2015-11-02             12746.50      4818.48   \n",
       "\n",
       "   CreditLimit  DelqCycle  \n",
       "0      16200.0          0  \n",
       "1      12000.0          0  \n",
       "2      16200.0          0  \n",
       "3      16200.0          0  \n",
       "4      16200.0          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billing_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57427180</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29617912</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61632809</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14117855</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE PERIODID_MY  Default\n",
       "0  99690111  2015-12-01        0\n",
       "1  57427180  2012-12-01        0\n",
       "2  29617912  2015-12-01        0\n",
       "3  61632809  2015-12-01        0\n",
       "4  14117855  2013-12-01        0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basic scikit-learn wrapper model class\n",
    "class SklearnWrapper:\n",
    "    def __init__(self, clf, seed=0, params=None, seed_bool=True):\n",
    "        if (seed_bool == True):\n",
    "            params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "    \n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create basic xgboost wrapper model class\n",
    "class XgbWrapper:\n",
    "    def __init__(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 250)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(xgb.DMatrix(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create basic lightGBM wrapper model class\n",
    "class LightGbmWrapper:\n",
    "    def __init(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 1550)\n",
    "        self.verbose_eval = params.pop('verbose_eval', 100)\n",
    "        \n",
    "    def train(self, x_train, y_train):\n",
    "        lgtrain = lgb.Dataset(x_train, y_train)\n",
    "        self.lgbm = lgb.train(self.param, lgtrain, num_boost_round=self.nrounds, verbose_eval=self.verbose_eval)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.lgbm.predict(lgb.Dataset(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create out-of-fold predictions \n",
    "# make good use of k-fold CV's result \n",
    "# serving for the staking alogrithm \n",
    "# create a new column generated from model's score\n",
    "\n",
    "def get_oof(clf, x_train, y, x_test):\n",
    "    '''\n",
    "    clf: the classifer, which can be logistic regression, SVM regression, Bayes classifier, etc.\n",
    "    x_train: the training x in training dataset\n",
    "    y: the training y in training dataset\n",
    "    x_test: the testing x in training dataset \n",
    "    '''\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        print('\\nFold {}'.format(i))\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "        \n",
    "        clf.fit(x_tr, y_tr)\n",
    "        \n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "    \n",
    "    m = stats.mode(oof_test_skf, axis=1)\n",
    "    oof_test[:] = m[0][0]\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocess\n",
    "\n",
    "class DataPreprocess:\n",
    "    def __init__(self, label_encoder):\n",
    "        self.lbl = label_encoder\n",
    "    \n",
    "    def convert_date(self, statement_date, period_date):\n",
    "        statement_day = statement_date.split('-')[-1]\n",
    "        period_day = period_date.split('-')[-1]\n",
    "        statement_month = statement_date.split('-')[-2]\n",
    "        period_month = period_date.split('-')[-2]\n",
    "        if int(statement_month) < int(period_month):\n",
    "            tmp = 0\n",
    "        else:\n",
    "            if int(statement_day) > 20:\n",
    "                tmp = 1\n",
    "            else:\n",
    "                tmp = 0\n",
    "        return tmp\n",
    "    \n",
    "    \n",
    "    def initialize_billing(self, billing_df):\n",
    "        tmp = []\n",
    "        for index, row in billing_df.iterrows():\n",
    "            tmp.append(self.convert_date(row['StatementDate'], row['PERIODID_MY']))\n",
    "\n",
    "        billing_df['statement_time'] = tmp\n",
    "        \n",
    "        return billing_df\n",
    "    \n",
    "    def preprocess_transcation(self, transaction_df):\n",
    "        categorical_columns = ['MERCHANT_CATEGORY_XCD', 'MERCHANT_CITY_NAME', 'MERCHANT_COUNTRY_XCD', \n",
    "                               'DECISION_XCD', 'TRANSACTION_CATEGORY_XCD', 'TRANSACTION_TYPE_XCD', 'SICGROUP']\n",
    "        \n",
    "        for col in categorical_columns:\n",
    "            transaction_df[col].fillna('unknown')\n",
    "            transaction_df[col] = self.lbl.fit_transform(transaction_df[col].astype(str))\n",
    "        \n",
    "        transaction_df = transaction_df.groupby(['ID_CPTE', 'MERCHANT_CATEGORY_XCD'])['TRANSACTION_AMT'].sum()\n",
    "        transaction_df = transaction_df.reset_index()\n",
    "        transaction_df = transaction_df.pivot_table('TRANSACTION_AMT', ['ID_CPTE'], 'MERCHANT_CATEGORY_XCD')\n",
    "        transaction_df.columns = ['MERCHANT_CATEGORY_' + str(i) for i in transaction_df.columns]\n",
    "        transaction_df = transaction_df.fillna(0)\n",
    "        \n",
    "        return transaction_df\n",
    "    \n",
    "    def preprocess_payment(self, payment_df, billing_df):\n",
    "        payment_df = payment_df.fillna(0)\n",
    "        payment_df['TRANSACTION_DTTM'] = payment_df['TRANSACTION_DTTM'].apply(lambda x: str(x).split(' ')[0][:-3])\n",
    "        payment_df = payment_df.sort_values(['ID_CPTE', 'TRANSACTION_DTTM'])\n",
    "#         payment_df['PAYMENT_N_COUNT'] = payment_df['PAYMENT_REVERSAL_XFLG'] == 'N'\n",
    "#         payment_df = payment_df.groupby(['ID_CPTE', 'TRANSACTION_DTTM'])[['TRANSACTION_AMT', 'PAYMENT_N_COUNT']].sum().reset_index()\n",
    "        payment_df = payment_df.groupby('ID_CPTE').tail(12)\n",
    "        \n",
    "        billing_df['PERIODID_MY'] = billing_df['PERIODID_MY'].apply(lambda x: x[:-3])\n",
    "        billing_df = billing_df.sort_values(['ID_CPTE', 'PERIODID_MY'])\n",
    "        billing_df = billing_df.reset_index(drop=True)\n",
    "        billing_df = billing_df.groupby('ID_CPTE').tail(12)\n",
    "        billing_df = billing_df.rename(columns={'PERIODID_MY': 'TRANSACTION_DTTM'})\n",
    "        \n",
    "        payment_df = payment_df.merge(billing_df[['ID_CPTE', 'TRANSACTION_DTTM', 'CreditLimit']], on=['ID_CPTE', 'TRANSACTION_DTTM'])\n",
    "        payment_df['PaymentRatio'] = payment_df['TRANSACTION_AMT'] / payment_df['CreditLimit']\n",
    "        \n",
    "#         tmp = payment_df.groupby(['ID_CPTE'])['PAYMENT_N_COUNT'].sum().reset_index()\n",
    "        \n",
    "        payment_df['TRANSACTION_DTTM'] = payment_df['TRANSACTION_DTTM'].apply(lambda x: x.split('-')[1])\n",
    "        payment_df = payment_df.pivot_table('PaymentRatio', ['ID_CPTE'], 'TRANSACTION_DTTM')\n",
    "        payment_df.columns = ['payment_ratio_' + str(i) for i in payment_df.columns + '_month']\n",
    "        payment_df = payment_df.reset_index()\n",
    "        payment_df = payment_df.fillna(0)\n",
    "        \n",
    "#         payment_df = payment_df.merge(tmp, on='ID_CPTE')\n",
    "        \n",
    "        return payment_df\n",
    "    \n",
    "    def preprocess_billing(self, billing_df):\n",
    "        billing_df['PERIODID_MY'] = billing_df['PERIODID_MY'].apply(lambda x: x[:-3])\n",
    "        billing_df = billing_df.sort_values(['ID_CPTE', 'PERIODID_MY'])\n",
    "        billing_df = billing_df.reset_index(drop=True)\n",
    "        billing_df = billing_df.groupby('ID_CPTE').tail(12)\n",
    "        billing_df = billing_df.reset_index(drop=True)\n",
    "        billing_df['CreditLeft'] = billing_df['CreditLimit'] - billing_df['CurrentTotalBalance']\n",
    "        billing_df['CashRatio'] = billing_df['CashBalance'] / billing_df['CurrentTotalBalance']\n",
    "        billing_df['tmp'] = np.append(np.array(billing_df['CreditLeft'][1:]), billing_df['CreditLeft'].tail(1).values)\n",
    "        billing_df['ConsecutiveLeft'] = billing_df['tmp'] - billing_df['CreditLeft']\n",
    "        billing_df['ConsecutiveLeft'] = np.append(np.array([0]), np.array(billing_df['ConsecutiveLeft'][:-1]))\n",
    "        \n",
    "        billing_df['PERIODID_MY'] = billing_df['PERIODID_MY'].apply(lambda x: x[-2:])\n",
    "        credit_left = billing_df.pivot_table('CreditLeft', ['ID_CPTE'], 'PERIODID_MY')\n",
    "        credit_left.columns = ['credit_left_' + str(i) for i in credit_left.columns + '_month']\n",
    "        \n",
    "        consecutive_left = billing_df.pivot_table('ConsecutiveLeft', ['ID_CPTE'], 'PERIODID_MY')\n",
    "        consecutive_left.columns = ['consecutive_left_' + str(i) for i in consecutive_left.columns + '_month']\n",
    "        \n",
    "        cash_ratio = billing_df.pivot_table('CashRatio', ['ID_CPTE'], 'PERIODID_MY')\n",
    "        cash_ratio.columns = ['cash_ratio_' + str(i) for i in cash_ratio.columns + '_month']\n",
    "        \n",
    "        delq_cycle_avg = billing_df.groupby(['ID_CPTE'])['DelqCycle'].mean().reset_index()\n",
    "        delq_cycle_avg = delq_cycle_avg.rename(columns={'DelqCycle': 'AvgDelqCycle'})\n",
    "        \n",
    "        delq_cycle = billing_df.groupby(['ID_CPTE'])['DelqCycle'].max().reset_index()\n",
    "        delq_cycle = delq_cycle.rename(columns={'DelqCycle': 'MaxDelqCycle'})\n",
    "        \n",
    "#         late_count = billing_df.groupby(['ID_CPTE'])['statement_time'].sum().reset_index()\n",
    "#         late_count = late_count.rename(columns={'statement_time': 'LateCount'})\n",
    "        \n",
    "        tmp1 = billing_df.groupby(['ID_CPTE'])[['ID_CPTE', 'CreditLimit']].head(1).set_index('ID_CPTE')\n",
    "        tmp2 = billing_df.groupby(['ID_CPTE'])[['ID_CPTE', 'CreditLimit']].tail(1).set_index('ID_CPTE')\n",
    "        credit_change = tmp2 - tmp1\n",
    "        credit_change = credit_change.reset_index()\n",
    "        credit_change = credit_change.rename(columns={'CreditLimit': 'CreditChange'})\n",
    "        \n",
    "        credit_left = credit_left.reset_index()\n",
    "        consecutive_left = consecutive_left.reset_index()\n",
    "        cash_ratio = cash_ratio.reset_index() \n",
    "        \n",
    "        tmp = credit_left.merge(cash_ratio, on='ID_CPTE')\n",
    "        tmp = tmp.merge(credit_change, on='ID_CPTE')\n",
    "        tmp = tmp.merge(consecutive_left, on='ID_CPTE')\n",
    "        \n",
    "        tmp = tmp.merge(delq_cycle, on='ID_CPTE')\n",
    "        tmp = tmp.merge(delq_cycle_avg, on='ID_CPTE')\n",
    "#         tmp = tmp.merge(late_count, on='ID_CPTE')\n",
    "        \n",
    "        return tmp\n",
    "    \n",
    "    def merge(self, payment, billing):\n",
    "        merge_df = payment.merge(billing, on='ID_CPTE', how='right')\n",
    "        return merge_df.set_index(['ID_CPTE']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>TRANSACTION_AMT</th>\n",
       "      <th>TRANSACTION_DTTM</th>\n",
       "      <th>PAYMENT_REVERSAL_XFLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99690111</td>\n",
       "      <td>208.0</td>\n",
       "      <td>2015-04-26 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99690111</td>\n",
       "      <td>176.8</td>\n",
       "      <td>2015-05-28 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99690111</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2015-03-27 04:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99690111</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2015-04-02 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99690111</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2015-11-24 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  TRANSACTION_AMT     TRANSACTION_DTTM PAYMENT_REVERSAL_XFLG\n",
       "0  99690111            208.0  2015-04-26 00:00:00                     Q\n",
       "1  99690111            176.8  2015-05-28 00:00:00                     Q\n",
       "2  99690111            200.0  2015-03-27 04:00:00                     Q\n",
       "3  99690111             80.8  2015-04-02 00:00:00                     Q\n",
       "4  99690111            250.0  2015-11-24 00:00:00                     Q"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payment_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "billing_training_cp = billing_training.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = DataPreprocess(label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#billing_training = preprocess.initialize_billing(billing_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_payment = preprocess.preprocess_payment(payment_training, billing_training_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_billing = preprocess.preprocess_billing(billing_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>credit_left_01_month</th>\n",
       "      <th>credit_left_02_month</th>\n",
       "      <th>credit_left_03_month</th>\n",
       "      <th>credit_left_04_month</th>\n",
       "      <th>credit_left_05_month</th>\n",
       "      <th>credit_left_06_month</th>\n",
       "      <th>credit_left_07_month</th>\n",
       "      <th>credit_left_08_month</th>\n",
       "      <th>credit_left_09_month</th>\n",
       "      <th>...</th>\n",
       "      <th>consecutive_left_05_month</th>\n",
       "      <th>consecutive_left_06_month</th>\n",
       "      <th>consecutive_left_07_month</th>\n",
       "      <th>consecutive_left_08_month</th>\n",
       "      <th>consecutive_left_09_month</th>\n",
       "      <th>consecutive_left_10_month</th>\n",
       "      <th>consecutive_left_11_month</th>\n",
       "      <th>consecutive_left_12_month</th>\n",
       "      <th>MaxDelqCycle</th>\n",
       "      <th>AvgDelqCycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001822</td>\n",
       "      <td>20.34</td>\n",
       "      <td>18.88</td>\n",
       "      <td>300.40</td>\n",
       "      <td>482.92</td>\n",
       "      <td>3420.58</td>\n",
       "      <td>2110.03</td>\n",
       "      <td>2184.77</td>\n",
       "      <td>1669.00</td>\n",
       "      <td>1246.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2937.66</td>\n",
       "      <td>-1310.55</td>\n",
       "      <td>74.74</td>\n",
       "      <td>-515.77</td>\n",
       "      <td>-423.00</td>\n",
       "      <td>-278.28</td>\n",
       "      <td>-1150.02</td>\n",
       "      <td>-249.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10007972</td>\n",
       "      <td>140.00</td>\n",
       "      <td>700.00</td>\n",
       "      <td>662.00</td>\n",
       "      <td>139.26</td>\n",
       "      <td>256.30</td>\n",
       "      <td>258.00</td>\n",
       "      <td>128.66</td>\n",
       "      <td>299.95</td>\n",
       "      <td>180.25</td>\n",
       "      <td>...</td>\n",
       "      <td>117.04</td>\n",
       "      <td>1.70</td>\n",
       "      <td>-129.34</td>\n",
       "      <td>171.29</td>\n",
       "      <td>-119.70</td>\n",
       "      <td>118.89</td>\n",
       "      <td>310.76</td>\n",
       "      <td>90.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10012520</td>\n",
       "      <td>565.04</td>\n",
       "      <td>353.05</td>\n",
       "      <td>771.55</td>\n",
       "      <td>1186.48</td>\n",
       "      <td>1580.97</td>\n",
       "      <td>1789.45</td>\n",
       "      <td>1704.09</td>\n",
       "      <td>1558.32</td>\n",
       "      <td>2323.32</td>\n",
       "      <td>...</td>\n",
       "      <td>394.49</td>\n",
       "      <td>208.48</td>\n",
       "      <td>-85.36</td>\n",
       "      <td>-145.77</td>\n",
       "      <td>765.00</td>\n",
       "      <td>-249.32</td>\n",
       "      <td>-467.90</td>\n",
       "      <td>316.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10025534</td>\n",
       "      <td>-7.90</td>\n",
       "      <td>-253.91</td>\n",
       "      <td>-177.08</td>\n",
       "      <td>-289.28</td>\n",
       "      <td>4825.89</td>\n",
       "      <td>1550.35</td>\n",
       "      <td>817.41</td>\n",
       "      <td>-212.78</td>\n",
       "      <td>-301.85</td>\n",
       "      <td>...</td>\n",
       "      <td>5115.17</td>\n",
       "      <td>-3275.54</td>\n",
       "      <td>-732.94</td>\n",
       "      <td>-1030.19</td>\n",
       "      <td>-89.07</td>\n",
       "      <td>78.87</td>\n",
       "      <td>53.04</td>\n",
       "      <td>-172.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10033579</td>\n",
       "      <td>90.24</td>\n",
       "      <td>248.55</td>\n",
       "      <td>68.00</td>\n",
       "      <td>83.42</td>\n",
       "      <td>114.16</td>\n",
       "      <td>25.12</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-24.28</td>\n",
       "      <td>-52.12</td>\n",
       "      <td>...</td>\n",
       "      <td>30.74</td>\n",
       "      <td>-89.04</td>\n",
       "      <td>-20.12</td>\n",
       "      <td>-29.28</td>\n",
       "      <td>-27.84</td>\n",
       "      <td>13.91</td>\n",
       "      <td>4.69</td>\n",
       "      <td>-95.81</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  credit_left_01_month  credit_left_02_month  credit_left_03_month  \\\n",
       "0  10001822                 20.34                 18.88                300.40   \n",
       "1  10007972                140.00                700.00                662.00   \n",
       "2  10012520                565.04                353.05                771.55   \n",
       "3  10025534                 -7.90               -253.91               -177.08   \n",
       "4  10033579                 90.24                248.55                 68.00   \n",
       "\n",
       "   credit_left_04_month  credit_left_05_month  credit_left_06_month  \\\n",
       "0                482.92               3420.58               2110.03   \n",
       "1                139.26                256.30                258.00   \n",
       "2               1186.48               1580.97               1789.45   \n",
       "3               -289.28               4825.89               1550.35   \n",
       "4                 83.42                114.16                 25.12   \n",
       "\n",
       "   credit_left_07_month  credit_left_08_month  credit_left_09_month  \\\n",
       "0               2184.77               1669.00               1246.00   \n",
       "1                128.66                299.95                180.25   \n",
       "2               1704.09               1558.32               2323.32   \n",
       "3                817.41               -212.78               -301.85   \n",
       "4                  5.00                -24.28                -52.12   \n",
       "\n",
       "       ...       consecutive_left_05_month  consecutive_left_06_month  \\\n",
       "0      ...                         2937.66                   -1310.55   \n",
       "1      ...                          117.04                       1.70   \n",
       "2      ...                          394.49                     208.48   \n",
       "3      ...                         5115.17                   -3275.54   \n",
       "4      ...                           30.74                     -89.04   \n",
       "\n",
       "   consecutive_left_07_month  consecutive_left_08_month  \\\n",
       "0                      74.74                    -515.77   \n",
       "1                    -129.34                     171.29   \n",
       "2                     -85.36                    -145.77   \n",
       "3                    -732.94                   -1030.19   \n",
       "4                     -20.12                     -29.28   \n",
       "\n",
       "   consecutive_left_09_month  consecutive_left_10_month  \\\n",
       "0                    -423.00                    -278.28   \n",
       "1                    -119.70                     118.89   \n",
       "2                     765.00                    -249.32   \n",
       "3                     -89.07                      78.87   \n",
       "4                     -27.84                      13.91   \n",
       "\n",
       "   consecutive_left_11_month  consecutive_left_12_month  MaxDelqCycle  \\\n",
       "0                   -1150.02                    -249.90             0   \n",
       "1                     310.76                      90.10             0   \n",
       "2                    -467.90                     316.70             0   \n",
       "3                      53.04                    -172.71             1   \n",
       "4                       4.69                     -95.81             1   \n",
       "\n",
       "   AvgDelqCycle  \n",
       "0      0.000000  \n",
       "1      0.000000  \n",
       "2      0.000000  \n",
       "3      0.416667  \n",
       "4      0.083333  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_billing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = preprocess.merge(processed_payment, processed_billing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_col = processed_data.iloc[:, :12].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with missing value in payment\n",
    "for col in transaction_col:\n",
    "    replace_value = processed_data[processed_data[col].notna()][col].mean()\n",
    "    processed_data[col] = processed_data[col].fillna(replace_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.merge(performance_training[['ID_CPTE', 'Default']], on='ID_CPTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.set_index('ID_CPTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features correlation and distribution analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>credit_left_01_month</th>\n",
       "      <th>credit_left_02_month</th>\n",
       "      <th>credit_left_03_month</th>\n",
       "      <th>credit_left_04_month</th>\n",
       "      <th>credit_left_05_month</th>\n",
       "      <th>credit_left_06_month</th>\n",
       "      <th>credit_left_07_month</th>\n",
       "      <th>credit_left_08_month</th>\n",
       "      <th>credit_left_09_month</th>\n",
       "      <th>...</th>\n",
       "      <th>lag11</th>\n",
       "      <th>lag12</th>\n",
       "      <th>lag13</th>\n",
       "      <th>default</th>\n",
       "      <th>date</th>\n",
       "      <th>num</th>\n",
       "      <th>avg_pay</th>\n",
       "      <th>total_reversal</th>\n",
       "      <th>total_exceed</th>\n",
       "      <th>no_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001822</td>\n",
       "      <td>20.34</td>\n",
       "      <td>18.88</td>\n",
       "      <td>300.40</td>\n",
       "      <td>482.92</td>\n",
       "      <td>3420.58</td>\n",
       "      <td>2110.03</td>\n",
       "      <td>2184.77</td>\n",
       "      <td>1669.00</td>\n",
       "      <td>1246.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20058</td>\n",
       "      <td>14</td>\n",
       "      <td>543.253540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10007972</td>\n",
       "      <td>140.00</td>\n",
       "      <td>700.00</td>\n",
       "      <td>662.00</td>\n",
       "      <td>139.26</td>\n",
       "      <td>256.30</td>\n",
       "      <td>258.00</td>\n",
       "      <td>128.66</td>\n",
       "      <td>299.95</td>\n",
       "      <td>180.25</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>19693</td>\n",
       "      <td>50</td>\n",
       "      <td>247.222600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10012520</td>\n",
       "      <td>565.04</td>\n",
       "      <td>353.05</td>\n",
       "      <td>771.55</td>\n",
       "      <td>1186.48</td>\n",
       "      <td>1580.97</td>\n",
       "      <td>1789.45</td>\n",
       "      <td>1704.09</td>\n",
       "      <td>1558.32</td>\n",
       "      <td>2323.32</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>20058</td>\n",
       "      <td>15</td>\n",
       "      <td>477.727360</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10025534</td>\n",
       "      <td>-7.90</td>\n",
       "      <td>-253.91</td>\n",
       "      <td>-177.08</td>\n",
       "      <td>-289.28</td>\n",
       "      <td>4825.89</td>\n",
       "      <td>1550.35</td>\n",
       "      <td>817.41</td>\n",
       "      <td>-212.78</td>\n",
       "      <td>-301.85</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>19693</td>\n",
       "      <td>6</td>\n",
       "      <td>1579.549900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10033579</td>\n",
       "      <td>90.24</td>\n",
       "      <td>248.55</td>\n",
       "      <td>68.00</td>\n",
       "      <td>83.42</td>\n",
       "      <td>114.16</td>\n",
       "      <td>25.12</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-24.28</td>\n",
       "      <td>-52.12</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>20423</td>\n",
       "      <td>44</td>\n",
       "      <td>82.637955</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  credit_left_01_month  credit_left_02_month  credit_left_03_month  \\\n",
       "0  10001822                 20.34                 18.88                300.40   \n",
       "1  10007972                140.00                700.00                662.00   \n",
       "2  10012520                565.04                353.05                771.55   \n",
       "3  10025534                 -7.90               -253.91               -177.08   \n",
       "4  10033579                 90.24                248.55                 68.00   \n",
       "\n",
       "   credit_left_04_month  credit_left_05_month  credit_left_06_month  \\\n",
       "0                482.92               3420.58               2110.03   \n",
       "1                139.26                256.30                258.00   \n",
       "2               1186.48               1580.97               1789.45   \n",
       "3               -289.28               4825.89               1550.35   \n",
       "4                 83.42                114.16                 25.12   \n",
       "\n",
       "   credit_left_07_month  credit_left_08_month  credit_left_09_month   ...    \\\n",
       "0               2184.77               1669.00               1246.00   ...     \n",
       "1                128.66                299.95                180.25   ...     \n",
       "2               1704.09               1558.32               2323.32   ...     \n",
       "3                817.41               -212.78               -301.85   ...     \n",
       "4                  5.00                -24.28                -52.12   ...     \n",
       "\n",
       "   lag11  lag12  lag13  default   date  num      avg_pay  total_reversal  \\\n",
       "0     -2      1      2        0  20058   14   543.253540               0   \n",
       "1     16     17     14        0  19693   50   247.222600               0   \n",
       "2     17     17     17        0  20058   15   477.727360               0   \n",
       "3     27     25     26        1  19693    6  1579.549900               0   \n",
       "4     -1      4     -1        0  20423   44    82.637955               0   \n",
       "\n",
       "   total_exceed  no_obs  \n",
       "0             0       1  \n",
       "1             0       1  \n",
       "2             0       1  \n",
       "3             0       1  \n",
       "4             0       1  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tmp1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-9f44717ea491>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprocessed_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tmp1' is not defined"
     ]
    }
   ],
   "source": [
    "processed_data = pd.concat((tmp1, tmp2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>credit_left_01_month</th>\n",
       "      <th>credit_left_02_month</th>\n",
       "      <th>credit_left_03_month</th>\n",
       "      <th>credit_left_04_month</th>\n",
       "      <th>credit_left_05_month</th>\n",
       "      <th>credit_left_06_month</th>\n",
       "      <th>credit_left_07_month</th>\n",
       "      <th>credit_left_08_month</th>\n",
       "      <th>credit_left_09_month</th>\n",
       "      <th>credit_left_10_month</th>\n",
       "      <th>credit_left_11_month</th>\n",
       "      <th>credit_left_12_month</th>\n",
       "      <th>MaxDelqCycle</th>\n",
       "      <th>AvgDelqCycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001822</td>\n",
       "      <td>20.34</td>\n",
       "      <td>18.88</td>\n",
       "      <td>300.40</td>\n",
       "      <td>482.92</td>\n",
       "      <td>3420.58</td>\n",
       "      <td>2110.03</td>\n",
       "      <td>2184.77</td>\n",
       "      <td>1669.00</td>\n",
       "      <td>1246.00</td>\n",
       "      <td>967.72</td>\n",
       "      <td>-182.30</td>\n",
       "      <td>-432.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10007972</td>\n",
       "      <td>140.00</td>\n",
       "      <td>700.00</td>\n",
       "      <td>662.00</td>\n",
       "      <td>139.26</td>\n",
       "      <td>256.30</td>\n",
       "      <td>258.00</td>\n",
       "      <td>128.66</td>\n",
       "      <td>299.95</td>\n",
       "      <td>180.25</td>\n",
       "      <td>299.14</td>\n",
       "      <td>609.90</td>\n",
       "      <td>700.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10012520</td>\n",
       "      <td>565.04</td>\n",
       "      <td>353.05</td>\n",
       "      <td>771.55</td>\n",
       "      <td>1186.48</td>\n",
       "      <td>1580.97</td>\n",
       "      <td>1789.45</td>\n",
       "      <td>1704.09</td>\n",
       "      <td>1558.32</td>\n",
       "      <td>2323.32</td>\n",
       "      <td>2074.00</td>\n",
       "      <td>1606.10</td>\n",
       "      <td>1922.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10025534</td>\n",
       "      <td>-7.90</td>\n",
       "      <td>-253.91</td>\n",
       "      <td>-177.08</td>\n",
       "      <td>-289.28</td>\n",
       "      <td>4825.89</td>\n",
       "      <td>1550.35</td>\n",
       "      <td>817.41</td>\n",
       "      <td>-212.78</td>\n",
       "      <td>-301.85</td>\n",
       "      <td>-222.98</td>\n",
       "      <td>-169.94</td>\n",
       "      <td>-342.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10033579</td>\n",
       "      <td>90.24</td>\n",
       "      <td>248.55</td>\n",
       "      <td>68.00</td>\n",
       "      <td>83.42</td>\n",
       "      <td>114.16</td>\n",
       "      <td>25.12</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-24.28</td>\n",
       "      <td>-52.12</td>\n",
       "      <td>-38.21</td>\n",
       "      <td>-33.52</td>\n",
       "      <td>-129.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  credit_left_01_month  credit_left_02_month  credit_left_03_month  \\\n",
       "0  10001822                 20.34                 18.88                300.40   \n",
       "1  10007972                140.00                700.00                662.00   \n",
       "2  10012520                565.04                353.05                771.55   \n",
       "3  10025534                 -7.90               -253.91               -177.08   \n",
       "4  10033579                 90.24                248.55                 68.00   \n",
       "\n",
       "   credit_left_04_month  credit_left_05_month  credit_left_06_month  \\\n",
       "0                482.92               3420.58               2110.03   \n",
       "1                139.26                256.30                258.00   \n",
       "2               1186.48               1580.97               1789.45   \n",
       "3               -289.28               4825.89               1550.35   \n",
       "4                 83.42                114.16                 25.12   \n",
       "\n",
       "   credit_left_07_month  credit_left_08_month  credit_left_09_month  \\\n",
       "0               2184.77               1669.00               1246.00   \n",
       "1                128.66                299.95                180.25   \n",
       "2               1704.09               1558.32               2323.32   \n",
       "3                817.41               -212.78               -301.85   \n",
       "4                  5.00                -24.28                -52.12   \n",
       "\n",
       "   credit_left_10_month  credit_left_11_month  credit_left_12_month  \\\n",
       "0                967.72               -182.30               -432.20   \n",
       "1                299.14                609.90                700.00   \n",
       "2               2074.00               1606.10               1922.80   \n",
       "3               -222.98               -169.94               -342.65   \n",
       "4                -38.21                -33.52               -129.33   \n",
       "\n",
       "   MaxDelqCycle  AvgDelqCycle  \n",
       "0             0      0.000000  \n",
       "1             0      0.000000  \n",
       "2             0      0.000000  \n",
       "3             1      0.416667  \n",
       "4             1      0.083333  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_features = pd.read_csv('../intermidiate_data/20180716_2_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11900, 11900)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_data), len(other_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_features = other_features.rename(columns={'id_cpte': 'ID_CPTE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.merge(other_features, on=['ID_CPTE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_y = processed_data['default'].copy()\n",
    "processed_X = processed_data.drop(['ID_CPTE', 'default'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['credit_left_01_month', 'credit_left_02_month', 'credit_left_03_month',\n",
       "       'credit_left_04_month', 'credit_left_05_month', 'credit_left_06_month',\n",
       "       'credit_left_07_month', 'credit_left_08_month', 'credit_left_09_month',\n",
       "       'credit_left_10_month', 'credit_left_11_month', 'credit_left_12_month',\n",
       "       'MaxDelqCycle', 'AvgDelqCycle', 'lag_pay1', 'lag_pay2', 'lag_pay3',\n",
       "       'lag_pay4', 'lag_pay5', 'lag_pay6', 'lag_pay7', 'lag_pay8', 'lag_pay9',\n",
       "       'lag_pay10', 'lag_pay11', 'lag_pay12', 'lag_pay13', 'delqcycle1',\n",
       "       'delqcycle2', 'delqcycle3', 'delqcycle4', 'delqcycle5', 'delqcycle6',\n",
       "       'delqcycle7', 'delqcycle8', 'delqcycle9', 'delqcycle10', 'delqcycle11',\n",
       "       'delqcycle12', 'delqcycle13', 'avg_balance', 'avg_cashbalance',\n",
       "       'creditlimit_max', 'lag1', 'lag2', 'lag3', 'lag4', 'lag5', 'lag6',\n",
       "       'lag7', 'lag8', 'lag9', 'lag10', 'lag11', 'lag12', 'lag13', 'date',\n",
       "       'num', 'avg_pay', 'total_reversal', 'total_exceed', 'no_obs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(processed_y)\n",
    "X = np.array(processed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\futai\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29d017da390>"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(processed_X['delqcycle1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\futai\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29d01855278>"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEFCAYAAAAsU2YoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl4lPW99/H3ZCb7QhKSKKvsbpyjoniO9gDtQQrurbSXR220lz0+1cer1l1EQJ8CVS5brYc+LYVHj0dQKrVYBXEBqoBsQZAtIPuWhWwkZJlMMsvv+WMykwQCyDT3ZG74vP4hmbkz88l93Xznm9/9u3+3wxhjEBERW4nr6gAiInL2VLxFRGxIxVtExIZUvEVEbEjFW0TEhlzReJOKirpTPpeVlUJ1tTsaMTqF3fKCMkeLMlvPbnnhH8ucm5t+yue6vPN2uZxdHeGs2C0vKHO0KLP17JYXrMvc5cVbRETOnoq3iIgNqXiLiNiQireIiA2peIuI2JCKt4iIDal4i4jYkIq3iIhFvL4AnmafJa8dlSssRUTOR6+9t4Vmv2HiPcM6/bVVvEVELFJ53IPPH7DktTVsIiJikUDAEOdwWPLaKt4iIhYxxhAXp+ItImIrAUPXFu8tW7aQn58PwM6dO7n77rvJz8/nZz/7GZWVlZYEExGxuy4dNpkzZw6TJk2iqakJgOnTpzN58mTmzp3LmDFjmDNnjiXBRETsLtCVwyZ9+/Zl5syZ4e9feeUVLr30UgD8fj+JiYmWBBMRsbtAwLrifcapgmPHjqWoqCj8fV5eHgCbNm1i3rx5vP3222d8k6yslNMuSH66u0XEIrvlBWWOFmW2nt3yxjkclmSOaJ73kiVL+OMf/8js2bPJzs4+4/anuwVQbm76aW+TFmvslheUOVqU2Xp2y+tr6bwjzXy6on/WxfuDDz7g3XffZe7cuWRmZkYUSETkfGC6ctikLb/fz/Tp0+nRowe/+MUvABg+fDiPPPKIJeFEROwsYAxOi2abfKvi3bt3bxYsWABAQUGBJUFERM41gUAXz/MWEZGz16VTBUVE5OwFjAHQ2iYiInYSCLQUb4uqrIq3iIgFjDpvERH7CbQs460xbxERGwmPeat4i4jYh05YiojYUOsJSxVvERHbaKndKt4iInYS7rw1bCIiYh+aKigiYkOts02seX0VbxERC2jMW0TEhozGvEVE7EcX6YiI2JDmeYuI2FBozNuqO+moeIuIWECdt4iIDWnMW0TEhrQwlYiIDRmt5y0iYj8aNhERsSEtTCUiYkPqvEVEbEgLU4mI2FD4BsRdOWyyZcsW8vPzATh06BB33XUXd999N88//zyBUEIREQkLdd7Orho2mTNnDpMmTaKpqQmAF198kUcffZR33nkHYwzLly+3JJiIiJ0Zi6+wdJ1pg759+zJz5kyefvppAAoLC7n22msBGDlyJKtXr2bMmDGnfY2srBRcLucpn8/NTT+bzF3ObnlBmaNFma1nl7xppXVAcNjEisxnLN5jx46lqKgo/L0xBkfLGE5qaip1dXVnfJPqavcpn8vNTaei4syvESvslheUOVqU2Xp2yltzvBEIdt6RZj5d0T/rE5ZxbU6dNjQ0kJGREVEoEZFzWcwtTHXZZZexfv16AFauXMk111zT6aFEROwu5tY2eeaZZ5g5cyZ33nknXq+XsWPHWpFLRMTWrO68zzjmDdC7d28WLFgAQP/+/Zk3b54lYUREzhUx13mLiMiZmfDd4615fRVvERELqPMWEbEhqy/SUfEWEbFAIDxsouItImIbWs9bRMSGtJ63iIgNqXiLiNiQhk1ERGxIJyxFRGwoNFXQqc5bRMQ+NOYtImJDKt4iIjYUEzcgFhGRs9PaeVvz+ireIiIWiLk76YiIyJlpVUERERsyoTFvdd4iIvah2SYiIjakYRMRERsKnbB0qvMWEbEPDZuIiNiQLtIREbEho85bRMR+NGwiImJDVt+MwRXJD3m9XiZMmEBxcTFxcXFMnTqVgQMHdnY2ERHbCt2MwaLaHVnnvWLFCnw+H3/+8595+OGH+d3vftfZuUREbC0mpwr2798fv99PIBCgvr4elyuiBl5E5Jxl9QnLiKpuSkoKxcXF3HjjjVRXVzNr1qzTbp+VlYLL5Tzl87m56ZHE6DJ2ywvKHC3KbD275HXFB2tenMNhSeaIivebb77Jv/3bv/HEE09QWlrKfffdx6JFi0hMTOxw++pq9ylfKzc3nYqKukhidAm75QVljhZltp6d8nqafECw84408+mKfkTFOyMjg/j4eAC6deuGz+fD7/dHFE5E5Fxk9XreERXvn/70p0ycOJG7774br9fLY489RkpKSmdnExGxLWPxwlQRFe/U1FRee+21zs4iInLO0J10RERsKGCs67pBxVtExBIBYyy7+TCoeIuIWCIQMOq8RUTsJmAMDovGu0HFW0TEEoGAxrxFRGzHGIOFjbeKt4iIFYInLNV5i4jYik5YiojYkDpvEREbCp6wtO71VbxFRCwQMAaHhk1EROxFwyYiIjZkdMJSRMR+Asa6FQVBxVtExBLBqYLWvb6Kt4iIBQJGwyYiIrajhalERGxI87xFRGzIaNhERMR+NGwiImIzxhiM7mEpImIvJnjjeI15i4jYSaCleusiHRERGwkEWoq3hk1EROwjGp23K9If/NOf/sTf//53vF4vd911Fz/+8Y87M5eIiG0FAsF/rey8Iyre69ev5+uvv2b+/Pk0NjbyxhtvdHYuERHbCnXeFtbuyIr3l19+yZAhQ3j44Yepr6/n6aef7uxcIiK2FbPDJtXV1ZSUlDBr1iyKiop46KGH+OSTT05514isrBRcLucpXy83Nz2SGF3GbnlBmaNFma1nh7yuWg8AyUnxgDWZIyremZmZDBgwgISEBAYMGEBiYiLHjh2je/fuHW5fXe0+5Wvl5qZTUVEXSYwuYbe8oMzRoszWs0ve6romALxeP0DEmU9X9COabXL11VezatUqjDGUlZXR2NhIZmZmROFERM41rVMFrXuPiDrv733ve2zYsIEf/ehHGGOYMmUKTueph0VERM4n4THvWJttAugkpYjIKYRnm+gKSxER+9AVliIiNhQILUylzltExD5MFE5YqniLiHSyaJywVPEWEelkWhJWRMSGorEwlYq3iEgna50qaN17qHiLiHQyTRUUEbEhoxOWIiL2E+q8rVzPW8VbRKST6SIdEREb0jxvEREbMprnLSJiP5rnLSJiQ63DJta9h4q3iEgnC8820bCJiIh96ISliIgNaWEqEREbMuETlta9h4q3iEgn07CJiIgNhRem0rCJiIh9qPMWEbGh0NomWs9bRMRGtJ63iIgNadhERMSGTKyfsKyqqmLUqFHs27evs/KIiNheeD3vWOy8vV4vU6ZMISkpqTPziIjYXusVlta9hyvSH5wxYwb/8R//wezZs8+4bVZWCi6X85TP5+amRxqjS9gtLyhztCiz9eyQNzk5AYCszFTAmswRFe+FCxeSnZ3NiBEjvlXxrq52n/K53Nx0KirqIonRJeyWF5Q5WpTZenbJW1fvAaC2rhEg4synK/oRNfV//etfWbNmDfn5+ezcuZNnnnmGioqKiMKJiJxrojFVMKLO++233w5/nZ+fzwsvvEBubm6nhRIRsbPWE5bWvYemCoqIdLJo3MMy4hOWIXPnzu2MHCIi5wxdYSkiYkOhqYIOFW8REfsI3z1eC1OJiNiH1jYREbEho+ItImI/ret5q3iLiNhG62wT695DxVtEpJMFojDPW8VbRKSTGc3zFhGxH802ERGxofDaJho2ERGxD52wFBGxofDl8bG8MJWIiMAXm4vDX5dXB2/CsHb7UQZe1N2S91PnLSLSyUx4YSrr3kPFW0Skk7Wcr9SqgiIidqLOW0TEhkxobRN13iIi9tFavK17DxVvEZFOFh42sfA9VLxFRDpZwAQLt4ZNRERsxBhj6ZAJqHiLiHQ6g7VdN6h4i4h0OnXebew6XM3mPZVdHUNEpEM19U3sKaoBgrNN1Hm3eGfZHuYs3tHVMUREOrR9/zHWbi+jvtEblc47ooWpvF4vEydOpLi4mObmZh566CFGjx7d2dnaqXM309jkw+cP4HLa5jNHRM4TnmYfAE3N/mDnbelEwQiL94cffkhmZiYvv/wy1dXV/PCHP7S8eLs9vvC/GakJlr6XiMjZavYGgv/6/LHbeY8bN46xY8eGv3c6nafdPisrBZfr1Nvk5qaf9ue9Pj/NvuCOSUxJOOP2Vuvq94+EMkeHMlsvVvN6/cEaFed0gsNBXJyD9LQkwJrMERXv1NRUAOrr63nkkUd49NFHT7t9dbX7lM/l5qZTUVF32p8/3tAc/rqo5DiJFn+inc63yRtrlDk6lNl6sZzX0+QHoLbOE76TTl29ByDizKcr+hEPHpeWlnLvvfdy++23c+utt0b6Mt+K2+Nt/brJZ+l7iYicLWMMzb5g8W7yBYLDJha/Z0Sdd2VlJffffz9Tpkzhuuuu6+xMJ2nw+Np87T3NliIi0dfk9YcXo2pu+drKmw9DhJ33rFmzqK2t5Q9/+AP5+fnk5+fj8Xg6O1tYu87bo85bRGJL27rU7PVjiNETlpMmTWLSpEmdneWU2nfeKt4iElsa2hXvQLDz1kU67T/V3Bo2EZEY07YuNfv8BHR5fJCGTUQklrk76Lx1eTzt/yRR8RaRWNO2RgVPXqrzBtoXbM02EZFY027YJNR5WzxZ0BbFu0HDJiISw9qdsPS1rG2izhsaWy7M6ZaWoNkmIhJzQk1lSqILY9AJy5AGj4+kBCfpyQm6wlJEYo67KTg6kJYSH35MJywJjielJrlITXLR2OQLrxsgIhILQiMC6clti7e172mL4t3g8ZGSFE9KUvCaInXfIhJL3B4fDgekJKvzDvMHAnia/S2dd3DHhM7sfv51Md8cqu7KeCJyHqptaOYvX+ylyRtcjKrB4yXB5STR1VpSrV6YKuaLd2PLMovJia5w593g8dHg8TL30138dcW+rownIuehlVtK+HjdYTbuKgeCnXdCfBzx8a33LTjvL48PTRNMPWHYpLy6EYDymsYuyyYi56dQ3QnVIXeTj4R4J4nxbTrvWFyYKprCU3DaDZv4aGgMFvU6t5fGJh/JiTH/q4jIOaKiTfPo9fnx+gIkuOJIaHPHsPN+zLu18247bOINf+IBVKj7FpEoCnXeFdWN4ZkmifFOEqLYecd88W7tvONJDQ2beHztCnbbQi4iYiWvz09NXRMQbBxDxTshPo6EeHXeYW2HTVISg8MmDR5vu+KtzltEoqWixkPoSpNat5fq2uCNaBJcJ3TeFueI+eLd0bBJo8dHeU1j+M+S0J8wAWP4/OtiauqbuiSriJx7TqwroXoTqj8HjwZvLpwQH0e8My78uIZNOhg2Od7QTHVtE/0uDN5ZOTRsUnjgGHM/3cWiNQe7JKuInHt2nFBXQicr+/fIAOBQuHg7cTgc4ZOW5/2wSWg8Kdh5B4dNDpfVYYBeuWl0S0sID5vsKaoBYG/R8S7JKiLnnt0t9WTPkeC/oc778n7ZABw8WgsET1gC4aETdd5NrZ13vCuOBFccVbXBP1/yMpPJy0ymqtaDzx8IF+2iivrwSoQiIv+IvS1NYXFLXQk1i5f3DxbvUD0KFe3QScvzvvMOXQqf0jKPOzmpdT53XlYyuZnJGBM8abm/JPgJaAzsKwkW8m37q/jF71aG/7QRETkVnz/AlNcLeGfp7vD3+0tb6grBulJR00hqkouLLkhv97Oh4ZKElkvkdcLS4yPBFUd8yw4JXagDkNvSeQN8tauCZl+A7hlJQOvQyfKNRTR4fKzYXBzl5CJiN4UHjlFUUc/KLSU0Nvk4Ul5Ps7e1ruw+cpyKGg95WckkJjjplpoQ/ll13idwe7zhWSZAu6/zspLJzQoW77XbjwIwZngfAPYWH6e+0UvhgWNAsLj7/AEA3l+5nyf+72pqG5qj8juISGz6/cJt/OrNDfgDwdpQsLMMgGZfgM17K9lbHGwCQ3Xlq2/K8fkD5LY0jaH6A61FO1Fj3kFuj69dt53aMnwSWmUw1HkfPeYG4MpB3enRPYV9JbUU7CzDHzCkJrmob/Sy81A1x+ub+KTgMNV1TSz96kj4dT9ae5CFK/dhjNYKFzkXbdlbyZxFheHzYXuKati0u4KDR+so2FFOk9fPpj2V4VltBTvKwn/Bh+pKqM7ktRTtUP1x0DpcEho+Oa8XpgoYg7vJd0LnHSzkHX3yZaQmkJuZzKBe3Whq9vPR2kMA5I+9GID1O8r4dMMRvL4ADkJDKl627qviryv2s3jNIQp2BlcJq6lv4v/89wbeWbY7XND9gQAFO47qPpoiMcQYw9Z9ldS5W/+S3rirggmz1rJ1XyUA1XVNzF5UyNrCMt5rWYl08ZpgfXAAi9ceZMveSpqa/Xz3ql70zUtj+4FjfHO4moyU+HBdCQnVn1DxTk50hYdJYnq2SSAQYMqUKdx5553k5+dz6NChzs4FgKcpeCPPdp13SyEPffKlJ8eTlBD8pBvUqxsOh4NBvYM7ubquiUG9uzH8kjy6ZySxaXcFn28qJjMtgR+MHICn2c9Haw7x1qff4IxzEO+K451lu6mua+L3C7dxqKyOZV8V8WnBEXz+AHMW7WDq6+t56e2N1DY0EzCGv63az2O//5LV20qB4IG0amsJ7yzdTW3LwWSMofDAMQoPHmvX2ZdVu9vdXBmgqdmv7l/OOc1eP4E2x7U/EKCooj48lAlQdszNmu2leH3+8DafbTjCX77YG+6WD5bWMvn19by6YAt17uD/wbc+3cXv/rKV6W9tpOq4h0NH65izqJDymkZmfVBIcUU98z7bRWOTn+REJ59vKmbphiNs21/FxX0yuX7ohZRWufnz8j0AXHvpBVx72QX4A4Y6t5dBvTPb1RVoLdqh5rFtg9k65m3FnmwV0VJ8y5Yto7m5mXfffZfNmzfz0ksv8cc//rGzs4VnmrRdMTC0k0KffA6Hg7zMZA6X14c/Gdt+Qv7LpRfgcDi49tI8Pl5/GIAfjhzAyCt68FnBYT4pCD52y/X9SEl0seDzvUx5fT0NHh9XD8llX8lx/vL5XjbtrmBv8XGy0hMpqmhgxjubyM1MZuu+KgBe/2gn+0tqKa9pDI+zr99Zxg9GDGDTrnIKDwZvGnF5/2xGXdGTLzYXs+NgNYkJTm64ujf9e2SwfGMROw9V0/eCNMZc0weXM46VW0o4dLSOKwZ15/p/6sGx4x7W7yyjzu3lqsE5/PPAHA6U1rJlbyVxcQ6uGpxDvwsz2HW4mp2HqsnKSGLEVb0xPj87Dx3j0NE6euWmcVm/LAIBw67DNVQcb6R/jwwG986kpr6JPUXHaWr2M7BXBn3y0iitcnOgtBaXM46BPTPo3i2JI+X1HC6rp1tqAv17ZJCU4ORQWR1l1W7yMlPod2E6Xn+Aw2V1HG9opmf3VHrnpVHb0MyR8nq8vgC9c1PJy0qmosZDcWUD8a44euWk0i01gf1l9ew6WEVGSgK9c9OId8VRUtlA5XEPOd2S6JWbSrM3QEllA/WNXi7ITuHC7GRqG7yUVDXgDxh6dk8hOyOJyppGSo+5SXA56ZmTSmqyi6NVbsprGumWmkDP7qk44hyUVjZwrK6J3G5J9MhJxdPso7iigQaPjx7dU7ggO4WauiZKKhswxtAzJ5WsjCTKq92UVrrJ7Z5KRsvt+oorGyirdpOVlkiv3DQAjpTXcay2iQuzU+iVm4rbEzwh5m7y0TMnlR7dU6g87uFIWT0AfS9Io3tGEsWVDRwpryclyUW/C9NJSXRx8GgdJZUN5GQmM6BHBv6AYV/xcSqPe+idl0r/Hhkcr29mT1ENbo+PAT0z6HNBOsUV9ew+UkNcnIOL+2RysTdAwbYSdh+pITMtkcv6ZZOS5GLbvir2l9bSNy+Nfx7YncZmP5t2VVB6rIFLL8rinwfmUFRez7odZbg9Xq6+OI/L+2WzZV8l6wqPkhDv5Dv/1IO+F6SxYnMJm3ZXkJuZzA1X9yYpwcXitQcpr24kNzOJm6/rR0llA8s3FuEPGP626gA3XXcRX24tDc8gK9hRzqgre7Jk3SE8zX6KKxr41Ztf0b9HOl/tqqBbagLlNY3MeGcT/oDB6wvw78N68fdNxbz09iYaPD4u7pPJ+FEDeXHeRua3FOpbvtOP7PRE1mw/Sk19Mz26p9A7N5XkBCfvfbGvXT3pqPMO/dth8bZ4vklExXvjxo2MGDECgCuvvJLt27d3aqgQT3PwEzg1uTVmanL7YRMIfvodLq9ncMsn44XZKaQlx9Pg8XLNJXlA8NP04/WHSUuOZ9QVPUlMcPL94X14f9UBenRP4dbr+xEXFyy4h47WMaBnBv/rtssoqmjgpbc3sbf4OJf0zeRXD36H//f+Vj7bcITSKjeX98/mhyMG8N9LdvL518EZLUMHZHNxn0w+XH2QuZ/uAlrmhIY68JbifnGfTI4ec4eHdwB656ZypLye1z/aGX4sIyWetYVlrC0sCz/mcjo4Ul7Ph6sPtttnoQ+Ttr74uv1Mm692VfDBlwfaPbZ629GTfm7pVyc9JHa18eSHln1VdNJjn2040u77wgPHwk1PyL7i2nZDDi5XHB98eSB8TCUnOql1e8PFD6BH9xQqajy8syxYNJ1xDv5pQHd2HjrGmx9/A0BOtyQu75/Nl1tLeeuT4P+bf7nsAnK6JfHxusMsXLmfpAQn//sHQympauCDVQeoqvXQv0c6j995JX/fWMT7q4IZxo8awM3X9SM1KZ5Faw7icsbx0xsv4YLsFEZf3ZtlG4vo3yODyy7KwuFwMPzSPAp2loebvZzMZAb2zGBfSW244w7VlSavn8z0RKB1BKDt6EDohGVcnLXF22Ei+Bv9ueee4/vf/z6jRo0C4Lvf/S7Lli3D5dKa2iIi0RDRmHdaWhoNDQ3h7wOBgAq3iEgURVS8hw0bxsqVKwHYvHkzQ4YM6dRQIiJyehENmwQCAV544QV27w5Oo/v1r3/NwIEDrcgnIiIdiKh4i4hI14rpi3RERKRjKt4iIjak4i0iYkOWz+/bsmULv/nNb5g7dy47d+5k6tSpOJ1OEhISmDFjBjk5Oe22/8EPfkB6enCd3N69e/Piiy9aHfG0mQsLC3nwwQfp168fAHfddRc33XRTeFuPx8NTTz1FVVUVqampzJgxg+zs7C7N/Nhjj1FZGVzTobi4mCuuuIJXX301vK0xhpEjR4Z/pyuvvJInnngialm9Xi8TJ06kuLiY5uZmHnroIQYNGsSECRNwOBwMHjyY559/nri41t6iK/dzR3l79uwZ08dyR5kvvPDCmD6WO8q8ePHimD6W/X4/kyZN4sCBAzidTl588UWMMdE5lo2FZs+ebW655Rbz4x//2BhjzD333GN27NhhjDFm/vz55te//nW77T0ej7n99tutjHRGJ2ZesGCBef3110+5/RtvvGH+67/+yxhjzOLFi83UqVOjkrOtEzOH1NTUmNtuu82UlZW1e/zgwYPm5z//eTQjtvPee++ZadOmGWOMOXbsmBk1apT5+c9/btatW2eMMWby5Mnms88+a/czXbmfO8ob68dyR5lj/VjuKHNIrB7LS5cuNRMmTDDGGLNu3Trz4IMPRu1YtnTYpG/fvsycOTP8/SuvvMKll14KBD+xEhMT223/zTff0NjYyP3338+9997L5s2brYzXoRMzb9++nS+++IJ77rmHiRMnUl9f3277tksFjBw5krVr10Y1L5ycOWTmzJn85Cc/IS8vr93jhYWFlJWVkZ+fzwMPPMD+/fujFRWAcePG8ctf/jL8vdPppLCwkGuvvRYI7sc1a9a0+5mu3M8d5Y31Y7mjzLF+LHeUOSRWj+UbbriBqVOnAlBSUkJOTk70juV/4EPnWzly5MhJHeHGjRvNuHHjTFVVVbvHv/nmG/Puu++aQCBg9u/fb0aPHm28Xq/VEU/SNvN7771ntm3bZowx5g9/+IN56aWX2m173333mb179xpjjPH7/WbEiBHRDdvixP1cWVlpbrrpJuPz+U7atqCgwCxZssQYY8yGDRvMHXfcEbWcbdXV1Zmf/OQn5sMPPzTf+c53wo+vWbPGPPHEE+22jYX93DZvSKwfy20z2+VYPnE/2+FYfvrpp81VV11lVq1aFbVjOeonLJcsWcLzzz/P7NmzTxrn6d+/P7fddhsOh4P+/fuTmZlJRUVFtCO2M2bMGIYOHRr+eseOHe2eb7tUQENDAxkZGVHP2JFPPvmEW265pV33EjJ06FBGjx4NwDXXXENZWVnUl6EtLS3l3nvv5fbbb+fWW29tNybY0X7s6v18Yl6I/WP5xMx2OJY72s+xfiwDzJgxg08//ZTJkyfT1NQUftzKYzmqxfuDDz5g3rx5zJ07lz59+pz0/HvvvcdLL70EQFlZGfX19eTm5kYz4kl+9rOfsXXrVgDWrl3L5Zdf3u75YcOGsWLFCgBWrlzJ1VdfHfWMHVm7di0jR47s8Lnf//73/M///A8Q/PO+Z8+elt9vr63Kykruv/9+nnrqKX70ox8BcNlll7F+/XoguB+vueaadj/Tlfu5o7yxfix3lDnWj+WOMoeyxuqx/Le//Y0//elPACQnJ+NwOBg6dGhUjmXLr7AsKiri8ccfZ/78+Vx33XX06NEj/EkzfPhwHnnkEZ5++mkeffRRcnJyePbZZykpKcHhcPDkk08ybNgwK+OdNvOCBQsoLCxk6tSpxMfHk5OTw9SpU0lLS+P+++9n1qxZ+P1+nnnmGSoqKoiPj+e3v/1tl3zgtM0McPPNNzN//vx2n+qhzI2NjTz11FO43W6cTidTpkyJ6vIG06ZN4+OPP2bAgAHhx5577jmmTZuG1+tlwIABTJs2DafTGRP7+cS8fr+fPXv20LNnz5g9ljvax48++igvv/xyzB7LHWWeM2cO48ePj9lj2e128+yzz1JZWYnP5+OBBx5g4MCBTJ482fJjWZfHi4jYkC7SERGxIRVvEREbUvEWEbEhFW8RERtS8RYRsSEVb7GN9evXk5+f39UxTmn16tXcd999XR1DzhMq3iL/oEAgwBtvvMHjjz9OIBDo6jhyntAt38V2CgoKePXVV/Fi+PRvAAAC/ElEQVR4PNTW1vLss89yww03cPToUZ588kmOHz/OkCFD2LBhQ/hG2R1ZuHAhX3zxBVVVVVRUVPC9732PCRMm4Pf7eeGFF9izZw+VlZVcfPHFvPLKK8yaNQtjDI899hgAEyZMYOTIkQwePJh9+/YxdepU5s6dG63dIOc5dd5iO/PmzWPatGm8//77TJs2jddeew2A6dOnc+ONN7Jo0SLGjRtHWVnZGV9r48aNvPbaayxevJgtW7awdOlSvv76a+Lj43n33XdZunQpdXV1rFixgvHjx7No0SKMMTQ2NrJu3TpGjx7N4MGDmT59Ot26dbP6VxcJU+cttvPyyy/z+eef88knn7Bly5bwIj+rV68O3/BgzJgx32rBn9GjR4dvonDTTTexbt06pkyZQmZmJm+//Tb79+/n4MGDuN1u+vTpQ69evdiwYQMlJSWMGjXqpKVgRaJFnbfYzt13383WrVsZOnQoDz74YPhxp9N51ivKtV2pLhAI4HQ6Wb58OU8++SRJSUnccccdDB8+PPy648ePZ/HixSxevJg77rijc34hkQioeIut1NTUcPDgQX75y18ycuRIli9fjt/vB+C6665j0aJFAKxYsYLa2tozvt6qVauoq6ujqamJjz76KLw4/o033sj48ePJyMhg/fr14fcYN24ca9eupbKykiuuuMK6X1TkDDRsIraSmZnJ9ddfz80334zL5eJf//Vf8Xg8uN1unnvuOZ555hkWLFjAJZdc8q2GTbKzs3nggQeorq7mtttuY8SIEeTl5fHkk0/y0UcfER8fz7BhwygqKgIgKSmJK6+8kiFDhlj9q4qcllYVlHPGW2+9xfXXX8+gQYMoLCxk8uTJLFy48JTbL1y4kIKCgvC622dijKGhoYE777yTN998s8vXmpfzmzpvOWdcdNFFPP7448TFxZGYmMjUqVNZsmRJeLH8E53tBTXbtm3jP//zP3n44YdVuKXLqfMWEbEhnbAUEbEhFW8RERtS8RYRsSEVbxERG1LxFhGxof8PabibPSEnhvAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(processed_X['lag_pay1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.array(processed_data.iloc[:, :-1])\n",
    "# y = np.array(processed_data.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_tmp = normalize(X[:, 13:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_tmp = np.hstack((X[:, :13], X_tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.hstack((X_tmp, X[:, -3:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sm = SMOTE(random_state=42, ratio=1)\n",
    "#X_res, y_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    " \n",
    "clf = LogisticRegression()\n",
    "rf = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_clf = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7688466480764355"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(predict_clf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7508365200764818"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(predict_rf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9922186872703859"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(predict_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>credit_left_10_month</th>\n",
       "      <td>0.061003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_12_month</th>\n",
       "      <td>0.056436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_11_month</th>\n",
       "      <td>0.049709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_09_month</th>\n",
       "      <td>0.045251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_08_month</th>\n",
       "      <td>0.045042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_cashbalance</th>\n",
       "      <td>0.037411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_05_month</th>\n",
       "      <td>0.035743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_04_month</th>\n",
       "      <td>0.035396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_03_month</th>\n",
       "      <td>0.035269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxDelqCycle</th>\n",
       "      <td>0.031860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_01_month</th>\n",
       "      <td>0.031489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_balance</th>\n",
       "      <td>0.028879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AvgDelqCycle</th>\n",
       "      <td>0.027209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_07_month</th>\n",
       "      <td>0.025600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delqcycle13</th>\n",
       "      <td>0.023666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_06_month</th>\n",
       "      <td>0.022395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num</th>\n",
       "      <td>0.021312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_pay</th>\n",
       "      <td>0.021137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_02_month</th>\n",
       "      <td>0.020198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag_pay13</th>\n",
       "      <td>0.017396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creditlimit_max</th>\n",
       "      <td>0.016303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag_pay12</th>\n",
       "      <td>0.015465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag_pay10</th>\n",
       "      <td>0.014947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag_pay8</th>\n",
       "      <td>0.014503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag_pay7</th>\n",
       "      <td>0.014163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag_pay6</th>\n",
       "      <td>0.014105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag_pay3</th>\n",
       "      <td>0.013148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag_pay5</th>\n",
       "      <td>0.012518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag_pay9</th>\n",
       "      <td>0.012208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag_pay4</th>\n",
       "      <td>0.012061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag6</th>\n",
       "      <td>0.011275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag8</th>\n",
       "      <td>0.011172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag10</th>\n",
       "      <td>0.010400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag1</th>\n",
       "      <td>0.010171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag9</th>\n",
       "      <td>0.010105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag3</th>\n",
       "      <td>0.009989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag13</th>\n",
       "      <td>0.009822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag7</th>\n",
       "      <td>0.009191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag11</th>\n",
       "      <td>0.009154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag5</th>\n",
       "      <td>0.009060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>0.008748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag4</th>\n",
       "      <td>0.008403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag2</th>\n",
       "      <td>0.007719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delqcycle12</th>\n",
       "      <td>0.006825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_exceed</th>\n",
       "      <td>0.004384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delqcycle10</th>\n",
       "      <td>0.003721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag_pay2</th>\n",
       "      <td>0.003705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_obs</th>\n",
       "      <td>0.002772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delqcycle2</th>\n",
       "      <td>0.002517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delqcycle11</th>\n",
       "      <td>0.002411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delqcycle5</th>\n",
       "      <td>0.002267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delqcycle7</th>\n",
       "      <td>0.002009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delqcycle1</th>\n",
       "      <td>0.001987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delqcycle3</th>\n",
       "      <td>0.001568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delqcycle6</th>\n",
       "      <td>0.001447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delqcycle9</th>\n",
       "      <td>0.001421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delqcycle4</th>\n",
       "      <td>0.001267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delqcycle8</th>\n",
       "      <td>0.001189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_reversal</th>\n",
       "      <td>0.000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag_pay1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Importance\n",
       "credit_left_10_month    0.061003\n",
       "credit_left_12_month    0.056436\n",
       "credit_left_11_month    0.049709\n",
       "credit_left_09_month    0.045251\n",
       "credit_left_08_month    0.045042\n",
       "avg_cashbalance         0.037411\n",
       "credit_left_05_month    0.035743\n",
       "credit_left_04_month    0.035396\n",
       "credit_left_03_month    0.035269\n",
       "MaxDelqCycle            0.031860\n",
       "credit_left_01_month    0.031489\n",
       "avg_balance             0.028879\n",
       "AvgDelqCycle            0.027209\n",
       "credit_left_07_month    0.025600\n",
       "delqcycle13             0.023666\n",
       "credit_left_06_month    0.022395\n",
       "num                     0.021312\n",
       "avg_pay                 0.021137\n",
       "credit_left_02_month    0.020198\n",
       "lag_pay13               0.017396\n",
       "creditlimit_max         0.016303\n",
       "lag_pay12               0.015465\n",
       "lag_pay10               0.014947\n",
       "lag_pay8                0.014503\n",
       "lag_pay7                0.014163\n",
       "lag_pay6                0.014105\n",
       "lag_pay3                0.013148\n",
       "lag_pay5                0.012518\n",
       "lag_pay9                0.012208\n",
       "lag_pay4                0.012061\n",
       "...                          ...\n",
       "lag6                    0.011275\n",
       "lag8                    0.011172\n",
       "lag10                   0.010400\n",
       "lag1                    0.010171\n",
       "lag9                    0.010105\n",
       "lag3                    0.009989\n",
       "lag13                   0.009822\n",
       "lag7                    0.009191\n",
       "lag11                   0.009154\n",
       "lag5                    0.009060\n",
       "date                    0.008748\n",
       "lag4                    0.008403\n",
       "lag2                    0.007719\n",
       "delqcycle12             0.006825\n",
       "total_exceed            0.004384\n",
       "delqcycle10             0.003721\n",
       "lag_pay2                0.003705\n",
       "no_obs                  0.002772\n",
       "delqcycle2              0.002517\n",
       "delqcycle11             0.002411\n",
       "delqcycle5              0.002267\n",
       "delqcycle7              0.002009\n",
       "delqcycle1              0.001987\n",
       "delqcycle3              0.001568\n",
       "delqcycle6              0.001447\n",
       "delqcycle9              0.001421\n",
       "delqcycle4              0.001267\n",
       "delqcycle8              0.001189\n",
       "total_reversal          0.000148\n",
       "lag_pay1                0.000000\n",
       "\n",
       "[62 rows x 1 columns]"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = rf.feature_importances_\n",
    "importance = pd.DataFrame(importance, index=processed_X.columns, columns=[\"Importance\"])\n",
    "importance.sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# L1-based feature selection\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 40)\n",
    "fit = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True,  True,  True,  True, False,  True,\n",
       "        True, False,  True, False, False, False, False, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_features = processed_X.columns[fit.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rfe = np.array(processed_X[select_features])\n",
    "y_rfe = np.array(processed_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_rfe, y_rfe, test_size=0.3, random_state=102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "rf = RandomForestClassifier(min_samples_split=200, max_depth=20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=200,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8060826837569688"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_clf = clf.predict(X_test)\n",
    "roc_auc_score(predict_clf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7780886029961747"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rf = rf.predict(X_test)\n",
    "roc_auc_score(predict_rf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "fit = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11900, 50)"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_pca = []\n",
    "for i in [20, 30, 40, 50, 60]:\n",
    "    pca = PCA(n_components=i)\n",
    "    fit = pca.fit_transform(X)\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(fit, y, test_size=0.3, random_state=102)\n",
    "    #rf.fit(X_train, y_train)\n",
    "    scores = cross_val_score(rf, fit, y, cv=10, scoring='roc_auc')\n",
    "    score_pca.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(fit, y, test_size=0.3, random_state=102)\n",
    "clf.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8056648243124367"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_clf = clf.predict(X_test)\n",
    "roc_auc_score(predict_clf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7949364460541188"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rf = rf.predict(X_test)\n",
    "roc_auc_score(predict_rf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8849091251766543"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(rf, X, y, cv=10, scoring='roc_auc')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11900, 40)"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(fit, y, test_size=0.3, random_state=102)\n",
    "clf.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8056648243124367"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_clf = clf.predict(X_test)\n",
    "roc_auc_score(predict_clf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7642525337837839"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rf = rf.predict(X_test)\n",
    "roc_auc_score(predict_rf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8563294921033338"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(rf, X, y, cv=10, scoring='roc_auc')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "pca = PCA(n_components=50)\n",
    "fit = pca.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(fit, y, test_size=0.3, random_state=102)\n",
    "\n",
    "svm_clf = svm.SVC(kernel='linear')\n",
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predict = svm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(svm_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params =  {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    #'max_depth': 15,\n",
    "    'num_leaves': 270,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 2,\n",
    "    'learning_rate': 0.0175,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgtrain = lgb.Dataset(X_train, y_train)\n",
    "lgtest = lgb.Dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.682127\n",
      "[2]\ttraining's binary_logloss: 0.67164\n",
      "[3]\ttraining's binary_logloss: 0.661697\n",
      "[4]\ttraining's binary_logloss: 0.651185\n",
      "[5]\ttraining's binary_logloss: 0.641871\n",
      "[6]\ttraining's binary_logloss: 0.632212\n",
      "[7]\ttraining's binary_logloss: 0.622792\n",
      "[8]\ttraining's binary_logloss: 0.613907\n",
      "[9]\ttraining's binary_logloss: 0.605209\n",
      "[10]\ttraining's binary_logloss: 0.596559\n",
      "[11]\ttraining's binary_logloss: 0.588349\n",
      "[12]\ttraining's binary_logloss: 0.580281\n",
      "[13]\ttraining's binary_logloss: 0.572207\n",
      "[14]\ttraining's binary_logloss: 0.564651\n",
      "[15]\ttraining's binary_logloss: 0.557306\n",
      "[16]\ttraining's binary_logloss: 0.550177\n",
      "[17]\ttraining's binary_logloss: 0.543231\n",
      "[18]\ttraining's binary_logloss: 0.536413\n",
      "[19]\ttraining's binary_logloss: 0.529934\n",
      "[20]\ttraining's binary_logloss: 0.523785\n",
      "[21]\ttraining's binary_logloss: 0.517604\n",
      "[22]\ttraining's binary_logloss: 0.510906\n",
      "[23]\ttraining's binary_logloss: 0.504854\n",
      "[24]\ttraining's binary_logloss: 0.499132\n",
      "[25]\ttraining's binary_logloss: 0.49288\n",
      "[26]\ttraining's binary_logloss: 0.48755\n",
      "[27]\ttraining's binary_logloss: 0.481975\n",
      "[28]\ttraining's binary_logloss: 0.476799\n",
      "[29]\ttraining's binary_logloss: 0.471542\n",
      "[30]\ttraining's binary_logloss: 0.466469\n",
      "[31]\ttraining's binary_logloss: 0.461507\n",
      "[32]\ttraining's binary_logloss: 0.456294\n",
      "[33]\ttraining's binary_logloss: 0.451267\n",
      "[34]\ttraining's binary_logloss: 0.446073\n",
      "[35]\ttraining's binary_logloss: 0.440956\n",
      "[36]\ttraining's binary_logloss: 0.436004\n",
      "[37]\ttraining's binary_logloss: 0.431684\n",
      "[38]\ttraining's binary_logloss: 0.42698\n",
      "[39]\ttraining's binary_logloss: 0.422794\n",
      "[40]\ttraining's binary_logloss: 0.418546\n",
      "[41]\ttraining's binary_logloss: 0.414136\n",
      "[42]\ttraining's binary_logloss: 0.409624\n",
      "[43]\ttraining's binary_logloss: 0.405413\n",
      "[44]\ttraining's binary_logloss: 0.401603\n",
      "[45]\ttraining's binary_logloss: 0.397415\n",
      "[46]\ttraining's binary_logloss: 0.393577\n",
      "[47]\ttraining's binary_logloss: 0.389766\n",
      "[48]\ttraining's binary_logloss: 0.386049\n",
      "[49]\ttraining's binary_logloss: 0.382427\n",
      "[50]\ttraining's binary_logloss: 0.378835\n",
      "[51]\ttraining's binary_logloss: 0.375133\n",
      "[52]\ttraining's binary_logloss: 0.371465\n",
      "[53]\ttraining's binary_logloss: 0.367868\n",
      "[54]\ttraining's binary_logloss: 0.364209\n",
      "[55]\ttraining's binary_logloss: 0.361058\n",
      "[56]\ttraining's binary_logloss: 0.357625\n",
      "[57]\ttraining's binary_logloss: 0.354391\n",
      "[58]\ttraining's binary_logloss: 0.351014\n",
      "[59]\ttraining's binary_logloss: 0.347687\n",
      "[60]\ttraining's binary_logloss: 0.344644\n",
      "[61]\ttraining's binary_logloss: 0.341426\n",
      "[62]\ttraining's binary_logloss: 0.338247\n",
      "[63]\ttraining's binary_logloss: 0.335189\n",
      "[64]\ttraining's binary_logloss: 0.332307\n",
      "[65]\ttraining's binary_logloss: 0.329482\n",
      "[66]\ttraining's binary_logloss: 0.326531\n",
      "[67]\ttraining's binary_logloss: 0.323939\n",
      "[68]\ttraining's binary_logloss: 0.321338\n",
      "[69]\ttraining's binary_logloss: 0.318758\n",
      "[70]\ttraining's binary_logloss: 0.315905\n",
      "[71]\ttraining's binary_logloss: 0.313173\n",
      "[72]\ttraining's binary_logloss: 0.310534\n",
      "[73]\ttraining's binary_logloss: 0.307842\n",
      "[74]\ttraining's binary_logloss: 0.305445\n",
      "[75]\ttraining's binary_logloss: 0.302858\n",
      "[76]\ttraining's binary_logloss: 0.300312\n",
      "[77]\ttraining's binary_logloss: 0.297743\n",
      "[78]\ttraining's binary_logloss: 0.295189\n",
      "[79]\ttraining's binary_logloss: 0.292749\n",
      "[80]\ttraining's binary_logloss: 0.290508\n",
      "[81]\ttraining's binary_logloss: 0.288208\n",
      "[82]\ttraining's binary_logloss: 0.285949\n",
      "[83]\ttraining's binary_logloss: 0.283691\n",
      "[84]\ttraining's binary_logloss: 0.281528\n",
      "[85]\ttraining's binary_logloss: 0.279588\n",
      "[86]\ttraining's binary_logloss: 0.277523\n",
      "[87]\ttraining's binary_logloss: 0.275343\n",
      "[88]\ttraining's binary_logloss: 0.273416\n",
      "[89]\ttraining's binary_logloss: 0.271339\n",
      "[90]\ttraining's binary_logloss: 0.269336\n",
      "[91]\ttraining's binary_logloss: 0.267203\n",
      "[92]\ttraining's binary_logloss: 0.265165\n",
      "[93]\ttraining's binary_logloss: 0.263137\n",
      "[94]\ttraining's binary_logloss: 0.261085\n",
      "[95]\ttraining's binary_logloss: 0.259129\n",
      "[96]\ttraining's binary_logloss: 0.257242\n",
      "[97]\ttraining's binary_logloss: 0.255352\n",
      "[98]\ttraining's binary_logloss: 0.253507\n",
      "[99]\ttraining's binary_logloss: 0.25169\n",
      "[100]\ttraining's binary_logloss: 0.249901\n",
      "[101]\ttraining's binary_logloss: 0.248207\n",
      "[102]\ttraining's binary_logloss: 0.246508\n",
      "[103]\ttraining's binary_logloss: 0.244733\n",
      "[104]\ttraining's binary_logloss: 0.242901\n",
      "[105]\ttraining's binary_logloss: 0.241265\n",
      "[106]\ttraining's binary_logloss: 0.239587\n",
      "[107]\ttraining's binary_logloss: 0.237891\n",
      "[108]\ttraining's binary_logloss: 0.236167\n",
      "[109]\ttraining's binary_logloss: 0.234495\n",
      "[110]\ttraining's binary_logloss: 0.232753\n",
      "[111]\ttraining's binary_logloss: 0.2311\n",
      "[112]\ttraining's binary_logloss: 0.229467\n",
      "[113]\ttraining's binary_logloss: 0.227832\n",
      "[114]\ttraining's binary_logloss: 0.22638\n",
      "[115]\ttraining's binary_logloss: 0.224784\n",
      "[116]\ttraining's binary_logloss: 0.223264\n",
      "[117]\ttraining's binary_logloss: 0.22177\n",
      "[118]\ttraining's binary_logloss: 0.220208\n",
      "[119]\ttraining's binary_logloss: 0.218716\n",
      "[120]\ttraining's binary_logloss: 0.217201\n",
      "[121]\ttraining's binary_logloss: 0.215725\n",
      "[122]\ttraining's binary_logloss: 0.214293\n",
      "[123]\ttraining's binary_logloss: 0.212846\n",
      "[124]\ttraining's binary_logloss: 0.211533\n",
      "[125]\ttraining's binary_logloss: 0.210095\n",
      "[126]\ttraining's binary_logloss: 0.208631\n",
      "[127]\ttraining's binary_logloss: 0.20721\n",
      "[128]\ttraining's binary_logloss: 0.205852\n",
      "[129]\ttraining's binary_logloss: 0.204504\n",
      "[130]\ttraining's binary_logloss: 0.203064\n",
      "[131]\ttraining's binary_logloss: 0.201698\n",
      "[132]\ttraining's binary_logloss: 0.200334\n",
      "[133]\ttraining's binary_logloss: 0.199025\n",
      "[134]\ttraining's binary_logloss: 0.197706\n",
      "[135]\ttraining's binary_logloss: 0.196428\n",
      "[136]\ttraining's binary_logloss: 0.195092\n",
      "[137]\ttraining's binary_logloss: 0.193833\n",
      "[138]\ttraining's binary_logloss: 0.192629\n",
      "[139]\ttraining's binary_logloss: 0.191412\n",
      "[140]\ttraining's binary_logloss: 0.190122\n",
      "[141]\ttraining's binary_logloss: 0.188897\n",
      "[142]\ttraining's binary_logloss: 0.187653\n",
      "[143]\ttraining's binary_logloss: 0.186398\n",
      "[144]\ttraining's binary_logloss: 0.185203\n",
      "[145]\ttraining's binary_logloss: 0.184062\n",
      "[146]\ttraining's binary_logloss: 0.182842\n",
      "[147]\ttraining's binary_logloss: 0.181675\n",
      "[148]\ttraining's binary_logloss: 0.180492\n",
      "[149]\ttraining's binary_logloss: 0.179331\n",
      "[150]\ttraining's binary_logloss: 0.178181\n",
      "[151]\ttraining's binary_logloss: 0.177006\n",
      "[152]\ttraining's binary_logloss: 0.175863\n",
      "[153]\ttraining's binary_logloss: 0.174687\n",
      "[154]\ttraining's binary_logloss: 0.173518\n",
      "[155]\ttraining's binary_logloss: 0.172372\n",
      "[156]\ttraining's binary_logloss: 0.171218\n",
      "[157]\ttraining's binary_logloss: 0.170114\n",
      "[158]\ttraining's binary_logloss: 0.169054\n",
      "[159]\ttraining's binary_logloss: 0.167992\n",
      "[160]\ttraining's binary_logloss: 0.16691\n",
      "[161]\ttraining's binary_logloss: 0.165873\n",
      "[162]\ttraining's binary_logloss: 0.164837\n",
      "[163]\ttraining's binary_logloss: 0.163778\n",
      "[164]\ttraining's binary_logloss: 0.162737\n",
      "[165]\ttraining's binary_logloss: 0.161749\n",
      "[166]\ttraining's binary_logloss: 0.160721\n",
      "[167]\ttraining's binary_logloss: 0.159711\n",
      "[168]\ttraining's binary_logloss: 0.158716\n",
      "[169]\ttraining's binary_logloss: 0.157736\n",
      "[170]\ttraining's binary_logloss: 0.156721\n",
      "[171]\ttraining's binary_logloss: 0.155748\n",
      "[172]\ttraining's binary_logloss: 0.154749\n",
      "[173]\ttraining's binary_logloss: 0.153762\n",
      "[174]\ttraining's binary_logloss: 0.152799\n",
      "[175]\ttraining's binary_logloss: 0.151842\n",
      "[176]\ttraining's binary_logloss: 0.150865\n",
      "[177]\ttraining's binary_logloss: 0.149919\n",
      "[178]\ttraining's binary_logloss: 0.149008\n",
      "[179]\ttraining's binary_logloss: 0.148071\n",
      "[180]\ttraining's binary_logloss: 0.147132\n",
      "[181]\ttraining's binary_logloss: 0.146214\n",
      "[182]\ttraining's binary_logloss: 0.145249\n",
      "[183]\ttraining's binary_logloss: 0.144291\n",
      "[184]\ttraining's binary_logloss: 0.143413\n",
      "[185]\ttraining's binary_logloss: 0.142477\n",
      "[186]\ttraining's binary_logloss: 0.141552\n",
      "[187]\ttraining's binary_logloss: 0.140702\n",
      "[188]\ttraining's binary_logloss: 0.139806\n",
      "[189]\ttraining's binary_logloss: 0.138947\n",
      "[190]\ttraining's binary_logloss: 0.138067\n",
      "[191]\ttraining's binary_logloss: 0.137229\n",
      "[192]\ttraining's binary_logloss: 0.136369\n",
      "[193]\ttraining's binary_logloss: 0.135532\n",
      "[194]\ttraining's binary_logloss: 0.134642\n",
      "[195]\ttraining's binary_logloss: 0.133794\n",
      "[196]\ttraining's binary_logloss: 0.132983\n",
      "[197]\ttraining's binary_logloss: 0.132165\n",
      "[198]\ttraining's binary_logloss: 0.131324\n",
      "[199]\ttraining's binary_logloss: 0.130473\n",
      "[200]\ttraining's binary_logloss: 0.129658\n",
      "[201]\ttraining's binary_logloss: 0.128858\n",
      "[202]\ttraining's binary_logloss: 0.12808\n",
      "[203]\ttraining's binary_logloss: 0.127304\n",
      "[204]\ttraining's binary_logloss: 0.126483\n",
      "[205]\ttraining's binary_logloss: 0.12571\n",
      "[206]\ttraining's binary_logloss: 0.12491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[207]\ttraining's binary_logloss: 0.124109\n",
      "[208]\ttraining's binary_logloss: 0.123338\n",
      "[209]\ttraining's binary_logloss: 0.122532\n",
      "[210]\ttraining's binary_logloss: 0.121787\n",
      "[211]\ttraining's binary_logloss: 0.121043\n",
      "[212]\ttraining's binary_logloss: 0.120256\n",
      "[213]\ttraining's binary_logloss: 0.119547\n",
      "[214]\ttraining's binary_logloss: 0.118806\n",
      "[215]\ttraining's binary_logloss: 0.118068\n",
      "[216]\ttraining's binary_logloss: 0.117353\n",
      "[217]\ttraining's binary_logloss: 0.116644\n",
      "[218]\ttraining's binary_logloss: 0.115906\n",
      "[219]\ttraining's binary_logloss: 0.115181\n",
      "[220]\ttraining's binary_logloss: 0.114431\n",
      "[221]\ttraining's binary_logloss: 0.113676\n",
      "[222]\ttraining's binary_logloss: 0.11292\n",
      "[223]\ttraining's binary_logloss: 0.11224\n",
      "[224]\ttraining's binary_logloss: 0.111533\n",
      "[225]\ttraining's binary_logloss: 0.110854\n",
      "[226]\ttraining's binary_logloss: 0.110177\n",
      "[227]\ttraining's binary_logloss: 0.109441\n",
      "[228]\ttraining's binary_logloss: 0.108761\n",
      "[229]\ttraining's binary_logloss: 0.108122\n",
      "[230]\ttraining's binary_logloss: 0.107441\n",
      "[231]\ttraining's binary_logloss: 0.106774\n",
      "[232]\ttraining's binary_logloss: 0.106101\n",
      "[233]\ttraining's binary_logloss: 0.105424\n",
      "[234]\ttraining's binary_logloss: 0.104742\n",
      "[235]\ttraining's binary_logloss: 0.1041\n",
      "[236]\ttraining's binary_logloss: 0.103483\n",
      "[237]\ttraining's binary_logloss: 0.10289\n",
      "[238]\ttraining's binary_logloss: 0.102264\n",
      "[239]\ttraining's binary_logloss: 0.101622\n",
      "[240]\ttraining's binary_logloss: 0.10102\n",
      "[241]\ttraining's binary_logloss: 0.100374\n",
      "[242]\ttraining's binary_logloss: 0.09979\n",
      "[243]\ttraining's binary_logloss: 0.0991441\n",
      "[244]\ttraining's binary_logloss: 0.0985108\n",
      "[245]\ttraining's binary_logloss: 0.0978902\n",
      "[246]\ttraining's binary_logloss: 0.0972822\n",
      "[247]\ttraining's binary_logloss: 0.0966687\n",
      "[248]\ttraining's binary_logloss: 0.0960459\n",
      "[249]\ttraining's binary_logloss: 0.0954385\n",
      "[250]\ttraining's binary_logloss: 0.0948137\n",
      "[251]\ttraining's binary_logloss: 0.0942185\n",
      "[252]\ttraining's binary_logloss: 0.0936577\n",
      "[253]\ttraining's binary_logloss: 0.0930749\n",
      "[254]\ttraining's binary_logloss: 0.0924753\n",
      "[255]\ttraining's binary_logloss: 0.0919367\n",
      "[256]\ttraining's binary_logloss: 0.091335\n",
      "[257]\ttraining's binary_logloss: 0.0908044\n",
      "[258]\ttraining's binary_logloss: 0.0902459\n",
      "[259]\ttraining's binary_logloss: 0.0897092\n",
      "[260]\ttraining's binary_logloss: 0.089184\n",
      "[261]\ttraining's binary_logloss: 0.0886786\n",
      "[262]\ttraining's binary_logloss: 0.0881682\n",
      "[263]\ttraining's binary_logloss: 0.0876212\n",
      "[264]\ttraining's binary_logloss: 0.0870408\n",
      "[265]\ttraining's binary_logloss: 0.0865104\n",
      "[266]\ttraining's binary_logloss: 0.0859768\n",
      "[267]\ttraining's binary_logloss: 0.0854116\n",
      "[268]\ttraining's binary_logloss: 0.0848749\n",
      "[269]\ttraining's binary_logloss: 0.0843096\n",
      "[270]\ttraining's binary_logloss: 0.083785\n",
      "[271]\ttraining's binary_logloss: 0.0832446\n",
      "[272]\ttraining's binary_logloss: 0.0827292\n",
      "[273]\ttraining's binary_logloss: 0.0822133\n",
      "[274]\ttraining's binary_logloss: 0.0817146\n",
      "[275]\ttraining's binary_logloss: 0.0811846\n",
      "[276]\ttraining's binary_logloss: 0.0806854\n",
      "[277]\ttraining's binary_logloss: 0.0801797\n",
      "[278]\ttraining's binary_logloss: 0.0797016\n",
      "[279]\ttraining's binary_logloss: 0.0791835\n",
      "[280]\ttraining's binary_logloss: 0.078664\n",
      "[281]\ttraining's binary_logloss: 0.0781677\n",
      "[282]\ttraining's binary_logloss: 0.0776846\n",
      "[283]\ttraining's binary_logloss: 0.0771988\n",
      "[284]\ttraining's binary_logloss: 0.0767476\n",
      "[285]\ttraining's binary_logloss: 0.0762273\n",
      "[286]\ttraining's binary_logloss: 0.0757909\n",
      "[287]\ttraining's binary_logloss: 0.0753366\n",
      "[288]\ttraining's binary_logloss: 0.0748528\n",
      "[289]\ttraining's binary_logloss: 0.0744233\n",
      "[290]\ttraining's binary_logloss: 0.0739606\n",
      "[291]\ttraining's binary_logloss: 0.0735062\n",
      "[292]\ttraining's binary_logloss: 0.073061\n",
      "[293]\ttraining's binary_logloss: 0.0725825\n",
      "[294]\ttraining's binary_logloss: 0.0721201\n",
      "[295]\ttraining's binary_logloss: 0.0716972\n",
      "[296]\ttraining's binary_logloss: 0.0712551\n",
      "[297]\ttraining's binary_logloss: 0.0708369\n",
      "[298]\ttraining's binary_logloss: 0.0703988\n",
      "[299]\ttraining's binary_logloss: 0.0699661\n",
      "[300]\ttraining's binary_logloss: 0.0695341\n",
      "[301]\ttraining's binary_logloss: 0.069124\n",
      "[302]\ttraining's binary_logloss: 0.0686983\n",
      "[303]\ttraining's binary_logloss: 0.0683008\n",
      "[304]\ttraining's binary_logloss: 0.0678825\n",
      "[305]\ttraining's binary_logloss: 0.067455\n",
      "[306]\ttraining's binary_logloss: 0.0670487\n",
      "[307]\ttraining's binary_logloss: 0.0665981\n",
      "[308]\ttraining's binary_logloss: 0.0661503\n",
      "[309]\ttraining's binary_logloss: 0.0657405\n",
      "[310]\ttraining's binary_logloss: 0.0653469\n",
      "[311]\ttraining's binary_logloss: 0.0649682\n",
      "[312]\ttraining's binary_logloss: 0.0645637\n",
      "[313]\ttraining's binary_logloss: 0.0641745\n",
      "[314]\ttraining's binary_logloss: 0.0637981\n",
      "[315]\ttraining's binary_logloss: 0.0633996\n",
      "[316]\ttraining's binary_logloss: 0.0630001\n",
      "[317]\ttraining's binary_logloss: 0.0626312\n",
      "[318]\ttraining's binary_logloss: 0.0622683\n",
      "[319]\ttraining's binary_logloss: 0.0619007\n",
      "[320]\ttraining's binary_logloss: 0.0615333\n",
      "[321]\ttraining's binary_logloss: 0.0611248\n",
      "[322]\ttraining's binary_logloss: 0.0607679\n",
      "[323]\ttraining's binary_logloss: 0.0604092\n",
      "[324]\ttraining's binary_logloss: 0.0600774\n",
      "[325]\ttraining's binary_logloss: 0.0597025\n",
      "[326]\ttraining's binary_logloss: 0.05932\n",
      "[327]\ttraining's binary_logloss: 0.0589469\n",
      "[328]\ttraining's binary_logloss: 0.0585932\n",
      "[329]\ttraining's binary_logloss: 0.0582135\n",
      "[330]\ttraining's binary_logloss: 0.0578516\n",
      "[331]\ttraining's binary_logloss: 0.0575074\n",
      "[332]\ttraining's binary_logloss: 0.0571619\n",
      "[333]\ttraining's binary_logloss: 0.0568067\n",
      "[334]\ttraining's binary_logloss: 0.0564801\n",
      "[335]\ttraining's binary_logloss: 0.0561347\n",
      "[336]\ttraining's binary_logloss: 0.0557764\n",
      "[337]\ttraining's binary_logloss: 0.0554525\n",
      "[338]\ttraining's binary_logloss: 0.0551158\n",
      "[339]\ttraining's binary_logloss: 0.0547616\n",
      "[340]\ttraining's binary_logloss: 0.0544307\n",
      "[341]\ttraining's binary_logloss: 0.0541161\n",
      "[342]\ttraining's binary_logloss: 0.0537863\n",
      "[343]\ttraining's binary_logloss: 0.0534378\n",
      "[344]\ttraining's binary_logloss: 0.0531291\n",
      "[345]\ttraining's binary_logloss: 0.0527817\n",
      "[346]\ttraining's binary_logloss: 0.0524369\n",
      "[347]\ttraining's binary_logloss: 0.05211\n",
      "[348]\ttraining's binary_logloss: 0.0517756\n",
      "[349]\ttraining's binary_logloss: 0.0514653\n",
      "[350]\ttraining's binary_logloss: 0.0511593\n",
      "[351]\ttraining's binary_logloss: 0.0508481\n",
      "[352]\ttraining's binary_logloss: 0.0505586\n",
      "[353]\ttraining's binary_logloss: 0.0502373\n",
      "[354]\ttraining's binary_logloss: 0.0499464\n",
      "[355]\ttraining's binary_logloss: 0.0496387\n",
      "[356]\ttraining's binary_logloss: 0.0493405\n",
      "[357]\ttraining's binary_logloss: 0.0490513\n",
      "[358]\ttraining's binary_logloss: 0.0487737\n",
      "[359]\ttraining's binary_logloss: 0.0484767\n",
      "[360]\ttraining's binary_logloss: 0.0481772\n",
      "[361]\ttraining's binary_logloss: 0.0478762\n",
      "[362]\ttraining's binary_logloss: 0.0475689\n",
      "[363]\ttraining's binary_logloss: 0.0472796\n",
      "[364]\ttraining's binary_logloss: 0.046969\n",
      "[365]\ttraining's binary_logloss: 0.0466888\n",
      "[366]\ttraining's binary_logloss: 0.0464178\n",
      "[367]\ttraining's binary_logloss: 0.0461345\n",
      "[368]\ttraining's binary_logloss: 0.0458542\n",
      "[369]\ttraining's binary_logloss: 0.0455677\n",
      "[370]\ttraining's binary_logloss: 0.0453118\n",
      "[371]\ttraining's binary_logloss: 0.0450442\n",
      "[372]\ttraining's binary_logloss: 0.0447539\n",
      "[373]\ttraining's binary_logloss: 0.0444778\n",
      "[374]\ttraining's binary_logloss: 0.0442188\n",
      "[375]\ttraining's binary_logloss: 0.0439757\n",
      "[376]\ttraining's binary_logloss: 0.0437216\n",
      "[377]\ttraining's binary_logloss: 0.0434576\n",
      "[378]\ttraining's binary_logloss: 0.0432212\n",
      "[379]\ttraining's binary_logloss: 0.0429376\n",
      "[380]\ttraining's binary_logloss: 0.042668\n",
      "[381]\ttraining's binary_logloss: 0.0424189\n",
      "[382]\ttraining's binary_logloss: 0.0421703\n",
      "[383]\ttraining's binary_logloss: 0.0419252\n",
      "[384]\ttraining's binary_logloss: 0.0416768\n",
      "[385]\ttraining's binary_logloss: 0.0414385\n",
      "[386]\ttraining's binary_logloss: 0.0411971\n",
      "[387]\ttraining's binary_logloss: 0.0409479\n",
      "[388]\ttraining's binary_logloss: 0.040702\n",
      "[389]\ttraining's binary_logloss: 0.0404665\n",
      "[390]\ttraining's binary_logloss: 0.0402121\n",
      "[391]\ttraining's binary_logloss: 0.0399639\n",
      "[392]\ttraining's binary_logloss: 0.039706\n",
      "[393]\ttraining's binary_logloss: 0.0394432\n",
      "[394]\ttraining's binary_logloss: 0.0392077\n",
      "[395]\ttraining's binary_logloss: 0.0389622\n",
      "[396]\ttraining's binary_logloss: 0.0387474\n",
      "[397]\ttraining's binary_logloss: 0.0385091\n",
      "[398]\ttraining's binary_logloss: 0.0382686\n",
      "[399]\ttraining's binary_logloss: 0.0380453\n",
      "[400]\ttraining's binary_logloss: 0.0378076\n",
      "[401]\ttraining's binary_logloss: 0.0375649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[402]\ttraining's binary_logloss: 0.0373257\n",
      "[403]\ttraining's binary_logloss: 0.0371167\n",
      "[404]\ttraining's binary_logloss: 0.0368923\n",
      "[405]\ttraining's binary_logloss: 0.0366763\n",
      "[406]\ttraining's binary_logloss: 0.0364383\n",
      "[407]\ttraining's binary_logloss: 0.0362066\n",
      "[408]\ttraining's binary_logloss: 0.0359912\n",
      "[409]\ttraining's binary_logloss: 0.0357488\n",
      "[410]\ttraining's binary_logloss: 0.0355183\n",
      "[411]\ttraining's binary_logloss: 0.0353141\n",
      "[412]\ttraining's binary_logloss: 0.0350905\n",
      "[413]\ttraining's binary_logloss: 0.034861\n",
      "[414]\ttraining's binary_logloss: 0.0346511\n",
      "[415]\ttraining's binary_logloss: 0.0344558\n",
      "[416]\ttraining's binary_logloss: 0.0342635\n",
      "[417]\ttraining's binary_logloss: 0.0340507\n",
      "[418]\ttraining's binary_logloss: 0.0338527\n",
      "[419]\ttraining's binary_logloss: 0.0336492\n",
      "[420]\ttraining's binary_logloss: 0.0334557\n",
      "[421]\ttraining's binary_logloss: 0.0332504\n",
      "[422]\ttraining's binary_logloss: 0.0330607\n",
      "[423]\ttraining's binary_logloss: 0.0328664\n",
      "[424]\ttraining's binary_logloss: 0.0326612\n",
      "[425]\ttraining's binary_logloss: 0.0324728\n",
      "[426]\ttraining's binary_logloss: 0.0322921\n",
      "[427]\ttraining's binary_logloss: 0.0321074\n",
      "[428]\ttraining's binary_logloss: 0.0319369\n",
      "[429]\ttraining's binary_logloss: 0.0317525\n",
      "[430]\ttraining's binary_logloss: 0.0315747\n",
      "[431]\ttraining's binary_logloss: 0.0313798\n",
      "[432]\ttraining's binary_logloss: 0.031186\n",
      "[433]\ttraining's binary_logloss: 0.0309985\n",
      "[434]\ttraining's binary_logloss: 0.0308053\n",
      "[435]\ttraining's binary_logloss: 0.0306239\n",
      "[436]\ttraining's binary_logloss: 0.030459\n",
      "[437]\ttraining's binary_logloss: 0.0302719\n",
      "[438]\ttraining's binary_logloss: 0.0301062\n",
      "[439]\ttraining's binary_logloss: 0.0299318\n",
      "[440]\ttraining's binary_logloss: 0.0297664\n",
      "[441]\ttraining's binary_logloss: 0.0295815\n",
      "[442]\ttraining's binary_logloss: 0.0294029\n",
      "[443]\ttraining's binary_logloss: 0.0292106\n",
      "[444]\ttraining's binary_logloss: 0.0290376\n",
      "[445]\ttraining's binary_logloss: 0.0288589\n",
      "[446]\ttraining's binary_logloss: 0.0286976\n",
      "[447]\ttraining's binary_logloss: 0.0285412\n",
      "[448]\ttraining's binary_logloss: 0.0283613\n",
      "[449]\ttraining's binary_logloss: 0.0281939\n",
      "[450]\ttraining's binary_logloss: 0.028016\n",
      "[451]\ttraining's binary_logloss: 0.0278398\n",
      "[452]\ttraining's binary_logloss: 0.0276633\n",
      "[453]\ttraining's binary_logloss: 0.0275007\n",
      "[454]\ttraining's binary_logloss: 0.0273283\n",
      "[455]\ttraining's binary_logloss: 0.0271643\n",
      "[456]\ttraining's binary_logloss: 0.027012\n",
      "[457]\ttraining's binary_logloss: 0.0268527\n",
      "[458]\ttraining's binary_logloss: 0.0266785\n",
      "[459]\ttraining's binary_logloss: 0.0265207\n",
      "[460]\ttraining's binary_logloss: 0.0263713\n",
      "[461]\ttraining's binary_logloss: 0.0262156\n",
      "[462]\ttraining's binary_logloss: 0.0260583\n",
      "[463]\ttraining's binary_logloss: 0.025899\n",
      "[464]\ttraining's binary_logloss: 0.0257325\n",
      "[465]\ttraining's binary_logloss: 0.0255732\n",
      "[466]\ttraining's binary_logloss: 0.0254241\n",
      "[467]\ttraining's binary_logloss: 0.0252867\n",
      "[468]\ttraining's binary_logloss: 0.0251232\n",
      "[469]\ttraining's binary_logloss: 0.024968\n",
      "[470]\ttraining's binary_logloss: 0.0248182\n",
      "[471]\ttraining's binary_logloss: 0.024658\n",
      "[472]\ttraining's binary_logloss: 0.0245199\n",
      "[473]\ttraining's binary_logloss: 0.0243791\n",
      "[474]\ttraining's binary_logloss: 0.0242309\n",
      "[475]\ttraining's binary_logloss: 0.0240794\n",
      "[476]\ttraining's binary_logloss: 0.0239355\n",
      "[477]\ttraining's binary_logloss: 0.0237819\n",
      "[478]\ttraining's binary_logloss: 0.0236444\n",
      "[479]\ttraining's binary_logloss: 0.0235032\n",
      "[480]\ttraining's binary_logloss: 0.0233627\n",
      "[481]\ttraining's binary_logloss: 0.0232154\n",
      "[482]\ttraining's binary_logloss: 0.0230639\n",
      "[483]\ttraining's binary_logloss: 0.022925\n",
      "[484]\ttraining's binary_logloss: 0.0227822\n",
      "[485]\ttraining's binary_logloss: 0.0226484\n",
      "[486]\ttraining's binary_logloss: 0.0225167\n",
      "[487]\ttraining's binary_logloss: 0.0223934\n",
      "[488]\ttraining's binary_logloss: 0.022256\n",
      "[489]\ttraining's binary_logloss: 0.0221263\n",
      "[490]\ttraining's binary_logloss: 0.0219883\n",
      "[491]\ttraining's binary_logloss: 0.021864\n",
      "[492]\ttraining's binary_logloss: 0.0217205\n",
      "[493]\ttraining's binary_logloss: 0.0215839\n",
      "[494]\ttraining's binary_logloss: 0.0214636\n",
      "[495]\ttraining's binary_logloss: 0.0213319\n",
      "[496]\ttraining's binary_logloss: 0.0212184\n",
      "[497]\ttraining's binary_logloss: 0.0210809\n",
      "[498]\ttraining's binary_logloss: 0.020965\n",
      "[499]\ttraining's binary_logloss: 0.0208345\n",
      "[500]\ttraining's binary_logloss: 0.0206997\n",
      "[501]\ttraining's binary_logloss: 0.0205845\n",
      "[502]\ttraining's binary_logloss: 0.020464\n",
      "[503]\ttraining's binary_logloss: 0.0203389\n",
      "[504]\ttraining's binary_logloss: 0.0202133\n",
      "[505]\ttraining's binary_logloss: 0.0200869\n",
      "[506]\ttraining's binary_logloss: 0.0199723\n",
      "[507]\ttraining's binary_logloss: 0.0198411\n",
      "[508]\ttraining's binary_logloss: 0.0197246\n",
      "[509]\ttraining's binary_logloss: 0.0196088\n",
      "[510]\ttraining's binary_logloss: 0.0194903\n",
      "[511]\ttraining's binary_logloss: 0.0193729\n",
      "[512]\ttraining's binary_logloss: 0.0192553\n",
      "[513]\ttraining's binary_logloss: 0.0191383\n",
      "[514]\ttraining's binary_logloss: 0.0190279\n",
      "[515]\ttraining's binary_logloss: 0.0189146\n",
      "[516]\ttraining's binary_logloss: 0.018797\n",
      "[517]\ttraining's binary_logloss: 0.0186862\n",
      "[518]\ttraining's binary_logloss: 0.0185724\n",
      "[519]\ttraining's binary_logloss: 0.0184595\n",
      "[520]\ttraining's binary_logloss: 0.0183482\n",
      "[521]\ttraining's binary_logloss: 0.0182335\n",
      "[522]\ttraining's binary_logloss: 0.0181158\n",
      "[523]\ttraining's binary_logloss: 0.0180023\n",
      "[524]\ttraining's binary_logloss: 0.0178959\n",
      "[525]\ttraining's binary_logloss: 0.0177962\n",
      "[526]\ttraining's binary_logloss: 0.0177008\n",
      "[527]\ttraining's binary_logloss: 0.0175924\n",
      "[528]\ttraining's binary_logloss: 0.0174886\n",
      "[529]\ttraining's binary_logloss: 0.0173838\n",
      "[530]\ttraining's binary_logloss: 0.017282\n",
      "[531]\ttraining's binary_logloss: 0.0171799\n",
      "[532]\ttraining's binary_logloss: 0.017085\n",
      "[533]\ttraining's binary_logloss: 0.0169761\n",
      "[534]\ttraining's binary_logloss: 0.016884\n",
      "[535]\ttraining's binary_logloss: 0.0167899\n",
      "[536]\ttraining's binary_logloss: 0.0166959\n",
      "[537]\ttraining's binary_logloss: 0.0166\n",
      "[538]\ttraining's binary_logloss: 0.0165002\n",
      "[539]\ttraining's binary_logloss: 0.0164002\n",
      "[540]\ttraining's binary_logloss: 0.0162975\n",
      "[541]\ttraining's binary_logloss: 0.0161934\n",
      "[542]\ttraining's binary_logloss: 0.0160954\n",
      "[543]\ttraining's binary_logloss: 0.0160045\n",
      "[544]\ttraining's binary_logloss: 0.0159165\n",
      "[545]\ttraining's binary_logloss: 0.01583\n",
      "[546]\ttraining's binary_logloss: 0.0157333\n",
      "[547]\ttraining's binary_logloss: 0.0156408\n",
      "[548]\ttraining's binary_logloss: 0.0155479\n",
      "[549]\ttraining's binary_logloss: 0.0154561\n",
      "[550]\ttraining's binary_logloss: 0.0153691\n",
      "[551]\ttraining's binary_logloss: 0.0152819\n",
      "[552]\ttraining's binary_logloss: 0.0151888\n",
      "[553]\ttraining's binary_logloss: 0.0150973\n",
      "[554]\ttraining's binary_logloss: 0.0150024\n",
      "[555]\ttraining's binary_logloss: 0.0149113\n",
      "[556]\ttraining's binary_logloss: 0.0148246\n",
      "[557]\ttraining's binary_logloss: 0.0147397\n",
      "[558]\ttraining's binary_logloss: 0.0146608\n",
      "[559]\ttraining's binary_logloss: 0.0145743\n",
      "[560]\ttraining's binary_logloss: 0.0144882\n",
      "[561]\ttraining's binary_logloss: 0.0143957\n",
      "[562]\ttraining's binary_logloss: 0.0143047\n",
      "[563]\ttraining's binary_logloss: 0.0142255\n",
      "[564]\ttraining's binary_logloss: 0.014135\n",
      "[565]\ttraining's binary_logloss: 0.0140518\n",
      "[566]\ttraining's binary_logloss: 0.0139708\n",
      "[567]\ttraining's binary_logloss: 0.0138856\n",
      "[568]\ttraining's binary_logloss: 0.0138059\n",
      "[569]\ttraining's binary_logloss: 0.0137201\n",
      "[570]\ttraining's binary_logloss: 0.0136436\n",
      "[571]\ttraining's binary_logloss: 0.0135605\n",
      "[572]\ttraining's binary_logloss: 0.0134775\n",
      "[573]\ttraining's binary_logloss: 0.013397\n",
      "[574]\ttraining's binary_logloss: 0.0133157\n",
      "[575]\ttraining's binary_logloss: 0.0132354\n",
      "[576]\ttraining's binary_logloss: 0.0131539\n",
      "[577]\ttraining's binary_logloss: 0.0130717\n",
      "[578]\ttraining's binary_logloss: 0.0129973\n",
      "[579]\ttraining's binary_logloss: 0.012917\n",
      "[580]\ttraining's binary_logloss: 0.0128373\n",
      "[581]\ttraining's binary_logloss: 0.012757\n",
      "[582]\ttraining's binary_logloss: 0.0126778\n",
      "[583]\ttraining's binary_logloss: 0.0125993\n",
      "[584]\ttraining's binary_logloss: 0.0125252\n",
      "[585]\ttraining's binary_logloss: 0.0124516\n",
      "[586]\ttraining's binary_logloss: 0.0123776\n",
      "[587]\ttraining's binary_logloss: 0.0123039\n",
      "[588]\ttraining's binary_logloss: 0.01223\n",
      "[589]\ttraining's binary_logloss: 0.0121618\n",
      "[590]\ttraining's binary_logloss: 0.0120865\n",
      "[591]\ttraining's binary_logloss: 0.0120164\n",
      "[592]\ttraining's binary_logloss: 0.0119457\n",
      "[593]\ttraining's binary_logloss: 0.011874\n",
      "[594]\ttraining's binary_logloss: 0.0118035\n",
      "[595]\ttraining's binary_logloss: 0.0117305\n",
      "[596]\ttraining's binary_logloss: 0.0116665\n",
      "[597]\ttraining's binary_logloss: 0.0116014\n",
      "[598]\ttraining's binary_logloss: 0.0115339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[599]\ttraining's binary_logloss: 0.0114648\n",
      "[600]\ttraining's binary_logloss: 0.0114047\n",
      "[601]\ttraining's binary_logloss: 0.0113338\n",
      "[602]\ttraining's binary_logloss: 0.011273\n",
      "[603]\ttraining's binary_logloss: 0.0112048\n",
      "[604]\ttraining's binary_logloss: 0.0111345\n",
      "[605]\ttraining's binary_logloss: 0.0110654\n",
      "[606]\ttraining's binary_logloss: 0.0110011\n",
      "[607]\ttraining's binary_logloss: 0.010935\n",
      "[608]\ttraining's binary_logloss: 0.0108658\n",
      "[609]\ttraining's binary_logloss: 0.0108001\n",
      "[610]\ttraining's binary_logloss: 0.0107403\n",
      "[611]\ttraining's binary_logloss: 0.010678\n",
      "[612]\ttraining's binary_logloss: 0.0106103\n",
      "[613]\ttraining's binary_logloss: 0.0105537\n",
      "[614]\ttraining's binary_logloss: 0.0104904\n",
      "[615]\ttraining's binary_logloss: 0.010431\n",
      "[616]\ttraining's binary_logloss: 0.0103736\n",
      "[617]\ttraining's binary_logloss: 0.0103108\n",
      "[618]\ttraining's binary_logloss: 0.0102497\n",
      "[619]\ttraining's binary_logloss: 0.0101876\n",
      "[620]\ttraining's binary_logloss: 0.0101252\n",
      "[621]\ttraining's binary_logloss: 0.0100636\n",
      "[622]\ttraining's binary_logloss: 0.0100044\n",
      "[623]\ttraining's binary_logloss: 0.0099461\n",
      "[624]\ttraining's binary_logloss: 0.00988554\n",
      "[625]\ttraining's binary_logloss: 0.00982206\n",
      "[626]\ttraining's binary_logloss: 0.00976435\n",
      "[627]\ttraining's binary_logloss: 0.00970246\n",
      "[628]\ttraining's binary_logloss: 0.00964615\n",
      "[629]\ttraining's binary_logloss: 0.00958751\n",
      "[630]\ttraining's binary_logloss: 0.00953208\n",
      "[631]\ttraining's binary_logloss: 0.00946971\n",
      "[632]\ttraining's binary_logloss: 0.00941365\n",
      "[633]\ttraining's binary_logloss: 0.00935883\n",
      "[634]\ttraining's binary_logloss: 0.00930522\n",
      "[635]\ttraining's binary_logloss: 0.00924813\n",
      "[636]\ttraining's binary_logloss: 0.00919051\n",
      "[637]\ttraining's binary_logloss: 0.00914064\n",
      "[638]\ttraining's binary_logloss: 0.00908842\n",
      "[639]\ttraining's binary_logloss: 0.00903767\n",
      "[640]\ttraining's binary_logloss: 0.00898742\n",
      "[641]\ttraining's binary_logloss: 0.00893255\n",
      "[642]\ttraining's binary_logloss: 0.00888334\n",
      "[643]\ttraining's binary_logloss: 0.008831\n",
      "[644]\ttraining's binary_logloss: 0.00877611\n",
      "[645]\ttraining's binary_logloss: 0.00872215\n",
      "[646]\ttraining's binary_logloss: 0.0086679\n",
      "[647]\ttraining's binary_logloss: 0.00861288\n",
      "[648]\ttraining's binary_logloss: 0.00855815\n",
      "[649]\ttraining's binary_logloss: 0.00850551\n",
      "[650]\ttraining's binary_logloss: 0.00845549\n",
      "[651]\ttraining's binary_logloss: 0.00840291\n",
      "[652]\ttraining's binary_logloss: 0.00834959\n",
      "[653]\ttraining's binary_logloss: 0.00829938\n",
      "[654]\ttraining's binary_logloss: 0.00825125\n",
      "[655]\ttraining's binary_logloss: 0.00820338\n",
      "[656]\ttraining's binary_logloss: 0.00815464\n",
      "[657]\ttraining's binary_logloss: 0.0081016\n",
      "[658]\ttraining's binary_logloss: 0.00805551\n",
      "[659]\ttraining's binary_logloss: 0.00801142\n",
      "[660]\ttraining's binary_logloss: 0.00796364\n",
      "[661]\ttraining's binary_logloss: 0.00791401\n",
      "[662]\ttraining's binary_logloss: 0.00786699\n",
      "[663]\ttraining's binary_logloss: 0.00782272\n",
      "[664]\ttraining's binary_logloss: 0.00777592\n",
      "[665]\ttraining's binary_logloss: 0.00773115\n",
      "[666]\ttraining's binary_logloss: 0.0076831\n",
      "[667]\ttraining's binary_logloss: 0.0076323\n",
      "[668]\ttraining's binary_logloss: 0.00758894\n",
      "[669]\ttraining's binary_logloss: 0.00754405\n",
      "[670]\ttraining's binary_logloss: 0.00749908\n",
      "[671]\ttraining's binary_logloss: 0.00745798\n",
      "[672]\ttraining's binary_logloss: 0.00741733\n",
      "[673]\ttraining's binary_logloss: 0.00737315\n",
      "[674]\ttraining's binary_logloss: 0.00733133\n",
      "[675]\ttraining's binary_logloss: 0.00728655\n",
      "[676]\ttraining's binary_logloss: 0.0072448\n",
      "[677]\ttraining's binary_logloss: 0.00720384\n",
      "[678]\ttraining's binary_logloss: 0.00716205\n",
      "[679]\ttraining's binary_logloss: 0.00711851\n",
      "[680]\ttraining's binary_logloss: 0.00707499\n",
      "[681]\ttraining's binary_logloss: 0.00703506\n",
      "[682]\ttraining's binary_logloss: 0.00699663\n",
      "[683]\ttraining's binary_logloss: 0.00695322\n",
      "[684]\ttraining's binary_logloss: 0.00691219\n",
      "[685]\ttraining's binary_logloss: 0.00686989\n",
      "[686]\ttraining's binary_logloss: 0.00683011\n",
      "[687]\ttraining's binary_logloss: 0.0067914\n",
      "[688]\ttraining's binary_logloss: 0.00675061\n",
      "[689]\ttraining's binary_logloss: 0.00670902\n",
      "[690]\ttraining's binary_logloss: 0.0066706\n",
      "[691]\ttraining's binary_logloss: 0.00663133\n",
      "[692]\ttraining's binary_logloss: 0.00659438\n",
      "[693]\ttraining's binary_logloss: 0.00655728\n",
      "[694]\ttraining's binary_logloss: 0.00652176\n",
      "[695]\ttraining's binary_logloss: 0.0064854\n",
      "[696]\ttraining's binary_logloss: 0.00644565\n",
      "[697]\ttraining's binary_logloss: 0.00640549\n",
      "[698]\ttraining's binary_logloss: 0.00636768\n",
      "[699]\ttraining's binary_logloss: 0.00632867\n",
      "[700]\ttraining's binary_logloss: 0.00629183\n",
      "[701]\ttraining's binary_logloss: 0.00625329\n",
      "[702]\ttraining's binary_logloss: 0.0062141\n",
      "[703]\ttraining's binary_logloss: 0.0061775\n",
      "[704]\ttraining's binary_logloss: 0.00614171\n",
      "[705]\ttraining's binary_logloss: 0.00610446\n",
      "[706]\ttraining's binary_logloss: 0.00606915\n",
      "[707]\ttraining's binary_logloss: 0.00603321\n",
      "[708]\ttraining's binary_logloss: 0.00599769\n",
      "[709]\ttraining's binary_logloss: 0.00596197\n",
      "[710]\ttraining's binary_logloss: 0.00592809\n",
      "[711]\ttraining's binary_logloss: 0.00589072\n",
      "[712]\ttraining's binary_logloss: 0.00585756\n",
      "[713]\ttraining's binary_logloss: 0.00582263\n",
      "[714]\ttraining's binary_logloss: 0.00578935\n",
      "[715]\ttraining's binary_logloss: 0.00575318\n",
      "[716]\ttraining's binary_logloss: 0.00571927\n",
      "[717]\ttraining's binary_logloss: 0.00568661\n",
      "[718]\ttraining's binary_logloss: 0.00565485\n",
      "[719]\ttraining's binary_logloss: 0.00562065\n",
      "[720]\ttraining's binary_logloss: 0.00558659\n",
      "[721]\ttraining's binary_logloss: 0.00555621\n",
      "[722]\ttraining's binary_logloss: 0.00552461\n",
      "[723]\ttraining's binary_logloss: 0.00548725\n",
      "[724]\ttraining's binary_logloss: 0.00545363\n",
      "[725]\ttraining's binary_logloss: 0.00542501\n",
      "[726]\ttraining's binary_logloss: 0.00539086\n",
      "[727]\ttraining's binary_logloss: 0.00535747\n",
      "[728]\ttraining's binary_logloss: 0.0053245\n",
      "[729]\ttraining's binary_logloss: 0.00529135\n",
      "[730]\ttraining's binary_logloss: 0.00525911\n",
      "[731]\ttraining's binary_logloss: 0.00523193\n",
      "[732]\ttraining's binary_logloss: 0.00520303\n",
      "[733]\ttraining's binary_logloss: 0.00517073\n",
      "[734]\ttraining's binary_logloss: 0.00513923\n",
      "[735]\ttraining's binary_logloss: 0.00510731\n",
      "[736]\ttraining's binary_logloss: 0.00507765\n",
      "[737]\ttraining's binary_logloss: 0.00504934\n",
      "[738]\ttraining's binary_logloss: 0.00502058\n",
      "[739]\ttraining's binary_logloss: 0.00498988\n",
      "[740]\ttraining's binary_logloss: 0.00495988\n",
      "[741]\ttraining's binary_logloss: 0.00493168\n",
      "[742]\ttraining's binary_logloss: 0.00490316\n",
      "[743]\ttraining's binary_logloss: 0.00487218\n",
      "[744]\ttraining's binary_logloss: 0.00484335\n",
      "[745]\ttraining's binary_logloss: 0.00481325\n",
      "[746]\ttraining's binary_logloss: 0.00478373\n",
      "[747]\ttraining's binary_logloss: 0.0047542\n",
      "[748]\ttraining's binary_logloss: 0.00472695\n",
      "[749]\ttraining's binary_logloss: 0.00469749\n",
      "[750]\ttraining's binary_logloss: 0.00467112\n",
      "[751]\ttraining's binary_logloss: 0.00464545\n",
      "[752]\ttraining's binary_logloss: 0.00461947\n",
      "[753]\ttraining's binary_logloss: 0.00459302\n",
      "[754]\ttraining's binary_logloss: 0.0045663\n",
      "[755]\ttraining's binary_logloss: 0.0045405\n",
      "[756]\ttraining's binary_logloss: 0.00451547\n",
      "[757]\ttraining's binary_logloss: 0.00448909\n",
      "[758]\ttraining's binary_logloss: 0.00446418\n",
      "[759]\ttraining's binary_logloss: 0.00443611\n",
      "[760]\ttraining's binary_logloss: 0.004408\n",
      "[761]\ttraining's binary_logloss: 0.00438116\n",
      "[762]\ttraining's binary_logloss: 0.00435457\n",
      "[763]\ttraining's binary_logloss: 0.0043295\n",
      "[764]\ttraining's binary_logloss: 0.00430189\n",
      "[765]\ttraining's binary_logloss: 0.00427605\n",
      "[766]\ttraining's binary_logloss: 0.0042492\n",
      "[767]\ttraining's binary_logloss: 0.00422444\n",
      "[768]\ttraining's binary_logloss: 0.00419766\n",
      "[769]\ttraining's binary_logloss: 0.00417152\n",
      "[770]\ttraining's binary_logloss: 0.00414771\n",
      "[771]\ttraining's binary_logloss: 0.00412308\n",
      "[772]\ttraining's binary_logloss: 0.00410001\n",
      "[773]\ttraining's binary_logloss: 0.00407691\n",
      "[774]\ttraining's binary_logloss: 0.00405275\n",
      "[775]\ttraining's binary_logloss: 0.00402913\n",
      "[776]\ttraining's binary_logloss: 0.00400361\n",
      "[777]\ttraining's binary_logloss: 0.00398076\n",
      "[778]\ttraining's binary_logloss: 0.00395862\n",
      "[779]\ttraining's binary_logloss: 0.00393586\n",
      "[780]\ttraining's binary_logloss: 0.00391193\n",
      "[781]\ttraining's binary_logloss: 0.00389011\n",
      "[782]\ttraining's binary_logloss: 0.00386823\n",
      "[783]\ttraining's binary_logloss: 0.00384351\n",
      "[784]\ttraining's binary_logloss: 0.0038197\n",
      "[785]\ttraining's binary_logloss: 0.00379875\n",
      "[786]\ttraining's binary_logloss: 0.00377606\n",
      "[787]\ttraining's binary_logloss: 0.00375401\n",
      "[788]\ttraining's binary_logloss: 0.00373146\n",
      "[789]\ttraining's binary_logloss: 0.00371016\n",
      "[790]\ttraining's binary_logloss: 0.00368708\n",
      "[791]\ttraining's binary_logloss: 0.00366462\n",
      "[792]\ttraining's binary_logloss: 0.00364376\n",
      "[793]\ttraining's binary_logloss: 0.00362129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[794]\ttraining's binary_logloss: 0.00360002\n",
      "[795]\ttraining's binary_logloss: 0.00357909\n",
      "[796]\ttraining's binary_logloss: 0.00355887\n",
      "[797]\ttraining's binary_logloss: 0.0035378\n",
      "[798]\ttraining's binary_logloss: 0.00351688\n",
      "[799]\ttraining's binary_logloss: 0.00349544\n",
      "[800]\ttraining's binary_logloss: 0.00347679\n",
      "[801]\ttraining's binary_logloss: 0.00345545\n",
      "[802]\ttraining's binary_logloss: 0.00343412\n",
      "[803]\ttraining's binary_logloss: 0.00341399\n",
      "[804]\ttraining's binary_logloss: 0.00339345\n",
      "[805]\ttraining's binary_logloss: 0.00337358\n",
      "[806]\ttraining's binary_logloss: 0.00335217\n",
      "[807]\ttraining's binary_logloss: 0.00333184\n",
      "[808]\ttraining's binary_logloss: 0.00331256\n",
      "[809]\ttraining's binary_logloss: 0.00329296\n",
      "[810]\ttraining's binary_logloss: 0.00327441\n",
      "[811]\ttraining's binary_logloss: 0.00325583\n",
      "[812]\ttraining's binary_logloss: 0.00323594\n",
      "[813]\ttraining's binary_logloss: 0.00321508\n",
      "[814]\ttraining's binary_logloss: 0.00319488\n",
      "[815]\ttraining's binary_logloss: 0.00317641\n",
      "[816]\ttraining's binary_logloss: 0.00315638\n",
      "[817]\ttraining's binary_logloss: 0.00313794\n",
      "[818]\ttraining's binary_logloss: 0.00311955\n",
      "[819]\ttraining's binary_logloss: 0.00309969\n",
      "[820]\ttraining's binary_logloss: 0.00308001\n",
      "[821]\ttraining's binary_logloss: 0.00306054\n",
      "[822]\ttraining's binary_logloss: 0.00304326\n",
      "[823]\ttraining's binary_logloss: 0.00302464\n",
      "[824]\ttraining's binary_logloss: 0.00300621\n",
      "[825]\ttraining's binary_logloss: 0.00298881\n",
      "[826]\ttraining's binary_logloss: 0.00297075\n",
      "[827]\ttraining's binary_logloss: 0.0029526\n",
      "[828]\ttraining's binary_logloss: 0.00293467\n",
      "[829]\ttraining's binary_logloss: 0.0029193\n",
      "[830]\ttraining's binary_logloss: 0.00290054\n",
      "[831]\ttraining's binary_logloss: 0.00288242\n",
      "[832]\ttraining's binary_logloss: 0.00286483\n",
      "[833]\ttraining's binary_logloss: 0.00284799\n",
      "[834]\ttraining's binary_logloss: 0.00283049\n",
      "[835]\ttraining's binary_logloss: 0.0028139\n",
      "[836]\ttraining's binary_logloss: 0.00279611\n",
      "[837]\ttraining's binary_logloss: 0.00278052\n",
      "[838]\ttraining's binary_logloss: 0.00276587\n",
      "[839]\ttraining's binary_logloss: 0.00274969\n",
      "[840]\ttraining's binary_logloss: 0.00273224\n",
      "[841]\ttraining's binary_logloss: 0.00271478\n",
      "[842]\ttraining's binary_logloss: 0.00269852\n",
      "[843]\ttraining's binary_logloss: 0.0026827\n",
      "[844]\ttraining's binary_logloss: 0.00266806\n",
      "[845]\ttraining's binary_logloss: 0.00265188\n",
      "[846]\ttraining's binary_logloss: 0.00263526\n",
      "[847]\ttraining's binary_logloss: 0.0026191\n",
      "[848]\ttraining's binary_logloss: 0.00260279\n",
      "[849]\ttraining's binary_logloss: 0.00258715\n",
      "[850]\ttraining's binary_logloss: 0.00257184\n",
      "[851]\ttraining's binary_logloss: 0.00255679\n",
      "[852]\ttraining's binary_logloss: 0.00254352\n",
      "[853]\ttraining's binary_logloss: 0.0025296\n",
      "[854]\ttraining's binary_logloss: 0.00251454\n",
      "[855]\ttraining's binary_logloss: 0.00249922\n",
      "[856]\ttraining's binary_logloss: 0.00248372\n",
      "[857]\ttraining's binary_logloss: 0.00246935\n",
      "[858]\ttraining's binary_logloss: 0.00245521\n",
      "[859]\ttraining's binary_logloss: 0.00244101\n",
      "[860]\ttraining's binary_logloss: 0.00242607\n",
      "[861]\ttraining's binary_logloss: 0.00241154\n",
      "[862]\ttraining's binary_logloss: 0.00239646\n",
      "[863]\ttraining's binary_logloss: 0.00238142\n",
      "[864]\ttraining's binary_logloss: 0.0023679\n",
      "[865]\ttraining's binary_logloss: 0.00235464\n",
      "[866]\ttraining's binary_logloss: 0.00234116\n",
      "[867]\ttraining's binary_logloss: 0.00232749\n",
      "[868]\ttraining's binary_logloss: 0.00231444\n",
      "[869]\ttraining's binary_logloss: 0.00230163\n",
      "[870]\ttraining's binary_logloss: 0.00228876\n",
      "[871]\ttraining's binary_logloss: 0.00227607\n",
      "[872]\ttraining's binary_logloss: 0.00226328\n",
      "[873]\ttraining's binary_logloss: 0.0022493\n",
      "[874]\ttraining's binary_logloss: 0.00223525\n",
      "[875]\ttraining's binary_logloss: 0.00222298\n",
      "[876]\ttraining's binary_logloss: 0.00220891\n",
      "[877]\ttraining's binary_logloss: 0.00219618\n",
      "[878]\ttraining's binary_logloss: 0.00218382\n",
      "[879]\ttraining's binary_logloss: 0.00217096\n",
      "[880]\ttraining's binary_logloss: 0.00215835\n",
      "[881]\ttraining's binary_logloss: 0.00214443\n",
      "[882]\ttraining's binary_logloss: 0.00213067\n",
      "[883]\ttraining's binary_logloss: 0.002117\n",
      "[884]\ttraining's binary_logloss: 0.00210498\n",
      "[885]\ttraining's binary_logloss: 0.00209141\n",
      "[886]\ttraining's binary_logloss: 0.00207785\n",
      "[887]\ttraining's binary_logloss: 0.00206492\n",
      "[888]\ttraining's binary_logloss: 0.00205227\n",
      "[889]\ttraining's binary_logloss: 0.00203997\n",
      "[890]\ttraining's binary_logloss: 0.00202805\n",
      "[891]\ttraining's binary_logloss: 0.00201551\n",
      "[892]\ttraining's binary_logloss: 0.00200461\n",
      "[893]\ttraining's binary_logloss: 0.00199376\n",
      "[894]\ttraining's binary_logloss: 0.00198267\n",
      "[895]\ttraining's binary_logloss: 0.00197127\n",
      "[896]\ttraining's binary_logloss: 0.00195918\n",
      "[897]\ttraining's binary_logloss: 0.001947\n",
      "[898]\ttraining's binary_logloss: 0.00193488\n",
      "[899]\ttraining's binary_logloss: 0.00192409\n",
      "[900]\ttraining's binary_logloss: 0.00191434\n",
      "[901]\ttraining's binary_logloss: 0.00190294\n",
      "[902]\ttraining's binary_logloss: 0.00189071\n",
      "[903]\ttraining's binary_logloss: 0.00187913\n",
      "[904]\ttraining's binary_logloss: 0.00186774\n",
      "[905]\ttraining's binary_logloss: 0.00185628\n",
      "[906]\ttraining's binary_logloss: 0.00184594\n",
      "[907]\ttraining's binary_logloss: 0.0018345\n",
      "[908]\ttraining's binary_logloss: 0.00182287\n",
      "[909]\ttraining's binary_logloss: 0.00181293\n",
      "[910]\ttraining's binary_logloss: 0.00180281\n",
      "[911]\ttraining's binary_logloss: 0.00179269\n",
      "[912]\ttraining's binary_logloss: 0.00178207\n",
      "[913]\ttraining's binary_logloss: 0.00177098\n",
      "[914]\ttraining's binary_logloss: 0.00176006\n",
      "[915]\ttraining's binary_logloss: 0.00174905\n",
      "[916]\ttraining's binary_logloss: 0.00173846\n",
      "[917]\ttraining's binary_logloss: 0.00172789\n",
      "[918]\ttraining's binary_logloss: 0.00171658\n",
      "[919]\ttraining's binary_logloss: 0.0017063\n",
      "[920]\ttraining's binary_logloss: 0.00169559\n",
      "[921]\ttraining's binary_logloss: 0.00168513\n",
      "[922]\ttraining's binary_logloss: 0.00167518\n",
      "[923]\ttraining's binary_logloss: 0.0016649\n",
      "[924]\ttraining's binary_logloss: 0.00165477\n",
      "[925]\ttraining's binary_logloss: 0.00164538\n",
      "[926]\ttraining's binary_logloss: 0.00163523\n",
      "[927]\ttraining's binary_logloss: 0.00162576\n",
      "[928]\ttraining's binary_logloss: 0.0016164\n",
      "[929]\ttraining's binary_logloss: 0.00160636\n",
      "[930]\ttraining's binary_logloss: 0.00159745\n",
      "[931]\ttraining's binary_logloss: 0.00158779\n",
      "[932]\ttraining's binary_logloss: 0.00157775\n",
      "[933]\ttraining's binary_logloss: 0.00156853\n",
      "[934]\ttraining's binary_logloss: 0.00155867\n",
      "[935]\ttraining's binary_logloss: 0.00154948\n",
      "[936]\ttraining's binary_logloss: 0.00153997\n",
      "[937]\ttraining's binary_logloss: 0.00153051\n",
      "[938]\ttraining's binary_logloss: 0.00152138\n",
      "[939]\ttraining's binary_logloss: 0.00151201\n",
      "[940]\ttraining's binary_logloss: 0.00150267\n",
      "[941]\ttraining's binary_logloss: 0.00149322\n",
      "[942]\ttraining's binary_logloss: 0.00148413\n",
      "[943]\ttraining's binary_logloss: 0.00147504\n",
      "[944]\ttraining's binary_logloss: 0.00146599\n",
      "[945]\ttraining's binary_logloss: 0.00145711\n",
      "[946]\ttraining's binary_logloss: 0.00144855\n",
      "[947]\ttraining's binary_logloss: 0.00144\n",
      "[948]\ttraining's binary_logloss: 0.00143135\n",
      "[949]\ttraining's binary_logloss: 0.00142267\n",
      "[950]\ttraining's binary_logloss: 0.00141486\n",
      "[951]\ttraining's binary_logloss: 0.00140682\n",
      "[952]\ttraining's binary_logloss: 0.00139901\n",
      "[953]\ttraining's binary_logloss: 0.00139054\n",
      "[954]\ttraining's binary_logloss: 0.00138161\n",
      "[955]\ttraining's binary_logloss: 0.00137392\n",
      "[956]\ttraining's binary_logloss: 0.00136628\n",
      "[957]\ttraining's binary_logloss: 0.00135821\n",
      "[958]\ttraining's binary_logloss: 0.00135\n",
      "[959]\ttraining's binary_logloss: 0.00134163\n",
      "[960]\ttraining's binary_logloss: 0.00133397\n",
      "[961]\ttraining's binary_logloss: 0.00132695\n",
      "[962]\ttraining's binary_logloss: 0.00132006\n",
      "[963]\ttraining's binary_logloss: 0.00131169\n",
      "[964]\ttraining's binary_logloss: 0.00130455\n",
      "[965]\ttraining's binary_logloss: 0.00129752\n",
      "[966]\ttraining's binary_logloss: 0.00129045\n",
      "[967]\ttraining's binary_logloss: 0.00128231\n",
      "[968]\ttraining's binary_logloss: 0.00127454\n",
      "[969]\ttraining's binary_logloss: 0.00126689\n",
      "[970]\ttraining's binary_logloss: 0.00125937\n",
      "[971]\ttraining's binary_logloss: 0.00125222\n",
      "[972]\ttraining's binary_logloss: 0.00124465\n",
      "[973]\ttraining's binary_logloss: 0.00123742\n",
      "[974]\ttraining's binary_logloss: 0.00122936\n",
      "[975]\ttraining's binary_logloss: 0.00122175\n",
      "[976]\ttraining's binary_logloss: 0.00121464\n",
      "[977]\ttraining's binary_logloss: 0.00120747\n",
      "[978]\ttraining's binary_logloss: 0.00119997\n",
      "[979]\ttraining's binary_logloss: 0.00119239\n",
      "[980]\ttraining's binary_logloss: 0.00118551\n",
      "[981]\ttraining's binary_logloss: 0.00117931\n",
      "[982]\ttraining's binary_logloss: 0.00117203\n",
      "[983]\ttraining's binary_logloss: 0.00116441\n",
      "[984]\ttraining's binary_logloss: 0.00115714\n",
      "[985]\ttraining's binary_logloss: 0.00115088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[986]\ttraining's binary_logloss: 0.00114436\n",
      "[987]\ttraining's binary_logloss: 0.00113871\n",
      "[988]\ttraining's binary_logloss: 0.00113271\n",
      "[989]\ttraining's binary_logloss: 0.00112565\n",
      "[990]\ttraining's binary_logloss: 0.00111854\n",
      "[991]\ttraining's binary_logloss: 0.00111176\n",
      "[992]\ttraining's binary_logloss: 0.00110549\n",
      "[993]\ttraining's binary_logloss: 0.00109887\n",
      "[994]\ttraining's binary_logloss: 0.00109223\n",
      "[995]\ttraining's binary_logloss: 0.00108555\n",
      "[996]\ttraining's binary_logloss: 0.00107903\n",
      "[997]\ttraining's binary_logloss: 0.00107289\n",
      "[998]\ttraining's binary_logloss: 0.0010662\n",
      "[999]\ttraining's binary_logloss: 0.00105965\n",
      "[1000]\ttraining's binary_logloss: 0.00105353\n",
      "[1001]\ttraining's binary_logloss: 0.00104737\n",
      "[1002]\ttraining's binary_logloss: 0.00104127\n",
      "[1003]\ttraining's binary_logloss: 0.00103542\n",
      "[1004]\ttraining's binary_logloss: 0.00102947\n",
      "[1005]\ttraining's binary_logloss: 0.0010236\n",
      "[1006]\ttraining's binary_logloss: 0.00101718\n",
      "[1007]\ttraining's binary_logloss: 0.0010115\n",
      "[1008]\ttraining's binary_logloss: 0.0010051\n",
      "[1009]\ttraining's binary_logloss: 0.000999025\n",
      "[1010]\ttraining's binary_logloss: 0.000992912\n",
      "[1011]\ttraining's binary_logloss: 0.000986671\n",
      "[1012]\ttraining's binary_logloss: 0.000980413\n",
      "[1013]\ttraining's binary_logloss: 0.000975214\n",
      "[1014]\ttraining's binary_logloss: 0.00096927\n",
      "[1015]\ttraining's binary_logloss: 0.000963112\n",
      "[1016]\ttraining's binary_logloss: 0.000957783\n",
      "[1017]\ttraining's binary_logloss: 0.000952057\n",
      "[1018]\ttraining's binary_logloss: 0.000946059\n",
      "[1019]\ttraining's binary_logloss: 0.000940279\n",
      "[1020]\ttraining's binary_logloss: 0.000934543\n",
      "[1021]\ttraining's binary_logloss: 0.000928783\n",
      "[1022]\ttraining's binary_logloss: 0.000922731\n",
      "[1023]\ttraining's binary_logloss: 0.000916863\n",
      "[1024]\ttraining's binary_logloss: 0.00091141\n",
      "[1025]\ttraining's binary_logloss: 0.000905819\n",
      "[1026]\ttraining's binary_logloss: 0.000900296\n",
      "[1027]\ttraining's binary_logloss: 0.000894698\n",
      "[1028]\ttraining's binary_logloss: 0.000889357\n",
      "[1029]\ttraining's binary_logloss: 0.000884366\n",
      "[1030]\ttraining's binary_logloss: 0.00087956\n",
      "[1031]\ttraining's binary_logloss: 0.000874121\n",
      "[1032]\ttraining's binary_logloss: 0.000868976\n",
      "[1033]\ttraining's binary_logloss: 0.000864312\n",
      "[1034]\ttraining's binary_logloss: 0.000859135\n",
      "[1035]\ttraining's binary_logloss: 0.000853913\n",
      "[1036]\ttraining's binary_logloss: 0.000849466\n",
      "[1037]\ttraining's binary_logloss: 0.000844181\n",
      "[1038]\ttraining's binary_logloss: 0.000838998\n",
      "[1039]\ttraining's binary_logloss: 0.000834036\n",
      "[1040]\ttraining's binary_logloss: 0.00082889\n",
      "[1041]\ttraining's binary_logloss: 0.000824371\n",
      "[1042]\ttraining's binary_logloss: 0.000819462\n",
      "[1043]\ttraining's binary_logloss: 0.000814507\n",
      "[1044]\ttraining's binary_logloss: 0.000809728\n",
      "[1045]\ttraining's binary_logloss: 0.00080473\n",
      "[1046]\ttraining's binary_logloss: 0.000800012\n",
      "[1047]\ttraining's binary_logloss: 0.000795434\n",
      "[1048]\ttraining's binary_logloss: 0.000790847\n",
      "[1049]\ttraining's binary_logloss: 0.000786355\n",
      "[1050]\ttraining's binary_logloss: 0.000781434\n",
      "[1051]\ttraining's binary_logloss: 0.000776629\n",
      "[1052]\ttraining's binary_logloss: 0.000772094\n",
      "[1053]\ttraining's binary_logloss: 0.000767185\n",
      "[1054]\ttraining's binary_logloss: 0.000762678\n",
      "[1055]\ttraining's binary_logloss: 0.000757999\n",
      "[1056]\ttraining's binary_logloss: 0.000753559\n",
      "[1057]\ttraining's binary_logloss: 0.000748985\n",
      "[1058]\ttraining's binary_logloss: 0.00074505\n",
      "[1059]\ttraining's binary_logloss: 0.000740883\n",
      "[1060]\ttraining's binary_logloss: 0.000737021\n",
      "[1061]\ttraining's binary_logloss: 0.00073253\n",
      "[1062]\ttraining's binary_logloss: 0.000728067\n",
      "[1063]\ttraining's binary_logloss: 0.000723776\n",
      "[1064]\ttraining's binary_logloss: 0.000719198\n",
      "[1065]\ttraining's binary_logloss: 0.00071523\n",
      "[1066]\ttraining's binary_logloss: 0.000711279\n",
      "[1067]\ttraining's binary_logloss: 0.000706871\n",
      "[1068]\ttraining's binary_logloss: 0.000702822\n",
      "[1069]\ttraining's binary_logloss: 0.000698474\n",
      "[1070]\ttraining's binary_logloss: 0.000694081\n",
      "[1071]\ttraining's binary_logloss: 0.000690215\n",
      "[1072]\ttraining's binary_logloss: 0.000686193\n",
      "[1073]\ttraining's binary_logloss: 0.000682245\n",
      "[1074]\ttraining's binary_logloss: 0.000677988\n",
      "[1075]\ttraining's binary_logloss: 0.000673658\n",
      "[1076]\ttraining's binary_logloss: 0.000669827\n",
      "[1077]\ttraining's binary_logloss: 0.000665675\n",
      "[1078]\ttraining's binary_logloss: 0.000661827\n",
      "[1079]\ttraining's binary_logloss: 0.000658237\n",
      "[1080]\ttraining's binary_logloss: 0.000654613\n",
      "[1081]\ttraining's binary_logloss: 0.000650826\n",
      "[1082]\ttraining's binary_logloss: 0.000646829\n",
      "[1083]\ttraining's binary_logloss: 0.000642985\n",
      "[1084]\ttraining's binary_logloss: 0.000639298\n",
      "[1085]\ttraining's binary_logloss: 0.000635441\n",
      "[1086]\ttraining's binary_logloss: 0.000631636\n",
      "[1087]\ttraining's binary_logloss: 0.000628141\n",
      "[1088]\ttraining's binary_logloss: 0.000624168\n",
      "[1089]\ttraining's binary_logloss: 0.000620737\n",
      "[1090]\ttraining's binary_logloss: 0.000616694\n",
      "[1091]\ttraining's binary_logloss: 0.000613213\n",
      "[1092]\ttraining's binary_logloss: 0.000609406\n",
      "[1093]\ttraining's binary_logloss: 0.000605503\n",
      "[1094]\ttraining's binary_logloss: 0.000602018\n",
      "[1095]\ttraining's binary_logloss: 0.000598358\n",
      "[1096]\ttraining's binary_logloss: 0.00059503\n",
      "[1097]\ttraining's binary_logloss: 0.000591377\n",
      "[1098]\ttraining's binary_logloss: 0.000588146\n",
      "[1099]\ttraining's binary_logloss: 0.000584384\n",
      "[1100]\ttraining's binary_logloss: 0.000580989\n",
      "[1101]\ttraining's binary_logloss: 0.000577687\n",
      "[1102]\ttraining's binary_logloss: 0.000574592\n",
      "[1103]\ttraining's binary_logloss: 0.000571126\n",
      "[1104]\ttraining's binary_logloss: 0.000567504\n",
      "[1105]\ttraining's binary_logloss: 0.000564018\n",
      "[1106]\ttraining's binary_logloss: 0.00056031\n",
      "[1107]\ttraining's binary_logloss: 0.000556875\n",
      "[1108]\ttraining's binary_logloss: 0.000553561\n",
      "[1109]\ttraining's binary_logloss: 0.000550148\n",
      "[1110]\ttraining's binary_logloss: 0.000547073\n",
      "[1111]\ttraining's binary_logloss: 0.000544079\n",
      "[1112]\ttraining's binary_logloss: 0.00054086\n",
      "[1113]\ttraining's binary_logloss: 0.000537729\n",
      "[1114]\ttraining's binary_logloss: 0.000534314\n",
      "[1115]\ttraining's binary_logloss: 0.000530997\n",
      "[1116]\ttraining's binary_logloss: 0.000527716\n",
      "[1117]\ttraining's binary_logloss: 0.000524587\n",
      "[1118]\ttraining's binary_logloss: 0.000521419\n",
      "[1119]\ttraining's binary_logloss: 0.000518086\n",
      "[1120]\ttraining's binary_logloss: 0.0005149\n",
      "[1121]\ttraining's binary_logloss: 0.000511842\n",
      "[1122]\ttraining's binary_logloss: 0.000509046\n",
      "[1123]\ttraining's binary_logloss: 0.000505996\n",
      "[1124]\ttraining's binary_logloss: 0.000503162\n",
      "[1125]\ttraining's binary_logloss: 0.000500286\n",
      "[1126]\ttraining's binary_logloss: 0.000497408\n",
      "[1127]\ttraining's binary_logloss: 0.00049441\n",
      "[1128]\ttraining's binary_logloss: 0.000491538\n",
      "[1129]\ttraining's binary_logloss: 0.000488422\n",
      "[1130]\ttraining's binary_logloss: 0.000485372\n",
      "[1131]\ttraining's binary_logloss: 0.000482371\n",
      "[1132]\ttraining's binary_logloss: 0.000479517\n",
      "[1133]\ttraining's binary_logloss: 0.000476715\n",
      "[1134]\ttraining's binary_logloss: 0.000474059\n",
      "[1135]\ttraining's binary_logloss: 0.000471457\n",
      "[1136]\ttraining's binary_logloss: 0.000468979\n",
      "[1137]\ttraining's binary_logloss: 0.000466462\n",
      "[1138]\ttraining's binary_logloss: 0.000463517\n",
      "[1139]\ttraining's binary_logloss: 0.000460492\n",
      "[1140]\ttraining's binary_logloss: 0.0004575\n",
      "[1141]\ttraining's binary_logloss: 0.000454741\n",
      "[1142]\ttraining's binary_logloss: 0.000452184\n",
      "[1143]\ttraining's binary_logloss: 0.000449345\n",
      "[1144]\ttraining's binary_logloss: 0.00044657\n",
      "[1145]\ttraining's binary_logloss: 0.000444308\n",
      "[1146]\ttraining's binary_logloss: 0.000441919\n",
      "[1147]\ttraining's binary_logloss: 0.000439391\n",
      "[1148]\ttraining's binary_logloss: 0.000436781\n",
      "[1149]\ttraining's binary_logloss: 0.000434386\n",
      "[1150]\ttraining's binary_logloss: 0.000431793\n",
      "[1151]\ttraining's binary_logloss: 0.000429375\n",
      "[1152]\ttraining's binary_logloss: 0.000426717\n",
      "[1153]\ttraining's binary_logloss: 0.000424025\n",
      "[1154]\ttraining's binary_logloss: 0.000421604\n",
      "[1155]\ttraining's binary_logloss: 0.000419147\n",
      "[1156]\ttraining's binary_logloss: 0.000416592\n",
      "[1157]\ttraining's binary_logloss: 0.000414228\n",
      "[1158]\ttraining's binary_logloss: 0.000411718\n",
      "[1159]\ttraining's binary_logloss: 0.00040924\n",
      "[1160]\ttraining's binary_logloss: 0.000406661\n",
      "[1161]\ttraining's binary_logloss: 0.000404033\n",
      "[1162]\ttraining's binary_logloss: 0.000401645\n",
      "[1163]\ttraining's binary_logloss: 0.00039918\n",
      "[1164]\ttraining's binary_logloss: 0.000397031\n",
      "[1165]\ttraining's binary_logloss: 0.000394828\n",
      "[1166]\ttraining's binary_logloss: 0.000392611\n",
      "[1167]\ttraining's binary_logloss: 0.000390072\n",
      "[1168]\ttraining's binary_logloss: 0.000387913\n",
      "[1169]\ttraining's binary_logloss: 0.000385603\n",
      "[1170]\ttraining's binary_logloss: 0.000383366\n",
      "[1171]\ttraining's binary_logloss: 0.000380943\n",
      "[1172]\ttraining's binary_logloss: 0.000378725\n",
      "[1173]\ttraining's binary_logloss: 0.000376425\n",
      "[1174]\ttraining's binary_logloss: 0.000374029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1175]\ttraining's binary_logloss: 0.000371864\n",
      "[1176]\ttraining's binary_logloss: 0.000369613\n",
      "[1177]\ttraining's binary_logloss: 0.000367457\n",
      "[1178]\ttraining's binary_logloss: 0.000365241\n",
      "[1179]\ttraining's binary_logloss: 0.000362967\n",
      "[1180]\ttraining's binary_logloss: 0.000360696\n",
      "[1181]\ttraining's binary_logloss: 0.000358411\n",
      "[1182]\ttraining's binary_logloss: 0.000356233\n",
      "[1183]\ttraining's binary_logloss: 0.000354258\n",
      "[1184]\ttraining's binary_logloss: 0.000352137\n",
      "[1185]\ttraining's binary_logloss: 0.000350108\n",
      "[1186]\ttraining's binary_logloss: 0.000347991\n",
      "[1187]\ttraining's binary_logloss: 0.000345915\n",
      "[1188]\ttraining's binary_logloss: 0.000343997\n",
      "[1189]\ttraining's binary_logloss: 0.000341948\n",
      "[1190]\ttraining's binary_logloss: 0.000339951\n",
      "[1191]\ttraining's binary_logloss: 0.00033794\n",
      "[1192]\ttraining's binary_logloss: 0.000335937\n",
      "[1193]\ttraining's binary_logloss: 0.000334029\n",
      "[1194]\ttraining's binary_logloss: 0.000332269\n",
      "[1195]\ttraining's binary_logloss: 0.000330268\n",
      "[1196]\ttraining's binary_logloss: 0.000328345\n",
      "[1197]\ttraining's binary_logloss: 0.000326406\n",
      "[1198]\ttraining's binary_logloss: 0.000324592\n",
      "[1199]\ttraining's binary_logloss: 0.000322627\n",
      "[1200]\ttraining's binary_logloss: 0.000320637\n",
      "[1201]\ttraining's binary_logloss: 0.000318763\n",
      "[1202]\ttraining's binary_logloss: 0.000316828\n",
      "[1203]\ttraining's binary_logloss: 0.00031499\n",
      "[1204]\ttraining's binary_logloss: 0.000313278\n",
      "[1205]\ttraining's binary_logloss: 0.0003113\n",
      "[1206]\ttraining's binary_logloss: 0.000309387\n",
      "[1207]\ttraining's binary_logloss: 0.000307507\n",
      "[1208]\ttraining's binary_logloss: 0.00030558\n",
      "[1209]\ttraining's binary_logloss: 0.000303728\n",
      "[1210]\ttraining's binary_logloss: 0.000301943\n",
      "[1211]\ttraining's binary_logloss: 0.000300008\n",
      "[1212]\ttraining's binary_logloss: 0.000298255\n",
      "[1213]\ttraining's binary_logloss: 0.000296623\n",
      "[1214]\ttraining's binary_logloss: 0.000294948\n",
      "[1215]\ttraining's binary_logloss: 0.000293189\n",
      "[1216]\ttraining's binary_logloss: 0.000291392\n",
      "[1217]\ttraining's binary_logloss: 0.000289565\n",
      "[1218]\ttraining's binary_logloss: 0.00028776\n",
      "[1219]\ttraining's binary_logloss: 0.00028592\n",
      "[1220]\ttraining's binary_logloss: 0.000284133\n",
      "[1221]\ttraining's binary_logloss: 0.000282467\n",
      "[1222]\ttraining's binary_logloss: 0.000280642\n",
      "[1223]\ttraining's binary_logloss: 0.000279039\n",
      "[1224]\ttraining's binary_logloss: 0.000277373\n",
      "[1225]\ttraining's binary_logloss: 0.000275906\n",
      "[1226]\ttraining's binary_logloss: 0.000274331\n",
      "[1227]\ttraining's binary_logloss: 0.000272742\n",
      "[1228]\ttraining's binary_logloss: 0.000271185\n",
      "[1229]\ttraining's binary_logloss: 0.000269593\n",
      "[1230]\ttraining's binary_logloss: 0.000268033\n",
      "[1231]\ttraining's binary_logloss: 0.000266395\n",
      "[1232]\ttraining's binary_logloss: 0.000264679\n",
      "[1233]\ttraining's binary_logloss: 0.000263097\n",
      "[1234]\ttraining's binary_logloss: 0.000261612\n",
      "[1235]\ttraining's binary_logloss: 0.000260054\n",
      "[1236]\ttraining's binary_logloss: 0.000258521\n",
      "[1237]\ttraining's binary_logloss: 0.000256865\n",
      "[1238]\ttraining's binary_logloss: 0.000255417\n",
      "[1239]\ttraining's binary_logloss: 0.000253824\n",
      "[1240]\ttraining's binary_logloss: 0.000252441\n",
      "[1241]\ttraining's binary_logloss: 0.000250857\n",
      "[1242]\ttraining's binary_logloss: 0.00024936\n",
      "[1243]\ttraining's binary_logloss: 0.000247899\n",
      "[1244]\ttraining's binary_logloss: 0.000246541\n",
      "[1245]\ttraining's binary_logloss: 0.000245058\n",
      "[1246]\ttraining's binary_logloss: 0.000243611\n",
      "[1247]\ttraining's binary_logloss: 0.000242327\n",
      "[1248]\ttraining's binary_logloss: 0.000240921\n",
      "[1249]\ttraining's binary_logloss: 0.000239467\n",
      "[1250]\ttraining's binary_logloss: 0.000238012\n",
      "[1251]\ttraining's binary_logloss: 0.000236572\n",
      "[1252]\ttraining's binary_logloss: 0.000235158\n",
      "[1253]\ttraining's binary_logloss: 0.00023382\n",
      "[1254]\ttraining's binary_logloss: 0.000232451\n",
      "[1255]\ttraining's binary_logloss: 0.000231022\n",
      "[1256]\ttraining's binary_logloss: 0.000229753\n",
      "[1257]\ttraining's binary_logloss: 0.000228487\n",
      "[1258]\ttraining's binary_logloss: 0.0002272\n",
      "[1259]\ttraining's binary_logloss: 0.000225766\n",
      "[1260]\ttraining's binary_logloss: 0.000224419\n",
      "[1261]\ttraining's binary_logloss: 0.000223076\n",
      "[1262]\ttraining's binary_logloss: 0.000221873\n",
      "[1263]\ttraining's binary_logloss: 0.000220625\n",
      "[1264]\ttraining's binary_logloss: 0.000219364\n",
      "[1265]\ttraining's binary_logloss: 0.000218006\n",
      "[1266]\ttraining's binary_logloss: 0.000216647\n",
      "[1267]\ttraining's binary_logloss: 0.000215375\n",
      "[1268]\ttraining's binary_logloss: 0.000214127\n",
      "[1269]\ttraining's binary_logloss: 0.000212734\n",
      "[1270]\ttraining's binary_logloss: 0.000211506\n",
      "[1271]\ttraining's binary_logloss: 0.000210183\n",
      "[1272]\ttraining's binary_logloss: 0.000209035\n",
      "[1273]\ttraining's binary_logloss: 0.00020784\n",
      "[1274]\ttraining's binary_logloss: 0.000206658\n",
      "[1275]\ttraining's binary_logloss: 0.000205414\n",
      "[1276]\ttraining's binary_logloss: 0.000204148\n",
      "[1277]\ttraining's binary_logloss: 0.000202886\n",
      "[1278]\ttraining's binary_logloss: 0.000201847\n",
      "[1279]\ttraining's binary_logloss: 0.000200639\n",
      "[1280]\ttraining's binary_logloss: 0.00019945\n",
      "[1281]\ttraining's binary_logloss: 0.000198249\n",
      "[1282]\ttraining's binary_logloss: 0.000197119\n",
      "[1283]\ttraining's binary_logloss: 0.00019596\n",
      "[1284]\ttraining's binary_logloss: 0.000194839\n",
      "[1285]\ttraining's binary_logloss: 0.000193619\n",
      "[1286]\ttraining's binary_logloss: 0.000192391\n",
      "[1287]\ttraining's binary_logloss: 0.000191356\n",
      "[1288]\ttraining's binary_logloss: 0.000190229\n",
      "[1289]\ttraining's binary_logloss: 0.000189196\n",
      "[1290]\ttraining's binary_logloss: 0.000188084\n",
      "[1291]\ttraining's binary_logloss: 0.000187051\n",
      "[1292]\ttraining's binary_logloss: 0.000185862\n",
      "[1293]\ttraining's binary_logloss: 0.000184797\n",
      "[1294]\ttraining's binary_logloss: 0.000183745\n",
      "[1295]\ttraining's binary_logloss: 0.000182712\n",
      "[1296]\ttraining's binary_logloss: 0.00018159\n",
      "[1297]\ttraining's binary_logloss: 0.000180467\n",
      "[1298]\ttraining's binary_logloss: 0.000179401\n",
      "[1299]\ttraining's binary_logloss: 0.000178449\n",
      "[1300]\ttraining's binary_logloss: 0.000177454\n",
      "[1301]\ttraining's binary_logloss: 0.000176396\n",
      "[1302]\ttraining's binary_logloss: 0.000175334\n",
      "[1303]\ttraining's binary_logloss: 0.00017431\n",
      "[1304]\ttraining's binary_logloss: 0.000173333\n",
      "[1305]\ttraining's binary_logloss: 0.000172344\n",
      "[1306]\ttraining's binary_logloss: 0.000171359\n",
      "[1307]\ttraining's binary_logloss: 0.000170316\n",
      "[1308]\ttraining's binary_logloss: 0.000169292\n",
      "[1309]\ttraining's binary_logloss: 0.000168202\n",
      "[1310]\ttraining's binary_logloss: 0.000167119\n",
      "[1311]\ttraining's binary_logloss: 0.000166189\n",
      "[1312]\ttraining's binary_logloss: 0.000165188\n",
      "[1313]\ttraining's binary_logloss: 0.00016417\n",
      "[1314]\ttraining's binary_logloss: 0.000163148\n",
      "[1315]\ttraining's binary_logloss: 0.000162252\n",
      "[1316]\ttraining's binary_logloss: 0.000161327\n",
      "[1317]\ttraining's binary_logloss: 0.000160397\n",
      "[1318]\ttraining's binary_logloss: 0.000159508\n",
      "[1319]\ttraining's binary_logloss: 0.000158569\n",
      "[1320]\ttraining's binary_logloss: 0.000157673\n",
      "[1321]\ttraining's binary_logloss: 0.000156742\n",
      "[1322]\ttraining's binary_logloss: 0.000155946\n",
      "[1323]\ttraining's binary_logloss: 0.000155004\n",
      "[1324]\ttraining's binary_logloss: 0.000154085\n",
      "[1325]\ttraining's binary_logloss: 0.000153176\n",
      "[1326]\ttraining's binary_logloss: 0.00015236\n",
      "[1327]\ttraining's binary_logloss: 0.00015145\n",
      "[1328]\ttraining's binary_logloss: 0.00015064\n",
      "[1329]\ttraining's binary_logloss: 0.000149862\n",
      "[1330]\ttraining's binary_logloss: 0.000148899\n",
      "[1331]\ttraining's binary_logloss: 0.000147992\n",
      "[1332]\ttraining's binary_logloss: 0.000147184\n",
      "[1333]\ttraining's binary_logloss: 0.000146293\n",
      "[1334]\ttraining's binary_logloss: 0.000145492\n",
      "[1335]\ttraining's binary_logloss: 0.000144656\n",
      "[1336]\ttraining's binary_logloss: 0.000143799\n",
      "[1337]\ttraining's binary_logloss: 0.00014289\n",
      "[1338]\ttraining's binary_logloss: 0.000142006\n",
      "[1339]\ttraining's binary_logloss: 0.000141234\n",
      "[1340]\ttraining's binary_logloss: 0.000140507\n",
      "[1341]\ttraining's binary_logloss: 0.000139735\n",
      "[1342]\ttraining's binary_logloss: 0.000138898\n",
      "[1343]\ttraining's binary_logloss: 0.000138039\n",
      "[1344]\ttraining's binary_logloss: 0.000137208\n",
      "[1345]\ttraining's binary_logloss: 0.000136416\n",
      "[1346]\ttraining's binary_logloss: 0.000135699\n",
      "[1347]\ttraining's binary_logloss: 0.00013485\n",
      "[1348]\ttraining's binary_logloss: 0.000133986\n",
      "[1349]\ttraining's binary_logloss: 0.000133196\n",
      "[1350]\ttraining's binary_logloss: 0.000132377\n",
      "[1351]\ttraining's binary_logloss: 0.000131567\n",
      "[1352]\ttraining's binary_logloss: 0.000130767\n",
      "[1353]\ttraining's binary_logloss: 0.00012996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1354]\ttraining's binary_logloss: 0.000129187\n",
      "[1355]\ttraining's binary_logloss: 0.000128402\n",
      "[1356]\ttraining's binary_logloss: 0.000127668\n",
      "[1357]\ttraining's binary_logloss: 0.000126971\n",
      "[1358]\ttraining's binary_logloss: 0.000126218\n",
      "[1359]\ttraining's binary_logloss: 0.000125499\n",
      "[1360]\ttraining's binary_logloss: 0.000124758\n",
      "[1361]\ttraining's binary_logloss: 0.000124049\n",
      "[1362]\ttraining's binary_logloss: 0.000123359\n",
      "[1363]\ttraining's binary_logloss: 0.000122601\n",
      "[1364]\ttraining's binary_logloss: 0.000121846\n",
      "[1365]\ttraining's binary_logloss: 0.000121081\n",
      "[1366]\ttraining's binary_logloss: 0.000120367\n",
      "[1367]\ttraining's binary_logloss: 0.000119681\n",
      "[1368]\ttraining's binary_logloss: 0.000119058\n",
      "[1369]\ttraining's binary_logloss: 0.000118389\n",
      "[1370]\ttraining's binary_logloss: 0.000117719\n",
      "[1371]\ttraining's binary_logloss: 0.000117025\n",
      "[1372]\ttraining's binary_logloss: 0.000116377\n",
      "[1373]\ttraining's binary_logloss: 0.000115743\n",
      "[1374]\ttraining's binary_logloss: 0.00011505\n",
      "[1375]\ttraining's binary_logloss: 0.000114335\n",
      "[1376]\ttraining's binary_logloss: 0.000113712\n",
      "[1377]\ttraining's binary_logloss: 0.000113079\n",
      "[1378]\ttraining's binary_logloss: 0.000112472\n",
      "[1379]\ttraining's binary_logloss: 0.000111924\n",
      "[1380]\ttraining's binary_logloss: 0.000111376\n",
      "[1381]\ttraining's binary_logloss: 0.000110793\n",
      "[1382]\ttraining's binary_logloss: 0.000110208\n",
      "[1383]\ttraining's binary_logloss: 0.000109539\n",
      "[1384]\ttraining's binary_logloss: 0.000108869\n",
      "[1385]\ttraining's binary_logloss: 0.000108214\n",
      "[1386]\ttraining's binary_logloss: 0.00010757\n",
      "[1387]\ttraining's binary_logloss: 0.000106988\n",
      "[1388]\ttraining's binary_logloss: 0.000106383\n",
      "[1389]\ttraining's binary_logloss: 0.000105712\n",
      "[1390]\ttraining's binary_logloss: 0.000105143\n",
      "[1391]\ttraining's binary_logloss: 0.000104491\n",
      "[1392]\ttraining's binary_logloss: 0.000103822\n",
      "[1393]\ttraining's binary_logloss: 0.000103208\n",
      "[1394]\ttraining's binary_logloss: 0.00010261\n",
      "[1395]\ttraining's binary_logloss: 0.000102037\n",
      "[1396]\ttraining's binary_logloss: 0.000101487\n",
      "[1397]\ttraining's binary_logloss: 0.00010093\n",
      "[1398]\ttraining's binary_logloss: 0.000100359\n",
      "[1399]\ttraining's binary_logloss: 9.97815e-05\n",
      "[1400]\ttraining's binary_logloss: 9.9162e-05\n",
      "[1401]\ttraining's binary_logloss: 9.85623e-05\n",
      "[1402]\ttraining's binary_logloss: 9.79589e-05\n",
      "[1403]\ttraining's binary_logloss: 9.73681e-05\n",
      "[1404]\ttraining's binary_logloss: 9.67743e-05\n",
      "[1405]\ttraining's binary_logloss: 9.62044e-05\n",
      "[1406]\ttraining's binary_logloss: 9.56678e-05\n",
      "[1407]\ttraining's binary_logloss: 9.51831e-05\n",
      "[1408]\ttraining's binary_logloss: 9.46902e-05\n",
      "[1409]\ttraining's binary_logloss: 9.41346e-05\n",
      "[1410]\ttraining's binary_logloss: 9.35907e-05\n",
      "[1411]\ttraining's binary_logloss: 9.30412e-05\n",
      "[1412]\ttraining's binary_logloss: 9.24903e-05\n",
      "[1413]\ttraining's binary_logloss: 9.19569e-05\n",
      "[1414]\ttraining's binary_logloss: 9.14652e-05\n",
      "[1415]\ttraining's binary_logloss: 9.09496e-05\n",
      "[1416]\ttraining's binary_logloss: 9.04727e-05\n",
      "[1417]\ttraining's binary_logloss: 8.99436e-05\n",
      "[1418]\ttraining's binary_logloss: 8.94103e-05\n",
      "[1419]\ttraining's binary_logloss: 8.88531e-05\n",
      "[1420]\ttraining's binary_logloss: 8.83398e-05\n",
      "[1421]\ttraining's binary_logloss: 8.78313e-05\n",
      "[1422]\ttraining's binary_logloss: 8.73018e-05\n",
      "[1423]\ttraining's binary_logloss: 8.68514e-05\n",
      "[1424]\ttraining's binary_logloss: 8.63894e-05\n",
      "[1425]\ttraining's binary_logloss: 8.59711e-05\n",
      "[1426]\ttraining's binary_logloss: 8.55477e-05\n",
      "[1427]\ttraining's binary_logloss: 8.50536e-05\n",
      "[1428]\ttraining's binary_logloss: 8.45428e-05\n",
      "[1429]\ttraining's binary_logloss: 8.40381e-05\n",
      "[1430]\ttraining's binary_logloss: 8.35704e-05\n",
      "[1431]\ttraining's binary_logloss: 8.31095e-05\n",
      "[1432]\ttraining's binary_logloss: 8.26367e-05\n",
      "[1433]\ttraining's binary_logloss: 8.21852e-05\n",
      "[1434]\ttraining's binary_logloss: 8.17327e-05\n",
      "[1435]\ttraining's binary_logloss: 8.12211e-05\n",
      "[1436]\ttraining's binary_logloss: 8.07571e-05\n",
      "[1437]\ttraining's binary_logloss: 8.02882e-05\n",
      "[1438]\ttraining's binary_logloss: 7.98259e-05\n",
      "[1439]\ttraining's binary_logloss: 7.9375e-05\n",
      "[1440]\ttraining's binary_logloss: 7.89264e-05\n",
      "[1441]\ttraining's binary_logloss: 7.84691e-05\n",
      "[1442]\ttraining's binary_logloss: 7.79738e-05\n",
      "[1443]\ttraining's binary_logloss: 7.7549e-05\n",
      "[1444]\ttraining's binary_logloss: 7.70994e-05\n",
      "[1445]\ttraining's binary_logloss: 7.67008e-05\n",
      "[1446]\ttraining's binary_logloss: 7.63109e-05\n",
      "[1447]\ttraining's binary_logloss: 7.58507e-05\n",
      "[1448]\ttraining's binary_logloss: 7.54326e-05\n",
      "[1449]\ttraining's binary_logloss: 7.50051e-05\n",
      "[1450]\ttraining's binary_logloss: 7.45543e-05\n",
      "[1451]\ttraining's binary_logloss: 7.41585e-05\n",
      "[1452]\ttraining's binary_logloss: 7.37373e-05\n",
      "[1453]\ttraining's binary_logloss: 7.33092e-05\n",
      "[1454]\ttraining's binary_logloss: 7.29268e-05\n",
      "[1455]\ttraining's binary_logloss: 7.25096e-05\n",
      "[1456]\ttraining's binary_logloss: 7.21225e-05\n",
      "[1457]\ttraining's binary_logloss: 7.17178e-05\n",
      "[1458]\ttraining's binary_logloss: 7.13582e-05\n",
      "[1459]\ttraining's binary_logloss: 7.0957e-05\n",
      "[1460]\ttraining's binary_logloss: 7.05656e-05\n",
      "[1461]\ttraining's binary_logloss: 7.01436e-05\n",
      "[1462]\ttraining's binary_logloss: 6.97242e-05\n",
      "[1463]\ttraining's binary_logloss: 6.93467e-05\n",
      "[1464]\ttraining's binary_logloss: 6.8956e-05\n",
      "[1465]\ttraining's binary_logloss: 6.85507e-05\n",
      "[1466]\ttraining's binary_logloss: 6.81697e-05\n",
      "[1467]\ttraining's binary_logloss: 6.77762e-05\n",
      "[1468]\ttraining's binary_logloss: 6.74119e-05\n",
      "[1469]\ttraining's binary_logloss: 6.70339e-05\n",
      "[1470]\ttraining's binary_logloss: 6.66706e-05\n",
      "[1471]\ttraining's binary_logloss: 6.63499e-05\n",
      "[1472]\ttraining's binary_logloss: 6.59292e-05\n",
      "[1473]\ttraining's binary_logloss: 6.559e-05\n",
      "[1474]\ttraining's binary_logloss: 6.52189e-05\n",
      "[1475]\ttraining's binary_logloss: 6.48622e-05\n",
      "[1476]\ttraining's binary_logloss: 6.45226e-05\n",
      "[1477]\ttraining's binary_logloss: 6.41713e-05\n",
      "[1478]\ttraining's binary_logloss: 6.37776e-05\n",
      "[1479]\ttraining's binary_logloss: 6.3459e-05\n",
      "[1480]\ttraining's binary_logloss: 6.31279e-05\n",
      "[1481]\ttraining's binary_logloss: 6.27849e-05\n",
      "[1482]\ttraining's binary_logloss: 6.24298e-05\n",
      "[1483]\ttraining's binary_logloss: 6.20799e-05\n",
      "[1484]\ttraining's binary_logloss: 6.17227e-05\n",
      "[1485]\ttraining's binary_logloss: 6.13862e-05\n",
      "[1486]\ttraining's binary_logloss: 6.10731e-05\n",
      "[1487]\ttraining's binary_logloss: 6.07301e-05\n",
      "[1488]\ttraining's binary_logloss: 6.04119e-05\n",
      "[1489]\ttraining's binary_logloss: 6.00904e-05\n",
      "[1490]\ttraining's binary_logloss: 5.9778e-05\n",
      "[1491]\ttraining's binary_logloss: 5.94737e-05\n",
      "[1492]\ttraining's binary_logloss: 5.91466e-05\n",
      "[1493]\ttraining's binary_logloss: 5.88516e-05\n",
      "[1494]\ttraining's binary_logloss: 5.8519e-05\n",
      "[1495]\ttraining's binary_logloss: 5.81915e-05\n",
      "[1496]\ttraining's binary_logloss: 5.79005e-05\n",
      "[1497]\ttraining's binary_logloss: 5.76391e-05\n",
      "[1498]\ttraining's binary_logloss: 5.73149e-05\n",
      "[1499]\ttraining's binary_logloss: 5.70216e-05\n",
      "[1500]\ttraining's binary_logloss: 5.67035e-05\n",
      "[1501]\ttraining's binary_logloss: 5.63773e-05\n",
      "[1502]\ttraining's binary_logloss: 5.60951e-05\n",
      "[1503]\ttraining's binary_logloss: 5.58378e-05\n",
      "[1504]\ttraining's binary_logloss: 5.55294e-05\n",
      "[1505]\ttraining's binary_logloss: 5.5242e-05\n",
      "[1506]\ttraining's binary_logloss: 5.49499e-05\n",
      "[1507]\ttraining's binary_logloss: 5.46595e-05\n",
      "[1508]\ttraining's binary_logloss: 5.43675e-05\n",
      "[1509]\ttraining's binary_logloss: 5.40796e-05\n",
      "[1510]\ttraining's binary_logloss: 5.38042e-05\n",
      "[1511]\ttraining's binary_logloss: 5.35386e-05\n",
      "[1512]\ttraining's binary_logloss: 5.32676e-05\n",
      "[1513]\ttraining's binary_logloss: 5.29731e-05\n",
      "[1514]\ttraining's binary_logloss: 5.27137e-05\n",
      "[1515]\ttraining's binary_logloss: 5.24532e-05\n",
      "[1516]\ttraining's binary_logloss: 5.21852e-05\n",
      "[1517]\ttraining's binary_logloss: 5.18806e-05\n",
      "[1518]\ttraining's binary_logloss: 5.16139e-05\n",
      "[1519]\ttraining's binary_logloss: 5.13462e-05\n",
      "[1520]\ttraining's binary_logloss: 5.10868e-05\n",
      "[1521]\ttraining's binary_logloss: 5.08183e-05\n",
      "[1522]\ttraining's binary_logloss: 5.05585e-05\n",
      "[1523]\ttraining's binary_logloss: 5.03016e-05\n",
      "[1524]\ttraining's binary_logloss: 5.00579e-05\n",
      "[1525]\ttraining's binary_logloss: 4.97811e-05\n",
      "[1526]\ttraining's binary_logloss: 4.95297e-05\n",
      "[1527]\ttraining's binary_logloss: 4.92819e-05\n",
      "[1528]\ttraining's binary_logloss: 4.90381e-05\n",
      "[1529]\ttraining's binary_logloss: 4.87898e-05\n",
      "[1530]\ttraining's binary_logloss: 4.85484e-05\n",
      "[1531]\ttraining's binary_logloss: 4.82922e-05\n",
      "[1532]\ttraining's binary_logloss: 4.80567e-05\n",
      "[1533]\ttraining's binary_logloss: 4.78318e-05\n",
      "[1534]\ttraining's binary_logloss: 4.75845e-05\n",
      "[1535]\ttraining's binary_logloss: 4.73446e-05\n",
      "[1536]\ttraining's binary_logloss: 4.71276e-05\n",
      "[1537]\ttraining's binary_logloss: 4.69089e-05\n",
      "[1538]\ttraining's binary_logloss: 4.66495e-05\n",
      "[1539]\ttraining's binary_logloss: 4.63964e-05\n",
      "[1540]\ttraining's binary_logloss: 4.61669e-05\n",
      "[1541]\ttraining's binary_logloss: 4.59229e-05\n",
      "[1542]\ttraining's binary_logloss: 4.56674e-05\n",
      "[1543]\ttraining's binary_logloss: 4.54279e-05\n",
      "[1544]\ttraining's binary_logloss: 4.51823e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1545]\ttraining's binary_logloss: 4.49605e-05\n",
      "[1546]\ttraining's binary_logloss: 4.47498e-05\n",
      "[1547]\ttraining's binary_logloss: 4.45365e-05\n",
      "[1548]\ttraining's binary_logloss: 4.43244e-05\n",
      "[1549]\ttraining's binary_logloss: 4.41115e-05\n",
      "[1550]\ttraining's binary_logloss: 4.3918e-05\n",
      "[1551]\ttraining's binary_logloss: 4.37029e-05\n",
      "[1552]\ttraining's binary_logloss: 4.34928e-05\n",
      "[1553]\ttraining's binary_logloss: 4.32918e-05\n",
      "[1554]\ttraining's binary_logloss: 4.30628e-05\n",
      "[1555]\ttraining's binary_logloss: 4.28548e-05\n",
      "[1556]\ttraining's binary_logloss: 4.26303e-05\n",
      "[1557]\ttraining's binary_logloss: 4.24379e-05\n",
      "[1558]\ttraining's binary_logloss: 4.22262e-05\n",
      "[1559]\ttraining's binary_logloss: 4.20165e-05\n",
      "[1560]\ttraining's binary_logloss: 4.18292e-05\n",
      "[1561]\ttraining's binary_logloss: 4.16204e-05\n",
      "[1562]\ttraining's binary_logloss: 4.1414e-05\n",
      "[1563]\ttraining's binary_logloss: 4.12278e-05\n",
      "[1564]\ttraining's binary_logloss: 4.10355e-05\n",
      "[1565]\ttraining's binary_logloss: 4.08358e-05\n",
      "[1566]\ttraining's binary_logloss: 4.06412e-05\n",
      "[1567]\ttraining's binary_logloss: 4.04503e-05\n",
      "[1568]\ttraining's binary_logloss: 4.0263e-05\n",
      "[1569]\ttraining's binary_logloss: 4.00586e-05\n",
      "[1570]\ttraining's binary_logloss: 3.98766e-05\n",
      "[1571]\ttraining's binary_logloss: 3.96707e-05\n",
      "[1572]\ttraining's binary_logloss: 3.94655e-05\n",
      "[1573]\ttraining's binary_logloss: 3.9263e-05\n",
      "[1574]\ttraining's binary_logloss: 3.90724e-05\n",
      "[1575]\ttraining's binary_logloss: 3.88871e-05\n",
      "[1576]\ttraining's binary_logloss: 3.86869e-05\n",
      "[1577]\ttraining's binary_logloss: 3.84975e-05\n",
      "[1578]\ttraining's binary_logloss: 3.8311e-05\n",
      "[1579]\ttraining's binary_logloss: 3.81265e-05\n",
      "[1580]\ttraining's binary_logloss: 3.79576e-05\n",
      "[1581]\ttraining's binary_logloss: 3.77667e-05\n",
      "[1582]\ttraining's binary_logloss: 3.75974e-05\n",
      "[1583]\ttraining's binary_logloss: 3.7418e-05\n",
      "[1584]\ttraining's binary_logloss: 3.72486e-05\n",
      "[1585]\ttraining's binary_logloss: 3.707e-05\n",
      "[1586]\ttraining's binary_logloss: 3.68939e-05\n",
      "[1587]\ttraining's binary_logloss: 3.67198e-05\n",
      "[1588]\ttraining's binary_logloss: 3.65489e-05\n",
      "[1589]\ttraining's binary_logloss: 3.63733e-05\n",
      "[1590]\ttraining's binary_logloss: 3.62027e-05\n",
      "[1591]\ttraining's binary_logloss: 3.60372e-05\n",
      "[1592]\ttraining's binary_logloss: 3.5862e-05\n",
      "[1593]\ttraining's binary_logloss: 3.56939e-05\n",
      "[1594]\ttraining's binary_logloss: 3.55356e-05\n",
      "[1595]\ttraining's binary_logloss: 3.53617e-05\n",
      "[1596]\ttraining's binary_logloss: 3.5186e-05\n",
      "[1597]\ttraining's binary_logloss: 3.50285e-05\n",
      "[1598]\ttraining's binary_logloss: 3.48569e-05\n",
      "[1599]\ttraining's binary_logloss: 3.46904e-05\n",
      "[1600]\ttraining's binary_logloss: 3.4536e-05\n",
      "[1601]\ttraining's binary_logloss: 3.4377e-05\n",
      "[1602]\ttraining's binary_logloss: 3.42293e-05\n",
      "[1603]\ttraining's binary_logloss: 3.40721e-05\n",
      "[1604]\ttraining's binary_logloss: 3.39151e-05\n",
      "[1605]\ttraining's binary_logloss: 3.37606e-05\n",
      "[1606]\ttraining's binary_logloss: 3.36091e-05\n",
      "[1607]\ttraining's binary_logloss: 3.34469e-05\n",
      "[1608]\ttraining's binary_logloss: 3.32892e-05\n",
      "[1609]\ttraining's binary_logloss: 3.31388e-05\n",
      "[1610]\ttraining's binary_logloss: 3.29876e-05\n",
      "[1611]\ttraining's binary_logloss: 3.28478e-05\n",
      "[1612]\ttraining's binary_logloss: 3.26996e-05\n",
      "[1613]\ttraining's binary_logloss: 3.25394e-05\n",
      "[1614]\ttraining's binary_logloss: 3.24035e-05\n",
      "[1615]\ttraining's binary_logloss: 3.22588e-05\n",
      "[1616]\ttraining's binary_logloss: 3.21098e-05\n",
      "[1617]\ttraining's binary_logloss: 3.19644e-05\n",
      "[1618]\ttraining's binary_logloss: 3.18127e-05\n",
      "[1619]\ttraining's binary_logloss: 3.16673e-05\n",
      "[1620]\ttraining's binary_logloss: 3.15279e-05\n",
      "[1621]\ttraining's binary_logloss: 3.13942e-05\n",
      "[1622]\ttraining's binary_logloss: 3.12577e-05\n",
      "[1623]\ttraining's binary_logloss: 3.1122e-05\n",
      "[1624]\ttraining's binary_logloss: 3.09855e-05\n",
      "[1625]\ttraining's binary_logloss: 3.08395e-05\n",
      "[1626]\ttraining's binary_logloss: 3.07047e-05\n",
      "[1627]\ttraining's binary_logloss: 3.05635e-05\n",
      "[1628]\ttraining's binary_logloss: 3.04162e-05\n",
      "[1629]\ttraining's binary_logloss: 3.02808e-05\n",
      "[1630]\ttraining's binary_logloss: 3.01552e-05\n",
      "[1631]\ttraining's binary_logloss: 3.00171e-05\n",
      "[1632]\ttraining's binary_logloss: 2.98864e-05\n",
      "[1633]\ttraining's binary_logloss: 2.97548e-05\n",
      "[1634]\ttraining's binary_logloss: 2.9627e-05\n",
      "[1635]\ttraining's binary_logloss: 2.94996e-05\n",
      "[1636]\ttraining's binary_logloss: 2.93719e-05\n",
      "[1637]\ttraining's binary_logloss: 2.92465e-05\n",
      "[1638]\ttraining's binary_logloss: 2.91212e-05\n",
      "[1639]\ttraining's binary_logloss: 2.89881e-05\n",
      "[1640]\ttraining's binary_logloss: 2.88639e-05\n",
      "[1641]\ttraining's binary_logloss: 2.87364e-05\n",
      "[1642]\ttraining's binary_logloss: 2.8618e-05\n",
      "[1643]\ttraining's binary_logloss: 2.85038e-05\n",
      "[1644]\ttraining's binary_logloss: 2.83847e-05\n",
      "[1645]\ttraining's binary_logloss: 2.82591e-05\n",
      "[1646]\ttraining's binary_logloss: 2.8144e-05\n",
      "[1647]\ttraining's binary_logloss: 2.80273e-05\n",
      "[1648]\ttraining's binary_logloss: 2.79077e-05\n",
      "[1649]\ttraining's binary_logloss: 2.77906e-05\n",
      "[1650]\ttraining's binary_logloss: 2.76675e-05\n",
      "[1651]\ttraining's binary_logloss: 2.75596e-05\n",
      "[1652]\ttraining's binary_logloss: 2.7449e-05\n",
      "[1653]\ttraining's binary_logloss: 2.73397e-05\n",
      "[1654]\ttraining's binary_logloss: 2.72206e-05\n",
      "[1655]\ttraining's binary_logloss: 2.71089e-05\n",
      "[1656]\ttraining's binary_logloss: 2.69899e-05\n",
      "[1657]\ttraining's binary_logloss: 2.68775e-05\n",
      "[1658]\ttraining's binary_logloss: 2.67689e-05\n",
      "[1659]\ttraining's binary_logloss: 2.66602e-05\n",
      "[1660]\ttraining's binary_logloss: 2.65534e-05\n",
      "[1661]\ttraining's binary_logloss: 2.64463e-05\n",
      "[1662]\ttraining's binary_logloss: 2.63388e-05\n",
      "[1663]\ttraining's binary_logloss: 2.62273e-05\n",
      "[1664]\ttraining's binary_logloss: 2.61165e-05\n",
      "[1665]\ttraining's binary_logloss: 2.60112e-05\n",
      "[1666]\ttraining's binary_logloss: 2.59009e-05\n",
      "[1667]\ttraining's binary_logloss: 2.57881e-05\n",
      "[1668]\ttraining's binary_logloss: 2.56854e-05\n",
      "[1669]\ttraining's binary_logloss: 2.55798e-05\n",
      "[1670]\ttraining's binary_logloss: 2.54799e-05\n",
      "[1671]\ttraining's binary_logloss: 2.53806e-05\n",
      "[1672]\ttraining's binary_logloss: 2.52821e-05\n",
      "[1673]\ttraining's binary_logloss: 2.51833e-05\n",
      "[1674]\ttraining's binary_logloss: 2.50936e-05\n",
      "[1675]\ttraining's binary_logloss: 2.49827e-05\n",
      "[1676]\ttraining's binary_logloss: 2.48762e-05\n",
      "[1677]\ttraining's binary_logloss: 2.47837e-05\n",
      "[1678]\ttraining's binary_logloss: 2.46843e-05\n",
      "[1679]\ttraining's binary_logloss: 2.45938e-05\n",
      "[1680]\ttraining's binary_logloss: 2.4499e-05\n",
      "[1681]\ttraining's binary_logloss: 2.44107e-05\n",
      "[1682]\ttraining's binary_logloss: 2.43229e-05\n",
      "[1683]\ttraining's binary_logloss: 2.42333e-05\n",
      "[1684]\ttraining's binary_logloss: 2.41403e-05\n",
      "[1685]\ttraining's binary_logloss: 2.40506e-05\n",
      "[1686]\ttraining's binary_logloss: 2.3963e-05\n",
      "[1687]\ttraining's binary_logloss: 2.38745e-05\n",
      "[1688]\ttraining's binary_logloss: 2.37812e-05\n",
      "[1689]\ttraining's binary_logloss: 2.36927e-05\n",
      "[1690]\ttraining's binary_logloss: 2.36047e-05\n",
      "[1691]\ttraining's binary_logloss: 2.35138e-05\n",
      "[1692]\ttraining's binary_logloss: 2.34296e-05\n",
      "[1693]\ttraining's binary_logloss: 2.33402e-05\n",
      "[1694]\ttraining's binary_logloss: 2.32488e-05\n",
      "[1695]\ttraining's binary_logloss: 2.31574e-05\n",
      "[1696]\ttraining's binary_logloss: 2.30701e-05\n",
      "[1697]\ttraining's binary_logloss: 2.2985e-05\n",
      "[1698]\ttraining's binary_logloss: 2.29051e-05\n",
      "[1699]\ttraining's binary_logloss: 2.28202e-05\n",
      "[1700]\ttraining's binary_logloss: 2.27332e-05\n",
      "[1701]\ttraining's binary_logloss: 2.26439e-05\n",
      "[1702]\ttraining's binary_logloss: 2.25622e-05\n",
      "[1703]\ttraining's binary_logloss: 2.24846e-05\n",
      "[1704]\ttraining's binary_logloss: 2.23992e-05\n",
      "[1705]\ttraining's binary_logloss: 2.23174e-05\n",
      "[1706]\ttraining's binary_logloss: 2.22384e-05\n",
      "[1707]\ttraining's binary_logloss: 2.21647e-05\n",
      "[1708]\ttraining's binary_logloss: 2.20836e-05\n",
      "[1709]\ttraining's binary_logloss: 2.20019e-05\n",
      "[1710]\ttraining's binary_logloss: 2.1925e-05\n",
      "[1711]\ttraining's binary_logloss: 2.18422e-05\n",
      "[1712]\ttraining's binary_logloss: 2.17634e-05\n",
      "[1713]\ttraining's binary_logloss: 2.16891e-05\n",
      "[1714]\ttraining's binary_logloss: 2.16124e-05\n",
      "[1715]\ttraining's binary_logloss: 2.15386e-05\n",
      "[1716]\ttraining's binary_logloss: 2.14713e-05\n",
      "[1717]\ttraining's binary_logloss: 2.13921e-05\n",
      "[1718]\ttraining's binary_logloss: 2.13177e-05\n",
      "[1719]\ttraining's binary_logloss: 2.12437e-05\n",
      "[1720]\ttraining's binary_logloss: 2.11635e-05\n",
      "[1721]\ttraining's binary_logloss: 2.10912e-05\n",
      "[1722]\ttraining's binary_logloss: 2.10263e-05\n",
      "[1723]\ttraining's binary_logloss: 2.09537e-05\n",
      "[1724]\ttraining's binary_logloss: 2.08874e-05\n",
      "[1725]\ttraining's binary_logloss: 2.08137e-05\n",
      "[1726]\ttraining's binary_logloss: 2.07397e-05\n",
      "[1727]\ttraining's binary_logloss: 2.06736e-05\n",
      "[1728]\ttraining's binary_logloss: 2.06071e-05\n",
      "[1729]\ttraining's binary_logloss: 2.05363e-05\n",
      "[1730]\ttraining's binary_logloss: 2.04693e-05\n",
      "[1731]\ttraining's binary_logloss: 2.04008e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1732]\ttraining's binary_logloss: 2.03322e-05\n",
      "[1733]\ttraining's binary_logloss: 2.02585e-05\n",
      "[1734]\ttraining's binary_logloss: 2.01914e-05\n",
      "[1735]\ttraining's binary_logloss: 2.01321e-05\n",
      "[1736]\ttraining's binary_logloss: 2.00688e-05\n",
      "[1737]\ttraining's binary_logloss: 2.00038e-05\n",
      "[1738]\ttraining's binary_logloss: 1.99357e-05\n",
      "[1739]\ttraining's binary_logloss: 1.98696e-05\n",
      "[1740]\ttraining's binary_logloss: 1.98049e-05\n",
      "[1741]\ttraining's binary_logloss: 1.97387e-05\n",
      "[1742]\ttraining's binary_logloss: 1.96766e-05\n",
      "[1743]\ttraining's binary_logloss: 1.96143e-05\n",
      "[1744]\ttraining's binary_logloss: 1.95542e-05\n",
      "[1745]\ttraining's binary_logloss: 1.9491e-05\n",
      "[1746]\ttraining's binary_logloss: 1.94251e-05\n",
      "[1747]\ttraining's binary_logloss: 1.93601e-05\n",
      "[1748]\ttraining's binary_logloss: 1.92974e-05\n",
      "[1749]\ttraining's binary_logloss: 1.92356e-05\n",
      "[1750]\ttraining's binary_logloss: 1.91752e-05\n",
      "[1751]\ttraining's binary_logloss: 1.91141e-05\n",
      "[1752]\ttraining's binary_logloss: 1.90598e-05\n",
      "[1753]\ttraining's binary_logloss: 1.90011e-05\n",
      "[1754]\ttraining's binary_logloss: 1.89444e-05\n",
      "[1755]\ttraining's binary_logloss: 1.88927e-05\n",
      "[1756]\ttraining's binary_logloss: 1.88357e-05\n",
      "[1757]\ttraining's binary_logloss: 1.87829e-05\n",
      "[1758]\ttraining's binary_logloss: 1.87202e-05\n",
      "[1759]\ttraining's binary_logloss: 1.86643e-05\n",
      "[1760]\ttraining's binary_logloss: 1.86123e-05\n",
      "[1761]\ttraining's binary_logloss: 1.85597e-05\n",
      "[1762]\ttraining's binary_logloss: 1.84969e-05\n",
      "[1763]\ttraining's binary_logloss: 1.84363e-05\n",
      "[1764]\ttraining's binary_logloss: 1.83843e-05\n",
      "[1765]\ttraining's binary_logloss: 1.83325e-05\n",
      "[1766]\ttraining's binary_logloss: 1.82775e-05\n",
      "[1767]\ttraining's binary_logloss: 1.82217e-05\n",
      "[1768]\ttraining's binary_logloss: 1.81654e-05\n",
      "[1769]\ttraining's binary_logloss: 1.81116e-05\n",
      "[1770]\ttraining's binary_logloss: 1.80555e-05\n",
      "[1771]\ttraining's binary_logloss: 1.8004e-05\n",
      "[1772]\ttraining's binary_logloss: 1.79494e-05\n",
      "[1773]\ttraining's binary_logloss: 1.7896e-05\n",
      "[1774]\ttraining's binary_logloss: 1.78477e-05\n",
      "[1775]\ttraining's binary_logloss: 1.77951e-05\n",
      "[1776]\ttraining's binary_logloss: 1.77426e-05\n",
      "[1777]\ttraining's binary_logloss: 1.76898e-05\n",
      "[1778]\ttraining's binary_logloss: 1.76364e-05\n",
      "[1779]\ttraining's binary_logloss: 1.75844e-05\n",
      "[1780]\ttraining's binary_logloss: 1.75354e-05\n",
      "[1781]\ttraining's binary_logloss: 1.74859e-05\n",
      "[1782]\ttraining's binary_logloss: 1.74399e-05\n",
      "[1783]\ttraining's binary_logloss: 1.73895e-05\n",
      "[1784]\ttraining's binary_logloss: 1.73384e-05\n",
      "[1785]\ttraining's binary_logloss: 1.72867e-05\n",
      "[1786]\ttraining's binary_logloss: 1.72378e-05\n",
      "[1787]\ttraining's binary_logloss: 1.71876e-05\n",
      "[1788]\ttraining's binary_logloss: 1.71399e-05\n",
      "[1789]\ttraining's binary_logloss: 1.70922e-05\n",
      "[1790]\ttraining's binary_logloss: 1.70443e-05\n",
      "[1791]\ttraining's binary_logloss: 1.69967e-05\n",
      "[1792]\ttraining's binary_logloss: 1.69519e-05\n",
      "[1793]\ttraining's binary_logloss: 1.69074e-05\n",
      "[1794]\ttraining's binary_logloss: 1.68619e-05\n",
      "[1795]\ttraining's binary_logloss: 1.68132e-05\n",
      "[1796]\ttraining's binary_logloss: 1.67658e-05\n",
      "[1797]\ttraining's binary_logloss: 1.67195e-05\n",
      "[1798]\ttraining's binary_logloss: 1.66709e-05\n",
      "[1799]\ttraining's binary_logloss: 1.66238e-05\n",
      "[1800]\ttraining's binary_logloss: 1.65738e-05\n",
      "[1801]\ttraining's binary_logloss: 1.653e-05\n",
      "[1802]\ttraining's binary_logloss: 1.64859e-05\n",
      "[1803]\ttraining's binary_logloss: 1.64459e-05\n",
      "[1804]\ttraining's binary_logloss: 1.64026e-05\n",
      "[1805]\ttraining's binary_logloss: 1.63603e-05\n",
      "[1806]\ttraining's binary_logloss: 1.63174e-05\n",
      "[1807]\ttraining's binary_logloss: 1.62754e-05\n",
      "[1808]\ttraining's binary_logloss: 1.62355e-05\n",
      "[1809]\ttraining's binary_logloss: 1.61938e-05\n",
      "[1810]\ttraining's binary_logloss: 1.61524e-05\n",
      "[1811]\ttraining's binary_logloss: 1.61092e-05\n",
      "[1812]\ttraining's binary_logloss: 1.60656e-05\n",
      "[1813]\ttraining's binary_logloss: 1.60226e-05\n",
      "[1814]\ttraining's binary_logloss: 1.59805e-05\n",
      "[1815]\ttraining's binary_logloss: 1.59352e-05\n",
      "[1816]\ttraining's binary_logloss: 1.58952e-05\n",
      "[1817]\ttraining's binary_logloss: 1.58531e-05\n",
      "[1818]\ttraining's binary_logloss: 1.58094e-05\n",
      "[1819]\ttraining's binary_logloss: 1.57649e-05\n",
      "[1820]\ttraining's binary_logloss: 1.57247e-05\n",
      "[1821]\ttraining's binary_logloss: 1.56854e-05\n",
      "[1822]\ttraining's binary_logloss: 1.56433e-05\n",
      "[1823]\ttraining's binary_logloss: 1.55994e-05\n",
      "[1824]\ttraining's binary_logloss: 1.55552e-05\n",
      "[1825]\ttraining's binary_logloss: 1.55173e-05\n",
      "[1826]\ttraining's binary_logloss: 1.54767e-05\n",
      "[1827]\ttraining's binary_logloss: 1.5439e-05\n",
      "[1828]\ttraining's binary_logloss: 1.54031e-05\n",
      "[1829]\ttraining's binary_logloss: 1.53654e-05\n",
      "[1830]\ttraining's binary_logloss: 1.53228e-05\n",
      "[1831]\ttraining's binary_logloss: 1.52881e-05\n",
      "[1832]\ttraining's binary_logloss: 1.52505e-05\n",
      "[1833]\ttraining's binary_logloss: 1.52075e-05\n",
      "[1834]\ttraining's binary_logloss: 1.51682e-05\n",
      "[1835]\ttraining's binary_logloss: 1.51292e-05\n",
      "[1836]\ttraining's binary_logloss: 1.5091e-05\n",
      "[1837]\ttraining's binary_logloss: 1.50548e-05\n",
      "[1838]\ttraining's binary_logloss: 1.50181e-05\n",
      "[1839]\ttraining's binary_logloss: 1.49839e-05\n",
      "[1840]\ttraining's binary_logloss: 1.49477e-05\n",
      "[1841]\ttraining's binary_logloss: 1.49107e-05\n",
      "[1842]\ttraining's binary_logloss: 1.48744e-05\n",
      "[1843]\ttraining's binary_logloss: 1.48377e-05\n",
      "[1844]\ttraining's binary_logloss: 1.48003e-05\n",
      "[1845]\ttraining's binary_logloss: 1.4766e-05\n",
      "[1846]\ttraining's binary_logloss: 1.47297e-05\n",
      "[1847]\ttraining's binary_logloss: 1.4694e-05\n",
      "[1848]\ttraining's binary_logloss: 1.46597e-05\n",
      "[1849]\ttraining's binary_logloss: 1.46216e-05\n",
      "[1850]\ttraining's binary_logloss: 1.45875e-05\n",
      "[1851]\ttraining's binary_logloss: 1.45535e-05\n",
      "[1852]\ttraining's binary_logloss: 1.4519e-05\n",
      "[1853]\ttraining's binary_logloss: 1.44885e-05\n",
      "[1854]\ttraining's binary_logloss: 1.44538e-05\n",
      "[1855]\ttraining's binary_logloss: 1.4419e-05\n",
      "[1856]\ttraining's binary_logloss: 1.43862e-05\n",
      "[1857]\ttraining's binary_logloss: 1.4354e-05\n",
      "[1858]\ttraining's binary_logloss: 1.43208e-05\n",
      "[1859]\ttraining's binary_logloss: 1.42827e-05\n",
      "[1860]\ttraining's binary_logloss: 1.42495e-05\n",
      "[1861]\ttraining's binary_logloss: 1.42182e-05\n",
      "[1862]\ttraining's binary_logloss: 1.41856e-05\n",
      "[1863]\ttraining's binary_logloss: 1.41508e-05\n",
      "[1864]\ttraining's binary_logloss: 1.4119e-05\n",
      "[1865]\ttraining's binary_logloss: 1.40842e-05\n",
      "[1866]\ttraining's binary_logloss: 1.40518e-05\n",
      "[1867]\ttraining's binary_logloss: 1.40193e-05\n",
      "[1868]\ttraining's binary_logloss: 1.39886e-05\n",
      "[1869]\ttraining's binary_logloss: 1.39602e-05\n",
      "[1870]\ttraining's binary_logloss: 1.39292e-05\n",
      "[1871]\ttraining's binary_logloss: 1.38972e-05\n",
      "[1872]\ttraining's binary_logloss: 1.38645e-05\n",
      "[1873]\ttraining's binary_logloss: 1.38344e-05\n",
      "[1874]\ttraining's binary_logloss: 1.38042e-05\n",
      "[1875]\ttraining's binary_logloss: 1.37731e-05\n",
      "[1876]\ttraining's binary_logloss: 1.37439e-05\n",
      "[1877]\ttraining's binary_logloss: 1.37088e-05\n",
      "[1878]\ttraining's binary_logloss: 1.36762e-05\n",
      "[1879]\ttraining's binary_logloss: 1.36421e-05\n",
      "[1880]\ttraining's binary_logloss: 1.36113e-05\n",
      "[1881]\ttraining's binary_logloss: 1.35792e-05\n",
      "[1882]\ttraining's binary_logloss: 1.35476e-05\n",
      "[1883]\ttraining's binary_logloss: 1.3517e-05\n",
      "[1884]\ttraining's binary_logloss: 1.34906e-05\n",
      "[1885]\ttraining's binary_logloss: 1.3457e-05\n",
      "[1886]\ttraining's binary_logloss: 1.34246e-05\n",
      "[1887]\ttraining's binary_logloss: 1.3396e-05\n",
      "[1888]\ttraining's binary_logloss: 1.33652e-05\n",
      "[1889]\ttraining's binary_logloss: 1.33376e-05\n",
      "[1890]\ttraining's binary_logloss: 1.33047e-05\n",
      "[1891]\ttraining's binary_logloss: 1.32735e-05\n",
      "[1892]\ttraining's binary_logloss: 1.32471e-05\n",
      "[1893]\ttraining's binary_logloss: 1.32167e-05\n",
      "[1894]\ttraining's binary_logloss: 1.31856e-05\n",
      "[1895]\ttraining's binary_logloss: 1.31576e-05\n",
      "[1896]\ttraining's binary_logloss: 1.31272e-05\n",
      "[1897]\ttraining's binary_logloss: 1.31008e-05\n",
      "[1898]\ttraining's binary_logloss: 1.30727e-05\n",
      "[1899]\ttraining's binary_logloss: 1.30438e-05\n",
      "[1900]\ttraining's binary_logloss: 1.30152e-05\n",
      "[1901]\ttraining's binary_logloss: 1.29865e-05\n",
      "[1902]\ttraining's binary_logloss: 1.29565e-05\n",
      "[1903]\ttraining's binary_logloss: 1.29278e-05\n",
      "[1904]\ttraining's binary_logloss: 1.28999e-05\n",
      "[1905]\ttraining's binary_logloss: 1.28716e-05\n",
      "[1906]\ttraining's binary_logloss: 1.28438e-05\n",
      "[1907]\ttraining's binary_logloss: 1.28152e-05\n",
      "[1908]\ttraining's binary_logloss: 1.27871e-05\n",
      "[1909]\ttraining's binary_logloss: 1.27576e-05\n",
      "[1910]\ttraining's binary_logloss: 1.27296e-05\n",
      "[1911]\ttraining's binary_logloss: 1.27011e-05\n",
      "[1912]\ttraining's binary_logloss: 1.26788e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1913]\ttraining's binary_logloss: 1.26541e-05\n",
      "[1914]\ttraining's binary_logloss: 1.26276e-05\n",
      "[1915]\ttraining's binary_logloss: 1.26026e-05\n",
      "[1916]\ttraining's binary_logloss: 1.2575e-05\n",
      "[1917]\ttraining's binary_logloss: 1.25507e-05\n",
      "[1918]\ttraining's binary_logloss: 1.25275e-05\n",
      "[1919]\ttraining's binary_logloss: 1.24986e-05\n",
      "[1920]\ttraining's binary_logloss: 1.24721e-05\n",
      "[1921]\ttraining's binary_logloss: 1.24471e-05\n",
      "[1922]\ttraining's binary_logloss: 1.24204e-05\n",
      "[1923]\ttraining's binary_logloss: 1.23953e-05\n",
      "[1924]\ttraining's binary_logloss: 1.23693e-05\n",
      "[1925]\ttraining's binary_logloss: 1.23454e-05\n",
      "[1926]\ttraining's binary_logloss: 1.23203e-05\n",
      "[1927]\ttraining's binary_logloss: 1.22959e-05\n",
      "[1928]\ttraining's binary_logloss: 1.22722e-05\n",
      "[1929]\ttraining's binary_logloss: 1.22487e-05\n",
      "[1930]\ttraining's binary_logloss: 1.2225e-05\n",
      "[1931]\ttraining's binary_logloss: 1.22018e-05\n",
      "[1932]\ttraining's binary_logloss: 1.21785e-05\n",
      "[1933]\ttraining's binary_logloss: 1.21539e-05\n",
      "[1934]\ttraining's binary_logloss: 1.21296e-05\n",
      "[1935]\ttraining's binary_logloss: 1.21062e-05\n",
      "[1936]\ttraining's binary_logloss: 1.20824e-05\n",
      "[1937]\ttraining's binary_logloss: 1.20557e-05\n",
      "[1938]\ttraining's binary_logloss: 1.20312e-05\n",
      "[1939]\ttraining's binary_logloss: 1.2005e-05\n",
      "[1940]\ttraining's binary_logloss: 1.19805e-05\n",
      "[1941]\ttraining's binary_logloss: 1.19591e-05\n",
      "[1942]\ttraining's binary_logloss: 1.19351e-05\n",
      "[1943]\ttraining's binary_logloss: 1.19119e-05\n",
      "[1944]\ttraining's binary_logloss: 1.18847e-05\n",
      "[1945]\ttraining's binary_logloss: 1.18631e-05\n",
      "[1946]\ttraining's binary_logloss: 1.18396e-05\n",
      "[1947]\ttraining's binary_logloss: 1.18157e-05\n",
      "[1948]\ttraining's binary_logloss: 1.1795e-05\n",
      "[1949]\ttraining's binary_logloss: 1.17733e-05\n",
      "[1950]\ttraining's binary_logloss: 1.17516e-05\n",
      "[1951]\ttraining's binary_logloss: 1.17279e-05\n",
      "[1952]\ttraining's binary_logloss: 1.17063e-05\n",
      "[1953]\ttraining's binary_logloss: 1.16844e-05\n",
      "[1954]\ttraining's binary_logloss: 1.16586e-05\n",
      "[1955]\ttraining's binary_logloss: 1.1636e-05\n",
      "[1956]\ttraining's binary_logloss: 1.1613e-05\n",
      "[1957]\ttraining's binary_logloss: 1.15917e-05\n",
      "[1958]\ttraining's binary_logloss: 1.1569e-05\n",
      "[1959]\ttraining's binary_logloss: 1.15467e-05\n",
      "[1960]\ttraining's binary_logloss: 1.1524e-05\n",
      "[1961]\ttraining's binary_logloss: 1.15027e-05\n",
      "[1962]\ttraining's binary_logloss: 1.14816e-05\n",
      "[1963]\ttraining's binary_logloss: 1.14591e-05\n",
      "[1964]\ttraining's binary_logloss: 1.14356e-05\n",
      "[1965]\ttraining's binary_logloss: 1.14155e-05\n",
      "[1966]\ttraining's binary_logloss: 1.13939e-05\n",
      "[1967]\ttraining's binary_logloss: 1.13715e-05\n",
      "[1968]\ttraining's binary_logloss: 1.13488e-05\n",
      "[1969]\ttraining's binary_logloss: 1.13304e-05\n",
      "[1970]\ttraining's binary_logloss: 1.13114e-05\n",
      "[1971]\ttraining's binary_logloss: 1.12907e-05\n",
      "[1972]\ttraining's binary_logloss: 1.12701e-05\n",
      "[1973]\ttraining's binary_logloss: 1.125e-05\n",
      "[1974]\ttraining's binary_logloss: 1.12299e-05\n",
      "[1975]\ttraining's binary_logloss: 1.1211e-05\n",
      "[1976]\ttraining's binary_logloss: 1.11919e-05\n",
      "[1977]\ttraining's binary_logloss: 1.11692e-05\n",
      "[1978]\ttraining's binary_logloss: 1.11505e-05\n",
      "[1979]\ttraining's binary_logloss: 1.11319e-05\n",
      "[1980]\ttraining's binary_logloss: 1.11126e-05\n",
      "[1981]\ttraining's binary_logloss: 1.10921e-05\n",
      "[1982]\ttraining's binary_logloss: 1.1072e-05\n",
      "[1983]\ttraining's binary_logloss: 1.10506e-05\n",
      "[1984]\ttraining's binary_logloss: 1.1029e-05\n",
      "[1985]\ttraining's binary_logloss: 1.10076e-05\n",
      "[1986]\ttraining's binary_logloss: 1.09879e-05\n",
      "[1987]\ttraining's binary_logloss: 1.09695e-05\n",
      "[1988]\ttraining's binary_logloss: 1.09499e-05\n",
      "[1989]\ttraining's binary_logloss: 1.09309e-05\n",
      "[1990]\ttraining's binary_logloss: 1.09079e-05\n",
      "[1991]\ttraining's binary_logloss: 1.08882e-05\n",
      "[1992]\ttraining's binary_logloss: 1.0869e-05\n",
      "[1993]\ttraining's binary_logloss: 1.0851e-05\n",
      "[1994]\ttraining's binary_logloss: 1.08329e-05\n",
      "[1995]\ttraining's binary_logloss: 1.08127e-05\n",
      "[1996]\ttraining's binary_logloss: 1.07928e-05\n",
      "[1997]\ttraining's binary_logloss: 1.07708e-05\n",
      "[1998]\ttraining's binary_logloss: 1.07497e-05\n",
      "[1999]\ttraining's binary_logloss: 1.07327e-05\n",
      "[2000]\ttraining's binary_logloss: 1.07151e-05\n",
      "[2001]\ttraining's binary_logloss: 1.06983e-05\n",
      "[2002]\ttraining's binary_logloss: 1.06817e-05\n",
      "[2003]\ttraining's binary_logloss: 1.06619e-05\n",
      "[2004]\ttraining's binary_logloss: 1.06419e-05\n",
      "[2005]\ttraining's binary_logloss: 1.06231e-05\n",
      "[2006]\ttraining's binary_logloss: 1.06056e-05\n",
      "[2007]\ttraining's binary_logloss: 1.05855e-05\n",
      "[2008]\ttraining's binary_logloss: 1.05653e-05\n",
      "[2009]\ttraining's binary_logloss: 1.05467e-05\n",
      "[2010]\ttraining's binary_logloss: 1.05309e-05\n",
      "[2011]\ttraining's binary_logloss: 1.05135e-05\n",
      "[2012]\ttraining's binary_logloss: 1.04965e-05\n",
      "[2013]\ttraining's binary_logloss: 1.0478e-05\n",
      "[2014]\ttraining's binary_logloss: 1.0459e-05\n",
      "[2015]\ttraining's binary_logloss: 1.04417e-05\n",
      "[2016]\ttraining's binary_logloss: 1.04229e-05\n",
      "[2017]\ttraining's binary_logloss: 1.04046e-05\n",
      "[2018]\ttraining's binary_logloss: 1.03864e-05\n",
      "[2019]\ttraining's binary_logloss: 1.03668e-05\n",
      "[2020]\ttraining's binary_logloss: 1.03494e-05\n",
      "[2021]\ttraining's binary_logloss: 1.03302e-05\n",
      "[2022]\ttraining's binary_logloss: 1.03131e-05\n",
      "[2023]\ttraining's binary_logloss: 1.02959e-05\n",
      "[2024]\ttraining's binary_logloss: 1.02788e-05\n",
      "[2025]\ttraining's binary_logloss: 1.02608e-05\n",
      "[2026]\ttraining's binary_logloss: 1.02445e-05\n",
      "[2027]\ttraining's binary_logloss: 1.02272e-05\n",
      "[2028]\ttraining's binary_logloss: 1.02097e-05\n",
      "[2029]\ttraining's binary_logloss: 1.01934e-05\n",
      "[2030]\ttraining's binary_logloss: 1.01749e-05\n",
      "[2031]\ttraining's binary_logloss: 1.0157e-05\n",
      "[2032]\ttraining's binary_logloss: 1.01372e-05\n",
      "[2033]\ttraining's binary_logloss: 1.0121e-05\n",
      "[2034]\ttraining's binary_logloss: 1.0105e-05\n",
      "[2035]\ttraining's binary_logloss: 1.00886e-05\n",
      "[2036]\ttraining's binary_logloss: 1.00708e-05\n",
      "[2037]\ttraining's binary_logloss: 1.00546e-05\n",
      "[2038]\ttraining's binary_logloss: 1.00386e-05\n",
      "[2039]\ttraining's binary_logloss: 1.00231e-05\n",
      "[2040]\ttraining's binary_logloss: 1.00073e-05\n",
      "[2041]\ttraining's binary_logloss: 9.99173e-06\n",
      "[2042]\ttraining's binary_logloss: 9.97528e-06\n",
      "[2043]\ttraining's binary_logloss: 9.96032e-06\n",
      "[2044]\ttraining's binary_logloss: 9.94414e-06\n",
      "[2045]\ttraining's binary_logloss: 9.92936e-06\n",
      "[2046]\ttraining's binary_logloss: 9.91172e-06\n",
      "[2047]\ttraining's binary_logloss: 9.89593e-06\n",
      "[2048]\ttraining's binary_logloss: 9.88027e-06\n",
      "[2049]\ttraining's binary_logloss: 9.86395e-06\n",
      "[2050]\ttraining's binary_logloss: 9.84732e-06\n",
      "[2051]\ttraining's binary_logloss: 9.83218e-06\n",
      "[2052]\ttraining's binary_logloss: 9.81753e-06\n",
      "[2053]\ttraining's binary_logloss: 9.80183e-06\n",
      "[2054]\ttraining's binary_logloss: 9.78673e-06\n",
      "[2055]\ttraining's binary_logloss: 9.7708e-06\n",
      "[2056]\ttraining's binary_logloss: 9.75536e-06\n",
      "[2057]\ttraining's binary_logloss: 9.7393e-06\n",
      "[2058]\ttraining's binary_logloss: 9.72412e-06\n",
      "[2059]\ttraining's binary_logloss: 9.70784e-06\n",
      "[2060]\ttraining's binary_logloss: 9.69279e-06\n",
      "[2061]\ttraining's binary_logloss: 9.67752e-06\n",
      "[2062]\ttraining's binary_logloss: 9.65998e-06\n",
      "[2063]\ttraining's binary_logloss: 9.64442e-06\n",
      "[2064]\ttraining's binary_logloss: 9.62747e-06\n",
      "[2065]\ttraining's binary_logloss: 9.61316e-06\n",
      "[2066]\ttraining's binary_logloss: 9.59882e-06\n",
      "[2067]\ttraining's binary_logloss: 9.58461e-06\n",
      "[2068]\ttraining's binary_logloss: 9.5709e-06\n",
      "[2069]\ttraining's binary_logloss: 9.55542e-06\n",
      "[2070]\ttraining's binary_logloss: 9.54119e-06\n",
      "[2071]\ttraining's binary_logloss: 9.52606e-06\n",
      "[2072]\ttraining's binary_logloss: 9.51298e-06\n",
      "[2073]\ttraining's binary_logloss: 9.49757e-06\n",
      "[2074]\ttraining's binary_logloss: 9.48309e-06\n",
      "[2075]\ttraining's binary_logloss: 9.46887e-06\n",
      "[2076]\ttraining's binary_logloss: 9.45456e-06\n",
      "[2077]\ttraining's binary_logloss: 9.43958e-06\n",
      "[2078]\ttraining's binary_logloss: 9.42399e-06\n",
      "[2079]\ttraining's binary_logloss: 9.40809e-06\n",
      "[2080]\ttraining's binary_logloss: 9.3925e-06\n",
      "[2081]\ttraining's binary_logloss: 9.37733e-06\n",
      "[2082]\ttraining's binary_logloss: 9.36378e-06\n",
      "[2083]\ttraining's binary_logloss: 9.35081e-06\n",
      "[2084]\ttraining's binary_logloss: 9.33785e-06\n",
      "[2085]\ttraining's binary_logloss: 9.32385e-06\n",
      "[2086]\ttraining's binary_logloss: 9.31031e-06\n",
      "[2087]\ttraining's binary_logloss: 9.29456e-06\n",
      "[2088]\ttraining's binary_logloss: 9.2816e-06\n",
      "[2089]\ttraining's binary_logloss: 9.26663e-06\n",
      "[2090]\ttraining's binary_logloss: 9.25222e-06\n",
      "[2091]\ttraining's binary_logloss: 9.23894e-06\n",
      "[2092]\ttraining's binary_logloss: 9.22587e-06\n",
      "[2093]\ttraining's binary_logloss: 9.21216e-06\n",
      "[2094]\ttraining's binary_logloss: 9.19904e-06\n",
      "[2095]\ttraining's binary_logloss: 9.18438e-06\n",
      "[2096]\ttraining's binary_logloss: 9.16976e-06\n",
      "[2097]\ttraining's binary_logloss: 9.15621e-06\n",
      "[2098]\ttraining's binary_logloss: 9.14385e-06\n",
      "[2099]\ttraining's binary_logloss: 9.12982e-06\n",
      "[2100]\ttraining's binary_logloss: 9.11661e-06\n",
      "[2101]\ttraining's binary_logloss: 9.1016e-06\n",
      "[2102]\ttraining's binary_logloss: 9.08716e-06\n",
      "[2103]\ttraining's binary_logloss: 9.07409e-06\n",
      "[2104]\ttraining's binary_logloss: 9.06202e-06\n",
      "[2105]\ttraining's binary_logloss: 9.04792e-06\n",
      "[2106]\ttraining's binary_logloss: 9.03399e-06\n",
      "[2107]\ttraining's binary_logloss: 9.02018e-06\n",
      "[2108]\ttraining's binary_logloss: 9.00686e-06\n",
      "[2109]\ttraining's binary_logloss: 8.99371e-06\n",
      "[2110]\ttraining's binary_logloss: 8.98071e-06\n",
      "[2111]\ttraining's binary_logloss: 8.96726e-06\n",
      "[2112]\ttraining's binary_logloss: 8.95526e-06\n",
      "[2113]\ttraining's binary_logloss: 8.94278e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2114]\ttraining's binary_logloss: 8.93062e-06\n",
      "[2115]\ttraining's binary_logloss: 8.91724e-06\n",
      "[2116]\ttraining's binary_logloss: 8.90375e-06\n",
      "[2117]\ttraining's binary_logloss: 8.89222e-06\n",
      "[2118]\ttraining's binary_logloss: 8.88093e-06\n",
      "[2119]\ttraining's binary_logloss: 8.86886e-06\n",
      "[2120]\ttraining's binary_logloss: 8.85758e-06\n",
      "[2121]\ttraining's binary_logloss: 8.84595e-06\n",
      "[2122]\ttraining's binary_logloss: 8.83402e-06\n",
      "[2123]\ttraining's binary_logloss: 8.82083e-06\n",
      "[2124]\ttraining's binary_logloss: 8.80649e-06\n",
      "[2125]\ttraining's binary_logloss: 8.79449e-06\n",
      "[2126]\ttraining's binary_logloss: 8.78277e-06\n",
      "[2127]\ttraining's binary_logloss: 8.77066e-06\n",
      "[2128]\ttraining's binary_logloss: 8.75789e-06\n",
      "[2129]\ttraining's binary_logloss: 8.74499e-06\n",
      "[2130]\ttraining's binary_logloss: 8.73311e-06\n",
      "[2131]\ttraining's binary_logloss: 8.72241e-06\n",
      "[2132]\ttraining's binary_logloss: 8.70848e-06\n",
      "[2133]\ttraining's binary_logloss: 8.69479e-06\n",
      "[2134]\ttraining's binary_logloss: 8.68418e-06\n",
      "[2135]\ttraining's binary_logloss: 8.67147e-06\n",
      "[2136]\ttraining's binary_logloss: 8.65879e-06\n",
      "[2137]\ttraining's binary_logloss: 8.64611e-06\n",
      "[2138]\ttraining's binary_logloss: 8.63464e-06\n",
      "[2139]\ttraining's binary_logloss: 8.62221e-06\n",
      "[2140]\ttraining's binary_logloss: 8.61035e-06\n",
      "[2141]\ttraining's binary_logloss: 8.59857e-06\n",
      "[2142]\ttraining's binary_logloss: 8.58698e-06\n",
      "[2143]\ttraining's binary_logloss: 8.57338e-06\n",
      "[2144]\ttraining's binary_logloss: 8.56293e-06\n",
      "[2145]\ttraining's binary_logloss: 8.55037e-06\n",
      "[2146]\ttraining's binary_logloss: 8.538e-06\n",
      "[2147]\ttraining's binary_logloss: 8.52555e-06\n",
      "[2148]\ttraining's binary_logloss: 8.5143e-06\n",
      "[2149]\ttraining's binary_logloss: 8.50351e-06\n",
      "[2150]\ttraining's binary_logloss: 8.49252e-06\n",
      "[2151]\ttraining's binary_logloss: 8.48138e-06\n",
      "[2152]\ttraining's binary_logloss: 8.47037e-06\n",
      "[2153]\ttraining's binary_logloss: 8.45878e-06\n",
      "[2154]\ttraining's binary_logloss: 8.44827e-06\n",
      "[2155]\ttraining's binary_logloss: 8.43713e-06\n",
      "[2156]\ttraining's binary_logloss: 8.42529e-06\n",
      "[2157]\ttraining's binary_logloss: 8.41431e-06\n",
      "[2158]\ttraining's binary_logloss: 8.4018e-06\n",
      "[2159]\ttraining's binary_logloss: 8.39199e-06\n",
      "[2160]\ttraining's binary_logloss: 8.38241e-06\n",
      "[2161]\ttraining's binary_logloss: 8.37297e-06\n",
      "[2162]\ttraining's binary_logloss: 8.36225e-06\n",
      "[2163]\ttraining's binary_logloss: 8.35111e-06\n",
      "[2164]\ttraining's binary_logloss: 8.34002e-06\n",
      "[2165]\ttraining's binary_logloss: 8.33073e-06\n",
      "[2166]\ttraining's binary_logloss: 8.31915e-06\n",
      "[2167]\ttraining's binary_logloss: 8.30868e-06\n",
      "[2168]\ttraining's binary_logloss: 8.29758e-06\n",
      "[2169]\ttraining's binary_logloss: 8.28693e-06\n",
      "[2170]\ttraining's binary_logloss: 8.27649e-06\n",
      "[2171]\ttraining's binary_logloss: 8.26496e-06\n",
      "[2172]\ttraining's binary_logloss: 8.25427e-06\n",
      "[2173]\ttraining's binary_logloss: 8.24237e-06\n",
      "[2174]\ttraining's binary_logloss: 8.22977e-06\n",
      "[2175]\ttraining's binary_logloss: 8.21935e-06\n",
      "[2176]\ttraining's binary_logloss: 8.2089e-06\n",
      "[2177]\ttraining's binary_logloss: 8.19762e-06\n",
      "[2178]\ttraining's binary_logloss: 8.18717e-06\n",
      "[2179]\ttraining's binary_logloss: 8.17523e-06\n",
      "[2180]\ttraining's binary_logloss: 8.16386e-06\n",
      "[2181]\ttraining's binary_logloss: 8.15421e-06\n",
      "[2182]\ttraining's binary_logloss: 8.14392e-06\n",
      "[2183]\ttraining's binary_logloss: 8.13269e-06\n",
      "[2184]\ttraining's binary_logloss: 8.12267e-06\n",
      "[2185]\ttraining's binary_logloss: 8.11137e-06\n",
      "[2186]\ttraining's binary_logloss: 8.1009e-06\n",
      "[2187]\ttraining's binary_logloss: 8.09064e-06\n",
      "[2188]\ttraining's binary_logloss: 8.0811e-06\n",
      "[2189]\ttraining's binary_logloss: 8.07115e-06\n",
      "[2190]\ttraining's binary_logloss: 8.0607e-06\n",
      "[2191]\ttraining's binary_logloss: 8.04973e-06\n",
      "[2192]\ttraining's binary_logloss: 8.03758e-06\n",
      "[2193]\ttraining's binary_logloss: 8.02664e-06\n",
      "[2194]\ttraining's binary_logloss: 8.01584e-06\n",
      "[2195]\ttraining's binary_logloss: 8.00563e-06\n",
      "[2196]\ttraining's binary_logloss: 7.99587e-06\n",
      "[2197]\ttraining's binary_logloss: 7.9869e-06\n",
      "[2198]\ttraining's binary_logloss: 7.97626e-06\n",
      "[2199]\ttraining's binary_logloss: 7.9655e-06\n",
      "[2200]\ttraining's binary_logloss: 7.95544e-06\n",
      "[2201]\ttraining's binary_logloss: 7.94646e-06\n",
      "[2202]\ttraining's binary_logloss: 7.93713e-06\n",
      "[2203]\ttraining's binary_logloss: 7.92683e-06\n",
      "[2204]\ttraining's binary_logloss: 7.91789e-06\n",
      "[2205]\ttraining's binary_logloss: 7.90762e-06\n",
      "[2206]\ttraining's binary_logloss: 7.89792e-06\n",
      "[2207]\ttraining's binary_logloss: 7.8883e-06\n",
      "[2208]\ttraining's binary_logloss: 7.87896e-06\n",
      "[2209]\ttraining's binary_logloss: 7.86889e-06\n",
      "[2210]\ttraining's binary_logloss: 7.85964e-06\n",
      "[2211]\ttraining's binary_logloss: 7.85174e-06\n",
      "[2212]\ttraining's binary_logloss: 7.84134e-06\n",
      "[2213]\ttraining's binary_logloss: 7.83113e-06\n",
      "[2214]\ttraining's binary_logloss: 7.82177e-06\n",
      "[2215]\ttraining's binary_logloss: 7.8131e-06\n",
      "[2216]\ttraining's binary_logloss: 7.80401e-06\n",
      "[2217]\ttraining's binary_logloss: 7.79427e-06\n",
      "[2218]\ttraining's binary_logloss: 7.78526e-06\n",
      "[2219]\ttraining's binary_logloss: 7.77569e-06\n",
      "[2220]\ttraining's binary_logloss: 7.76632e-06\n",
      "[2221]\ttraining's binary_logloss: 7.75636e-06\n",
      "[2222]\ttraining's binary_logloss: 7.74802e-06\n",
      "[2223]\ttraining's binary_logloss: 7.73964e-06\n",
      "[2224]\ttraining's binary_logloss: 7.72998e-06\n",
      "[2225]\ttraining's binary_logloss: 7.71947e-06\n",
      "[2226]\ttraining's binary_logloss: 7.70884e-06\n",
      "[2227]\ttraining's binary_logloss: 7.69857e-06\n",
      "[2228]\ttraining's binary_logloss: 7.68871e-06\n",
      "[2229]\ttraining's binary_logloss: 7.67904e-06\n",
      "[2230]\ttraining's binary_logloss: 7.66868e-06\n",
      "[2231]\ttraining's binary_logloss: 7.6582e-06\n",
      "[2232]\ttraining's binary_logloss: 7.64763e-06\n",
      "[2233]\ttraining's binary_logloss: 7.63853e-06\n",
      "[2234]\ttraining's binary_logloss: 7.62948e-06\n",
      "[2235]\ttraining's binary_logloss: 7.62074e-06\n",
      "[2236]\ttraining's binary_logloss: 7.61152e-06\n",
      "[2237]\ttraining's binary_logloss: 7.6019e-06\n",
      "[2238]\ttraining's binary_logloss: 7.59372e-06\n",
      "[2239]\ttraining's binary_logloss: 7.58477e-06\n",
      "[2240]\ttraining's binary_logloss: 7.57631e-06\n",
      "[2241]\ttraining's binary_logloss: 7.56723e-06\n",
      "[2242]\ttraining's binary_logloss: 7.55771e-06\n",
      "[2243]\ttraining's binary_logloss: 7.54885e-06\n",
      "[2244]\ttraining's binary_logloss: 7.5409e-06\n",
      "[2245]\ttraining's binary_logloss: 7.53042e-06\n",
      "[2246]\ttraining's binary_logloss: 7.52298e-06\n",
      "[2247]\ttraining's binary_logloss: 7.5127e-06\n",
      "[2248]\ttraining's binary_logloss: 7.50338e-06\n",
      "[2249]\ttraining's binary_logloss: 7.49464e-06\n",
      "[2250]\ttraining's binary_logloss: 7.48601e-06\n",
      "[2251]\ttraining's binary_logloss: 7.47673e-06\n",
      "[2252]\ttraining's binary_logloss: 7.46795e-06\n",
      "[2253]\ttraining's binary_logloss: 7.4592e-06\n",
      "[2254]\ttraining's binary_logloss: 7.45076e-06\n",
      "[2255]\ttraining's binary_logloss: 7.4412e-06\n",
      "[2256]\ttraining's binary_logloss: 7.43219e-06\n",
      "[2257]\ttraining's binary_logloss: 7.42431e-06\n",
      "[2258]\ttraining's binary_logloss: 7.41569e-06\n",
      "[2259]\ttraining's binary_logloss: 7.40735e-06\n",
      "[2260]\ttraining's binary_logloss: 7.39662e-06\n",
      "[2261]\ttraining's binary_logloss: 7.38889e-06\n",
      "[2262]\ttraining's binary_logloss: 7.38047e-06\n",
      "[2263]\ttraining's binary_logloss: 7.37205e-06\n",
      "[2264]\ttraining's binary_logloss: 7.36258e-06\n",
      "[2265]\ttraining's binary_logloss: 7.35497e-06\n",
      "[2266]\ttraining's binary_logloss: 7.3466e-06\n",
      "[2267]\ttraining's binary_logloss: 7.33769e-06\n",
      "[2268]\ttraining's binary_logloss: 7.33013e-06\n",
      "[2269]\ttraining's binary_logloss: 7.32102e-06\n",
      "[2270]\ttraining's binary_logloss: 7.31212e-06\n",
      "[2271]\ttraining's binary_logloss: 7.30369e-06\n",
      "[2272]\ttraining's binary_logloss: 7.29665e-06\n",
      "[2273]\ttraining's binary_logloss: 7.28934e-06\n",
      "[2274]\ttraining's binary_logloss: 7.28206e-06\n",
      "[2275]\ttraining's binary_logloss: 7.27374e-06\n",
      "[2276]\ttraining's binary_logloss: 7.2655e-06\n",
      "[2277]\ttraining's binary_logloss: 7.25752e-06\n",
      "[2278]\ttraining's binary_logloss: 7.25007e-06\n",
      "[2279]\ttraining's binary_logloss: 7.24111e-06\n",
      "[2280]\ttraining's binary_logloss: 7.23337e-06\n",
      "[2281]\ttraining's binary_logloss: 7.22596e-06\n",
      "[2282]\ttraining's binary_logloss: 7.2182e-06\n",
      "[2283]\ttraining's binary_logloss: 7.20948e-06\n",
      "[2284]\ttraining's binary_logloss: 7.20036e-06\n",
      "[2285]\ttraining's binary_logloss: 7.19117e-06\n",
      "[2286]\ttraining's binary_logloss: 7.18398e-06\n",
      "[2287]\ttraining's binary_logloss: 7.17644e-06\n",
      "[2288]\ttraining's binary_logloss: 7.16793e-06\n",
      "[2289]\ttraining's binary_logloss: 7.1594e-06\n",
      "[2290]\ttraining's binary_logloss: 7.15014e-06\n",
      "[2291]\ttraining's binary_logloss: 7.14175e-06\n",
      "[2292]\ttraining's binary_logloss: 7.13259e-06\n",
      "[2293]\ttraining's binary_logloss: 7.12483e-06\n",
      "[2294]\ttraining's binary_logloss: 7.11705e-06\n",
      "[2295]\ttraining's binary_logloss: 7.11015e-06\n",
      "[2296]\ttraining's binary_logloss: 7.10233e-06\n",
      "[2297]\ttraining's binary_logloss: 7.09276e-06\n",
      "[2298]\ttraining's binary_logloss: 7.08528e-06\n",
      "[2299]\ttraining's binary_logloss: 7.07696e-06\n",
      "[2300]\ttraining's binary_logloss: 7.06919e-06\n",
      "[2301]\ttraining's binary_logloss: 7.06232e-06\n",
      "[2302]\ttraining's binary_logloss: 7.05327e-06\n",
      "[2303]\ttraining's binary_logloss: 7.0445e-06\n",
      "[2304]\ttraining's binary_logloss: 7.03691e-06\n",
      "[2305]\ttraining's binary_logloss: 7.02868e-06\n",
      "[2306]\ttraining's binary_logloss: 7.02062e-06\n",
      "[2307]\ttraining's binary_logloss: 7.01212e-06\n",
      "[2308]\ttraining's binary_logloss: 7.00443e-06\n",
      "[2309]\ttraining's binary_logloss: 6.99699e-06\n",
      "[2310]\ttraining's binary_logloss: 6.98926e-06\n",
      "[2311]\ttraining's binary_logloss: 6.98223e-06\n",
      "[2312]\ttraining's binary_logloss: 6.97435e-06\n",
      "[2313]\ttraining's binary_logloss: 6.96673e-06\n",
      "[2314]\ttraining's binary_logloss: 6.9598e-06\n",
      "[2315]\ttraining's binary_logloss: 6.95185e-06\n",
      "[2316]\ttraining's binary_logloss: 6.94436e-06\n",
      "[2317]\ttraining's binary_logloss: 6.93726e-06\n",
      "[2318]\ttraining's binary_logloss: 6.92901e-06\n",
      "[2319]\ttraining's binary_logloss: 6.92132e-06\n",
      "[2320]\ttraining's binary_logloss: 6.91363e-06\n",
      "[2321]\ttraining's binary_logloss: 6.90662e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2322]\ttraining's binary_logloss: 6.89897e-06\n",
      "[2323]\ttraining's binary_logloss: 6.89206e-06\n",
      "[2324]\ttraining's binary_logloss: 6.88506e-06\n",
      "[2325]\ttraining's binary_logloss: 6.87709e-06\n",
      "[2326]\ttraining's binary_logloss: 6.86885e-06\n",
      "[2327]\ttraining's binary_logloss: 6.86128e-06\n",
      "[2328]\ttraining's binary_logloss: 6.85458e-06\n",
      "[2329]\ttraining's binary_logloss: 6.84605e-06\n",
      "[2330]\ttraining's binary_logloss: 6.83895e-06\n",
      "[2331]\ttraining's binary_logloss: 6.8312e-06\n",
      "[2332]\ttraining's binary_logloss: 6.82387e-06\n",
      "[2333]\ttraining's binary_logloss: 6.81632e-06\n",
      "[2334]\ttraining's binary_logloss: 6.80914e-06\n",
      "[2335]\ttraining's binary_logloss: 6.80199e-06\n",
      "[2336]\ttraining's binary_logloss: 6.7952e-06\n",
      "[2337]\ttraining's binary_logloss: 6.788e-06\n",
      "[2338]\ttraining's binary_logloss: 6.78179e-06\n",
      "[2339]\ttraining's binary_logloss: 6.77405e-06\n",
      "[2340]\ttraining's binary_logloss: 6.76733e-06\n",
      "[2341]\ttraining's binary_logloss: 6.7612e-06\n",
      "[2342]\ttraining's binary_logloss: 6.75366e-06\n",
      "[2343]\ttraining's binary_logloss: 6.74633e-06\n",
      "[2344]\ttraining's binary_logloss: 6.73872e-06\n",
      "[2345]\ttraining's binary_logloss: 6.73206e-06\n",
      "[2346]\ttraining's binary_logloss: 6.72508e-06\n",
      "[2347]\ttraining's binary_logloss: 6.71845e-06\n",
      "[2348]\ttraining's binary_logloss: 6.71224e-06\n",
      "[2349]\ttraining's binary_logloss: 6.70491e-06\n",
      "[2350]\ttraining's binary_logloss: 6.69764e-06\n",
      "[2351]\ttraining's binary_logloss: 6.68997e-06\n",
      "[2352]\ttraining's binary_logloss: 6.68286e-06\n",
      "[2353]\ttraining's binary_logloss: 6.67587e-06\n",
      "[2354]\ttraining's binary_logloss: 6.66824e-06\n",
      "[2355]\ttraining's binary_logloss: 6.66093e-06\n",
      "[2356]\ttraining's binary_logloss: 6.65446e-06\n",
      "[2357]\ttraining's binary_logloss: 6.64768e-06\n",
      "[2358]\ttraining's binary_logloss: 6.64061e-06\n",
      "[2359]\ttraining's binary_logloss: 6.6333e-06\n",
      "[2360]\ttraining's binary_logloss: 6.62679e-06\n",
      "[2361]\ttraining's binary_logloss: 6.61912e-06\n",
      "[2362]\ttraining's binary_logloss: 6.61244e-06\n",
      "[2363]\ttraining's binary_logloss: 6.60525e-06\n",
      "[2364]\ttraining's binary_logloss: 6.59806e-06\n",
      "[2365]\ttraining's binary_logloss: 6.59137e-06\n",
      "[2366]\ttraining's binary_logloss: 6.58439e-06\n",
      "[2367]\ttraining's binary_logloss: 6.5779e-06\n",
      "[2368]\ttraining's binary_logloss: 6.56993e-06\n",
      "[2369]\ttraining's binary_logloss: 6.56163e-06\n",
      "[2370]\ttraining's binary_logloss: 6.55392e-06\n",
      "[2371]\ttraining's binary_logloss: 6.54759e-06\n",
      "[2372]\ttraining's binary_logloss: 6.5401e-06\n",
      "[2373]\ttraining's binary_logloss: 6.53296e-06\n",
      "[2374]\ttraining's binary_logloss: 6.52647e-06\n",
      "[2375]\ttraining's binary_logloss: 6.52008e-06\n",
      "[2376]\ttraining's binary_logloss: 6.51296e-06\n",
      "[2377]\ttraining's binary_logloss: 6.50686e-06\n",
      "[2378]\ttraining's binary_logloss: 6.49998e-06\n",
      "[2379]\ttraining's binary_logloss: 6.494e-06\n",
      "[2380]\ttraining's binary_logloss: 6.48886e-06\n",
      "[2381]\ttraining's binary_logloss: 6.48268e-06\n",
      "[2382]\ttraining's binary_logloss: 6.47612e-06\n",
      "[2383]\ttraining's binary_logloss: 6.4696e-06\n",
      "[2384]\ttraining's binary_logloss: 6.46261e-06\n",
      "[2385]\ttraining's binary_logloss: 6.45628e-06\n",
      "[2386]\ttraining's binary_logloss: 6.45017e-06\n",
      "[2387]\ttraining's binary_logloss: 6.4446e-06\n",
      "[2388]\ttraining's binary_logloss: 6.43836e-06\n",
      "[2389]\ttraining's binary_logloss: 6.4319e-06\n",
      "[2390]\ttraining's binary_logloss: 6.42564e-06\n",
      "[2391]\ttraining's binary_logloss: 6.4201e-06\n",
      "[2392]\ttraining's binary_logloss: 6.41447e-06\n",
      "[2393]\ttraining's binary_logloss: 6.40822e-06\n",
      "[2394]\ttraining's binary_logloss: 6.40274e-06\n",
      "[2395]\ttraining's binary_logloss: 6.39662e-06\n",
      "[2396]\ttraining's binary_logloss: 6.3895e-06\n",
      "[2397]\ttraining's binary_logloss: 6.38339e-06\n",
      "[2398]\ttraining's binary_logloss: 6.37664e-06\n",
      "[2399]\ttraining's binary_logloss: 6.3699e-06\n",
      "[2400]\ttraining's binary_logloss: 6.36413e-06\n",
      "[2401]\ttraining's binary_logloss: 6.35768e-06\n",
      "[2402]\ttraining's binary_logloss: 6.35123e-06\n",
      "[2403]\ttraining's binary_logloss: 6.34495e-06\n",
      "[2404]\ttraining's binary_logloss: 6.33926e-06\n",
      "[2405]\ttraining's binary_logloss: 6.33345e-06\n",
      "[2406]\ttraining's binary_logloss: 6.32651e-06\n",
      "[2407]\ttraining's binary_logloss: 6.3207e-06\n",
      "[2408]\ttraining's binary_logloss: 6.31407e-06\n",
      "[2409]\ttraining's binary_logloss: 6.30706e-06\n",
      "[2410]\ttraining's binary_logloss: 6.30071e-06\n",
      "[2411]\ttraining's binary_logloss: 6.29434e-06\n",
      "[2412]\ttraining's binary_logloss: 6.28843e-06\n",
      "[2413]\ttraining's binary_logloss: 6.28264e-06\n",
      "[2414]\ttraining's binary_logloss: 6.27694e-06\n",
      "[2415]\ttraining's binary_logloss: 6.2708e-06\n",
      "[2416]\ttraining's binary_logloss: 6.26447e-06\n",
      "[2417]\ttraining's binary_logloss: 6.25873e-06\n",
      "[2418]\ttraining's binary_logloss: 6.25316e-06\n",
      "[2419]\ttraining's binary_logloss: 6.24722e-06\n",
      "[2420]\ttraining's binary_logloss: 6.24183e-06\n",
      "[2421]\ttraining's binary_logloss: 6.23636e-06\n",
      "[2422]\ttraining's binary_logloss: 6.23048e-06\n",
      "[2423]\ttraining's binary_logloss: 6.22469e-06\n",
      "[2424]\ttraining's binary_logloss: 6.21935e-06\n",
      "[2425]\ttraining's binary_logloss: 6.21287e-06\n",
      "[2426]\ttraining's binary_logloss: 6.20731e-06\n",
      "[2427]\ttraining's binary_logloss: 6.20075e-06\n",
      "[2428]\ttraining's binary_logloss: 6.19479e-06\n",
      "[2429]\ttraining's binary_logloss: 6.18947e-06\n",
      "[2430]\ttraining's binary_logloss: 6.1828e-06\n",
      "[2431]\ttraining's binary_logloss: 6.17703e-06\n",
      "[2432]\ttraining's binary_logloss: 6.1714e-06\n",
      "[2433]\ttraining's binary_logloss: 6.16593e-06\n",
      "[2434]\ttraining's binary_logloss: 6.15996e-06\n",
      "[2435]\ttraining's binary_logloss: 6.1538e-06\n",
      "[2436]\ttraining's binary_logloss: 6.14804e-06\n",
      "[2437]\ttraining's binary_logloss: 6.14225e-06\n",
      "[2438]\ttraining's binary_logloss: 6.13619e-06\n",
      "[2439]\ttraining's binary_logloss: 6.13065e-06\n",
      "[2440]\ttraining's binary_logloss: 6.12514e-06\n",
      "[2441]\ttraining's binary_logloss: 6.1196e-06\n",
      "[2442]\ttraining's binary_logloss: 6.11365e-06\n",
      "[2443]\ttraining's binary_logloss: 6.10773e-06\n",
      "[2444]\ttraining's binary_logloss: 6.10256e-06\n",
      "[2445]\ttraining's binary_logloss: 6.09623e-06\n",
      "[2446]\ttraining's binary_logloss: 6.08973e-06\n",
      "[2447]\ttraining's binary_logloss: 6.08385e-06\n",
      "[2448]\ttraining's binary_logloss: 6.0785e-06\n",
      "[2449]\ttraining's binary_logloss: 6.07276e-06\n",
      "[2450]\ttraining's binary_logloss: 6.06717e-06\n",
      "[2451]\ttraining's binary_logloss: 6.06127e-06\n",
      "[2452]\ttraining's binary_logloss: 6.05521e-06\n",
      "[2453]\ttraining's binary_logloss: 6.04881e-06\n",
      "[2454]\ttraining's binary_logloss: 6.04256e-06\n",
      "[2455]\ttraining's binary_logloss: 6.03681e-06\n",
      "[2456]\ttraining's binary_logloss: 6.03177e-06\n",
      "[2457]\ttraining's binary_logloss: 6.02562e-06\n",
      "[2458]\ttraining's binary_logloss: 6.02063e-06\n",
      "[2459]\ttraining's binary_logloss: 6.01541e-06\n",
      "[2460]\ttraining's binary_logloss: 6.01014e-06\n",
      "[2461]\ttraining's binary_logloss: 6.00374e-06\n",
      "[2462]\ttraining's binary_logloss: 5.99783e-06\n",
      "[2463]\ttraining's binary_logloss: 5.99268e-06\n",
      "[2464]\ttraining's binary_logloss: 5.98782e-06\n",
      "[2465]\ttraining's binary_logloss: 5.98243e-06\n",
      "[2466]\ttraining's binary_logloss: 5.97674e-06\n",
      "[2467]\ttraining's binary_logloss: 5.9718e-06\n",
      "[2468]\ttraining's binary_logloss: 5.96627e-06\n",
      "[2469]\ttraining's binary_logloss: 5.96029e-06\n",
      "[2470]\ttraining's binary_logloss: 5.95513e-06\n",
      "[2471]\ttraining's binary_logloss: 5.94999e-06\n",
      "[2472]\ttraining's binary_logloss: 5.94526e-06\n",
      "[2473]\ttraining's binary_logloss: 5.93995e-06\n",
      "[2474]\ttraining's binary_logloss: 5.93458e-06\n",
      "[2475]\ttraining's binary_logloss: 5.92975e-06\n",
      "[2476]\ttraining's binary_logloss: 5.92466e-06\n",
      "[2477]\ttraining's binary_logloss: 5.91847e-06\n",
      "[2478]\ttraining's binary_logloss: 5.91285e-06\n",
      "[2479]\ttraining's binary_logloss: 5.90642e-06\n",
      "[2480]\ttraining's binary_logloss: 5.90106e-06\n",
      "[2481]\ttraining's binary_logloss: 5.89616e-06\n",
      "[2482]\ttraining's binary_logloss: 5.89088e-06\n",
      "[2483]\ttraining's binary_logloss: 5.88546e-06\n",
      "[2484]\ttraining's binary_logloss: 5.87989e-06\n",
      "[2485]\ttraining's binary_logloss: 5.87579e-06\n",
      "[2486]\ttraining's binary_logloss: 5.871e-06\n",
      "[2487]\ttraining's binary_logloss: 5.86566e-06\n",
      "[2488]\ttraining's binary_logloss: 5.85983e-06\n",
      "[2489]\ttraining's binary_logloss: 5.8547e-06\n",
      "[2490]\ttraining's binary_logloss: 5.84912e-06\n",
      "[2491]\ttraining's binary_logloss: 5.84385e-06\n",
      "[2492]\ttraining's binary_logloss: 5.83891e-06\n",
      "[2493]\ttraining's binary_logloss: 5.83366e-06\n",
      "[2494]\ttraining's binary_logloss: 5.82839e-06\n",
      "[2495]\ttraining's binary_logloss: 5.82388e-06\n",
      "[2496]\ttraining's binary_logloss: 5.81861e-06\n",
      "[2497]\ttraining's binary_logloss: 5.81283e-06\n",
      "[2498]\ttraining's binary_logloss: 5.80759e-06\n",
      "[2499]\ttraining's binary_logloss: 5.80324e-06\n",
      "[2500]\ttraining's binary_logloss: 5.7989e-06\n",
      "[2501]\ttraining's binary_logloss: 5.79409e-06\n",
      "[2502]\ttraining's binary_logloss: 5.78954e-06\n",
      "[2503]\ttraining's binary_logloss: 5.7846e-06\n",
      "[2504]\ttraining's binary_logloss: 5.77927e-06\n",
      "[2505]\ttraining's binary_logloss: 5.77389e-06\n",
      "[2506]\ttraining's binary_logloss: 5.76842e-06\n",
      "[2507]\ttraining's binary_logloss: 5.76314e-06\n",
      "[2508]\ttraining's binary_logloss: 5.75693e-06\n",
      "[2509]\ttraining's binary_logloss: 5.75233e-06\n",
      "[2510]\ttraining's binary_logloss: 5.74755e-06\n",
      "[2511]\ttraining's binary_logloss: 5.74258e-06\n",
      "[2512]\ttraining's binary_logloss: 5.73727e-06\n",
      "[2513]\ttraining's binary_logloss: 5.73164e-06\n",
      "[2514]\ttraining's binary_logloss: 5.72619e-06\n",
      "[2515]\ttraining's binary_logloss: 5.72107e-06\n",
      "[2516]\ttraining's binary_logloss: 5.71656e-06\n",
      "[2517]\ttraining's binary_logloss: 5.71187e-06\n",
      "[2518]\ttraining's binary_logloss: 5.70741e-06\n",
      "[2519]\ttraining's binary_logloss: 5.70304e-06\n",
      "[2520]\ttraining's binary_logloss: 5.69863e-06\n",
      "[2521]\ttraining's binary_logloss: 5.69348e-06\n",
      "[2522]\ttraining's binary_logloss: 5.6887e-06\n",
      "[2523]\ttraining's binary_logloss: 5.68414e-06\n",
      "[2524]\ttraining's binary_logloss: 5.67908e-06\n",
      "[2525]\ttraining's binary_logloss: 5.67442e-06\n",
      "[2526]\ttraining's binary_logloss: 5.66948e-06\n",
      "[2527]\ttraining's binary_logloss: 5.66417e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2528]\ttraining's binary_logloss: 5.65945e-06\n",
      "[2529]\ttraining's binary_logloss: 5.65439e-06\n",
      "[2530]\ttraining's binary_logloss: 5.64993e-06\n",
      "[2531]\ttraining's binary_logloss: 5.64461e-06\n",
      "[2532]\ttraining's binary_logloss: 5.63981e-06\n",
      "[2533]\ttraining's binary_logloss: 5.63477e-06\n",
      "[2534]\ttraining's binary_logloss: 5.63028e-06\n",
      "[2535]\ttraining's binary_logloss: 5.62559e-06\n",
      "[2536]\ttraining's binary_logloss: 5.62084e-06\n",
      "[2537]\ttraining's binary_logloss: 5.61606e-06\n",
      "[2538]\ttraining's binary_logloss: 5.61161e-06\n",
      "[2539]\ttraining's binary_logloss: 5.60645e-06\n",
      "[2540]\ttraining's binary_logloss: 5.60208e-06\n",
      "[2541]\ttraining's binary_logloss: 5.5977e-06\n",
      "[2542]\ttraining's binary_logloss: 5.59288e-06\n",
      "[2543]\ttraining's binary_logloss: 5.58823e-06\n",
      "[2544]\ttraining's binary_logloss: 5.58404e-06\n",
      "[2545]\ttraining's binary_logloss: 5.57873e-06\n",
      "[2546]\ttraining's binary_logloss: 5.57421e-06\n",
      "[2547]\ttraining's binary_logloss: 5.56906e-06\n",
      "[2548]\ttraining's binary_logloss: 5.5646e-06\n",
      "[2549]\ttraining's binary_logloss: 5.55943e-06\n",
      "[2550]\ttraining's binary_logloss: 5.55437e-06\n",
      "[2551]\ttraining's binary_logloss: 5.5497e-06\n",
      "[2552]\ttraining's binary_logloss: 5.54594e-06\n",
      "[2553]\ttraining's binary_logloss: 5.54084e-06\n",
      "[2554]\ttraining's binary_logloss: 5.53714e-06\n",
      "[2555]\ttraining's binary_logloss: 5.5314e-06\n",
      "[2556]\ttraining's binary_logloss: 5.52756e-06\n",
      "[2557]\ttraining's binary_logloss: 5.52243e-06\n",
      "[2558]\ttraining's binary_logloss: 5.5184e-06\n",
      "[2559]\ttraining's binary_logloss: 5.51331e-06\n",
      "[2560]\ttraining's binary_logloss: 5.50861e-06\n",
      "[2561]\ttraining's binary_logloss: 5.50457e-06\n",
      "[2562]\ttraining's binary_logloss: 5.50004e-06\n",
      "[2563]\ttraining's binary_logloss: 5.49579e-06\n",
      "[2564]\ttraining's binary_logloss: 5.49186e-06\n",
      "[2565]\ttraining's binary_logloss: 5.48774e-06\n",
      "[2566]\ttraining's binary_logloss: 5.48264e-06\n",
      "[2567]\ttraining's binary_logloss: 5.47858e-06\n",
      "[2568]\ttraining's binary_logloss: 5.47449e-06\n",
      "[2569]\ttraining's binary_logloss: 5.47012e-06\n",
      "[2570]\ttraining's binary_logloss: 5.46551e-06\n",
      "[2571]\ttraining's binary_logloss: 5.46087e-06\n",
      "[2572]\ttraining's binary_logloss: 5.45608e-06\n",
      "[2573]\ttraining's binary_logloss: 5.45132e-06\n",
      "[2574]\ttraining's binary_logloss: 5.44728e-06\n",
      "[2575]\ttraining's binary_logloss: 5.44255e-06\n",
      "[2576]\ttraining's binary_logloss: 5.43841e-06\n",
      "[2577]\ttraining's binary_logloss: 5.43434e-06\n",
      "[2578]\ttraining's binary_logloss: 5.42956e-06\n",
      "[2579]\ttraining's binary_logloss: 5.42581e-06\n",
      "[2580]\ttraining's binary_logloss: 5.42123e-06\n",
      "[2581]\ttraining's binary_logloss: 5.41653e-06\n",
      "[2582]\ttraining's binary_logloss: 5.41139e-06\n",
      "[2583]\ttraining's binary_logloss: 5.40706e-06\n",
      "[2584]\ttraining's binary_logloss: 5.40264e-06\n",
      "[2585]\ttraining's binary_logloss: 5.39796e-06\n",
      "[2586]\ttraining's binary_logloss: 5.394e-06\n",
      "[2587]\ttraining's binary_logloss: 5.38984e-06\n",
      "[2588]\ttraining's binary_logloss: 5.38523e-06\n",
      "[2589]\ttraining's binary_logloss: 5.38095e-06\n",
      "[2590]\ttraining's binary_logloss: 5.3773e-06\n",
      "[2591]\ttraining's binary_logloss: 5.37268e-06\n",
      "[2592]\ttraining's binary_logloss: 5.36787e-06\n",
      "[2593]\ttraining's binary_logloss: 5.36334e-06\n",
      "[2594]\ttraining's binary_logloss: 5.35853e-06\n",
      "[2595]\ttraining's binary_logloss: 5.3545e-06\n",
      "[2596]\ttraining's binary_logloss: 5.35018e-06\n",
      "[2597]\ttraining's binary_logloss: 5.34569e-06\n",
      "[2598]\ttraining's binary_logloss: 5.34134e-06\n",
      "[2599]\ttraining's binary_logloss: 5.33728e-06\n",
      "[2600]\ttraining's binary_logloss: 5.33331e-06\n",
      "[2601]\ttraining's binary_logloss: 5.32942e-06\n",
      "[2602]\ttraining's binary_logloss: 5.32495e-06\n",
      "[2603]\ttraining's binary_logloss: 5.32118e-06\n",
      "[2604]\ttraining's binary_logloss: 5.31684e-06\n",
      "[2605]\ttraining's binary_logloss: 5.31256e-06\n",
      "[2606]\ttraining's binary_logloss: 5.30841e-06\n",
      "[2607]\ttraining's binary_logloss: 5.30446e-06\n",
      "[2608]\ttraining's binary_logloss: 5.30055e-06\n",
      "[2609]\ttraining's binary_logloss: 5.29652e-06\n",
      "[2610]\ttraining's binary_logloss: 5.29264e-06\n",
      "[2611]\ttraining's binary_logloss: 5.28875e-06\n",
      "[2612]\ttraining's binary_logloss: 5.28406e-06\n",
      "[2613]\ttraining's binary_logloss: 5.27983e-06\n",
      "[2614]\ttraining's binary_logloss: 5.27568e-06\n",
      "[2615]\ttraining's binary_logloss: 5.27163e-06\n",
      "[2616]\ttraining's binary_logloss: 5.26729e-06\n",
      "[2617]\ttraining's binary_logloss: 5.26323e-06\n",
      "[2618]\ttraining's binary_logloss: 5.25905e-06\n",
      "[2619]\ttraining's binary_logloss: 5.25483e-06\n",
      "[2620]\ttraining's binary_logloss: 5.25136e-06\n",
      "[2621]\ttraining's binary_logloss: 5.24796e-06\n",
      "[2622]\ttraining's binary_logloss: 5.24322e-06\n",
      "[2623]\ttraining's binary_logloss: 5.23969e-06\n",
      "[2624]\ttraining's binary_logloss: 5.23536e-06\n",
      "[2625]\ttraining's binary_logloss: 5.23194e-06\n",
      "[2626]\ttraining's binary_logloss: 5.22753e-06\n",
      "[2627]\ttraining's binary_logloss: 5.2238e-06\n",
      "[2628]\ttraining's binary_logloss: 5.21929e-06\n",
      "[2629]\ttraining's binary_logloss: 5.21537e-06\n",
      "[2630]\ttraining's binary_logloss: 5.21128e-06\n",
      "[2631]\ttraining's binary_logloss: 5.20681e-06\n",
      "[2632]\ttraining's binary_logloss: 5.20286e-06\n",
      "[2633]\ttraining's binary_logloss: 5.19877e-06\n",
      "[2634]\ttraining's binary_logloss: 5.19529e-06\n",
      "[2635]\ttraining's binary_logloss: 5.19128e-06\n",
      "[2636]\ttraining's binary_logloss: 5.18644e-06\n",
      "[2637]\ttraining's binary_logloss: 5.18198e-06\n",
      "[2638]\ttraining's binary_logloss: 5.17881e-06\n",
      "[2639]\ttraining's binary_logloss: 5.17509e-06\n",
      "[2640]\ttraining's binary_logloss: 5.17033e-06\n",
      "[2641]\ttraining's binary_logloss: 5.16637e-06\n",
      "[2642]\ttraining's binary_logloss: 5.16182e-06\n",
      "[2643]\ttraining's binary_logloss: 5.15776e-06\n",
      "[2644]\ttraining's binary_logloss: 5.15389e-06\n",
      "[2645]\ttraining's binary_logloss: 5.14982e-06\n",
      "[2646]\ttraining's binary_logloss: 5.14604e-06\n",
      "[2647]\ttraining's binary_logloss: 5.14235e-06\n",
      "[2648]\ttraining's binary_logloss: 5.13841e-06\n",
      "[2649]\ttraining's binary_logloss: 5.13481e-06\n",
      "[2650]\ttraining's binary_logloss: 5.13106e-06\n",
      "[2651]\ttraining's binary_logloss: 5.12703e-06\n",
      "[2652]\ttraining's binary_logloss: 5.12342e-06\n",
      "[2653]\ttraining's binary_logloss: 5.11948e-06\n",
      "[2654]\ttraining's binary_logloss: 5.11528e-06\n",
      "[2655]\ttraining's binary_logloss: 5.11099e-06\n",
      "[2656]\ttraining's binary_logloss: 5.10681e-06\n",
      "[2657]\ttraining's binary_logloss: 5.10335e-06\n",
      "[2658]\ttraining's binary_logloss: 5.09973e-06\n",
      "[2659]\ttraining's binary_logloss: 5.09562e-06\n",
      "[2660]\ttraining's binary_logloss: 5.09198e-06\n",
      "[2661]\ttraining's binary_logloss: 5.08807e-06\n",
      "[2662]\ttraining's binary_logloss: 5.08481e-06\n",
      "[2663]\ttraining's binary_logloss: 5.08107e-06\n",
      "[2664]\ttraining's binary_logloss: 5.07755e-06\n",
      "[2665]\ttraining's binary_logloss: 5.07383e-06\n",
      "[2666]\ttraining's binary_logloss: 5.06958e-06\n",
      "[2667]\ttraining's binary_logloss: 5.06668e-06\n",
      "[2668]\ttraining's binary_logloss: 5.06313e-06\n",
      "[2669]\ttraining's binary_logloss: 5.05881e-06\n",
      "[2670]\ttraining's binary_logloss: 5.0553e-06\n",
      "[2671]\ttraining's binary_logloss: 5.05115e-06\n",
      "[2672]\ttraining's binary_logloss: 5.04722e-06\n",
      "[2673]\ttraining's binary_logloss: 5.04322e-06\n",
      "[2674]\ttraining's binary_logloss: 5.03929e-06\n",
      "[2675]\ttraining's binary_logloss: 5.03524e-06\n",
      "[2676]\ttraining's binary_logloss: 5.0312e-06\n",
      "[2677]\ttraining's binary_logloss: 5.02661e-06\n",
      "[2678]\ttraining's binary_logloss: 5.02257e-06\n",
      "[2679]\ttraining's binary_logloss: 5.01925e-06\n",
      "[2680]\ttraining's binary_logloss: 5.0159e-06\n",
      "[2681]\ttraining's binary_logloss: 5.01216e-06\n",
      "[2682]\ttraining's binary_logloss: 5.00866e-06\n",
      "[2683]\ttraining's binary_logloss: 5.00505e-06\n",
      "[2684]\ttraining's binary_logloss: 5.00108e-06\n",
      "[2685]\ttraining's binary_logloss: 4.99764e-06\n",
      "[2686]\ttraining's binary_logloss: 4.99383e-06\n",
      "[2687]\ttraining's binary_logloss: 4.99054e-06\n",
      "[2688]\ttraining's binary_logloss: 4.98723e-06\n",
      "[2689]\ttraining's binary_logloss: 4.98358e-06\n",
      "[2690]\ttraining's binary_logloss: 4.97957e-06\n",
      "[2691]\ttraining's binary_logloss: 4.9759e-06\n",
      "[2692]\ttraining's binary_logloss: 4.97219e-06\n",
      "[2693]\ttraining's binary_logloss: 4.96837e-06\n",
      "[2694]\ttraining's binary_logloss: 4.96482e-06\n",
      "[2695]\ttraining's binary_logloss: 4.96074e-06\n",
      "[2696]\ttraining's binary_logloss: 4.95717e-06\n",
      "[2697]\ttraining's binary_logloss: 4.95364e-06\n",
      "[2698]\ttraining's binary_logloss: 4.95044e-06\n",
      "[2699]\ttraining's binary_logloss: 4.947e-06\n",
      "[2700]\ttraining's binary_logloss: 4.94359e-06\n",
      "[2701]\ttraining's binary_logloss: 4.94031e-06\n",
      "[2702]\ttraining's binary_logloss: 4.93656e-06\n",
      "[2703]\ttraining's binary_logloss: 4.93335e-06\n",
      "[2704]\ttraining's binary_logloss: 4.93005e-06\n",
      "[2705]\ttraining's binary_logloss: 4.92707e-06\n",
      "[2706]\ttraining's binary_logloss: 4.92389e-06\n",
      "[2707]\ttraining's binary_logloss: 4.91995e-06\n",
      "[2708]\ttraining's binary_logloss: 4.91659e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2709]\ttraining's binary_logloss: 4.91365e-06\n",
      "[2710]\ttraining's binary_logloss: 4.91012e-06\n",
      "[2711]\ttraining's binary_logloss: 4.90621e-06\n",
      "[2712]\ttraining's binary_logloss: 4.90297e-06\n",
      "[2713]\ttraining's binary_logloss: 4.8991e-06\n",
      "[2714]\ttraining's binary_logloss: 4.89562e-06\n",
      "[2715]\ttraining's binary_logloss: 4.89249e-06\n",
      "[2716]\ttraining's binary_logloss: 4.88869e-06\n",
      "[2717]\ttraining's binary_logloss: 4.88565e-06\n",
      "[2718]\ttraining's binary_logloss: 4.88204e-06\n",
      "[2719]\ttraining's binary_logloss: 4.8787e-06\n",
      "[2720]\ttraining's binary_logloss: 4.87492e-06\n",
      "[2721]\ttraining's binary_logloss: 4.87119e-06\n",
      "[2722]\ttraining's binary_logloss: 4.86736e-06\n",
      "[2723]\ttraining's binary_logloss: 4.86344e-06\n",
      "[2724]\ttraining's binary_logloss: 4.85991e-06\n",
      "[2725]\ttraining's binary_logloss: 4.85637e-06\n",
      "[2726]\ttraining's binary_logloss: 4.85297e-06\n",
      "[2727]\ttraining's binary_logloss: 4.8488e-06\n",
      "[2728]\ttraining's binary_logloss: 4.84472e-06\n",
      "[2729]\ttraining's binary_logloss: 4.84145e-06\n",
      "[2730]\ttraining's binary_logloss: 4.83812e-06\n",
      "[2731]\ttraining's binary_logloss: 4.83455e-06\n",
      "[2732]\ttraining's binary_logloss: 4.83127e-06\n",
      "[2733]\ttraining's binary_logloss: 4.82771e-06\n",
      "[2734]\ttraining's binary_logloss: 4.82448e-06\n",
      "[2735]\ttraining's binary_logloss: 4.82097e-06\n",
      "[2736]\ttraining's binary_logloss: 4.81735e-06\n",
      "[2737]\ttraining's binary_logloss: 4.81424e-06\n",
      "[2738]\ttraining's binary_logloss: 4.81094e-06\n",
      "[2739]\ttraining's binary_logloss: 4.80795e-06\n",
      "[2740]\ttraining's binary_logloss: 4.80469e-06\n",
      "[2741]\ttraining's binary_logloss: 4.80146e-06\n",
      "[2742]\ttraining's binary_logloss: 4.79781e-06\n",
      "[2743]\ttraining's binary_logloss: 4.79406e-06\n",
      "[2744]\ttraining's binary_logloss: 4.79063e-06\n",
      "[2745]\ttraining's binary_logloss: 4.78745e-06\n",
      "[2746]\ttraining's binary_logloss: 4.78445e-06\n",
      "[2747]\ttraining's binary_logloss: 4.78125e-06\n",
      "[2748]\ttraining's binary_logloss: 4.77762e-06\n",
      "[2749]\ttraining's binary_logloss: 4.77423e-06\n",
      "[2750]\ttraining's binary_logloss: 4.77075e-06\n",
      "[2751]\ttraining's binary_logloss: 4.76747e-06\n",
      "[2752]\ttraining's binary_logloss: 4.76414e-06\n",
      "[2753]\ttraining's binary_logloss: 4.7608e-06\n",
      "[2754]\ttraining's binary_logloss: 4.75746e-06\n",
      "[2755]\ttraining's binary_logloss: 4.75395e-06\n",
      "[2756]\ttraining's binary_logloss: 4.75088e-06\n",
      "[2757]\ttraining's binary_logloss: 4.74767e-06\n",
      "[2758]\ttraining's binary_logloss: 4.74462e-06\n",
      "[2759]\ttraining's binary_logloss: 4.74091e-06\n",
      "[2760]\ttraining's binary_logloss: 4.7374e-06\n",
      "[2761]\ttraining's binary_logloss: 4.73409e-06\n",
      "[2762]\ttraining's binary_logloss: 4.73113e-06\n",
      "[2763]\ttraining's binary_logloss: 4.72797e-06\n",
      "[2764]\ttraining's binary_logloss: 4.72496e-06\n",
      "[2765]\ttraining's binary_logloss: 4.72136e-06\n",
      "[2766]\ttraining's binary_logloss: 4.7183e-06\n",
      "[2767]\ttraining's binary_logloss: 4.71505e-06\n",
      "[2768]\ttraining's binary_logloss: 4.71148e-06\n",
      "[2769]\ttraining's binary_logloss: 4.70802e-06\n",
      "[2770]\ttraining's binary_logloss: 4.70474e-06\n",
      "[2771]\ttraining's binary_logloss: 4.70107e-06\n",
      "[2772]\ttraining's binary_logloss: 4.69802e-06\n",
      "[2773]\ttraining's binary_logloss: 4.69487e-06\n",
      "[2774]\ttraining's binary_logloss: 4.6917e-06\n",
      "[2775]\ttraining's binary_logloss: 4.68829e-06\n",
      "[2776]\ttraining's binary_logloss: 4.68552e-06\n",
      "[2777]\ttraining's binary_logloss: 4.68191e-06\n",
      "[2778]\ttraining's binary_logloss: 4.67883e-06\n",
      "[2779]\ttraining's binary_logloss: 4.67595e-06\n",
      "[2780]\ttraining's binary_logloss: 4.67292e-06\n",
      "[2781]\ttraining's binary_logloss: 4.66997e-06\n",
      "[2782]\ttraining's binary_logloss: 4.66676e-06\n",
      "[2783]\ttraining's binary_logloss: 4.664e-06\n",
      "[2784]\ttraining's binary_logloss: 4.66047e-06\n",
      "[2785]\ttraining's binary_logloss: 4.65792e-06\n",
      "[2786]\ttraining's binary_logloss: 4.65494e-06\n",
      "[2787]\ttraining's binary_logloss: 4.65238e-06\n",
      "[2788]\ttraining's binary_logloss: 4.64933e-06\n",
      "[2789]\ttraining's binary_logloss: 4.64662e-06\n",
      "[2790]\ttraining's binary_logloss: 4.6432e-06\n",
      "[2791]\ttraining's binary_logloss: 4.64077e-06\n",
      "[2792]\ttraining's binary_logloss: 4.63688e-06\n",
      "[2793]\ttraining's binary_logloss: 4.63346e-06\n",
      "[2794]\ttraining's binary_logloss: 4.63067e-06\n",
      "[2795]\ttraining's binary_logloss: 4.62697e-06\n",
      "[2796]\ttraining's binary_logloss: 4.62398e-06\n",
      "[2797]\ttraining's binary_logloss: 4.62112e-06\n",
      "[2798]\ttraining's binary_logloss: 4.61773e-06\n",
      "[2799]\ttraining's binary_logloss: 4.61472e-06\n",
      "[2800]\ttraining's binary_logloss: 4.61131e-06\n",
      "[2801]\ttraining's binary_logloss: 4.60807e-06\n",
      "[2802]\ttraining's binary_logloss: 4.60532e-06\n",
      "[2803]\ttraining's binary_logloss: 4.60251e-06\n",
      "[2804]\ttraining's binary_logloss: 4.59988e-06\n",
      "[2805]\ttraining's binary_logloss: 4.59709e-06\n",
      "[2806]\ttraining's binary_logloss: 4.59384e-06\n",
      "[2807]\ttraining's binary_logloss: 4.59087e-06\n",
      "[2808]\ttraining's binary_logloss: 4.58766e-06\n",
      "[2809]\ttraining's binary_logloss: 4.58465e-06\n",
      "[2810]\ttraining's binary_logloss: 4.5812e-06\n",
      "[2811]\ttraining's binary_logloss: 4.57774e-06\n",
      "[2812]\ttraining's binary_logloss: 4.57493e-06\n",
      "[2813]\ttraining's binary_logloss: 4.57204e-06\n",
      "[2814]\ttraining's binary_logloss: 4.56912e-06\n",
      "[2815]\ttraining's binary_logloss: 4.56626e-06\n",
      "[2816]\ttraining's binary_logloss: 4.56266e-06\n",
      "[2817]\ttraining's binary_logloss: 4.55952e-06\n",
      "[2818]\ttraining's binary_logloss: 4.55643e-06\n",
      "[2819]\ttraining's binary_logloss: 4.55357e-06\n",
      "[2820]\ttraining's binary_logloss: 4.55102e-06\n",
      "[2821]\ttraining's binary_logloss: 4.54791e-06\n",
      "[2822]\ttraining's binary_logloss: 4.54533e-06\n",
      "[2823]\ttraining's binary_logloss: 4.54213e-06\n",
      "[2824]\ttraining's binary_logloss: 4.53945e-06\n",
      "[2825]\ttraining's binary_logloss: 4.53632e-06\n",
      "[2826]\ttraining's binary_logloss: 4.53379e-06\n",
      "[2827]\ttraining's binary_logloss: 4.53112e-06\n",
      "[2828]\ttraining's binary_logloss: 4.52814e-06\n",
      "[2829]\ttraining's binary_logloss: 4.525e-06\n",
      "[2830]\ttraining's binary_logloss: 4.52206e-06\n",
      "[2831]\ttraining's binary_logloss: 4.5193e-06\n",
      "[2832]\ttraining's binary_logloss: 4.51645e-06\n",
      "[2833]\ttraining's binary_logloss: 4.51313e-06\n",
      "[2834]\ttraining's binary_logloss: 4.51017e-06\n",
      "[2835]\ttraining's binary_logloss: 4.50709e-06\n",
      "[2836]\ttraining's binary_logloss: 4.50419e-06\n",
      "[2837]\ttraining's binary_logloss: 4.50071e-06\n",
      "[2838]\ttraining's binary_logloss: 4.49785e-06\n",
      "[2839]\ttraining's binary_logloss: 4.4945e-06\n",
      "[2840]\ttraining's binary_logloss: 4.49145e-06\n",
      "[2841]\ttraining's binary_logloss: 4.48866e-06\n",
      "[2842]\ttraining's binary_logloss: 4.48583e-06\n",
      "[2843]\ttraining's binary_logloss: 4.48314e-06\n",
      "[2844]\ttraining's binary_logloss: 4.48099e-06\n",
      "[2845]\ttraining's binary_logloss: 4.47825e-06\n",
      "[2846]\ttraining's binary_logloss: 4.47521e-06\n",
      "[2847]\ttraining's binary_logloss: 4.47191e-06\n",
      "[2848]\ttraining's binary_logloss: 4.4695e-06\n",
      "[2849]\ttraining's binary_logloss: 4.46619e-06\n",
      "[2850]\ttraining's binary_logloss: 4.46308e-06\n",
      "[2851]\ttraining's binary_logloss: 4.46044e-06\n",
      "[2852]\ttraining's binary_logloss: 4.45773e-06\n",
      "[2853]\ttraining's binary_logloss: 4.45491e-06\n",
      "[2854]\ttraining's binary_logloss: 4.45183e-06\n",
      "[2855]\ttraining's binary_logloss: 4.44859e-06\n",
      "[2856]\ttraining's binary_logloss: 4.44586e-06\n",
      "[2857]\ttraining's binary_logloss: 4.44299e-06\n",
      "[2858]\ttraining's binary_logloss: 4.44009e-06\n",
      "[2859]\ttraining's binary_logloss: 4.43742e-06\n",
      "[2860]\ttraining's binary_logloss: 4.43477e-06\n",
      "[2861]\ttraining's binary_logloss: 4.4314e-06\n",
      "[2862]\ttraining's binary_logloss: 4.42843e-06\n",
      "[2863]\ttraining's binary_logloss: 4.42591e-06\n",
      "[2864]\ttraining's binary_logloss: 4.42303e-06\n",
      "[2865]\ttraining's binary_logloss: 4.42039e-06\n",
      "[2866]\ttraining's binary_logloss: 4.41738e-06\n",
      "[2867]\ttraining's binary_logloss: 4.4146e-06\n",
      "[2868]\ttraining's binary_logloss: 4.41171e-06\n",
      "[2869]\ttraining's binary_logloss: 4.40903e-06\n",
      "[2870]\ttraining's binary_logloss: 4.40665e-06\n",
      "[2871]\ttraining's binary_logloss: 4.40402e-06\n",
      "[2872]\ttraining's binary_logloss: 4.40128e-06\n",
      "[2873]\ttraining's binary_logloss: 4.39861e-06\n",
      "[2874]\ttraining's binary_logloss: 4.39649e-06\n",
      "[2875]\ttraining's binary_logloss: 4.39362e-06\n",
      "[2876]\ttraining's binary_logloss: 4.39099e-06\n",
      "[2877]\ttraining's binary_logloss: 4.38775e-06\n",
      "[2878]\ttraining's binary_logloss: 4.38466e-06\n",
      "[2879]\ttraining's binary_logloss: 4.38209e-06\n",
      "[2880]\ttraining's binary_logloss: 4.37942e-06\n",
      "[2881]\ttraining's binary_logloss: 4.37632e-06\n",
      "[2882]\ttraining's binary_logloss: 4.37379e-06\n",
      "[2883]\ttraining's binary_logloss: 4.37059e-06\n",
      "[2884]\ttraining's binary_logloss: 4.36776e-06\n",
      "[2885]\ttraining's binary_logloss: 4.36538e-06\n",
      "[2886]\ttraining's binary_logloss: 4.36282e-06\n",
      "[2887]\ttraining's binary_logloss: 4.36038e-06\n",
      "[2888]\ttraining's binary_logloss: 4.35789e-06\n",
      "[2889]\ttraining's binary_logloss: 4.35564e-06\n",
      "[2890]\ttraining's binary_logloss: 4.35236e-06\n",
      "[2891]\ttraining's binary_logloss: 4.35022e-06\n",
      "[2892]\ttraining's binary_logloss: 4.34752e-06\n",
      "[2893]\ttraining's binary_logloss: 4.34498e-06\n",
      "[2894]\ttraining's binary_logloss: 4.34196e-06\n",
      "[2895]\ttraining's binary_logloss: 4.33945e-06\n",
      "[2896]\ttraining's binary_logloss: 4.33749e-06\n",
      "[2897]\ttraining's binary_logloss: 4.33524e-06\n",
      "[2898]\ttraining's binary_logloss: 4.33296e-06\n",
      "[2899]\ttraining's binary_logloss: 4.32977e-06\n",
      "[2900]\ttraining's binary_logloss: 4.32642e-06\n",
      "[2901]\ttraining's binary_logloss: 4.3239e-06\n",
      "[2902]\ttraining's binary_logloss: 4.32098e-06\n",
      "[2903]\ttraining's binary_logloss: 4.31867e-06\n",
      "[2904]\ttraining's binary_logloss: 4.31584e-06\n",
      "[2905]\ttraining's binary_logloss: 4.31307e-06\n",
      "[2906]\ttraining's binary_logloss: 4.31056e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2907]\ttraining's binary_logloss: 4.30787e-06\n",
      "[2908]\ttraining's binary_logloss: 4.30556e-06\n",
      "[2909]\ttraining's binary_logloss: 4.30339e-06\n",
      "[2910]\ttraining's binary_logloss: 4.30088e-06\n",
      "[2911]\ttraining's binary_logloss: 4.2982e-06\n",
      "[2912]\ttraining's binary_logloss: 4.29551e-06\n",
      "[2913]\ttraining's binary_logloss: 4.29231e-06\n",
      "[2914]\ttraining's binary_logloss: 4.28962e-06\n",
      "[2915]\ttraining's binary_logloss: 4.28699e-06\n",
      "[2916]\ttraining's binary_logloss: 4.2842e-06\n",
      "[2917]\ttraining's binary_logloss: 4.28219e-06\n",
      "[2918]\ttraining's binary_logloss: 4.27965e-06\n",
      "[2919]\ttraining's binary_logloss: 4.27708e-06\n",
      "[2920]\ttraining's binary_logloss: 4.27454e-06\n",
      "[2921]\ttraining's binary_logloss: 4.27231e-06\n",
      "[2922]\ttraining's binary_logloss: 4.27003e-06\n",
      "[2923]\ttraining's binary_logloss: 4.26742e-06\n",
      "[2924]\ttraining's binary_logloss: 4.26479e-06\n",
      "[2925]\ttraining's binary_logloss: 4.2625e-06\n",
      "[2926]\ttraining's binary_logloss: 4.25994e-06\n",
      "[2927]\ttraining's binary_logloss: 4.25711e-06\n",
      "[2928]\ttraining's binary_logloss: 4.25436e-06\n",
      "[2929]\ttraining's binary_logloss: 4.25187e-06\n",
      "[2930]\ttraining's binary_logloss: 4.24962e-06\n",
      "[2931]\ttraining's binary_logloss: 4.24721e-06\n",
      "[2932]\ttraining's binary_logloss: 4.24464e-06\n",
      "[2933]\ttraining's binary_logloss: 4.24195e-06\n",
      "[2934]\ttraining's binary_logloss: 4.23945e-06\n",
      "[2935]\ttraining's binary_logloss: 4.23718e-06\n",
      "[2936]\ttraining's binary_logloss: 4.23507e-06\n",
      "[2937]\ttraining's binary_logloss: 4.23248e-06\n",
      "[2938]\ttraining's binary_logloss: 4.23003e-06\n",
      "[2939]\ttraining's binary_logloss: 4.2277e-06\n",
      "[2940]\ttraining's binary_logloss: 4.22516e-06\n",
      "[2941]\ttraining's binary_logloss: 4.2226e-06\n",
      "[2942]\ttraining's binary_logloss: 4.22009e-06\n",
      "[2943]\ttraining's binary_logloss: 4.2177e-06\n",
      "[2944]\ttraining's binary_logloss: 4.21506e-06\n",
      "[2945]\ttraining's binary_logloss: 4.21242e-06\n",
      "[2946]\ttraining's binary_logloss: 4.21017e-06\n",
      "[2947]\ttraining's binary_logloss: 4.20771e-06\n",
      "[2948]\ttraining's binary_logloss: 4.20519e-06\n",
      "[2949]\ttraining's binary_logloss: 4.20306e-06\n",
      "[2950]\ttraining's binary_logloss: 4.20042e-06\n",
      "[2951]\ttraining's binary_logloss: 4.19853e-06\n",
      "[2952]\ttraining's binary_logloss: 4.19637e-06\n",
      "[2953]\ttraining's binary_logloss: 4.19354e-06\n",
      "[2954]\ttraining's binary_logloss: 4.19143e-06\n",
      "[2955]\ttraining's binary_logloss: 4.18928e-06\n",
      "[2956]\ttraining's binary_logloss: 4.1867e-06\n",
      "[2957]\ttraining's binary_logloss: 4.18428e-06\n",
      "[2958]\ttraining's binary_logloss: 4.18127e-06\n",
      "[2959]\ttraining's binary_logloss: 4.17833e-06\n",
      "[2960]\ttraining's binary_logloss: 4.17624e-06\n",
      "[2961]\ttraining's binary_logloss: 4.17411e-06\n",
      "[2962]\ttraining's binary_logloss: 4.17194e-06\n",
      "[2963]\ttraining's binary_logloss: 4.16941e-06\n",
      "[2964]\ttraining's binary_logloss: 4.16673e-06\n",
      "[2965]\ttraining's binary_logloss: 4.16413e-06\n",
      "[2966]\ttraining's binary_logloss: 4.16164e-06\n",
      "[2967]\ttraining's binary_logloss: 4.15933e-06\n",
      "[2968]\ttraining's binary_logloss: 4.15729e-06\n",
      "[2969]\ttraining's binary_logloss: 4.1552e-06\n",
      "[2970]\ttraining's binary_logloss: 4.1529e-06\n",
      "[2971]\ttraining's binary_logloss: 4.15004e-06\n",
      "[2972]\ttraining's binary_logloss: 4.14775e-06\n",
      "[2973]\ttraining's binary_logloss: 4.1452e-06\n",
      "[2974]\ttraining's binary_logloss: 4.14302e-06\n",
      "[2975]\ttraining's binary_logloss: 4.14057e-06\n",
      "[2976]\ttraining's binary_logloss: 4.13791e-06\n",
      "[2977]\ttraining's binary_logloss: 4.13574e-06\n",
      "[2978]\ttraining's binary_logloss: 4.13318e-06\n",
      "[2979]\ttraining's binary_logloss: 4.13062e-06\n",
      "[2980]\ttraining's binary_logloss: 4.1281e-06\n",
      "[2981]\ttraining's binary_logloss: 4.12585e-06\n",
      "[2982]\ttraining's binary_logloss: 4.12337e-06\n",
      "[2983]\ttraining's binary_logloss: 4.12072e-06\n",
      "[2984]\ttraining's binary_logloss: 4.11847e-06\n",
      "[2985]\ttraining's binary_logloss: 4.11646e-06\n",
      "[2986]\ttraining's binary_logloss: 4.1138e-06\n",
      "[2987]\ttraining's binary_logloss: 4.11151e-06\n",
      "[2988]\ttraining's binary_logloss: 4.10973e-06\n",
      "[2989]\ttraining's binary_logloss: 4.1072e-06\n",
      "[2990]\ttraining's binary_logloss: 4.10509e-06\n",
      "[2991]\ttraining's binary_logloss: 4.10315e-06\n",
      "[2992]\ttraining's binary_logloss: 4.10055e-06\n",
      "[2993]\ttraining's binary_logloss: 4.09835e-06\n",
      "[2994]\ttraining's binary_logloss: 4.09618e-06\n",
      "[2995]\ttraining's binary_logloss: 4.09393e-06\n",
      "[2996]\ttraining's binary_logloss: 4.09195e-06\n",
      "[2997]\ttraining's binary_logloss: 4.08952e-06\n",
      "[2998]\ttraining's binary_logloss: 4.0868e-06\n",
      "[2999]\ttraining's binary_logloss: 4.08389e-06\n",
      "[3000]\ttraining's binary_logloss: 4.08166e-06\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = lgb.train(\n",
    "    lgbm_params,\n",
    "    lgtrain,\n",
    "    valid_sets=lgtrain,\n",
    "    num_boost_round=3000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lgb = lgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lgb = np.array([0 if i < 0.5 else 1 for i in predict_lgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8113080715032615"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(predict_lgb, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV based auroc score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(rf, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8463866032226383"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999925617375781"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(predict_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search, tune parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameters to search\n",
    "gridParams = {\n",
    "    'learning_rate': [0.0125, 0.0175, 0.0225],\n",
    "    'n_estimators': [40],\n",
    "    'num_leaves': [170, 220, 270, 320],\n",
    "    #'max_depth': [15, 25, 35],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'feature_fraction': [0.4, 0.5, 0.6]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classifier to use. Note that parameters have to be input manually\n",
    "# not as a dict!\n",
    "mdl = lgb.LGBMClassifier(boosting_type= 'gbdt', objective = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(mdl, gridParams, verbose=0, cv=5, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "        n_jobs=-1, num_leaves=31, objective='binary', random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=0),\n",
       "       fit_params=None, iid=True, n_jobs=2,\n",
       "       param_grid={'learning_rate': [0.0125, 0.0175, 0.0225], 'n_estimators': [40], 'num_leaves': [170, 220, 270, 320], 'boosting_type': ['gbdt'], 'objective': ['binary'], 'feature_fraction': [0.4, 0.5, 0.6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'gbdt', 'feature_fraction': 0.5, 'learning_rate': 0.0225, 'n_estimators': 40, 'num_leaves': 320, 'objective': 'binary'}\n",
      "0.8844150432336702\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters found\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using parameters already set above, replace in the best from the grid search\n",
    "\n",
    "# params['max_bin'] = grid.best_params_['max_bin']\n",
    "lgbm_params['feature_fraction'] = grid.best_params_['feature_fraction']\n",
    "lgbm_params['learning_rate'] = grid.best_params_['learning_rate']\n",
    "lgbm_params['num_leaves'] = grid.best_params_['num_leaves']\n",
    "#lgbm_params['max_depth'] = grid.best_params_['max_depth']\n",
    "#lgbm_params['reg_alpha'] = grid.best_params_['reg_alpha']\n",
    "#lgbm_params['reg_lambda'] = grid.best_params_['reg_lambda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with params: \n",
      "{'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'binary_logloss', 'num_leaves': 320, 'feature_fraction': 0.5, 'bagging_fraction': 0.75, 'bagging_freq': 2, 'learning_rate': 0.0225, 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "print('Fitting with params: ')\n",
    "print(lgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'binary_logloss', 'num_leaves': 320, 'feature_fraction': 0.5, 'bagging_fraction': 0.75, 'bagging_freq': 2, 'learning_rate': 0.0225, 'verbose': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgtrain = lgb.Dataset(X_train, y_train)\n",
    "lgtest = lgb.Dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.48389\n",
      "[2]\ttraining's binary_logloss: 0.474278\n",
      "[3]\ttraining's binary_logloss: 0.465419\n",
      "[4]\ttraining's binary_logloss: 0.457028\n",
      "[5]\ttraining's binary_logloss: 0.449707\n",
      "[6]\ttraining's binary_logloss: 0.441757\n",
      "[7]\ttraining's binary_logloss: 0.434344\n",
      "[8]\ttraining's binary_logloss: 0.426919\n",
      "[9]\ttraining's binary_logloss: 0.420335\n",
      "[10]\ttraining's binary_logloss: 0.413895\n",
      "[11]\ttraining's binary_logloss: 0.407566\n",
      "[12]\ttraining's binary_logloss: 0.40167\n",
      "[13]\ttraining's binary_logloss: 0.39614\n",
      "[14]\ttraining's binary_logloss: 0.390756\n",
      "[15]\ttraining's binary_logloss: 0.385582\n",
      "[16]\ttraining's binary_logloss: 0.38014\n",
      "[17]\ttraining's binary_logloss: 0.375172\n",
      "[18]\ttraining's binary_logloss: 0.370514\n",
      "[19]\ttraining's binary_logloss: 0.365811\n",
      "[20]\ttraining's binary_logloss: 0.361176\n",
      "[21]\ttraining's binary_logloss: 0.356688\n",
      "[22]\ttraining's binary_logloss: 0.352116\n",
      "[23]\ttraining's binary_logloss: 0.34796\n",
      "[24]\ttraining's binary_logloss: 0.343785\n",
      "[25]\ttraining's binary_logloss: 0.339794\n",
      "[26]\ttraining's binary_logloss: 0.33588\n",
      "[27]\ttraining's binary_logloss: 0.331926\n",
      "[28]\ttraining's binary_logloss: 0.328377\n",
      "[29]\ttraining's binary_logloss: 0.324875\n",
      "[30]\ttraining's binary_logloss: 0.321391\n",
      "[31]\ttraining's binary_logloss: 0.31785\n",
      "[32]\ttraining's binary_logloss: 0.314609\n",
      "[33]\ttraining's binary_logloss: 0.311225\n",
      "[34]\ttraining's binary_logloss: 0.307998\n",
      "[35]\ttraining's binary_logloss: 0.304963\n",
      "[36]\ttraining's binary_logloss: 0.301751\n",
      "[37]\ttraining's binary_logloss: 0.298596\n",
      "[38]\ttraining's binary_logloss: 0.295711\n",
      "[39]\ttraining's binary_logloss: 0.292763\n",
      "[40]\ttraining's binary_logloss: 0.289903\n",
      "[41]\ttraining's binary_logloss: 0.28704\n",
      "[42]\ttraining's binary_logloss: 0.284316\n",
      "[43]\ttraining's binary_logloss: 0.281667\n",
      "[44]\ttraining's binary_logloss: 0.279147\n",
      "[45]\ttraining's binary_logloss: 0.276534\n",
      "[46]\ttraining's binary_logloss: 0.274064\n",
      "[47]\ttraining's binary_logloss: 0.27163\n",
      "[48]\ttraining's binary_logloss: 0.269189\n",
      "[49]\ttraining's binary_logloss: 0.266743\n",
      "[50]\ttraining's binary_logloss: 0.264314\n",
      "[51]\ttraining's binary_logloss: 0.262045\n",
      "[52]\ttraining's binary_logloss: 0.25983\n",
      "[53]\ttraining's binary_logloss: 0.257627\n",
      "[54]\ttraining's binary_logloss: 0.255391\n",
      "[55]\ttraining's binary_logloss: 0.253225\n",
      "[56]\ttraining's binary_logloss: 0.25102\n",
      "[57]\ttraining's binary_logloss: 0.24882\n",
      "[58]\ttraining's binary_logloss: 0.246724\n",
      "[59]\ttraining's binary_logloss: 0.244707\n",
      "[60]\ttraining's binary_logloss: 0.242665\n",
      "[61]\ttraining's binary_logloss: 0.240807\n",
      "[62]\ttraining's binary_logloss: 0.238826\n",
      "[63]\ttraining's binary_logloss: 0.236873\n",
      "[64]\ttraining's binary_logloss: 0.235035\n",
      "[65]\ttraining's binary_logloss: 0.233135\n",
      "[66]\ttraining's binary_logloss: 0.231166\n",
      "[67]\ttraining's binary_logloss: 0.229303\n",
      "[68]\ttraining's binary_logloss: 0.227568\n",
      "[69]\ttraining's binary_logloss: 0.225828\n",
      "[70]\ttraining's binary_logloss: 0.224051\n",
      "[71]\ttraining's binary_logloss: 0.222278\n",
      "[72]\ttraining's binary_logloss: 0.220558\n",
      "[73]\ttraining's binary_logloss: 0.218765\n",
      "[74]\ttraining's binary_logloss: 0.217069\n",
      "[75]\ttraining's binary_logloss: 0.215451\n",
      "[76]\ttraining's binary_logloss: 0.213757\n",
      "[77]\ttraining's binary_logloss: 0.212185\n",
      "[78]\ttraining's binary_logloss: 0.210671\n",
      "[79]\ttraining's binary_logloss: 0.209083\n",
      "[80]\ttraining's binary_logloss: 0.207497\n",
      "[81]\ttraining's binary_logloss: 0.205949\n",
      "[82]\ttraining's binary_logloss: 0.204476\n",
      "[83]\ttraining's binary_logloss: 0.202964\n",
      "[84]\ttraining's binary_logloss: 0.20142\n",
      "[85]\ttraining's binary_logloss: 0.200025\n",
      "[86]\ttraining's binary_logloss: 0.198529\n",
      "[87]\ttraining's binary_logloss: 0.196976\n",
      "[88]\ttraining's binary_logloss: 0.195546\n",
      "[89]\ttraining's binary_logloss: 0.194201\n",
      "[90]\ttraining's binary_logloss: 0.192775\n",
      "[91]\ttraining's binary_logloss: 0.191268\n",
      "[92]\ttraining's binary_logloss: 0.189935\n",
      "[93]\ttraining's binary_logloss: 0.188561\n",
      "[94]\ttraining's binary_logloss: 0.187187\n",
      "[95]\ttraining's binary_logloss: 0.185834\n",
      "[96]\ttraining's binary_logloss: 0.184448\n",
      "[97]\ttraining's binary_logloss: 0.18319\n",
      "[98]\ttraining's binary_logloss: 0.181883\n",
      "[99]\ttraining's binary_logloss: 0.180548\n",
      "[100]\ttraining's binary_logloss: 0.179316\n",
      "[101]\ttraining's binary_logloss: 0.177953\n",
      "[102]\ttraining's binary_logloss: 0.176676\n",
      "[103]\ttraining's binary_logloss: 0.175366\n",
      "[104]\ttraining's binary_logloss: 0.174167\n",
      "[105]\ttraining's binary_logloss: 0.172906\n",
      "[106]\ttraining's binary_logloss: 0.171642\n",
      "[107]\ttraining's binary_logloss: 0.170473\n",
      "[108]\ttraining's binary_logloss: 0.169299\n",
      "[109]\ttraining's binary_logloss: 0.168141\n",
      "[110]\ttraining's binary_logloss: 0.167043\n",
      "[111]\ttraining's binary_logloss: 0.165885\n",
      "[112]\ttraining's binary_logloss: 0.164785\n",
      "[113]\ttraining's binary_logloss: 0.16351\n",
      "[114]\ttraining's binary_logloss: 0.162349\n",
      "[115]\ttraining's binary_logloss: 0.161207\n",
      "[116]\ttraining's binary_logloss: 0.160102\n",
      "[117]\ttraining's binary_logloss: 0.158935\n",
      "[118]\ttraining's binary_logloss: 0.157782\n",
      "[119]\ttraining's binary_logloss: 0.156673\n",
      "[120]\ttraining's binary_logloss: 0.155495\n",
      "[121]\ttraining's binary_logloss: 0.154451\n",
      "[122]\ttraining's binary_logloss: 0.153344\n",
      "[123]\ttraining's binary_logloss: 0.152283\n",
      "[124]\ttraining's binary_logloss: 0.151225\n",
      "[125]\ttraining's binary_logloss: 0.150157\n",
      "[126]\ttraining's binary_logloss: 0.14907\n",
      "[127]\ttraining's binary_logloss: 0.148051\n",
      "[128]\ttraining's binary_logloss: 0.147054\n",
      "[129]\ttraining's binary_logloss: 0.145918\n",
      "[130]\ttraining's binary_logloss: 0.144898\n",
      "[131]\ttraining's binary_logloss: 0.143899\n",
      "[132]\ttraining's binary_logloss: 0.142856\n",
      "[133]\ttraining's binary_logloss: 0.141863\n",
      "[134]\ttraining's binary_logloss: 0.140812\n",
      "[135]\ttraining's binary_logloss: 0.139869\n",
      "[136]\ttraining's binary_logloss: 0.138898\n",
      "[137]\ttraining's binary_logloss: 0.138016\n",
      "[138]\ttraining's binary_logloss: 0.137116\n",
      "[139]\ttraining's binary_logloss: 0.136234\n",
      "[140]\ttraining's binary_logloss: 0.135283\n",
      "[141]\ttraining's binary_logloss: 0.134418\n",
      "[142]\ttraining's binary_logloss: 0.133557\n",
      "[143]\ttraining's binary_logloss: 0.132647\n",
      "[144]\ttraining's binary_logloss: 0.131731\n",
      "[145]\ttraining's binary_logloss: 0.130788\n",
      "[146]\ttraining's binary_logloss: 0.129894\n",
      "[147]\ttraining's binary_logloss: 0.129033\n",
      "[148]\ttraining's binary_logloss: 0.128124\n",
      "[149]\ttraining's binary_logloss: 0.127225\n",
      "[150]\ttraining's binary_logloss: 0.12638\n",
      "[151]\ttraining's binary_logloss: 0.125552\n",
      "[152]\ttraining's binary_logloss: 0.124684\n",
      "[153]\ttraining's binary_logloss: 0.123791\n",
      "[154]\ttraining's binary_logloss: 0.122956\n",
      "[155]\ttraining's binary_logloss: 0.12207\n",
      "[156]\ttraining's binary_logloss: 0.121267\n",
      "[157]\ttraining's binary_logloss: 0.120388\n",
      "[158]\ttraining's binary_logloss: 0.119561\n",
      "[159]\ttraining's binary_logloss: 0.118714\n",
      "[160]\ttraining's binary_logloss: 0.117846\n",
      "[161]\ttraining's binary_logloss: 0.117083\n",
      "[162]\ttraining's binary_logloss: 0.116238\n",
      "[163]\ttraining's binary_logloss: 0.115433\n",
      "[164]\ttraining's binary_logloss: 0.114669\n",
      "[165]\ttraining's binary_logloss: 0.113867\n",
      "[166]\ttraining's binary_logloss: 0.113134\n",
      "[167]\ttraining's binary_logloss: 0.112297\n",
      "[168]\ttraining's binary_logloss: 0.111495\n",
      "[169]\ttraining's binary_logloss: 0.110681\n",
      "[170]\ttraining's binary_logloss: 0.109914\n",
      "[171]\ttraining's binary_logloss: 0.109045\n",
      "[172]\ttraining's binary_logloss: 0.108318\n",
      "[173]\ttraining's binary_logloss: 0.107609\n",
      "[174]\ttraining's binary_logloss: 0.106945\n",
      "[175]\ttraining's binary_logloss: 0.106254\n",
      "[176]\ttraining's binary_logloss: 0.105544\n",
      "[177]\ttraining's binary_logloss: 0.104791\n",
      "[178]\ttraining's binary_logloss: 0.104062\n",
      "[179]\ttraining's binary_logloss: 0.103398\n",
      "[180]\ttraining's binary_logloss: 0.102694\n",
      "[181]\ttraining's binary_logloss: 0.102016\n",
      "[182]\ttraining's binary_logloss: 0.10126\n",
      "[183]\ttraining's binary_logloss: 0.100562\n",
      "[184]\ttraining's binary_logloss: 0.09985\n",
      "[185]\ttraining's binary_logloss: 0.0991335\n",
      "[186]\ttraining's binary_logloss: 0.0984561\n",
      "[187]\ttraining's binary_logloss: 0.097779\n",
      "[188]\ttraining's binary_logloss: 0.0971024\n",
      "[189]\ttraining's binary_logloss: 0.096436\n",
      "[190]\ttraining's binary_logloss: 0.0958268\n",
      "[191]\ttraining's binary_logloss: 0.0951621\n",
      "[192]\ttraining's binary_logloss: 0.0944561\n",
      "[193]\ttraining's binary_logloss: 0.0938171\n",
      "[194]\ttraining's binary_logloss: 0.0932061\n",
      "[195]\ttraining's binary_logloss: 0.0925596\n",
      "[196]\ttraining's binary_logloss: 0.0919416\n",
      "[197]\ttraining's binary_logloss: 0.0912845\n",
      "[198]\ttraining's binary_logloss: 0.0906135\n",
      "[199]\ttraining's binary_logloss: 0.0899927\n",
      "[200]\ttraining's binary_logloss: 0.0893651\n",
      "[201]\ttraining's binary_logloss: 0.0887293\n",
      "[202]\ttraining's binary_logloss: 0.0881344\n",
      "[203]\ttraining's binary_logloss: 0.0875016\n",
      "[204]\ttraining's binary_logloss: 0.0869135\n",
      "[205]\ttraining's binary_logloss: 0.0863496\n",
      "[206]\ttraining's binary_logloss: 0.0857757\n",
      "[207]\ttraining's binary_logloss: 0.0852042\n",
      "[208]\ttraining's binary_logloss: 0.0846026\n",
      "[209]\ttraining's binary_logloss: 0.0840149\n",
      "[210]\ttraining's binary_logloss: 0.0835043\n",
      "[211]\ttraining's binary_logloss: 0.0829857\n",
      "[212]\ttraining's binary_logloss: 0.0824953\n",
      "[213]\ttraining's binary_logloss: 0.0819818\n",
      "[214]\ttraining's binary_logloss: 0.0814433\n",
      "[215]\ttraining's binary_logloss: 0.080919\n",
      "[216]\ttraining's binary_logloss: 0.0803866\n",
      "[217]\ttraining's binary_logloss: 0.07984\n",
      "[218]\ttraining's binary_logloss: 0.0792693\n",
      "[219]\ttraining's binary_logloss: 0.0787457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[220]\ttraining's binary_logloss: 0.078174\n",
      "[221]\ttraining's binary_logloss: 0.0776206\n",
      "[222]\ttraining's binary_logloss: 0.0770574\n",
      "[223]\ttraining's binary_logloss: 0.0765112\n",
      "[224]\ttraining's binary_logloss: 0.0760052\n",
      "[225]\ttraining's binary_logloss: 0.0754996\n",
      "[226]\ttraining's binary_logloss: 0.0749912\n",
      "[227]\ttraining's binary_logloss: 0.0744813\n",
      "[228]\ttraining's binary_logloss: 0.0739605\n",
      "[229]\ttraining's binary_logloss: 0.0735121\n",
      "[230]\ttraining's binary_logloss: 0.0730239\n",
      "[231]\ttraining's binary_logloss: 0.0725395\n",
      "[232]\ttraining's binary_logloss: 0.0720216\n",
      "[233]\ttraining's binary_logloss: 0.0715387\n",
      "[234]\ttraining's binary_logloss: 0.0710778\n",
      "[235]\ttraining's binary_logloss: 0.0706146\n",
      "[236]\ttraining's binary_logloss: 0.0701231\n",
      "[237]\ttraining's binary_logloss: 0.0696934\n",
      "[238]\ttraining's binary_logloss: 0.0691961\n",
      "[239]\ttraining's binary_logloss: 0.0687162\n",
      "[240]\ttraining's binary_logloss: 0.0682545\n",
      "[241]\ttraining's binary_logloss: 0.0678161\n",
      "[242]\ttraining's binary_logloss: 0.0673949\n",
      "[243]\ttraining's binary_logloss: 0.0669676\n",
      "[244]\ttraining's binary_logloss: 0.0665229\n",
      "[245]\ttraining's binary_logloss: 0.0660528\n",
      "[246]\ttraining's binary_logloss: 0.0656062\n",
      "[247]\ttraining's binary_logloss: 0.0651624\n",
      "[248]\ttraining's binary_logloss: 0.0647381\n",
      "[249]\ttraining's binary_logloss: 0.0642847\n",
      "[250]\ttraining's binary_logloss: 0.0638581\n",
      "[251]\ttraining's binary_logloss: 0.06344\n",
      "[252]\ttraining's binary_logloss: 0.0630531\n",
      "[253]\ttraining's binary_logloss: 0.0626722\n",
      "[254]\ttraining's binary_logloss: 0.0622765\n",
      "[255]\ttraining's binary_logloss: 0.0618364\n",
      "[256]\ttraining's binary_logloss: 0.061433\n",
      "[257]\ttraining's binary_logloss: 0.0610247\n",
      "[258]\ttraining's binary_logloss: 0.0606643\n",
      "[259]\ttraining's binary_logloss: 0.0602542\n",
      "[260]\ttraining's binary_logloss: 0.0598294\n",
      "[261]\ttraining's binary_logloss: 0.0594156\n",
      "[262]\ttraining's binary_logloss: 0.059027\n",
      "[263]\ttraining's binary_logloss: 0.0586649\n",
      "[264]\ttraining's binary_logloss: 0.0582875\n",
      "[265]\ttraining's binary_logloss: 0.0579197\n",
      "[266]\ttraining's binary_logloss: 0.0575503\n",
      "[267]\ttraining's binary_logloss: 0.0571957\n",
      "[268]\ttraining's binary_logloss: 0.0567927\n",
      "[269]\ttraining's binary_logloss: 0.0564421\n",
      "[270]\ttraining's binary_logloss: 0.0560656\n",
      "[271]\ttraining's binary_logloss: 0.0557202\n",
      "[272]\ttraining's binary_logloss: 0.0553626\n",
      "[273]\ttraining's binary_logloss: 0.0550011\n",
      "[274]\ttraining's binary_logloss: 0.0546002\n",
      "[275]\ttraining's binary_logloss: 0.0542049\n",
      "[276]\ttraining's binary_logloss: 0.0538394\n",
      "[277]\ttraining's binary_logloss: 0.0535113\n",
      "[278]\ttraining's binary_logloss: 0.053131\n",
      "[279]\ttraining's binary_logloss: 0.0527248\n",
      "[280]\ttraining's binary_logloss: 0.0523538\n",
      "[281]\ttraining's binary_logloss: 0.0520154\n",
      "[282]\ttraining's binary_logloss: 0.0516795\n",
      "[283]\ttraining's binary_logloss: 0.0513235\n",
      "[284]\ttraining's binary_logloss: 0.0510067\n",
      "[285]\ttraining's binary_logloss: 0.0506698\n",
      "[286]\ttraining's binary_logloss: 0.0503272\n",
      "[287]\ttraining's binary_logloss: 0.0500472\n",
      "[288]\ttraining's binary_logloss: 0.0497237\n",
      "[289]\ttraining's binary_logloss: 0.0493868\n",
      "[290]\ttraining's binary_logloss: 0.0490561\n",
      "[291]\ttraining's binary_logloss: 0.048739\n",
      "[292]\ttraining's binary_logloss: 0.048444\n",
      "[293]\ttraining's binary_logloss: 0.0481207\n",
      "[294]\ttraining's binary_logloss: 0.0478126\n",
      "[295]\ttraining's binary_logloss: 0.0475163\n",
      "[296]\ttraining's binary_logloss: 0.0472\n",
      "[297]\ttraining's binary_logloss: 0.0468743\n",
      "[298]\ttraining's binary_logloss: 0.0465651\n",
      "[299]\ttraining's binary_logloss: 0.0462799\n",
      "[300]\ttraining's binary_logloss: 0.0459647\n",
      "[301]\ttraining's binary_logloss: 0.0456547\n",
      "[302]\ttraining's binary_logloss: 0.0453626\n",
      "[303]\ttraining's binary_logloss: 0.045074\n",
      "[304]\ttraining's binary_logloss: 0.044784\n",
      "[305]\ttraining's binary_logloss: 0.0444812\n",
      "[306]\ttraining's binary_logloss: 0.0442042\n",
      "[307]\ttraining's binary_logloss: 0.0439177\n",
      "[308]\ttraining's binary_logloss: 0.0436461\n",
      "[309]\ttraining's binary_logloss: 0.0433738\n",
      "[310]\ttraining's binary_logloss: 0.0430868\n",
      "[311]\ttraining's binary_logloss: 0.0428418\n",
      "[312]\ttraining's binary_logloss: 0.042602\n",
      "[313]\ttraining's binary_logloss: 0.0423211\n",
      "[314]\ttraining's binary_logloss: 0.0420577\n",
      "[315]\ttraining's binary_logloss: 0.0417742\n",
      "[316]\ttraining's binary_logloss: 0.0415067\n",
      "[317]\ttraining's binary_logloss: 0.0412366\n",
      "[318]\ttraining's binary_logloss: 0.0409856\n",
      "[319]\ttraining's binary_logloss: 0.0406892\n",
      "[320]\ttraining's binary_logloss: 0.040435\n",
      "[321]\ttraining's binary_logloss: 0.0401732\n",
      "[322]\ttraining's binary_logloss: 0.0399282\n",
      "[323]\ttraining's binary_logloss: 0.0396797\n",
      "[324]\ttraining's binary_logloss: 0.0394374\n",
      "[325]\ttraining's binary_logloss: 0.039193\n",
      "[326]\ttraining's binary_logloss: 0.0389533\n",
      "[327]\ttraining's binary_logloss: 0.0386968\n",
      "[328]\ttraining's binary_logloss: 0.0384623\n",
      "[329]\ttraining's binary_logloss: 0.0382018\n",
      "[330]\ttraining's binary_logloss: 0.0379537\n",
      "[331]\ttraining's binary_logloss: 0.0377134\n",
      "[332]\ttraining's binary_logloss: 0.0374632\n",
      "[333]\ttraining's binary_logloss: 0.0372184\n",
      "[334]\ttraining's binary_logloss: 0.0369894\n",
      "[335]\ttraining's binary_logloss: 0.0367669\n",
      "[336]\ttraining's binary_logloss: 0.0365556\n",
      "[337]\ttraining's binary_logloss: 0.0363485\n",
      "[338]\ttraining's binary_logloss: 0.0361091\n",
      "[339]\ttraining's binary_logloss: 0.0358931\n",
      "[340]\ttraining's binary_logloss: 0.0356745\n",
      "[341]\ttraining's binary_logloss: 0.0354458\n",
      "[342]\ttraining's binary_logloss: 0.0352084\n",
      "[343]\ttraining's binary_logloss: 0.0349919\n",
      "[344]\ttraining's binary_logloss: 0.0347811\n",
      "[345]\ttraining's binary_logloss: 0.0345737\n",
      "[346]\ttraining's binary_logloss: 0.0343524\n",
      "[347]\ttraining's binary_logloss: 0.0341235\n",
      "[348]\ttraining's binary_logloss: 0.0338945\n",
      "[349]\ttraining's binary_logloss: 0.0336867\n",
      "[350]\ttraining's binary_logloss: 0.0334712\n",
      "[351]\ttraining's binary_logloss: 0.0332554\n",
      "[352]\ttraining's binary_logloss: 0.0330629\n",
      "[353]\ttraining's binary_logloss: 0.0328657\n",
      "[354]\ttraining's binary_logloss: 0.0326491\n",
      "[355]\ttraining's binary_logloss: 0.03245\n",
      "[356]\ttraining's binary_logloss: 0.032234\n",
      "[357]\ttraining's binary_logloss: 0.032023\n",
      "[358]\ttraining's binary_logloss: 0.0318063\n",
      "[359]\ttraining's binary_logloss: 0.0316041\n",
      "[360]\ttraining's binary_logloss: 0.0314165\n",
      "[361]\ttraining's binary_logloss: 0.0312439\n",
      "[362]\ttraining's binary_logloss: 0.0310625\n",
      "[363]\ttraining's binary_logloss: 0.0308718\n",
      "[364]\ttraining's binary_logloss: 0.0306873\n",
      "[365]\ttraining's binary_logloss: 0.0305074\n",
      "[366]\ttraining's binary_logloss: 0.0303409\n",
      "[367]\ttraining's binary_logloss: 0.0301551\n",
      "[368]\ttraining's binary_logloss: 0.0299741\n",
      "[369]\ttraining's binary_logloss: 0.0297747\n",
      "[370]\ttraining's binary_logloss: 0.0295662\n",
      "[371]\ttraining's binary_logloss: 0.0293802\n",
      "[372]\ttraining's binary_logloss: 0.0291886\n",
      "[373]\ttraining's binary_logloss: 0.0289764\n",
      "[374]\ttraining's binary_logloss: 0.0287946\n",
      "[375]\ttraining's binary_logloss: 0.0286268\n",
      "[376]\ttraining's binary_logloss: 0.0284586\n",
      "[377]\ttraining's binary_logloss: 0.0282892\n",
      "[378]\ttraining's binary_logloss: 0.0281189\n",
      "[379]\ttraining's binary_logloss: 0.0279391\n",
      "[380]\ttraining's binary_logloss: 0.0277586\n",
      "[381]\ttraining's binary_logloss: 0.0275879\n",
      "[382]\ttraining's binary_logloss: 0.0274139\n",
      "[383]\ttraining's binary_logloss: 0.0272431\n",
      "[384]\ttraining's binary_logloss: 0.0270786\n",
      "[385]\ttraining's binary_logloss: 0.0269105\n",
      "[386]\ttraining's binary_logloss: 0.0267494\n",
      "[387]\ttraining's binary_logloss: 0.0266015\n",
      "[388]\ttraining's binary_logloss: 0.026459\n",
      "[389]\ttraining's binary_logloss: 0.0263024\n",
      "[390]\ttraining's binary_logloss: 0.026142\n",
      "[391]\ttraining's binary_logloss: 0.0259887\n",
      "[392]\ttraining's binary_logloss: 0.0258404\n",
      "[393]\ttraining's binary_logloss: 0.0256966\n",
      "[394]\ttraining's binary_logloss: 0.0255466\n",
      "[395]\ttraining's binary_logloss: 0.025381\n",
      "[396]\ttraining's binary_logloss: 0.0252384\n",
      "[397]\ttraining's binary_logloss: 0.0250845\n",
      "[398]\ttraining's binary_logloss: 0.0249304\n",
      "[399]\ttraining's binary_logloss: 0.0247907\n",
      "[400]\ttraining's binary_logloss: 0.02464\n",
      "[401]\ttraining's binary_logloss: 0.0245066\n",
      "[402]\ttraining's binary_logloss: 0.0243691\n",
      "[403]\ttraining's binary_logloss: 0.0242169\n",
      "[404]\ttraining's binary_logloss: 0.0240586\n",
      "[405]\ttraining's binary_logloss: 0.0238929\n",
      "[406]\ttraining's binary_logloss: 0.0237509\n",
      "[407]\ttraining's binary_logloss: 0.0236053\n",
      "[408]\ttraining's binary_logloss: 0.0234506\n",
      "[409]\ttraining's binary_logloss: 0.0232926\n",
      "[410]\ttraining's binary_logloss: 0.023143\n",
      "[411]\ttraining's binary_logloss: 0.023\n",
      "[412]\ttraining's binary_logloss: 0.022864\n",
      "[413]\ttraining's binary_logloss: 0.022736\n",
      "[414]\ttraining's binary_logloss: 0.0225937\n",
      "[415]\ttraining's binary_logloss: 0.0224534\n",
      "[416]\ttraining's binary_logloss: 0.0223085\n",
      "[417]\ttraining's binary_logloss: 0.0221728\n",
      "[418]\ttraining's binary_logloss: 0.0220428\n",
      "[419]\ttraining's binary_logloss: 0.0219213\n",
      "[420]\ttraining's binary_logloss: 0.0217951\n",
      "[421]\ttraining's binary_logloss: 0.0216604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[422]\ttraining's binary_logloss: 0.0215401\n",
      "[423]\ttraining's binary_logloss: 0.0214098\n",
      "[424]\ttraining's binary_logloss: 0.0212868\n",
      "[425]\ttraining's binary_logloss: 0.0211618\n",
      "[426]\ttraining's binary_logloss: 0.0210383\n",
      "[427]\ttraining's binary_logloss: 0.0209066\n",
      "[428]\ttraining's binary_logloss: 0.0207839\n",
      "[429]\ttraining's binary_logloss: 0.0206506\n",
      "[430]\ttraining's binary_logloss: 0.0205182\n",
      "[431]\ttraining's binary_logloss: 0.0203889\n",
      "[432]\ttraining's binary_logloss: 0.0202745\n",
      "[433]\ttraining's binary_logloss: 0.020153\n",
      "[434]\ttraining's binary_logloss: 0.020022\n",
      "[435]\ttraining's binary_logloss: 0.0199043\n",
      "[436]\ttraining's binary_logloss: 0.0197824\n",
      "[437]\ttraining's binary_logloss: 0.0196756\n",
      "[438]\ttraining's binary_logloss: 0.0195644\n",
      "[439]\ttraining's binary_logloss: 0.0194422\n",
      "[440]\ttraining's binary_logloss: 0.0193272\n",
      "[441]\ttraining's binary_logloss: 0.0192142\n",
      "[442]\ttraining's binary_logloss: 0.01912\n",
      "[443]\ttraining's binary_logloss: 0.0189857\n",
      "[444]\ttraining's binary_logloss: 0.0188637\n",
      "[445]\ttraining's binary_logloss: 0.018757\n",
      "[446]\ttraining's binary_logloss: 0.0186405\n",
      "[447]\ttraining's binary_logloss: 0.0185085\n",
      "[448]\ttraining's binary_logloss: 0.0183884\n",
      "[449]\ttraining's binary_logloss: 0.0182764\n",
      "[450]\ttraining's binary_logloss: 0.0181661\n",
      "[451]\ttraining's binary_logloss: 0.0180517\n",
      "[452]\ttraining's binary_logloss: 0.0179468\n",
      "[453]\ttraining's binary_logloss: 0.0178401\n",
      "[454]\ttraining's binary_logloss: 0.0177384\n",
      "[455]\ttraining's binary_logloss: 0.0176366\n",
      "[456]\ttraining's binary_logloss: 0.0175342\n",
      "[457]\ttraining's binary_logloss: 0.0174358\n",
      "[458]\ttraining's binary_logloss: 0.0173372\n",
      "[459]\ttraining's binary_logloss: 0.017237\n",
      "[460]\ttraining's binary_logloss: 0.0171436\n",
      "[461]\ttraining's binary_logloss: 0.0170401\n",
      "[462]\ttraining's binary_logloss: 0.0169354\n",
      "[463]\ttraining's binary_logloss: 0.0168398\n",
      "[464]\ttraining's binary_logloss: 0.0167435\n",
      "[465]\ttraining's binary_logloss: 0.0166525\n",
      "[466]\ttraining's binary_logloss: 0.0165558\n",
      "[467]\ttraining's binary_logloss: 0.0164448\n",
      "[468]\ttraining's binary_logloss: 0.0163424\n",
      "[469]\ttraining's binary_logloss: 0.016253\n",
      "[470]\ttraining's binary_logloss: 0.0161583\n",
      "[471]\ttraining's binary_logloss: 0.0160612\n",
      "[472]\ttraining's binary_logloss: 0.0159694\n",
      "[473]\ttraining's binary_logloss: 0.0158733\n",
      "[474]\ttraining's binary_logloss: 0.0157776\n",
      "[475]\ttraining's binary_logloss: 0.0156838\n",
      "[476]\ttraining's binary_logloss: 0.0155926\n",
      "[477]\ttraining's binary_logloss: 0.0154861\n",
      "[478]\ttraining's binary_logloss: 0.0153973\n",
      "[479]\ttraining's binary_logloss: 0.0153137\n",
      "[480]\ttraining's binary_logloss: 0.0152324\n",
      "[481]\ttraining's binary_logloss: 0.0151451\n",
      "[482]\ttraining's binary_logloss: 0.0150568\n",
      "[483]\ttraining's binary_logloss: 0.0149749\n",
      "[484]\ttraining's binary_logloss: 0.0148899\n",
      "[485]\ttraining's binary_logloss: 0.0148076\n",
      "[486]\ttraining's binary_logloss: 0.0147238\n",
      "[487]\ttraining's binary_logloss: 0.0146386\n",
      "[488]\ttraining's binary_logloss: 0.0145584\n",
      "[489]\ttraining's binary_logloss: 0.0144732\n",
      "[490]\ttraining's binary_logloss: 0.0143796\n",
      "[491]\ttraining's binary_logloss: 0.014294\n",
      "[492]\ttraining's binary_logloss: 0.0142034\n",
      "[493]\ttraining's binary_logloss: 0.0141227\n",
      "[494]\ttraining's binary_logloss: 0.0140313\n",
      "[495]\ttraining's binary_logloss: 0.0139496\n",
      "[496]\ttraining's binary_logloss: 0.0138707\n",
      "[497]\ttraining's binary_logloss: 0.0137919\n",
      "[498]\ttraining's binary_logloss: 0.0137107\n",
      "[499]\ttraining's binary_logloss: 0.0136251\n",
      "[500]\ttraining's binary_logloss: 0.0135386\n",
      "[501]\ttraining's binary_logloss: 0.0134539\n",
      "[502]\ttraining's binary_logloss: 0.013378\n",
      "[503]\ttraining's binary_logloss: 0.0132934\n",
      "[504]\ttraining's binary_logloss: 0.0132183\n",
      "[505]\ttraining's binary_logloss: 0.0131398\n",
      "[506]\ttraining's binary_logloss: 0.013066\n",
      "[507]\ttraining's binary_logloss: 0.0129974\n",
      "[508]\ttraining's binary_logloss: 0.0129196\n",
      "[509]\ttraining's binary_logloss: 0.0128348\n",
      "[510]\ttraining's binary_logloss: 0.0127563\n",
      "[511]\ttraining's binary_logloss: 0.0126745\n",
      "[512]\ttraining's binary_logloss: 0.0125998\n",
      "[513]\ttraining's binary_logloss: 0.0125293\n",
      "[514]\ttraining's binary_logloss: 0.0124558\n",
      "[515]\ttraining's binary_logloss: 0.0123793\n",
      "[516]\ttraining's binary_logloss: 0.0123052\n",
      "[517]\ttraining's binary_logloss: 0.0122332\n",
      "[518]\ttraining's binary_logloss: 0.0121666\n",
      "[519]\ttraining's binary_logloss: 0.0120994\n",
      "[520]\ttraining's binary_logloss: 0.0120255\n",
      "[521]\ttraining's binary_logloss: 0.0119536\n",
      "[522]\ttraining's binary_logloss: 0.01188\n",
      "[523]\ttraining's binary_logloss: 0.0118106\n",
      "[524]\ttraining's binary_logloss: 0.011733\n",
      "[525]\ttraining's binary_logloss: 0.011664\n",
      "[526]\ttraining's binary_logloss: 0.0116001\n",
      "[527]\ttraining's binary_logloss: 0.0115152\n",
      "[528]\ttraining's binary_logloss: 0.0114471\n",
      "[529]\ttraining's binary_logloss: 0.0113752\n",
      "[530]\ttraining's binary_logloss: 0.0113124\n",
      "[531]\ttraining's binary_logloss: 0.0112455\n",
      "[532]\ttraining's binary_logloss: 0.0111819\n",
      "[533]\ttraining's binary_logloss: 0.0111134\n",
      "[534]\ttraining's binary_logloss: 0.0110415\n",
      "[535]\ttraining's binary_logloss: 0.0109703\n",
      "[536]\ttraining's binary_logloss: 0.0109048\n",
      "[537]\ttraining's binary_logloss: 0.0108433\n",
      "[538]\ttraining's binary_logloss: 0.0107779\n",
      "[539]\ttraining's binary_logloss: 0.010714\n",
      "[540]\ttraining's binary_logloss: 0.010655\n",
      "[541]\ttraining's binary_logloss: 0.0105869\n",
      "[542]\ttraining's binary_logloss: 0.010521\n",
      "[543]\ttraining's binary_logloss: 0.0104553\n",
      "[544]\ttraining's binary_logloss: 0.0103988\n",
      "[545]\ttraining's binary_logloss: 0.0103386\n",
      "[546]\ttraining's binary_logloss: 0.0102763\n",
      "[547]\ttraining's binary_logloss: 0.0102224\n",
      "[548]\ttraining's binary_logloss: 0.0101652\n",
      "[549]\ttraining's binary_logloss: 0.0100976\n",
      "[550]\ttraining's binary_logloss: 0.0100357\n",
      "[551]\ttraining's binary_logloss: 0.00998089\n",
      "[552]\ttraining's binary_logloss: 0.0099246\n",
      "[553]\ttraining's binary_logloss: 0.00986666\n",
      "[554]\ttraining's binary_logloss: 0.0097993\n",
      "[555]\ttraining's binary_logloss: 0.00974269\n",
      "[556]\ttraining's binary_logloss: 0.00968819\n",
      "[557]\ttraining's binary_logloss: 0.00962888\n",
      "[558]\ttraining's binary_logloss: 0.00957491\n",
      "[559]\ttraining's binary_logloss: 0.00951516\n",
      "[560]\ttraining's binary_logloss: 0.00945512\n",
      "[561]\ttraining's binary_logloss: 0.00940101\n",
      "[562]\ttraining's binary_logloss: 0.00935053\n",
      "[563]\ttraining's binary_logloss: 0.00928465\n",
      "[564]\ttraining's binary_logloss: 0.00922309\n",
      "[565]\ttraining's binary_logloss: 0.00916694\n",
      "[566]\ttraining's binary_logloss: 0.00910942\n",
      "[567]\ttraining's binary_logloss: 0.00906141\n",
      "[568]\ttraining's binary_logloss: 0.00900161\n",
      "[569]\ttraining's binary_logloss: 0.00894004\n",
      "[570]\ttraining's binary_logloss: 0.00888919\n",
      "[571]\ttraining's binary_logloss: 0.00884048\n",
      "[572]\ttraining's binary_logloss: 0.00879289\n",
      "[573]\ttraining's binary_logloss: 0.00874211\n",
      "[574]\ttraining's binary_logloss: 0.00868669\n",
      "[575]\ttraining's binary_logloss: 0.00862984\n",
      "[576]\ttraining's binary_logloss: 0.00858302\n",
      "[577]\ttraining's binary_logloss: 0.00853235\n",
      "[578]\ttraining's binary_logloss: 0.008485\n",
      "[579]\ttraining's binary_logloss: 0.0084384\n",
      "[580]\ttraining's binary_logloss: 0.00839\n",
      "[581]\ttraining's binary_logloss: 0.00834101\n",
      "[582]\ttraining's binary_logloss: 0.00829258\n",
      "[583]\ttraining's binary_logloss: 0.00824672\n",
      "[584]\ttraining's binary_logloss: 0.0081993\n",
      "[585]\ttraining's binary_logloss: 0.00815596\n",
      "[586]\ttraining's binary_logloss: 0.00810477\n",
      "[587]\ttraining's binary_logloss: 0.00804984\n",
      "[588]\ttraining's binary_logloss: 0.0080002\n",
      "[589]\ttraining's binary_logloss: 0.00795332\n",
      "[590]\ttraining's binary_logloss: 0.00790604\n",
      "[591]\ttraining's binary_logloss: 0.00785458\n",
      "[592]\ttraining's binary_logloss: 0.00780569\n",
      "[593]\ttraining's binary_logloss: 0.00776251\n",
      "[594]\ttraining's binary_logloss: 0.00772298\n",
      "[595]\ttraining's binary_logloss: 0.00767792\n",
      "[596]\ttraining's binary_logloss: 0.00763399\n",
      "[597]\ttraining's binary_logloss: 0.00758886\n",
      "[598]\ttraining's binary_logloss: 0.0075415\n",
      "[599]\ttraining's binary_logloss: 0.00750238\n",
      "[600]\ttraining's binary_logloss: 0.00746049\n",
      "[601]\ttraining's binary_logloss: 0.00742256\n",
      "[602]\ttraining's binary_logloss: 0.00737864\n",
      "[603]\ttraining's binary_logloss: 0.00732765\n",
      "[604]\ttraining's binary_logloss: 0.00728671\n",
      "[605]\ttraining's binary_logloss: 0.00724208\n",
      "[606]\ttraining's binary_logloss: 0.00718702\n",
      "[607]\ttraining's binary_logloss: 0.00714582\n",
      "[608]\ttraining's binary_logloss: 0.00709774\n",
      "[609]\ttraining's binary_logloss: 0.00705544\n",
      "[610]\ttraining's binary_logloss: 0.00700973\n",
      "[611]\ttraining's binary_logloss: 0.00696871\n",
      "[612]\ttraining's binary_logloss: 0.00693193\n",
      "[613]\ttraining's binary_logloss: 0.00689096\n",
      "[614]\ttraining's binary_logloss: 0.00685018\n",
      "[615]\ttraining's binary_logloss: 0.00680885\n",
      "[616]\ttraining's binary_logloss: 0.00676603\n",
      "[617]\ttraining's binary_logloss: 0.00672904\n",
      "[618]\ttraining's binary_logloss: 0.00668742\n",
      "[619]\ttraining's binary_logloss: 0.00664826\n",
      "[620]\ttraining's binary_logloss: 0.00660544\n",
      "[621]\ttraining's binary_logloss: 0.00656526\n",
      "[622]\ttraining's binary_logloss: 0.00652171\n",
      "[623]\ttraining's binary_logloss: 0.00648197\n",
      "[624]\ttraining's binary_logloss: 0.00644341\n",
      "[625]\ttraining's binary_logloss: 0.00640762\n",
      "[626]\ttraining's binary_logloss: 0.00637024\n",
      "[627]\ttraining's binary_logloss: 0.00633277\n",
      "[628]\ttraining's binary_logloss: 0.00629658\n",
      "[629]\ttraining's binary_logloss: 0.00625853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[630]\ttraining's binary_logloss: 0.00621669\n",
      "[631]\ttraining's binary_logloss: 0.006182\n",
      "[632]\ttraining's binary_logloss: 0.0061465\n",
      "[633]\ttraining's binary_logloss: 0.00610969\n",
      "[634]\ttraining's binary_logloss: 0.0060752\n",
      "[635]\ttraining's binary_logloss: 0.00603915\n",
      "[636]\ttraining's binary_logloss: 0.00600874\n",
      "[637]\ttraining's binary_logloss: 0.00597243\n",
      "[638]\ttraining's binary_logloss: 0.00593535\n",
      "[639]\ttraining's binary_logloss: 0.00589821\n",
      "[640]\ttraining's binary_logloss: 0.00586767\n",
      "[641]\ttraining's binary_logloss: 0.00583341\n",
      "[642]\ttraining's binary_logloss: 0.00580063\n",
      "[643]\ttraining's binary_logloss: 0.00575977\n",
      "[644]\ttraining's binary_logloss: 0.00572943\n",
      "[645]\ttraining's binary_logloss: 0.00569473\n",
      "[646]\ttraining's binary_logloss: 0.00566273\n",
      "[647]\ttraining's binary_logloss: 0.00562896\n",
      "[648]\ttraining's binary_logloss: 0.00559706\n",
      "[649]\ttraining's binary_logloss: 0.00556078\n",
      "[650]\ttraining's binary_logloss: 0.00553222\n",
      "[651]\ttraining's binary_logloss: 0.00549751\n",
      "[652]\ttraining's binary_logloss: 0.00546792\n",
      "[653]\ttraining's binary_logloss: 0.00543579\n",
      "[654]\ttraining's binary_logloss: 0.00540482\n",
      "[655]\ttraining's binary_logloss: 0.00537413\n",
      "[656]\ttraining's binary_logloss: 0.00534434\n",
      "[657]\ttraining's binary_logloss: 0.00531474\n",
      "[658]\ttraining's binary_logloss: 0.00528351\n",
      "[659]\ttraining's binary_logloss: 0.00525335\n",
      "[660]\ttraining's binary_logloss: 0.00522279\n",
      "[661]\ttraining's binary_logloss: 0.00519154\n",
      "[662]\ttraining's binary_logloss: 0.00516303\n",
      "[663]\ttraining's binary_logloss: 0.00513393\n",
      "[664]\ttraining's binary_logloss: 0.00510195\n",
      "[665]\ttraining's binary_logloss: 0.00507339\n",
      "[666]\ttraining's binary_logloss: 0.00504266\n",
      "[667]\ttraining's binary_logloss: 0.00501335\n",
      "[668]\ttraining's binary_logloss: 0.0049833\n",
      "[669]\ttraining's binary_logloss: 0.0049536\n",
      "[670]\ttraining's binary_logloss: 0.00492427\n",
      "[671]\ttraining's binary_logloss: 0.00489593\n",
      "[672]\ttraining's binary_logloss: 0.00486771\n",
      "[673]\ttraining's binary_logloss: 0.00483536\n",
      "[674]\ttraining's binary_logloss: 0.00480892\n",
      "[675]\ttraining's binary_logloss: 0.00478388\n",
      "[676]\ttraining's binary_logloss: 0.00476057\n",
      "[677]\ttraining's binary_logloss: 0.00473257\n",
      "[678]\ttraining's binary_logloss: 0.00470409\n",
      "[679]\ttraining's binary_logloss: 0.0046727\n",
      "[680]\ttraining's binary_logloss: 0.00464492\n",
      "[681]\ttraining's binary_logloss: 0.00461496\n",
      "[682]\ttraining's binary_logloss: 0.00458669\n",
      "[683]\ttraining's binary_logloss: 0.00455955\n",
      "[684]\ttraining's binary_logloss: 0.00453026\n",
      "[685]\ttraining's binary_logloss: 0.00450101\n",
      "[686]\ttraining's binary_logloss: 0.00447694\n",
      "[687]\ttraining's binary_logloss: 0.00445165\n",
      "[688]\ttraining's binary_logloss: 0.00442697\n",
      "[689]\ttraining's binary_logloss: 0.00440516\n",
      "[690]\ttraining's binary_logloss: 0.00437836\n",
      "[691]\ttraining's binary_logloss: 0.00435432\n",
      "[692]\ttraining's binary_logloss: 0.00432922\n",
      "[693]\ttraining's binary_logloss: 0.00430277\n",
      "[694]\ttraining's binary_logloss: 0.00427691\n",
      "[695]\ttraining's binary_logloss: 0.00424903\n",
      "[696]\ttraining's binary_logloss: 0.00422557\n",
      "[697]\ttraining's binary_logloss: 0.00420417\n",
      "[698]\ttraining's binary_logloss: 0.00418158\n",
      "[699]\ttraining's binary_logloss: 0.00415747\n",
      "[700]\ttraining's binary_logloss: 0.00413277\n",
      "[701]\ttraining's binary_logloss: 0.00410774\n",
      "[702]\ttraining's binary_logloss: 0.00408689\n",
      "[703]\ttraining's binary_logloss: 0.00406125\n",
      "[704]\ttraining's binary_logloss: 0.00403829\n",
      "[705]\ttraining's binary_logloss: 0.0040131\n",
      "[706]\ttraining's binary_logloss: 0.00398678\n",
      "[707]\ttraining's binary_logloss: 0.0039631\n",
      "[708]\ttraining's binary_logloss: 0.00394048\n",
      "[709]\ttraining's binary_logloss: 0.0039185\n",
      "[710]\ttraining's binary_logloss: 0.00389887\n",
      "[711]\ttraining's binary_logloss: 0.00387556\n",
      "[712]\ttraining's binary_logloss: 0.00385425\n",
      "[713]\ttraining's binary_logloss: 0.00383288\n",
      "[714]\ttraining's binary_logloss: 0.00380974\n",
      "[715]\ttraining's binary_logloss: 0.00378667\n",
      "[716]\ttraining's binary_logloss: 0.0037607\n",
      "[717]\ttraining's binary_logloss: 0.00374086\n",
      "[718]\ttraining's binary_logloss: 0.00371987\n",
      "[719]\ttraining's binary_logloss: 0.00369097\n",
      "[720]\ttraining's binary_logloss: 0.00366996\n",
      "[721]\ttraining's binary_logloss: 0.00364757\n",
      "[722]\ttraining's binary_logloss: 0.00362445\n",
      "[723]\ttraining's binary_logloss: 0.00360405\n",
      "[724]\ttraining's binary_logloss: 0.00358483\n",
      "[725]\ttraining's binary_logloss: 0.00356589\n",
      "[726]\ttraining's binary_logloss: 0.00354762\n",
      "[727]\ttraining's binary_logloss: 0.00352757\n",
      "[728]\ttraining's binary_logloss: 0.00350876\n",
      "[729]\ttraining's binary_logloss: 0.00348646\n",
      "[730]\ttraining's binary_logloss: 0.00346993\n",
      "[731]\ttraining's binary_logloss: 0.00344787\n",
      "[732]\ttraining's binary_logloss: 0.00342851\n",
      "[733]\ttraining's binary_logloss: 0.00340733\n",
      "[734]\ttraining's binary_logloss: 0.00338682\n",
      "[735]\ttraining's binary_logloss: 0.00336462\n",
      "[736]\ttraining's binary_logloss: 0.00334368\n",
      "[737]\ttraining's binary_logloss: 0.00332314\n",
      "[738]\ttraining's binary_logloss: 0.00330144\n",
      "[739]\ttraining's binary_logloss: 0.00328375\n",
      "[740]\ttraining's binary_logloss: 0.00326165\n",
      "[741]\ttraining's binary_logloss: 0.00324446\n",
      "[742]\ttraining's binary_logloss: 0.00322613\n",
      "[743]\ttraining's binary_logloss: 0.00320554\n",
      "[744]\ttraining's binary_logloss: 0.00318862\n",
      "[745]\ttraining's binary_logloss: 0.00317019\n",
      "[746]\ttraining's binary_logloss: 0.00315305\n",
      "[747]\ttraining's binary_logloss: 0.00313444\n",
      "[748]\ttraining's binary_logloss: 0.00311666\n",
      "[749]\ttraining's binary_logloss: 0.0031011\n",
      "[750]\ttraining's binary_logloss: 0.00308332\n",
      "[751]\ttraining's binary_logloss: 0.00306554\n",
      "[752]\ttraining's binary_logloss: 0.0030482\n",
      "[753]\ttraining's binary_logloss: 0.00303076\n",
      "[754]\ttraining's binary_logloss: 0.00301252\n",
      "[755]\ttraining's binary_logloss: 0.00299281\n",
      "[756]\ttraining's binary_logloss: 0.00297374\n",
      "[757]\ttraining's binary_logloss: 0.00295739\n",
      "[758]\ttraining's binary_logloss: 0.00293948\n",
      "[759]\ttraining's binary_logloss: 0.00292321\n",
      "[760]\ttraining's binary_logloss: 0.00290786\n",
      "[761]\ttraining's binary_logloss: 0.0028925\n",
      "[762]\ttraining's binary_logloss: 0.0028781\n",
      "[763]\ttraining's binary_logloss: 0.00286125\n",
      "[764]\ttraining's binary_logloss: 0.00284469\n",
      "[765]\ttraining's binary_logloss: 0.0028285\n",
      "[766]\ttraining's binary_logloss: 0.00281226\n",
      "[767]\ttraining's binary_logloss: 0.00279886\n",
      "[768]\ttraining's binary_logloss: 0.00278269\n",
      "[769]\ttraining's binary_logloss: 0.00276728\n",
      "[770]\ttraining's binary_logloss: 0.00275248\n",
      "[771]\ttraining's binary_logloss: 0.00273835\n",
      "[772]\ttraining's binary_logloss: 0.00272387\n",
      "[773]\ttraining's binary_logloss: 0.00271139\n",
      "[774]\ttraining's binary_logloss: 0.0026962\n",
      "[775]\ttraining's binary_logloss: 0.00267829\n",
      "[776]\ttraining's binary_logloss: 0.00266465\n",
      "[777]\ttraining's binary_logloss: 0.00264777\n",
      "[778]\ttraining's binary_logloss: 0.00263212\n",
      "[779]\ttraining's binary_logloss: 0.00261776\n",
      "[780]\ttraining's binary_logloss: 0.00260315\n",
      "[781]\ttraining's binary_logloss: 0.00258838\n",
      "[782]\ttraining's binary_logloss: 0.00257133\n",
      "[783]\ttraining's binary_logloss: 0.00255701\n",
      "[784]\ttraining's binary_logloss: 0.00254377\n",
      "[785]\ttraining's binary_logloss: 0.00252875\n",
      "[786]\ttraining's binary_logloss: 0.00251309\n",
      "[787]\ttraining's binary_logloss: 0.00249936\n",
      "[788]\ttraining's binary_logloss: 0.00248567\n",
      "[789]\ttraining's binary_logloss: 0.00247242\n",
      "[790]\ttraining's binary_logloss: 0.00245918\n",
      "[791]\ttraining's binary_logloss: 0.00244475\n",
      "[792]\ttraining's binary_logloss: 0.00242986\n",
      "[793]\ttraining's binary_logloss: 0.00241744\n",
      "[794]\ttraining's binary_logloss: 0.00240105\n",
      "[795]\ttraining's binary_logloss: 0.00238796\n",
      "[796]\ttraining's binary_logloss: 0.00237072\n",
      "[797]\ttraining's binary_logloss: 0.00235406\n",
      "[798]\ttraining's binary_logloss: 0.00233999\n",
      "[799]\ttraining's binary_logloss: 0.00232592\n",
      "[800]\ttraining's binary_logloss: 0.00230972\n",
      "[801]\ttraining's binary_logloss: 0.00229761\n",
      "[802]\ttraining's binary_logloss: 0.00228528\n",
      "[803]\ttraining's binary_logloss: 0.00227214\n",
      "[804]\ttraining's binary_logloss: 0.00225862\n",
      "[805]\ttraining's binary_logloss: 0.00224349\n",
      "[806]\ttraining's binary_logloss: 0.0022304\n",
      "[807]\ttraining's binary_logloss: 0.00221724\n",
      "[808]\ttraining's binary_logloss: 0.0022038\n",
      "[809]\ttraining's binary_logloss: 0.00219114\n",
      "[810]\ttraining's binary_logloss: 0.00217728\n",
      "[811]\ttraining's binary_logloss: 0.00216528\n",
      "[812]\ttraining's binary_logloss: 0.0021523\n",
      "[813]\ttraining's binary_logloss: 0.00214035\n",
      "[814]\ttraining's binary_logloss: 0.00212822\n",
      "[815]\ttraining's binary_logloss: 0.00211557\n",
      "[816]\ttraining's binary_logloss: 0.00210282\n",
      "[817]\ttraining's binary_logloss: 0.00209307\n",
      "[818]\ttraining's binary_logloss: 0.0020823\n",
      "[819]\ttraining's binary_logloss: 0.00207044\n",
      "[820]\ttraining's binary_logloss: 0.00205872\n",
      "[821]\ttraining's binary_logloss: 0.00204797\n",
      "[822]\ttraining's binary_logloss: 0.00203636\n",
      "[823]\ttraining's binary_logloss: 0.00202429\n",
      "[824]\ttraining's binary_logloss: 0.00201102\n",
      "[825]\ttraining's binary_logloss: 0.00199997\n",
      "[826]\ttraining's binary_logloss: 0.00198726\n",
      "[827]\ttraining's binary_logloss: 0.00197557\n",
      "[828]\ttraining's binary_logloss: 0.00196425\n",
      "[829]\ttraining's binary_logloss: 0.00195201\n",
      "[830]\ttraining's binary_logloss: 0.00194222\n",
      "[831]\ttraining's binary_logloss: 0.00193229\n",
      "[832]\ttraining's binary_logloss: 0.00192082\n",
      "[833]\ttraining's binary_logloss: 0.00190887\n",
      "[834]\ttraining's binary_logloss: 0.00189658\n",
      "[835]\ttraining's binary_logloss: 0.00188615\n",
      "[836]\ttraining's binary_logloss: 0.00187699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[837]\ttraining's binary_logloss: 0.00186615\n",
      "[838]\ttraining's binary_logloss: 0.00185577\n",
      "[839]\ttraining's binary_logloss: 0.00184575\n",
      "[840]\ttraining's binary_logloss: 0.00183529\n",
      "[841]\ttraining's binary_logloss: 0.00182382\n",
      "[842]\ttraining's binary_logloss: 0.00181351\n",
      "[843]\ttraining's binary_logloss: 0.00180279\n",
      "[844]\ttraining's binary_logloss: 0.00179381\n",
      "[845]\ttraining's binary_logloss: 0.00178375\n",
      "[846]\ttraining's binary_logloss: 0.00177296\n",
      "[847]\ttraining's binary_logloss: 0.00176383\n",
      "[848]\ttraining's binary_logloss: 0.00175437\n",
      "[849]\ttraining's binary_logloss: 0.00174424\n",
      "[850]\ttraining's binary_logloss: 0.00173306\n",
      "[851]\ttraining's binary_logloss: 0.00172428\n",
      "[852]\ttraining's binary_logloss: 0.00171539\n",
      "[853]\ttraining's binary_logloss: 0.00170646\n",
      "[854]\ttraining's binary_logloss: 0.0016959\n",
      "[855]\ttraining's binary_logloss: 0.0016873\n",
      "[856]\ttraining's binary_logloss: 0.00167714\n",
      "[857]\ttraining's binary_logloss: 0.00166795\n",
      "[858]\ttraining's binary_logloss: 0.00165821\n",
      "[859]\ttraining's binary_logloss: 0.00164977\n",
      "[860]\ttraining's binary_logloss: 0.00164068\n",
      "[861]\ttraining's binary_logloss: 0.00163252\n",
      "[862]\ttraining's binary_logloss: 0.00162386\n",
      "[863]\ttraining's binary_logloss: 0.00161545\n",
      "[864]\ttraining's binary_logloss: 0.00160617\n",
      "[865]\ttraining's binary_logloss: 0.00159741\n",
      "[866]\ttraining's binary_logloss: 0.00158722\n",
      "[867]\ttraining's binary_logloss: 0.00157851\n",
      "[868]\ttraining's binary_logloss: 0.0015708\n",
      "[869]\ttraining's binary_logloss: 0.00156278\n",
      "[870]\ttraining's binary_logloss: 0.00155305\n",
      "[871]\ttraining's binary_logloss: 0.00154353\n",
      "[872]\ttraining's binary_logloss: 0.00153313\n",
      "[873]\ttraining's binary_logloss: 0.00152426\n",
      "[874]\ttraining's binary_logloss: 0.00151613\n",
      "[875]\ttraining's binary_logloss: 0.00150661\n",
      "[876]\ttraining's binary_logloss: 0.00149786\n",
      "[877]\ttraining's binary_logloss: 0.00148848\n",
      "[878]\ttraining's binary_logloss: 0.00147963\n",
      "[879]\ttraining's binary_logloss: 0.00147263\n",
      "[880]\ttraining's binary_logloss: 0.00146502\n",
      "[881]\ttraining's binary_logloss: 0.00145586\n",
      "[882]\ttraining's binary_logloss: 0.00144821\n",
      "[883]\ttraining's binary_logloss: 0.00144057\n",
      "[884]\ttraining's binary_logloss: 0.00143335\n",
      "[885]\ttraining's binary_logloss: 0.00142698\n",
      "[886]\ttraining's binary_logloss: 0.00141997\n",
      "[887]\ttraining's binary_logloss: 0.00141222\n",
      "[888]\ttraining's binary_logloss: 0.00140416\n",
      "[889]\ttraining's binary_logloss: 0.00139471\n",
      "[890]\ttraining's binary_logloss: 0.00138769\n",
      "[891]\ttraining's binary_logloss: 0.00138192\n",
      "[892]\ttraining's binary_logloss: 0.00137414\n",
      "[893]\ttraining's binary_logloss: 0.00136576\n",
      "[894]\ttraining's binary_logloss: 0.00135887\n",
      "[895]\ttraining's binary_logloss: 0.00135013\n",
      "[896]\ttraining's binary_logloss: 0.00134184\n",
      "[897]\ttraining's binary_logloss: 0.00133421\n",
      "[898]\ttraining's binary_logloss: 0.00132652\n",
      "[899]\ttraining's binary_logloss: 0.00131831\n",
      "[900]\ttraining's binary_logloss: 0.001311\n",
      "[901]\ttraining's binary_logloss: 0.0013039\n",
      "[902]\ttraining's binary_logloss: 0.00129717\n",
      "[903]\ttraining's binary_logloss: 0.00129012\n",
      "[904]\ttraining's binary_logloss: 0.00128325\n",
      "[905]\ttraining's binary_logloss: 0.00127705\n",
      "[906]\ttraining's binary_logloss: 0.00127103\n",
      "[907]\ttraining's binary_logloss: 0.00126205\n",
      "[908]\ttraining's binary_logloss: 0.00125595\n",
      "[909]\ttraining's binary_logloss: 0.0012488\n",
      "[910]\ttraining's binary_logloss: 0.0012423\n",
      "[911]\ttraining's binary_logloss: 0.00123507\n",
      "[912]\ttraining's binary_logloss: 0.00122725\n",
      "[913]\ttraining's binary_logloss: 0.00121937\n",
      "[914]\ttraining's binary_logloss: 0.00121259\n",
      "[915]\ttraining's binary_logloss: 0.00120564\n",
      "[916]\ttraining's binary_logloss: 0.00119967\n",
      "[917]\ttraining's binary_logloss: 0.00119358\n",
      "[918]\ttraining's binary_logloss: 0.00118574\n",
      "[919]\ttraining's binary_logloss: 0.00117977\n",
      "[920]\ttraining's binary_logloss: 0.00117351\n",
      "[921]\ttraining's binary_logloss: 0.00116749\n",
      "[922]\ttraining's binary_logloss: 0.0011606\n",
      "[923]\ttraining's binary_logloss: 0.00115226\n",
      "[924]\ttraining's binary_logloss: 0.00114598\n",
      "[925]\ttraining's binary_logloss: 0.00114014\n",
      "[926]\ttraining's binary_logloss: 0.0011347\n",
      "[927]\ttraining's binary_logloss: 0.00112782\n",
      "[928]\ttraining's binary_logloss: 0.00112168\n",
      "[929]\ttraining's binary_logloss: 0.00111614\n",
      "[930]\ttraining's binary_logloss: 0.00110935\n",
      "[931]\ttraining's binary_logloss: 0.00110347\n",
      "[932]\ttraining's binary_logloss: 0.00109734\n",
      "[933]\ttraining's binary_logloss: 0.00109099\n",
      "[934]\ttraining's binary_logloss: 0.00108494\n",
      "[935]\ttraining's binary_logloss: 0.00107949\n",
      "[936]\ttraining's binary_logloss: 0.00107474\n",
      "[937]\ttraining's binary_logloss: 0.00106814\n",
      "[938]\ttraining's binary_logloss: 0.00106118\n",
      "[939]\ttraining's binary_logloss: 0.0010556\n",
      "[940]\ttraining's binary_logloss: 0.0010504\n",
      "[941]\ttraining's binary_logloss: 0.00104461\n",
      "[942]\ttraining's binary_logloss: 0.00103798\n",
      "[943]\ttraining's binary_logloss: 0.00103162\n",
      "[944]\ttraining's binary_logloss: 0.00102473\n",
      "[945]\ttraining's binary_logloss: 0.00101803\n",
      "[946]\ttraining's binary_logloss: 0.00101246\n",
      "[947]\ttraining's binary_logloss: 0.00100563\n",
      "[948]\ttraining's binary_logloss: 0.000998388\n",
      "[949]\ttraining's binary_logloss: 0.000993008\n",
      "[950]\ttraining's binary_logloss: 0.000988169\n",
      "[951]\ttraining's binary_logloss: 0.000983375\n",
      "[952]\ttraining's binary_logloss: 0.000979387\n",
      "[953]\ttraining's binary_logloss: 0.000973478\n",
      "[954]\ttraining's binary_logloss: 0.000967487\n",
      "[955]\ttraining's binary_logloss: 0.000961604\n",
      "[956]\ttraining's binary_logloss: 0.00095634\n",
      "[957]\ttraining's binary_logloss: 0.000950599\n",
      "[958]\ttraining's binary_logloss: 0.000945394\n",
      "[959]\ttraining's binary_logloss: 0.000940103\n",
      "[960]\ttraining's binary_logloss: 0.000933869\n",
      "[961]\ttraining's binary_logloss: 0.000929993\n",
      "[962]\ttraining's binary_logloss: 0.000925866\n",
      "[963]\ttraining's binary_logloss: 0.000919998\n",
      "[964]\ttraining's binary_logloss: 0.00091493\n",
      "[965]\ttraining's binary_logloss: 0.000909757\n",
      "[966]\ttraining's binary_logloss: 0.000904896\n",
      "[967]\ttraining's binary_logloss: 0.000900722\n",
      "[968]\ttraining's binary_logloss: 0.000896452\n",
      "[969]\ttraining's binary_logloss: 0.000890999\n",
      "[970]\ttraining's binary_logloss: 0.000886925\n",
      "[971]\ttraining's binary_logloss: 0.000881696\n",
      "[972]\ttraining's binary_logloss: 0.000876121\n",
      "[973]\ttraining's binary_logloss: 0.000872156\n",
      "[974]\ttraining's binary_logloss: 0.000867079\n",
      "[975]\ttraining's binary_logloss: 0.000861553\n",
      "[976]\ttraining's binary_logloss: 0.000856163\n",
      "[977]\ttraining's binary_logloss: 0.000851805\n",
      "[978]\ttraining's binary_logloss: 0.000847462\n",
      "[979]\ttraining's binary_logloss: 0.00084281\n",
      "[980]\ttraining's binary_logloss: 0.000838334\n",
      "[981]\ttraining's binary_logloss: 0.000832609\n",
      "[982]\ttraining's binary_logloss: 0.000827639\n",
      "[983]\ttraining's binary_logloss: 0.000821879\n",
      "[984]\ttraining's binary_logloss: 0.000817815\n",
      "[985]\ttraining's binary_logloss: 0.000813452\n",
      "[986]\ttraining's binary_logloss: 0.000809338\n",
      "[987]\ttraining's binary_logloss: 0.000805707\n",
      "[988]\ttraining's binary_logloss: 0.000801872\n",
      "[989]\ttraining's binary_logloss: 0.000796293\n",
      "[990]\ttraining's binary_logloss: 0.000790619\n",
      "[991]\ttraining's binary_logloss: 0.000786566\n",
      "[992]\ttraining's binary_logloss: 0.000782166\n",
      "[993]\ttraining's binary_logloss: 0.000778241\n",
      "[994]\ttraining's binary_logloss: 0.000774679\n",
      "[995]\ttraining's binary_logloss: 0.000770673\n",
      "[996]\ttraining's binary_logloss: 0.000767635\n",
      "[997]\ttraining's binary_logloss: 0.000763584\n",
      "[998]\ttraining's binary_logloss: 0.000759199\n",
      "[999]\ttraining's binary_logloss: 0.000753727\n",
      "[1000]\ttraining's binary_logloss: 0.000748044\n",
      "[1001]\ttraining's binary_logloss: 0.000744527\n",
      "[1002]\ttraining's binary_logloss: 0.000740985\n",
      "[1003]\ttraining's binary_logloss: 0.000735622\n",
      "[1004]\ttraining's binary_logloss: 0.000730677\n",
      "[1005]\ttraining's binary_logloss: 0.000727248\n",
      "[1006]\ttraining's binary_logloss: 0.000724508\n",
      "[1007]\ttraining's binary_logloss: 0.000720189\n",
      "[1008]\ttraining's binary_logloss: 0.000717058\n",
      "[1009]\ttraining's binary_logloss: 0.00071338\n",
      "[1010]\ttraining's binary_logloss: 0.000709093\n",
      "[1011]\ttraining's binary_logloss: 0.000704985\n",
      "[1012]\ttraining's binary_logloss: 0.000701055\n",
      "[1013]\ttraining's binary_logloss: 0.000697853\n",
      "[1014]\ttraining's binary_logloss: 0.000694064\n",
      "[1015]\ttraining's binary_logloss: 0.000690893\n",
      "[1016]\ttraining's binary_logloss: 0.000685861\n",
      "[1017]\ttraining's binary_logloss: 0.000682706\n",
      "[1018]\ttraining's binary_logloss: 0.000679714\n",
      "[1019]\ttraining's binary_logloss: 0.000676225\n",
      "[1020]\ttraining's binary_logloss: 0.000673012\n",
      "[1021]\ttraining's binary_logloss: 0.00066886\n",
      "[1022]\ttraining's binary_logloss: 0.000664222\n",
      "[1023]\ttraining's binary_logloss: 0.000661493\n",
      "[1024]\ttraining's binary_logloss: 0.000658421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1025]\ttraining's binary_logloss: 0.000653633\n",
      "[1026]\ttraining's binary_logloss: 0.000649204\n",
      "[1027]\ttraining's binary_logloss: 0.000645639\n",
      "[1028]\ttraining's binary_logloss: 0.000641737\n",
      "[1029]\ttraining's binary_logloss: 0.000638342\n",
      "[1030]\ttraining's binary_logloss: 0.000635344\n",
      "[1031]\ttraining's binary_logloss: 0.000631368\n",
      "[1032]\ttraining's binary_logloss: 0.00062728\n",
      "[1033]\ttraining's binary_logloss: 0.000624224\n",
      "[1034]\ttraining's binary_logloss: 0.000621362\n",
      "[1035]\ttraining's binary_logloss: 0.000618327\n",
      "[1036]\ttraining's binary_logloss: 0.000615863\n",
      "[1037]\ttraining's binary_logloss: 0.000613209\n",
      "[1038]\ttraining's binary_logloss: 0.000609447\n",
      "[1039]\ttraining's binary_logloss: 0.000605924\n",
      "[1040]\ttraining's binary_logloss: 0.00060314\n",
      "[1041]\ttraining's binary_logloss: 0.000599547\n",
      "[1042]\ttraining's binary_logloss: 0.000597547\n",
      "[1043]\ttraining's binary_logloss: 0.000594629\n",
      "[1044]\ttraining's binary_logloss: 0.000591481\n",
      "[1045]\ttraining's binary_logloss: 0.000588076\n",
      "[1046]\ttraining's binary_logloss: 0.000585245\n",
      "[1047]\ttraining's binary_logloss: 0.000580585\n",
      "[1048]\ttraining's binary_logloss: 0.000575399\n",
      "[1049]\ttraining's binary_logloss: 0.000572962\n",
      "[1050]\ttraining's binary_logloss: 0.000570856\n",
      "[1051]\ttraining's binary_logloss: 0.000566564\n",
      "[1052]\ttraining's binary_logloss: 0.000563683\n",
      "[1053]\ttraining's binary_logloss: 0.000560189\n",
      "[1054]\ttraining's binary_logloss: 0.000557058\n",
      "[1055]\ttraining's binary_logloss: 0.000553728\n",
      "[1056]\ttraining's binary_logloss: 0.000550936\n",
      "[1057]\ttraining's binary_logloss: 0.000547842\n",
      "[1058]\ttraining's binary_logloss: 0.000543964\n",
      "[1059]\ttraining's binary_logloss: 0.000540653\n",
      "[1060]\ttraining's binary_logloss: 0.000536842\n",
      "[1061]\ttraining's binary_logloss: 0.000532255\n",
      "[1062]\ttraining's binary_logloss: 0.0005301\n",
      "[1063]\ttraining's binary_logloss: 0.000525688\n",
      "[1064]\ttraining's binary_logloss: 0.000521039\n",
      "[1065]\ttraining's binary_logloss: 0.000519229\n",
      "[1066]\ttraining's binary_logloss: 0.000516445\n",
      "[1067]\ttraining's binary_logloss: 0.000512538\n",
      "[1068]\ttraining's binary_logloss: 0.000510316\n",
      "[1069]\ttraining's binary_logloss: 0.000508574\n",
      "[1070]\ttraining's binary_logloss: 0.000505506\n",
      "[1071]\ttraining's binary_logloss: 0.000502866\n",
      "[1072]\ttraining's binary_logloss: 0.000499735\n",
      "[1073]\ttraining's binary_logloss: 0.000497133\n",
      "[1074]\ttraining's binary_logloss: 0.000495042\n",
      "[1075]\ttraining's binary_logloss: 0.000490913\n",
      "[1076]\ttraining's binary_logloss: 0.000486603\n",
      "[1077]\ttraining's binary_logloss: 0.000484552\n",
      "[1078]\ttraining's binary_logloss: 0.000481751\n",
      "[1079]\ttraining's binary_logloss: 0.000480038\n",
      "[1080]\ttraining's binary_logloss: 0.000477834\n",
      "[1081]\ttraining's binary_logloss: 0.000475522\n",
      "[1082]\ttraining's binary_logloss: 0.00047235\n",
      "[1083]\ttraining's binary_logloss: 0.000468901\n",
      "[1084]\ttraining's binary_logloss: 0.000466891\n",
      "[1085]\ttraining's binary_logloss: 0.000464901\n",
      "[1086]\ttraining's binary_logloss: 0.000462414\n",
      "[1087]\ttraining's binary_logloss: 0.000460106\n",
      "[1088]\ttraining's binary_logloss: 0.00045793\n",
      "[1089]\ttraining's binary_logloss: 0.000454685\n",
      "[1090]\ttraining's binary_logloss: 0.000451865\n",
      "[1091]\ttraining's binary_logloss: 0.000448754\n",
      "[1092]\ttraining's binary_logloss: 0.000445734\n",
      "[1093]\ttraining's binary_logloss: 0.000443175\n",
      "[1094]\ttraining's binary_logloss: 0.000441089\n",
      "[1095]\ttraining's binary_logloss: 0.000437762\n",
      "[1096]\ttraining's binary_logloss: 0.000433995\n",
      "[1097]\ttraining's binary_logloss: 0.00043114\n",
      "[1098]\ttraining's binary_logloss: 0.000428529\n",
      "[1099]\ttraining's binary_logloss: 0.000425906\n",
      "[1100]\ttraining's binary_logloss: 0.000423757\n",
      "[1101]\ttraining's binary_logloss: 0.000422252\n",
      "[1102]\ttraining's binary_logloss: 0.000420548\n",
      "[1103]\ttraining's binary_logloss: 0.000417495\n",
      "[1104]\ttraining's binary_logloss: 0.000415602\n",
      "[1105]\ttraining's binary_logloss: 0.000414066\n",
      "[1106]\ttraining's binary_logloss: 0.000411517\n",
      "[1107]\ttraining's binary_logloss: 0.000408759\n",
      "[1108]\ttraining's binary_logloss: 0.000406691\n",
      "[1109]\ttraining's binary_logloss: 0.000404984\n",
      "[1110]\ttraining's binary_logloss: 0.00040256\n",
      "[1111]\ttraining's binary_logloss: 0.000400714\n",
      "[1112]\ttraining's binary_logloss: 0.000398156\n",
      "[1113]\ttraining's binary_logloss: 0.000394755\n",
      "[1114]\ttraining's binary_logloss: 0.00039137\n",
      "[1115]\ttraining's binary_logloss: 0.000388214\n",
      "[1116]\ttraining's binary_logloss: 0.000385907\n",
      "[1117]\ttraining's binary_logloss: 0.000384784\n",
      "[1118]\ttraining's binary_logloss: 0.00038316\n",
      "[1119]\ttraining's binary_logloss: 0.000379763\n",
      "[1120]\ttraining's binary_logloss: 0.000376937\n",
      "[1121]\ttraining's binary_logloss: 0.000375448\n",
      "[1122]\ttraining's binary_logloss: 0.000374306\n",
      "[1123]\ttraining's binary_logloss: 0.000372331\n",
      "[1124]\ttraining's binary_logloss: 0.000370837\n",
      "[1125]\ttraining's binary_logloss: 0.000369341\n",
      "[1126]\ttraining's binary_logloss: 0.000367301\n",
      "[1127]\ttraining's binary_logloss: 0.000365845\n",
      "[1128]\ttraining's binary_logloss: 0.000364833\n",
      "[1129]\ttraining's binary_logloss: 0.000363467\n",
      "[1130]\ttraining's binary_logloss: 0.000362098\n",
      "[1131]\ttraining's binary_logloss: 0.000360098\n",
      "[1132]\ttraining's binary_logloss: 0.000357849\n",
      "[1133]\ttraining's binary_logloss: 0.000354849\n",
      "[1134]\ttraining's binary_logloss: 0.000351872\n",
      "[1135]\ttraining's binary_logloss: 0.000349631\n",
      "[1136]\ttraining's binary_logloss: 0.000347763\n",
      "[1137]\ttraining's binary_logloss: 0.000346191\n",
      "[1138]\ttraining's binary_logloss: 0.000343338\n",
      "[1139]\ttraining's binary_logloss: 0.000340906\n",
      "[1140]\ttraining's binary_logloss: 0.000338139\n",
      "[1141]\ttraining's binary_logloss: 0.000337039\n",
      "[1142]\ttraining's binary_logloss: 0.00033612\n",
      "[1143]\ttraining's binary_logloss: 0.000333692\n",
      "[1144]\ttraining's binary_logloss: 0.000331148\n",
      "[1145]\ttraining's binary_logloss: 0.000328962\n",
      "[1146]\ttraining's binary_logloss: 0.000326526\n",
      "[1147]\ttraining's binary_logloss: 0.000323469\n",
      "[1148]\ttraining's binary_logloss: 0.000320563\n",
      "[1149]\ttraining's binary_logloss: 0.00031819\n",
      "[1150]\ttraining's binary_logloss: 0.000315619\n",
      "[1151]\ttraining's binary_logloss: 0.00031307\n",
      "[1152]\ttraining's binary_logloss: 0.000310906\n",
      "[1153]\ttraining's binary_logloss: 0.000308775\n",
      "[1154]\ttraining's binary_logloss: 0.000306315\n",
      "[1155]\ttraining's binary_logloss: 0.000305067\n",
      "[1156]\ttraining's binary_logloss: 0.000303764\n",
      "[1157]\ttraining's binary_logloss: 0.000301514\n",
      "[1158]\ttraining's binary_logloss: 0.000299248\n",
      "[1159]\ttraining's binary_logloss: 0.000297196\n",
      "[1160]\ttraining's binary_logloss: 0.000295029\n",
      "[1161]\ttraining's binary_logloss: 0.000294094\n",
      "[1162]\ttraining's binary_logloss: 0.000292591\n",
      "[1163]\ttraining's binary_logloss: 0.000291629\n",
      "[1164]\ttraining's binary_logloss: 0.000289663\n",
      "[1165]\ttraining's binary_logloss: 0.000287521\n",
      "[1166]\ttraining's binary_logloss: 0.000285765\n",
      "[1167]\ttraining's binary_logloss: 0.000284791\n",
      "[1168]\ttraining's binary_logloss: 0.000283029\n",
      "[1169]\ttraining's binary_logloss: 0.000281765\n",
      "[1170]\ttraining's binary_logloss: 0.000280968\n",
      "[1171]\ttraining's binary_logloss: 0.000280066\n",
      "[1172]\ttraining's binary_logloss: 0.000279283\n",
      "[1173]\ttraining's binary_logloss: 0.000277822\n",
      "[1174]\ttraining's binary_logloss: 0.000276181\n",
      "[1175]\ttraining's binary_logloss: 0.000274259\n",
      "[1176]\ttraining's binary_logloss: 0.000271939\n",
      "[1177]\ttraining's binary_logloss: 0.000269974\n",
      "[1178]\ttraining's binary_logloss: 0.000268273\n",
      "[1179]\ttraining's binary_logloss: 0.000266555\n",
      "[1180]\ttraining's binary_logloss: 0.000265\n",
      "[1181]\ttraining's binary_logloss: 0.000263966\n",
      "[1182]\ttraining's binary_logloss: 0.000262948\n",
      "[1183]\ttraining's binary_logloss: 0.00026125\n",
      "[1184]\ttraining's binary_logloss: 0.000259638\n",
      "[1185]\ttraining's binary_logloss: 0.000257949\n",
      "[1186]\ttraining's binary_logloss: 0.000256503\n",
      "[1187]\ttraining's binary_logloss: 0.000254707\n",
      "[1188]\ttraining's binary_logloss: 0.000252684\n",
      "[1189]\ttraining's binary_logloss: 0.000251996\n",
      "[1190]\ttraining's binary_logloss: 0.000250974\n",
      "[1191]\ttraining's binary_logloss: 0.000248837\n",
      "[1192]\ttraining's binary_logloss: 0.00024682\n",
      "[1193]\ttraining's binary_logloss: 0.000245997\n",
      "[1194]\ttraining's binary_logloss: 0.000245338\n",
      "[1195]\ttraining's binary_logloss: 0.000243362\n",
      "[1196]\ttraining's binary_logloss: 0.000241701\n",
      "[1197]\ttraining's binary_logloss: 0.000239945\n",
      "[1198]\ttraining's binary_logloss: 0.000238111\n",
      "[1199]\ttraining's binary_logloss: 0.000236627\n",
      "[1200]\ttraining's binary_logloss: 0.000235779\n",
      "[1201]\ttraining's binary_logloss: 0.000234313\n",
      "[1202]\ttraining's binary_logloss: 0.000232923\n",
      "[1203]\ttraining's binary_logloss: 0.000232028\n",
      "[1204]\ttraining's binary_logloss: 0.000230638\n",
      "[1205]\ttraining's binary_logloss: 0.000228575\n",
      "[1206]\ttraining's binary_logloss: 0.000226721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1207]\ttraining's binary_logloss: 0.000226022\n",
      "[1208]\ttraining's binary_logloss: 0.000224856\n",
      "[1209]\ttraining's binary_logloss: 0.000223187\n",
      "[1210]\ttraining's binary_logloss: 0.000221392\n",
      "[1211]\ttraining's binary_logloss: 0.000220283\n",
      "[1212]\ttraining's binary_logloss: 0.000219598\n",
      "[1213]\ttraining's binary_logloss: 0.000218094\n",
      "[1214]\ttraining's binary_logloss: 0.000216936\n",
      "[1215]\ttraining's binary_logloss: 0.000214951\n",
      "[1216]\ttraining's binary_logloss: 0.000213478\n",
      "[1217]\ttraining's binary_logloss: 0.000211924\n",
      "[1218]\ttraining's binary_logloss: 0.00021031\n",
      "[1219]\ttraining's binary_logloss: 0.000209056\n",
      "[1220]\ttraining's binary_logloss: 0.000208011\n",
      "[1221]\ttraining's binary_logloss: 0.000207135\n",
      "[1222]\ttraining's binary_logloss: 0.00020636\n",
      "[1223]\ttraining's binary_logloss: 0.000205743\n",
      "[1224]\ttraining's binary_logloss: 0.000204816\n",
      "[1225]\ttraining's binary_logloss: 0.000203463\n",
      "[1226]\ttraining's binary_logloss: 0.000202777\n",
      "[1227]\ttraining's binary_logloss: 0.000201697\n",
      "[1228]\ttraining's binary_logloss: 0.000200791\n",
      "[1229]\ttraining's binary_logloss: 0.000200001\n",
      "[1230]\ttraining's binary_logloss: 0.000198654\n",
      "[1231]\ttraining's binary_logloss: 0.000196927\n",
      "[1232]\ttraining's binary_logloss: 0.000195336\n",
      "[1233]\ttraining's binary_logloss: 0.000193915\n",
      "[1234]\ttraining's binary_logloss: 0.000192529\n",
      "[1235]\ttraining's binary_logloss: 0.000191223\n",
      "[1236]\ttraining's binary_logloss: 0.000189942\n",
      "[1237]\ttraining's binary_logloss: 0.000188611\n",
      "[1238]\ttraining's binary_logloss: 0.000187285\n",
      "[1239]\ttraining's binary_logloss: 0.000186016\n",
      "[1240]\ttraining's binary_logloss: 0.000184609\n",
      "[1241]\ttraining's binary_logloss: 0.000183533\n",
      "[1242]\ttraining's binary_logloss: 0.000182551\n",
      "[1243]\ttraining's binary_logloss: 0.000181111\n",
      "[1244]\ttraining's binary_logloss: 0.000179633\n",
      "[1245]\ttraining's binary_logloss: 0.000178324\n",
      "[1246]\ttraining's binary_logloss: 0.000176872\n",
      "[1247]\ttraining's binary_logloss: 0.00017557\n",
      "[1248]\ttraining's binary_logloss: 0.000174327\n",
      "[1249]\ttraining's binary_logloss: 0.000173035\n",
      "[1250]\ttraining's binary_logloss: 0.000171817\n",
      "[1251]\ttraining's binary_logloss: 0.000170882\n",
      "[1252]\ttraining's binary_logloss: 0.000169899\n",
      "[1253]\ttraining's binary_logloss: 0.00016871\n",
      "[1254]\ttraining's binary_logloss: 0.000167347\n",
      "[1255]\ttraining's binary_logloss: 0.000166034\n",
      "[1256]\ttraining's binary_logloss: 0.000164765\n",
      "[1257]\ttraining's binary_logloss: 0.000163564\n",
      "[1258]\ttraining's binary_logloss: 0.000162262\n",
      "[1259]\ttraining's binary_logloss: 0.00016155\n",
      "[1260]\ttraining's binary_logloss: 0.000160755\n",
      "[1261]\ttraining's binary_logloss: 0.000160118\n",
      "[1262]\ttraining's binary_logloss: 0.000159306\n",
      "[1263]\ttraining's binary_logloss: 0.000158268\n",
      "[1264]\ttraining's binary_logloss: 0.000157175\n",
      "[1265]\ttraining's binary_logloss: 0.000156171\n",
      "[1266]\ttraining's binary_logloss: 0.000155244\n",
      "[1267]\ttraining's binary_logloss: 0.000154054\n",
      "[1268]\ttraining's binary_logloss: 0.000152967\n",
      "[1269]\ttraining's binary_logloss: 0.000152147\n",
      "[1270]\ttraining's binary_logloss: 0.000151536\n",
      "[1271]\ttraining's binary_logloss: 0.00015062\n",
      "[1272]\ttraining's binary_logloss: 0.000149359\n",
      "[1273]\ttraining's binary_logloss: 0.000148334\n",
      "[1274]\ttraining's binary_logloss: 0.000147295\n",
      "[1275]\ttraining's binary_logloss: 0.00014621\n",
      "[1276]\ttraining's binary_logloss: 0.000145162\n",
      "[1277]\ttraining's binary_logloss: 0.000144302\n",
      "[1278]\ttraining's binary_logloss: 0.000143402\n",
      "[1279]\ttraining's binary_logloss: 0.000142383\n",
      "[1280]\ttraining's binary_logloss: 0.000141432\n",
      "[1281]\ttraining's binary_logloss: 0.000140576\n",
      "[1282]\ttraining's binary_logloss: 0.000139596\n",
      "[1283]\ttraining's binary_logloss: 0.000138767\n",
      "[1284]\ttraining's binary_logloss: 0.000137882\n",
      "[1285]\ttraining's binary_logloss: 0.000137246\n",
      "[1286]\ttraining's binary_logloss: 0.000136723\n",
      "[1287]\ttraining's binary_logloss: 0.000136128\n",
      "[1288]\ttraining's binary_logloss: 0.000135504\n",
      "[1289]\ttraining's binary_logloss: 0.000134607\n",
      "[1290]\ttraining's binary_logloss: 0.000133793\n",
      "[1291]\ttraining's binary_logloss: 0.000133198\n",
      "[1292]\ttraining's binary_logloss: 0.000132243\n",
      "[1293]\ttraining's binary_logloss: 0.000131391\n",
      "[1294]\ttraining's binary_logloss: 0.000130462\n",
      "[1295]\ttraining's binary_logloss: 0.000129585\n",
      "[1296]\ttraining's binary_logloss: 0.000128769\n",
      "[1297]\ttraining's binary_logloss: 0.000127899\n",
      "[1298]\ttraining's binary_logloss: 0.000126954\n",
      "[1299]\ttraining's binary_logloss: 0.000126177\n",
      "[1300]\ttraining's binary_logloss: 0.000125382\n",
      "[1301]\ttraining's binary_logloss: 0.000124563\n",
      "[1302]\ttraining's binary_logloss: 0.00012367\n",
      "[1303]\ttraining's binary_logloss: 0.000122898\n",
      "[1304]\ttraining's binary_logloss: 0.000122289\n",
      "[1305]\ttraining's binary_logloss: 0.000121427\n",
      "[1306]\ttraining's binary_logloss: 0.000120608\n",
      "[1307]\ttraining's binary_logloss: 0.000120054\n",
      "[1308]\ttraining's binary_logloss: 0.000119539\n",
      "[1309]\ttraining's binary_logloss: 0.000118822\n",
      "[1310]\ttraining's binary_logloss: 0.00011813\n",
      "[1311]\ttraining's binary_logloss: 0.000117611\n",
      "[1312]\ttraining's binary_logloss: 0.000117004\n",
      "[1313]\ttraining's binary_logloss: 0.000116557\n",
      "[1314]\ttraining's binary_logloss: 0.000116078\n",
      "[1315]\ttraining's binary_logloss: 0.000115356\n",
      "[1316]\ttraining's binary_logloss: 0.000114677\n",
      "[1317]\ttraining's binary_logloss: 0.000113929\n",
      "[1318]\ttraining's binary_logloss: 0.000113287\n",
      "[1319]\ttraining's binary_logloss: 0.0001126\n",
      "[1320]\ttraining's binary_logloss: 0.000111954\n",
      "[1321]\ttraining's binary_logloss: 0.000111256\n",
      "[1322]\ttraining's binary_logloss: 0.000110536\n",
      "[1323]\ttraining's binary_logloss: 0.000109788\n",
      "[1324]\ttraining's binary_logloss: 0.000109104\n",
      "[1325]\ttraining's binary_logloss: 0.000108508\n",
      "[1326]\ttraining's binary_logloss: 0.000107758\n",
      "[1327]\ttraining's binary_logloss: 0.000107194\n",
      "[1328]\ttraining's binary_logloss: 0.000106593\n",
      "[1329]\ttraining's binary_logloss: 0.000105967\n",
      "[1330]\ttraining's binary_logloss: 0.000105383\n",
      "[1331]\ttraining's binary_logloss: 0.00010472\n",
      "[1332]\ttraining's binary_logloss: 0.000104013\n",
      "[1333]\ttraining's binary_logloss: 0.000103428\n",
      "[1334]\ttraining's binary_logloss: 0.000102854\n",
      "[1335]\ttraining's binary_logloss: 0.000102241\n",
      "[1336]\ttraining's binary_logloss: 0.000101603\n",
      "[1337]\ttraining's binary_logloss: 0.000101044\n",
      "[1338]\ttraining's binary_logloss: 0.00010047\n",
      "[1339]\ttraining's binary_logloss: 9.99145e-05\n",
      "[1340]\ttraining's binary_logloss: 9.93875e-05\n",
      "[1341]\ttraining's binary_logloss: 9.88293e-05\n",
      "[1342]\ttraining's binary_logloss: 9.83084e-05\n",
      "[1343]\ttraining's binary_logloss: 9.77974e-05\n",
      "[1344]\ttraining's binary_logloss: 9.71568e-05\n",
      "[1345]\ttraining's binary_logloss: 9.65591e-05\n",
      "[1346]\ttraining's binary_logloss: 9.59038e-05\n",
      "[1347]\ttraining's binary_logloss: 9.53204e-05\n",
      "[1348]\ttraining's binary_logloss: 9.47553e-05\n",
      "[1349]\ttraining's binary_logloss: 9.42204e-05\n",
      "[1350]\ttraining's binary_logloss: 9.3664e-05\n",
      "[1351]\ttraining's binary_logloss: 9.3162e-05\n",
      "[1352]\ttraining's binary_logloss: 9.2633e-05\n",
      "[1353]\ttraining's binary_logloss: 9.21587e-05\n",
      "[1354]\ttraining's binary_logloss: 9.16596e-05\n",
      "[1355]\ttraining's binary_logloss: 9.11439e-05\n",
      "[1356]\ttraining's binary_logloss: 9.06688e-05\n",
      "[1357]\ttraining's binary_logloss: 9.02081e-05\n",
      "[1358]\ttraining's binary_logloss: 8.97343e-05\n",
      "[1359]\ttraining's binary_logloss: 8.92102e-05\n",
      "[1360]\ttraining's binary_logloss: 8.86366e-05\n",
      "[1361]\ttraining's binary_logloss: 8.81848e-05\n",
      "[1362]\ttraining's binary_logloss: 8.76919e-05\n",
      "[1363]\ttraining's binary_logloss: 8.71918e-05\n",
      "[1364]\ttraining's binary_logloss: 8.67071e-05\n",
      "[1365]\ttraining's binary_logloss: 8.62622e-05\n",
      "[1366]\ttraining's binary_logloss: 8.57444e-05\n",
      "[1367]\ttraining's binary_logloss: 8.52515e-05\n",
      "[1368]\ttraining's binary_logloss: 8.47866e-05\n",
      "[1369]\ttraining's binary_logloss: 8.42567e-05\n",
      "[1370]\ttraining's binary_logloss: 8.37778e-05\n",
      "[1371]\ttraining's binary_logloss: 8.33529e-05\n",
      "[1372]\ttraining's binary_logloss: 8.27982e-05\n",
      "[1373]\ttraining's binary_logloss: 8.23405e-05\n",
      "[1374]\ttraining's binary_logloss: 8.19055e-05\n",
      "[1375]\ttraining's binary_logloss: 8.14791e-05\n",
      "[1376]\ttraining's binary_logloss: 8.10332e-05\n",
      "[1377]\ttraining's binary_logloss: 8.05608e-05\n",
      "[1378]\ttraining's binary_logloss: 8.0071e-05\n",
      "[1379]\ttraining's binary_logloss: 7.96379e-05\n",
      "[1380]\ttraining's binary_logloss: 7.92237e-05\n",
      "[1381]\ttraining's binary_logloss: 7.87763e-05\n",
      "[1382]\ttraining's binary_logloss: 7.83383e-05\n",
      "[1383]\ttraining's binary_logloss: 7.79539e-05\n",
      "[1384]\ttraining's binary_logloss: 7.74489e-05\n",
      "[1385]\ttraining's binary_logloss: 7.70374e-05\n",
      "[1386]\ttraining's binary_logloss: 7.65817e-05\n",
      "[1387]\ttraining's binary_logloss: 7.61365e-05\n",
      "[1388]\ttraining's binary_logloss: 7.56995e-05\n",
      "[1389]\ttraining's binary_logloss: 7.53181e-05\n",
      "[1390]\ttraining's binary_logloss: 7.48752e-05\n",
      "[1391]\ttraining's binary_logloss: 7.44297e-05\n",
      "[1392]\ttraining's binary_logloss: 7.40334e-05\n",
      "[1393]\ttraining's binary_logloss: 7.36333e-05\n",
      "[1394]\ttraining's binary_logloss: 7.32469e-05\n",
      "[1395]\ttraining's binary_logloss: 7.28196e-05\n",
      "[1396]\ttraining's binary_logloss: 7.23966e-05\n",
      "[1397]\ttraining's binary_logloss: 7.20332e-05\n",
      "[1398]\ttraining's binary_logloss: 7.16037e-05\n",
      "[1399]\ttraining's binary_logloss: 7.11814e-05\n",
      "[1400]\ttraining's binary_logloss: 7.08333e-05\n",
      "[1401]\ttraining's binary_logloss: 7.04066e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1402]\ttraining's binary_logloss: 6.99636e-05\n",
      "[1403]\ttraining's binary_logloss: 6.95481e-05\n",
      "[1404]\ttraining's binary_logloss: 6.91949e-05\n",
      "[1405]\ttraining's binary_logloss: 6.88043e-05\n",
      "[1406]\ttraining's binary_logloss: 6.8381e-05\n",
      "[1407]\ttraining's binary_logloss: 6.80552e-05\n",
      "[1408]\ttraining's binary_logloss: 6.76914e-05\n",
      "[1409]\ttraining's binary_logloss: 6.7334e-05\n",
      "[1410]\ttraining's binary_logloss: 6.69918e-05\n",
      "[1411]\ttraining's binary_logloss: 6.66696e-05\n",
      "[1412]\ttraining's binary_logloss: 6.629e-05\n",
      "[1413]\ttraining's binary_logloss: 6.59239e-05\n",
      "[1414]\ttraining's binary_logloss: 6.55501e-05\n",
      "[1415]\ttraining's binary_logloss: 6.51702e-05\n",
      "[1416]\ttraining's binary_logloss: 6.48149e-05\n",
      "[1417]\ttraining's binary_logloss: 6.44228e-05\n",
      "[1418]\ttraining's binary_logloss: 6.40813e-05\n",
      "[1419]\ttraining's binary_logloss: 6.37522e-05\n",
      "[1420]\ttraining's binary_logloss: 6.34546e-05\n",
      "[1421]\ttraining's binary_logloss: 6.31226e-05\n",
      "[1422]\ttraining's binary_logloss: 6.28474e-05\n",
      "[1423]\ttraining's binary_logloss: 6.24691e-05\n",
      "[1424]\ttraining's binary_logloss: 6.21473e-05\n",
      "[1425]\ttraining's binary_logloss: 6.17464e-05\n",
      "[1426]\ttraining's binary_logloss: 6.13633e-05\n",
      "[1427]\ttraining's binary_logloss: 6.09814e-05\n",
      "[1428]\ttraining's binary_logloss: 6.07092e-05\n",
      "[1429]\ttraining's binary_logloss: 6.04166e-05\n",
      "[1430]\ttraining's binary_logloss: 6.01354e-05\n",
      "[1431]\ttraining's binary_logloss: 5.98393e-05\n",
      "[1432]\ttraining's binary_logloss: 5.9536e-05\n",
      "[1433]\ttraining's binary_logloss: 5.92245e-05\n",
      "[1434]\ttraining's binary_logloss: 5.89293e-05\n",
      "[1435]\ttraining's binary_logloss: 5.86183e-05\n",
      "[1436]\ttraining's binary_logloss: 5.82814e-05\n",
      "[1437]\ttraining's binary_logloss: 5.79842e-05\n",
      "[1438]\ttraining's binary_logloss: 5.76587e-05\n",
      "[1439]\ttraining's binary_logloss: 5.73654e-05\n",
      "[1440]\ttraining's binary_logloss: 5.71125e-05\n",
      "[1441]\ttraining's binary_logloss: 5.68128e-05\n",
      "[1442]\ttraining's binary_logloss: 5.65696e-05\n",
      "[1443]\ttraining's binary_logloss: 5.62671e-05\n",
      "[1444]\ttraining's binary_logloss: 5.60011e-05\n",
      "[1445]\ttraining's binary_logloss: 5.57232e-05\n",
      "[1446]\ttraining's binary_logloss: 5.54369e-05\n",
      "[1447]\ttraining's binary_logloss: 5.51322e-05\n",
      "[1448]\ttraining's binary_logloss: 5.48218e-05\n",
      "[1449]\ttraining's binary_logloss: 5.45625e-05\n",
      "[1450]\ttraining's binary_logloss: 5.42932e-05\n",
      "[1451]\ttraining's binary_logloss: 5.39589e-05\n",
      "[1452]\ttraining's binary_logloss: 5.36886e-05\n",
      "[1453]\ttraining's binary_logloss: 5.34193e-05\n",
      "[1454]\ttraining's binary_logloss: 5.31631e-05\n",
      "[1455]\ttraining's binary_logloss: 5.2905e-05\n",
      "[1456]\ttraining's binary_logloss: 5.26062e-05\n",
      "[1457]\ttraining's binary_logloss: 5.22907e-05\n",
      "[1458]\ttraining's binary_logloss: 5.20029e-05\n",
      "[1459]\ttraining's binary_logloss: 5.17252e-05\n",
      "[1460]\ttraining's binary_logloss: 5.14618e-05\n",
      "[1461]\ttraining's binary_logloss: 5.1231e-05\n",
      "[1462]\ttraining's binary_logloss: 5.09568e-05\n",
      "[1463]\ttraining's binary_logloss: 5.06942e-05\n",
      "[1464]\ttraining's binary_logloss: 5.04507e-05\n",
      "[1465]\ttraining's binary_logloss: 5.02237e-05\n",
      "[1466]\ttraining's binary_logloss: 4.99726e-05\n",
      "[1467]\ttraining's binary_logloss: 4.97172e-05\n",
      "[1468]\ttraining's binary_logloss: 4.94322e-05\n",
      "[1469]\ttraining's binary_logloss: 4.92017e-05\n",
      "[1470]\ttraining's binary_logloss: 4.89546e-05\n",
      "[1471]\ttraining's binary_logloss: 4.87102e-05\n",
      "[1472]\ttraining's binary_logloss: 4.85057e-05\n",
      "[1473]\ttraining's binary_logloss: 4.82558e-05\n",
      "[1474]\ttraining's binary_logloss: 4.80303e-05\n",
      "[1475]\ttraining's binary_logloss: 4.78035e-05\n",
      "[1476]\ttraining's binary_logloss: 4.75528e-05\n",
      "[1477]\ttraining's binary_logloss: 4.72814e-05\n",
      "[1478]\ttraining's binary_logloss: 4.70007e-05\n",
      "[1479]\ttraining's binary_logloss: 4.67942e-05\n",
      "[1480]\ttraining's binary_logloss: 4.65571e-05\n",
      "[1481]\ttraining's binary_logloss: 4.63469e-05\n",
      "[1482]\ttraining's binary_logloss: 4.60945e-05\n",
      "[1483]\ttraining's binary_logloss: 4.58839e-05\n",
      "[1484]\ttraining's binary_logloss: 4.56566e-05\n",
      "[1485]\ttraining's binary_logloss: 4.54447e-05\n",
      "[1486]\ttraining's binary_logloss: 4.52163e-05\n",
      "[1487]\ttraining's binary_logloss: 4.50111e-05\n",
      "[1488]\ttraining's binary_logloss: 4.4799e-05\n",
      "[1489]\ttraining's binary_logloss: 4.45948e-05\n",
      "[1490]\ttraining's binary_logloss: 4.43662e-05\n",
      "[1491]\ttraining's binary_logloss: 4.41566e-05\n",
      "[1492]\ttraining's binary_logloss: 4.39549e-05\n",
      "[1493]\ttraining's binary_logloss: 4.37619e-05\n",
      "[1494]\ttraining's binary_logloss: 4.35435e-05\n",
      "[1495]\ttraining's binary_logloss: 4.33518e-05\n",
      "[1496]\ttraining's binary_logloss: 4.31532e-05\n",
      "[1497]\ttraining's binary_logloss: 4.29522e-05\n",
      "[1498]\ttraining's binary_logloss: 4.27403e-05\n",
      "[1499]\ttraining's binary_logloss: 4.25373e-05\n",
      "[1500]\ttraining's binary_logloss: 4.23579e-05\n",
      "[1501]\ttraining's binary_logloss: 4.21765e-05\n",
      "[1502]\ttraining's binary_logloss: 4.19881e-05\n",
      "[1503]\ttraining's binary_logloss: 4.17988e-05\n",
      "[1504]\ttraining's binary_logloss: 4.16216e-05\n",
      "[1505]\ttraining's binary_logloss: 4.1408e-05\n",
      "[1506]\ttraining's binary_logloss: 4.12089e-05\n",
      "[1507]\ttraining's binary_logloss: 4.10426e-05\n",
      "[1508]\ttraining's binary_logloss: 4.08219e-05\n",
      "[1509]\ttraining's binary_logloss: 4.06343e-05\n",
      "[1510]\ttraining's binary_logloss: 4.04452e-05\n",
      "[1511]\ttraining's binary_logloss: 4.02543e-05\n",
      "[1512]\ttraining's binary_logloss: 4.0097e-05\n",
      "[1513]\ttraining's binary_logloss: 3.99012e-05\n",
      "[1514]\ttraining's binary_logloss: 3.96886e-05\n",
      "[1515]\ttraining's binary_logloss: 3.94964e-05\n",
      "[1516]\ttraining's binary_logloss: 3.93003e-05\n",
      "[1517]\ttraining's binary_logloss: 3.91054e-05\n",
      "[1518]\ttraining's binary_logloss: 3.89409e-05\n",
      "[1519]\ttraining's binary_logloss: 3.87234e-05\n",
      "[1520]\ttraining's binary_logloss: 3.8558e-05\n",
      "[1521]\ttraining's binary_logloss: 3.83948e-05\n",
      "[1522]\ttraining's binary_logloss: 3.82155e-05\n",
      "[1523]\ttraining's binary_logloss: 3.80288e-05\n",
      "[1524]\ttraining's binary_logloss: 3.78426e-05\n",
      "[1525]\ttraining's binary_logloss: 3.76552e-05\n",
      "[1526]\ttraining's binary_logloss: 3.74662e-05\n",
      "[1527]\ttraining's binary_logloss: 3.72773e-05\n",
      "[1528]\ttraining's binary_logloss: 3.71037e-05\n",
      "[1529]\ttraining's binary_logloss: 3.69276e-05\n",
      "[1530]\ttraining's binary_logloss: 3.67505e-05\n",
      "[1531]\ttraining's binary_logloss: 3.6569e-05\n",
      "[1532]\ttraining's binary_logloss: 3.64103e-05\n",
      "[1533]\ttraining's binary_logloss: 3.62311e-05\n",
      "[1534]\ttraining's binary_logloss: 3.60579e-05\n",
      "[1535]\ttraining's binary_logloss: 3.58982e-05\n",
      "[1536]\ttraining's binary_logloss: 3.57367e-05\n",
      "[1537]\ttraining's binary_logloss: 3.55725e-05\n",
      "[1538]\ttraining's binary_logloss: 3.54014e-05\n",
      "[1539]\ttraining's binary_logloss: 3.52423e-05\n",
      "[1540]\ttraining's binary_logloss: 3.50881e-05\n",
      "[1541]\ttraining's binary_logloss: 3.49189e-05\n",
      "[1542]\ttraining's binary_logloss: 3.47221e-05\n",
      "[1543]\ttraining's binary_logloss: 3.4579e-05\n",
      "[1544]\ttraining's binary_logloss: 3.44216e-05\n",
      "[1545]\ttraining's binary_logloss: 3.42398e-05\n",
      "[1546]\ttraining's binary_logloss: 3.40846e-05\n",
      "[1547]\ttraining's binary_logloss: 3.39189e-05\n",
      "[1548]\ttraining's binary_logloss: 3.3764e-05\n",
      "[1549]\ttraining's binary_logloss: 3.36279e-05\n",
      "[1550]\ttraining's binary_logloss: 3.34789e-05\n",
      "[1551]\ttraining's binary_logloss: 3.33281e-05\n",
      "[1552]\ttraining's binary_logloss: 3.31731e-05\n",
      "[1553]\ttraining's binary_logloss: 3.30345e-05\n",
      "[1554]\ttraining's binary_logloss: 3.29047e-05\n",
      "[1555]\ttraining's binary_logloss: 3.27438e-05\n",
      "[1556]\ttraining's binary_logloss: 3.26066e-05\n",
      "[1557]\ttraining's binary_logloss: 3.24292e-05\n",
      "[1558]\ttraining's binary_logloss: 3.22649e-05\n",
      "[1559]\ttraining's binary_logloss: 3.21199e-05\n",
      "[1560]\ttraining's binary_logloss: 3.1982e-05\n",
      "[1561]\ttraining's binary_logloss: 3.1838e-05\n",
      "[1562]\ttraining's binary_logloss: 3.17001e-05\n",
      "[1563]\ttraining's binary_logloss: 3.15528e-05\n",
      "[1564]\ttraining's binary_logloss: 3.14059e-05\n",
      "[1565]\ttraining's binary_logloss: 3.12657e-05\n",
      "[1566]\ttraining's binary_logloss: 3.11327e-05\n",
      "[1567]\ttraining's binary_logloss: 3.09947e-05\n",
      "[1568]\ttraining's binary_logloss: 3.08364e-05\n",
      "[1569]\ttraining's binary_logloss: 3.06975e-05\n",
      "[1570]\ttraining's binary_logloss: 3.05726e-05\n",
      "[1571]\ttraining's binary_logloss: 3.04542e-05\n",
      "[1572]\ttraining's binary_logloss: 3.03287e-05\n",
      "[1573]\ttraining's binary_logloss: 3.01901e-05\n",
      "[1574]\ttraining's binary_logloss: 3.00605e-05\n",
      "[1575]\ttraining's binary_logloss: 2.99328e-05\n",
      "[1576]\ttraining's binary_logloss: 2.97925e-05\n",
      "[1577]\ttraining's binary_logloss: 2.96445e-05\n",
      "[1578]\ttraining's binary_logloss: 2.95311e-05\n",
      "[1579]\ttraining's binary_logloss: 2.93994e-05\n",
      "[1580]\ttraining's binary_logloss: 2.92869e-05\n",
      "[1581]\ttraining's binary_logloss: 2.91539e-05\n",
      "[1582]\ttraining's binary_logloss: 2.90398e-05\n",
      "[1583]\ttraining's binary_logloss: 2.89232e-05\n",
      "[1584]\ttraining's binary_logloss: 2.88034e-05\n",
      "[1585]\ttraining's binary_logloss: 2.86647e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1586]\ttraining's binary_logloss: 2.85442e-05\n",
      "[1587]\ttraining's binary_logloss: 2.84278e-05\n",
      "[1588]\ttraining's binary_logloss: 2.83204e-05\n",
      "[1589]\ttraining's binary_logloss: 2.82165e-05\n",
      "[1590]\ttraining's binary_logloss: 2.80916e-05\n",
      "[1591]\ttraining's binary_logloss: 2.79647e-05\n",
      "[1592]\ttraining's binary_logloss: 2.78469e-05\n",
      "[1593]\ttraining's binary_logloss: 2.77338e-05\n",
      "[1594]\ttraining's binary_logloss: 2.76058e-05\n",
      "[1595]\ttraining's binary_logloss: 2.74874e-05\n",
      "[1596]\ttraining's binary_logloss: 2.73679e-05\n",
      "[1597]\ttraining's binary_logloss: 2.7242e-05\n",
      "[1598]\ttraining's binary_logloss: 2.71284e-05\n",
      "[1599]\ttraining's binary_logloss: 2.70151e-05\n",
      "[1600]\ttraining's binary_logloss: 2.6904e-05\n",
      "[1601]\ttraining's binary_logloss: 2.67999e-05\n",
      "[1602]\ttraining's binary_logloss: 2.66951e-05\n",
      "[1603]\ttraining's binary_logloss: 2.65822e-05\n",
      "[1604]\ttraining's binary_logloss: 2.64844e-05\n",
      "[1605]\ttraining's binary_logloss: 2.63776e-05\n",
      "[1606]\ttraining's binary_logloss: 2.62792e-05\n",
      "[1607]\ttraining's binary_logloss: 2.61699e-05\n",
      "[1608]\ttraining's binary_logloss: 2.60569e-05\n",
      "[1609]\ttraining's binary_logloss: 2.59504e-05\n",
      "[1610]\ttraining's binary_logloss: 2.58336e-05\n",
      "[1611]\ttraining's binary_logloss: 2.57367e-05\n",
      "[1612]\ttraining's binary_logloss: 2.56377e-05\n",
      "[1613]\ttraining's binary_logloss: 2.55414e-05\n",
      "[1614]\ttraining's binary_logloss: 2.54428e-05\n",
      "[1615]\ttraining's binary_logloss: 2.53455e-05\n",
      "[1616]\ttraining's binary_logloss: 2.52445e-05\n",
      "[1617]\ttraining's binary_logloss: 2.51516e-05\n",
      "[1618]\ttraining's binary_logloss: 2.50492e-05\n",
      "[1619]\ttraining's binary_logloss: 2.49478e-05\n",
      "[1620]\ttraining's binary_logloss: 2.48384e-05\n",
      "[1621]\ttraining's binary_logloss: 2.47334e-05\n",
      "[1622]\ttraining's binary_logloss: 2.46424e-05\n",
      "[1623]\ttraining's binary_logloss: 2.45476e-05\n",
      "[1624]\ttraining's binary_logloss: 2.44413e-05\n",
      "[1625]\ttraining's binary_logloss: 2.43444e-05\n",
      "[1626]\ttraining's binary_logloss: 2.42542e-05\n",
      "[1627]\ttraining's binary_logloss: 2.41673e-05\n",
      "[1628]\ttraining's binary_logloss: 2.40721e-05\n",
      "[1629]\ttraining's binary_logloss: 2.39838e-05\n",
      "[1630]\ttraining's binary_logloss: 2.38869e-05\n",
      "[1631]\ttraining's binary_logloss: 2.38017e-05\n",
      "[1632]\ttraining's binary_logloss: 2.37192e-05\n",
      "[1633]\ttraining's binary_logloss: 2.36331e-05\n",
      "[1634]\ttraining's binary_logloss: 2.35335e-05\n",
      "[1635]\ttraining's binary_logloss: 2.34482e-05\n",
      "[1636]\ttraining's binary_logloss: 2.33533e-05\n",
      "[1637]\ttraining's binary_logloss: 2.32711e-05\n",
      "[1638]\ttraining's binary_logloss: 2.31759e-05\n",
      "[1639]\ttraining's binary_logloss: 2.30861e-05\n",
      "[1640]\ttraining's binary_logloss: 2.29916e-05\n",
      "[1641]\ttraining's binary_logloss: 2.29121e-05\n",
      "[1642]\ttraining's binary_logloss: 2.2823e-05\n",
      "[1643]\ttraining's binary_logloss: 2.27428e-05\n",
      "[1644]\ttraining's binary_logloss: 2.26556e-05\n",
      "[1645]\ttraining's binary_logloss: 2.2565e-05\n",
      "[1646]\ttraining's binary_logloss: 2.24669e-05\n",
      "[1647]\ttraining's binary_logloss: 2.23722e-05\n",
      "[1648]\ttraining's binary_logloss: 2.22915e-05\n",
      "[1649]\ttraining's binary_logloss: 2.22127e-05\n",
      "[1650]\ttraining's binary_logloss: 2.21204e-05\n",
      "[1651]\ttraining's binary_logloss: 2.2036e-05\n",
      "[1652]\ttraining's binary_logloss: 2.19527e-05\n",
      "[1653]\ttraining's binary_logloss: 2.18794e-05\n",
      "[1654]\ttraining's binary_logloss: 2.17979e-05\n",
      "[1655]\ttraining's binary_logloss: 2.17153e-05\n",
      "[1656]\ttraining's binary_logloss: 2.16331e-05\n",
      "[1657]\ttraining's binary_logloss: 2.15499e-05\n",
      "[1658]\ttraining's binary_logloss: 2.14724e-05\n",
      "[1659]\ttraining's binary_logloss: 2.13989e-05\n",
      "[1660]\ttraining's binary_logloss: 2.1326e-05\n",
      "[1661]\ttraining's binary_logloss: 2.12378e-05\n",
      "[1662]\ttraining's binary_logloss: 2.11605e-05\n",
      "[1663]\ttraining's binary_logloss: 2.10803e-05\n",
      "[1664]\ttraining's binary_logloss: 2.10066e-05\n",
      "[1665]\ttraining's binary_logloss: 2.09326e-05\n",
      "[1666]\ttraining's binary_logloss: 2.08511e-05\n",
      "[1667]\ttraining's binary_logloss: 2.07813e-05\n",
      "[1668]\ttraining's binary_logloss: 2.07012e-05\n",
      "[1669]\ttraining's binary_logloss: 2.06335e-05\n",
      "[1670]\ttraining's binary_logloss: 2.05599e-05\n",
      "[1671]\ttraining's binary_logloss: 2.04809e-05\n",
      "[1672]\ttraining's binary_logloss: 2.04072e-05\n",
      "[1673]\ttraining's binary_logloss: 2.03298e-05\n",
      "[1674]\ttraining's binary_logloss: 2.0254e-05\n",
      "[1675]\ttraining's binary_logloss: 2.01854e-05\n",
      "[1676]\ttraining's binary_logloss: 2.01176e-05\n",
      "[1677]\ttraining's binary_logloss: 2.00482e-05\n",
      "[1678]\ttraining's binary_logloss: 1.99751e-05\n",
      "[1679]\ttraining's binary_logloss: 1.99081e-05\n",
      "[1680]\ttraining's binary_logloss: 1.98435e-05\n",
      "[1681]\ttraining's binary_logloss: 1.9777e-05\n",
      "[1682]\ttraining's binary_logloss: 1.97068e-05\n",
      "[1683]\ttraining's binary_logloss: 1.96432e-05\n",
      "[1684]\ttraining's binary_logloss: 1.95765e-05\n",
      "[1685]\ttraining's binary_logloss: 1.95098e-05\n",
      "[1686]\ttraining's binary_logloss: 1.94491e-05\n",
      "[1687]\ttraining's binary_logloss: 1.93818e-05\n",
      "[1688]\ttraining's binary_logloss: 1.93223e-05\n",
      "[1689]\ttraining's binary_logloss: 1.92574e-05\n",
      "[1690]\ttraining's binary_logloss: 1.91979e-05\n",
      "[1691]\ttraining's binary_logloss: 1.91302e-05\n",
      "[1692]\ttraining's binary_logloss: 1.90662e-05\n",
      "[1693]\ttraining's binary_logloss: 1.90043e-05\n",
      "[1694]\ttraining's binary_logloss: 1.89452e-05\n",
      "[1695]\ttraining's binary_logloss: 1.88842e-05\n",
      "[1696]\ttraining's binary_logloss: 1.8828e-05\n",
      "[1697]\ttraining's binary_logloss: 1.8763e-05\n",
      "[1698]\ttraining's binary_logloss: 1.86956e-05\n",
      "[1699]\ttraining's binary_logloss: 1.86314e-05\n",
      "[1700]\ttraining's binary_logloss: 1.85694e-05\n",
      "[1701]\ttraining's binary_logloss: 1.85074e-05\n",
      "[1702]\ttraining's binary_logloss: 1.84468e-05\n",
      "[1703]\ttraining's binary_logloss: 1.83901e-05\n",
      "[1704]\ttraining's binary_logloss: 1.83254e-05\n",
      "[1705]\ttraining's binary_logloss: 1.82658e-05\n",
      "[1706]\ttraining's binary_logloss: 1.82099e-05\n",
      "[1707]\ttraining's binary_logloss: 1.81453e-05\n",
      "[1708]\ttraining's binary_logloss: 1.80804e-05\n",
      "[1709]\ttraining's binary_logloss: 1.80257e-05\n",
      "[1710]\ttraining's binary_logloss: 1.79766e-05\n",
      "[1711]\ttraining's binary_logloss: 1.79118e-05\n",
      "[1712]\ttraining's binary_logloss: 1.78483e-05\n",
      "[1713]\ttraining's binary_logloss: 1.77811e-05\n",
      "[1714]\ttraining's binary_logloss: 1.7727e-05\n",
      "[1715]\ttraining's binary_logloss: 1.76685e-05\n",
      "[1716]\ttraining's binary_logloss: 1.76175e-05\n",
      "[1717]\ttraining's binary_logloss: 1.75615e-05\n",
      "[1718]\ttraining's binary_logloss: 1.75011e-05\n",
      "[1719]\ttraining's binary_logloss: 1.74513e-05\n",
      "[1720]\ttraining's binary_logloss: 1.7397e-05\n",
      "[1721]\ttraining's binary_logloss: 1.73408e-05\n",
      "[1722]\ttraining's binary_logloss: 1.72889e-05\n",
      "[1723]\ttraining's binary_logloss: 1.7233e-05\n",
      "[1724]\ttraining's binary_logloss: 1.71845e-05\n",
      "[1725]\ttraining's binary_logloss: 1.71305e-05\n",
      "[1726]\ttraining's binary_logloss: 1.70847e-05\n",
      "[1727]\ttraining's binary_logloss: 1.70358e-05\n",
      "[1728]\ttraining's binary_logloss: 1.69832e-05\n",
      "[1729]\ttraining's binary_logloss: 1.69271e-05\n",
      "[1730]\ttraining's binary_logloss: 1.68827e-05\n",
      "[1731]\ttraining's binary_logloss: 1.68337e-05\n",
      "[1732]\ttraining's binary_logloss: 1.67835e-05\n",
      "[1733]\ttraining's binary_logloss: 1.67333e-05\n",
      "[1734]\ttraining's binary_logloss: 1.6685e-05\n",
      "[1735]\ttraining's binary_logloss: 1.66381e-05\n",
      "[1736]\ttraining's binary_logloss: 1.65883e-05\n",
      "[1737]\ttraining's binary_logloss: 1.65453e-05\n",
      "[1738]\ttraining's binary_logloss: 1.64934e-05\n",
      "[1739]\ttraining's binary_logloss: 1.64432e-05\n",
      "[1740]\ttraining's binary_logloss: 1.63944e-05\n",
      "[1741]\ttraining's binary_logloss: 1.63474e-05\n",
      "[1742]\ttraining's binary_logloss: 1.63009e-05\n",
      "[1743]\ttraining's binary_logloss: 1.62522e-05\n",
      "[1744]\ttraining's binary_logloss: 1.62084e-05\n",
      "[1745]\ttraining's binary_logloss: 1.6163e-05\n",
      "[1746]\ttraining's binary_logloss: 1.61156e-05\n",
      "[1747]\ttraining's binary_logloss: 1.607e-05\n",
      "[1748]\ttraining's binary_logloss: 1.6027e-05\n",
      "[1749]\ttraining's binary_logloss: 1.59841e-05\n",
      "[1750]\ttraining's binary_logloss: 1.59386e-05\n",
      "[1751]\ttraining's binary_logloss: 1.58897e-05\n",
      "[1752]\ttraining's binary_logloss: 1.58485e-05\n",
      "[1753]\ttraining's binary_logloss: 1.57995e-05\n",
      "[1754]\ttraining's binary_logloss: 1.5753e-05\n",
      "[1755]\ttraining's binary_logloss: 1.57077e-05\n",
      "[1756]\ttraining's binary_logloss: 1.56574e-05\n",
      "[1757]\ttraining's binary_logloss: 1.56092e-05\n",
      "[1758]\ttraining's binary_logloss: 1.55685e-05\n",
      "[1759]\ttraining's binary_logloss: 1.55245e-05\n",
      "[1760]\ttraining's binary_logloss: 1.54765e-05\n",
      "[1761]\ttraining's binary_logloss: 1.54345e-05\n",
      "[1762]\ttraining's binary_logloss: 1.53934e-05\n",
      "[1763]\ttraining's binary_logloss: 1.53541e-05\n",
      "[1764]\ttraining's binary_logloss: 1.5312e-05\n",
      "[1765]\ttraining's binary_logloss: 1.52659e-05\n",
      "[1766]\ttraining's binary_logloss: 1.52288e-05\n",
      "[1767]\ttraining's binary_logloss: 1.51931e-05\n",
      "[1768]\ttraining's binary_logloss: 1.5154e-05\n",
      "[1769]\ttraining's binary_logloss: 1.51138e-05\n",
      "[1770]\ttraining's binary_logloss: 1.50713e-05\n",
      "[1771]\ttraining's binary_logloss: 1.50295e-05\n",
      "[1772]\ttraining's binary_logloss: 1.49944e-05\n",
      "[1773]\ttraining's binary_logloss: 1.49554e-05\n",
      "[1774]\ttraining's binary_logloss: 1.49149e-05\n",
      "[1775]\ttraining's binary_logloss: 1.48734e-05\n",
      "[1776]\ttraining's binary_logloss: 1.4834e-05\n",
      "[1777]\ttraining's binary_logloss: 1.47945e-05\n",
      "[1778]\ttraining's binary_logloss: 1.47553e-05\n",
      "[1779]\ttraining's binary_logloss: 1.47201e-05\n",
      "[1780]\ttraining's binary_logloss: 1.46813e-05\n",
      "[1781]\ttraining's binary_logloss: 1.4647e-05\n",
      "[1782]\ttraining's binary_logloss: 1.4614e-05\n",
      "[1783]\ttraining's binary_logloss: 1.45782e-05\n",
      "[1784]\ttraining's binary_logloss: 1.45397e-05\n",
      "[1785]\ttraining's binary_logloss: 1.45021e-05\n",
      "[1786]\ttraining's binary_logloss: 1.44668e-05\n",
      "[1787]\ttraining's binary_logloss: 1.44261e-05\n",
      "[1788]\ttraining's binary_logloss: 1.43917e-05\n",
      "[1789]\ttraining's binary_logloss: 1.43557e-05\n",
      "[1790]\ttraining's binary_logloss: 1.43176e-05\n",
      "[1791]\ttraining's binary_logloss: 1.42828e-05\n",
      "[1792]\ttraining's binary_logloss: 1.42485e-05\n",
      "[1793]\ttraining's binary_logloss: 1.4217e-05\n",
      "[1794]\ttraining's binary_logloss: 1.41792e-05\n",
      "[1795]\ttraining's binary_logloss: 1.4143e-05\n",
      "[1796]\ttraining's binary_logloss: 1.41098e-05\n",
      "[1797]\ttraining's binary_logloss: 1.40778e-05\n",
      "[1798]\ttraining's binary_logloss: 1.40455e-05\n",
      "[1799]\ttraining's binary_logloss: 1.40095e-05\n",
      "[1800]\ttraining's binary_logloss: 1.39789e-05\n",
      "[1801]\ttraining's binary_logloss: 1.39464e-05\n",
      "[1802]\ttraining's binary_logloss: 1.39089e-05\n",
      "[1803]\ttraining's binary_logloss: 1.38746e-05\n",
      "[1804]\ttraining's binary_logloss: 1.384e-05\n",
      "[1805]\ttraining's binary_logloss: 1.38119e-05\n",
      "[1806]\ttraining's binary_logloss: 1.37772e-05\n",
      "[1807]\ttraining's binary_logloss: 1.37461e-05\n",
      "[1808]\ttraining's binary_logloss: 1.37168e-05\n",
      "[1809]\ttraining's binary_logloss: 1.36847e-05\n",
      "[1810]\ttraining's binary_logloss: 1.36515e-05\n",
      "[1811]\ttraining's binary_logloss: 1.36169e-05\n",
      "[1812]\ttraining's binary_logloss: 1.35857e-05\n",
      "[1813]\ttraining's binary_logloss: 1.35574e-05\n",
      "[1814]\ttraining's binary_logloss: 1.35255e-05\n",
      "[1815]\ttraining's binary_logloss: 1.34913e-05\n",
      "[1816]\ttraining's binary_logloss: 1.34586e-05\n",
      "[1817]\ttraining's binary_logloss: 1.34261e-05\n",
      "[1818]\ttraining's binary_logloss: 1.33929e-05\n",
      "[1819]\ttraining's binary_logloss: 1.33628e-05\n",
      "[1820]\ttraining's binary_logloss: 1.33263e-05\n",
      "[1821]\ttraining's binary_logloss: 1.32986e-05\n",
      "[1822]\ttraining's binary_logloss: 1.32685e-05\n",
      "[1823]\ttraining's binary_logloss: 1.32369e-05\n",
      "[1824]\ttraining's binary_logloss: 1.32042e-05\n",
      "[1825]\ttraining's binary_logloss: 1.31738e-05\n",
      "[1826]\ttraining's binary_logloss: 1.31443e-05\n",
      "[1827]\ttraining's binary_logloss: 1.3111e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1828]\ttraining's binary_logloss: 1.30811e-05\n",
      "[1829]\ttraining's binary_logloss: 1.30507e-05\n",
      "[1830]\ttraining's binary_logloss: 1.30215e-05\n",
      "[1831]\ttraining's binary_logloss: 1.29946e-05\n",
      "[1832]\ttraining's binary_logloss: 1.29687e-05\n",
      "[1833]\ttraining's binary_logloss: 1.29378e-05\n",
      "[1834]\ttraining's binary_logloss: 1.29093e-05\n",
      "[1835]\ttraining's binary_logloss: 1.28829e-05\n",
      "[1836]\ttraining's binary_logloss: 1.28548e-05\n",
      "[1837]\ttraining's binary_logloss: 1.28232e-05\n",
      "[1838]\ttraining's binary_logloss: 1.27929e-05\n",
      "[1839]\ttraining's binary_logloss: 1.27612e-05\n",
      "[1840]\ttraining's binary_logloss: 1.27349e-05\n",
      "[1841]\ttraining's binary_logloss: 1.27091e-05\n",
      "[1842]\ttraining's binary_logloss: 1.26818e-05\n",
      "[1843]\ttraining's binary_logloss: 1.26575e-05\n",
      "[1844]\ttraining's binary_logloss: 1.263e-05\n",
      "[1845]\ttraining's binary_logloss: 1.26017e-05\n",
      "[1846]\ttraining's binary_logloss: 1.25739e-05\n",
      "[1847]\ttraining's binary_logloss: 1.25449e-05\n",
      "[1848]\ttraining's binary_logloss: 1.252e-05\n",
      "[1849]\ttraining's binary_logloss: 1.24941e-05\n",
      "[1850]\ttraining's binary_logloss: 1.24669e-05\n",
      "[1851]\ttraining's binary_logloss: 1.24394e-05\n",
      "[1852]\ttraining's binary_logloss: 1.24142e-05\n",
      "[1853]\ttraining's binary_logloss: 1.23915e-05\n",
      "[1854]\ttraining's binary_logloss: 1.23662e-05\n",
      "[1855]\ttraining's binary_logloss: 1.2342e-05\n",
      "[1856]\ttraining's binary_logloss: 1.23156e-05\n",
      "[1857]\ttraining's binary_logloss: 1.22873e-05\n",
      "[1858]\ttraining's binary_logloss: 1.22628e-05\n",
      "[1859]\ttraining's binary_logloss: 1.22365e-05\n",
      "[1860]\ttraining's binary_logloss: 1.22106e-05\n",
      "[1861]\ttraining's binary_logloss: 1.21822e-05\n",
      "[1862]\ttraining's binary_logloss: 1.2159e-05\n",
      "[1863]\ttraining's binary_logloss: 1.21355e-05\n",
      "[1864]\ttraining's binary_logloss: 1.21095e-05\n",
      "[1865]\ttraining's binary_logloss: 1.20854e-05\n",
      "[1866]\ttraining's binary_logloss: 1.20619e-05\n",
      "[1867]\ttraining's binary_logloss: 1.20344e-05\n",
      "[1868]\ttraining's binary_logloss: 1.20078e-05\n",
      "[1869]\ttraining's binary_logloss: 1.19824e-05\n",
      "[1870]\ttraining's binary_logloss: 1.19568e-05\n",
      "[1871]\ttraining's binary_logloss: 1.19314e-05\n",
      "[1872]\ttraining's binary_logloss: 1.19098e-05\n",
      "[1873]\ttraining's binary_logloss: 1.18837e-05\n",
      "[1874]\ttraining's binary_logloss: 1.18623e-05\n",
      "[1875]\ttraining's binary_logloss: 1.18398e-05\n",
      "[1876]\ttraining's binary_logloss: 1.18154e-05\n",
      "[1877]\ttraining's binary_logloss: 1.17924e-05\n",
      "[1878]\ttraining's binary_logloss: 1.1769e-05\n",
      "[1879]\ttraining's binary_logloss: 1.17468e-05\n",
      "[1880]\ttraining's binary_logloss: 1.17233e-05\n",
      "[1881]\ttraining's binary_logloss: 1.17002e-05\n",
      "[1882]\ttraining's binary_logloss: 1.16754e-05\n",
      "[1883]\ttraining's binary_logloss: 1.16545e-05\n",
      "[1884]\ttraining's binary_logloss: 1.16312e-05\n",
      "[1885]\ttraining's binary_logloss: 1.16075e-05\n",
      "[1886]\ttraining's binary_logloss: 1.15852e-05\n",
      "[1887]\ttraining's binary_logloss: 1.15642e-05\n",
      "[1888]\ttraining's binary_logloss: 1.15397e-05\n",
      "[1889]\ttraining's binary_logloss: 1.1518e-05\n",
      "[1890]\ttraining's binary_logloss: 1.14943e-05\n",
      "[1891]\ttraining's binary_logloss: 1.1471e-05\n",
      "[1892]\ttraining's binary_logloss: 1.14504e-05\n",
      "[1893]\ttraining's binary_logloss: 1.14316e-05\n",
      "[1894]\ttraining's binary_logloss: 1.14097e-05\n",
      "[1895]\ttraining's binary_logloss: 1.13898e-05\n",
      "[1896]\ttraining's binary_logloss: 1.13703e-05\n",
      "[1897]\ttraining's binary_logloss: 1.13475e-05\n",
      "[1898]\ttraining's binary_logloss: 1.13269e-05\n",
      "[1899]\ttraining's binary_logloss: 1.13017e-05\n",
      "[1900]\ttraining's binary_logloss: 1.12818e-05\n",
      "[1901]\ttraining's binary_logloss: 1.12597e-05\n",
      "[1902]\ttraining's binary_logloss: 1.12432e-05\n",
      "[1903]\ttraining's binary_logloss: 1.12212e-05\n",
      "[1904]\ttraining's binary_logloss: 1.12004e-05\n",
      "[1905]\ttraining's binary_logloss: 1.11813e-05\n",
      "[1906]\ttraining's binary_logloss: 1.11605e-05\n",
      "[1907]\ttraining's binary_logloss: 1.11411e-05\n",
      "[1908]\ttraining's binary_logloss: 1.1122e-05\n",
      "[1909]\ttraining's binary_logloss: 1.11027e-05\n",
      "[1910]\ttraining's binary_logloss: 1.10803e-05\n",
      "[1911]\ttraining's binary_logloss: 1.10598e-05\n",
      "[1912]\ttraining's binary_logloss: 1.10367e-05\n",
      "[1913]\ttraining's binary_logloss: 1.10199e-05\n",
      "[1914]\ttraining's binary_logloss: 1.10007e-05\n",
      "[1915]\ttraining's binary_logloss: 1.0982e-05\n",
      "[1916]\ttraining's binary_logloss: 1.09626e-05\n",
      "[1917]\ttraining's binary_logloss: 1.09401e-05\n",
      "[1918]\ttraining's binary_logloss: 1.09195e-05\n",
      "[1919]\ttraining's binary_logloss: 1.08995e-05\n",
      "[1920]\ttraining's binary_logloss: 1.08822e-05\n",
      "[1921]\ttraining's binary_logloss: 1.08626e-05\n",
      "[1922]\ttraining's binary_logloss: 1.08442e-05\n",
      "[1923]\ttraining's binary_logloss: 1.08231e-05\n",
      "[1924]\ttraining's binary_logloss: 1.08044e-05\n",
      "[1925]\ttraining's binary_logloss: 1.07864e-05\n",
      "[1926]\ttraining's binary_logloss: 1.07688e-05\n",
      "[1927]\ttraining's binary_logloss: 1.07497e-05\n",
      "[1928]\ttraining's binary_logloss: 1.07308e-05\n",
      "[1929]\ttraining's binary_logloss: 1.07101e-05\n",
      "[1930]\ttraining's binary_logloss: 1.06904e-05\n",
      "[1931]\ttraining's binary_logloss: 1.06729e-05\n",
      "[1932]\ttraining's binary_logloss: 1.06529e-05\n",
      "[1933]\ttraining's binary_logloss: 1.06347e-05\n",
      "[1934]\ttraining's binary_logloss: 1.06155e-05\n",
      "[1935]\ttraining's binary_logloss: 1.05946e-05\n",
      "[1936]\ttraining's binary_logloss: 1.0577e-05\n",
      "[1937]\ttraining's binary_logloss: 1.05604e-05\n",
      "[1938]\ttraining's binary_logloss: 1.05426e-05\n",
      "[1939]\ttraining's binary_logloss: 1.05229e-05\n",
      "[1940]\ttraining's binary_logloss: 1.05042e-05\n",
      "[1941]\ttraining's binary_logloss: 1.04863e-05\n",
      "[1942]\ttraining's binary_logloss: 1.04687e-05\n",
      "[1943]\ttraining's binary_logloss: 1.04501e-05\n",
      "[1944]\ttraining's binary_logloss: 1.04315e-05\n",
      "[1945]\ttraining's binary_logloss: 1.04115e-05\n",
      "[1946]\ttraining's binary_logloss: 1.03933e-05\n",
      "[1947]\ttraining's binary_logloss: 1.03743e-05\n",
      "[1948]\ttraining's binary_logloss: 1.03572e-05\n",
      "[1949]\ttraining's binary_logloss: 1.03384e-05\n",
      "[1950]\ttraining's binary_logloss: 1.03229e-05\n",
      "[1951]\ttraining's binary_logloss: 1.03045e-05\n",
      "[1952]\ttraining's binary_logloss: 1.02874e-05\n",
      "[1953]\ttraining's binary_logloss: 1.02721e-05\n",
      "[1954]\ttraining's binary_logloss: 1.02537e-05\n",
      "[1955]\ttraining's binary_logloss: 1.02356e-05\n",
      "[1956]\ttraining's binary_logloss: 1.02194e-05\n",
      "[1957]\ttraining's binary_logloss: 1.02038e-05\n",
      "[1958]\ttraining's binary_logloss: 1.01868e-05\n",
      "[1959]\ttraining's binary_logloss: 1.01698e-05\n",
      "[1960]\ttraining's binary_logloss: 1.01537e-05\n",
      "[1961]\ttraining's binary_logloss: 1.01384e-05\n",
      "[1962]\ttraining's binary_logloss: 1.01223e-05\n",
      "[1963]\ttraining's binary_logloss: 1.01059e-05\n",
      "[1964]\ttraining's binary_logloss: 1.00912e-05\n",
      "[1965]\ttraining's binary_logloss: 1.00776e-05\n",
      "[1966]\ttraining's binary_logloss: 1.00609e-05\n",
      "[1967]\ttraining's binary_logloss: 1.00423e-05\n",
      "[1968]\ttraining's binary_logloss: 1.00246e-05\n",
      "[1969]\ttraining's binary_logloss: 1.00109e-05\n",
      "[1970]\ttraining's binary_logloss: 9.99489e-06\n",
      "[1971]\ttraining's binary_logloss: 9.97779e-06\n",
      "[1972]\ttraining's binary_logloss: 9.96215e-06\n",
      "[1973]\ttraining's binary_logloss: 9.94603e-06\n",
      "[1974]\ttraining's binary_logloss: 9.93039e-06\n",
      "[1975]\ttraining's binary_logloss: 9.91178e-06\n",
      "[1976]\ttraining's binary_logloss: 9.89496e-06\n",
      "[1977]\ttraining's binary_logloss: 9.87976e-06\n",
      "[1978]\ttraining's binary_logloss: 9.86329e-06\n",
      "[1979]\ttraining's binary_logloss: 9.84891e-06\n",
      "[1980]\ttraining's binary_logloss: 9.83206e-06\n",
      "[1981]\ttraining's binary_logloss: 9.81815e-06\n",
      "[1982]\ttraining's binary_logloss: 9.80382e-06\n",
      "[1983]\ttraining's binary_logloss: 9.78869e-06\n",
      "[1984]\ttraining's binary_logloss: 9.77414e-06\n",
      "[1985]\ttraining's binary_logloss: 9.75913e-06\n",
      "[1986]\ttraining's binary_logloss: 9.74459e-06\n",
      "[1987]\ttraining's binary_logloss: 9.72944e-06\n",
      "[1988]\ttraining's binary_logloss: 9.7134e-06\n",
      "[1989]\ttraining's binary_logloss: 9.69693e-06\n",
      "[1990]\ttraining's binary_logloss: 9.68363e-06\n",
      "[1991]\ttraining's binary_logloss: 9.67107e-06\n",
      "[1992]\ttraining's binary_logloss: 9.65616e-06\n",
      "[1993]\ttraining's binary_logloss: 9.64273e-06\n",
      "[1994]\ttraining's binary_logloss: 9.62981e-06\n",
      "[1995]\ttraining's binary_logloss: 9.61639e-06\n",
      "[1996]\ttraining's binary_logloss: 9.60349e-06\n",
      "[1997]\ttraining's binary_logloss: 9.58732e-06\n",
      "[1998]\ttraining's binary_logloss: 9.57183e-06\n",
      "[1999]\ttraining's binary_logloss: 9.5589e-06\n",
      "[2000]\ttraining's binary_logloss: 9.5442e-06\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = lgb.train(\n",
    "    lgbm_params,\n",
    "    lgtrain,\n",
    "    valid_sets=lgtrain,\n",
    "    num_boost_round=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7884536364881524"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_lgb = lgb_clf.predict(X_test)\n",
    "predict_lgb = np.array([0 if i < 0.6 else 1 for i in predict_lgb])\n",
    "roc_auc_score(predict_lgb, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf, 'random_forest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.679963\n",
      "[2]\ttraining's binary_logloss: 0.66497\n",
      "[3]\ttraining's binary_logloss: 0.652721\n",
      "[4]\ttraining's binary_logloss: 0.638789\n",
      "[5]\ttraining's binary_logloss: 0.625434\n",
      "[6]\ttraining's binary_logloss: 0.61472\n",
      "[7]\ttraining's binary_logloss: 0.603808\n",
      "[8]\ttraining's binary_logloss: 0.591721\n",
      "[9]\ttraining's binary_logloss: 0.581847\n",
      "[10]\ttraining's binary_logloss: 0.57042\n",
      "[11]\ttraining's binary_logloss: 0.561189\n",
      "[12]\ttraining's binary_logloss: 0.550441\n",
      "[13]\ttraining's binary_logloss: 0.541623\n",
      "[14]\ttraining's binary_logloss: 0.53153\n",
      "[15]\ttraining's binary_logloss: 0.52316\n",
      "[16]\ttraining's binary_logloss: 0.515254\n",
      "[17]\ttraining's binary_logloss: 0.505888\n",
      "[18]\ttraining's binary_logloss: 0.498422\n",
      "[19]\ttraining's binary_logloss: 0.489725\n",
      "[20]\ttraining's binary_logloss: 0.482526\n",
      "[21]\ttraining's binary_logloss: 0.47419\n",
      "[22]\ttraining's binary_logloss: 0.467509\n",
      "[23]\ttraining's binary_logloss: 0.460875\n",
      "[24]\ttraining's binary_logloss: 0.454472\n",
      "[25]\ttraining's binary_logloss: 0.446948\n",
      "[26]\ttraining's binary_logloss: 0.439619\n",
      "[27]\ttraining's binary_logloss: 0.433498\n",
      "[28]\ttraining's binary_logloss: 0.426549\n",
      "[29]\ttraining's binary_logloss: 0.419785\n",
      "[30]\ttraining's binary_logloss: 0.414263\n",
      "[31]\ttraining's binary_logloss: 0.408809\n",
      "[32]\ttraining's binary_logloss: 0.40361\n",
      "[33]\ttraining's binary_logloss: 0.398344\n",
      "[34]\ttraining's binary_logloss: 0.392252\n",
      "[35]\ttraining's binary_logloss: 0.386275\n",
      "[36]\ttraining's binary_logloss: 0.380373\n",
      "[37]\ttraining's binary_logloss: 0.374821\n",
      "[38]\ttraining's binary_logloss: 0.369349\n",
      "[39]\ttraining's binary_logloss: 0.3649\n",
      "[40]\ttraining's binary_logloss: 0.359667\n",
      "[41]\ttraining's binary_logloss: 0.354524\n",
      "[42]\ttraining's binary_logloss: 0.350275\n",
      "[43]\ttraining's binary_logloss: 0.346366\n",
      "[44]\ttraining's binary_logloss: 0.342267\n",
      "[45]\ttraining's binary_logloss: 0.338377\n",
      "[46]\ttraining's binary_logloss: 0.333706\n",
      "[47]\ttraining's binary_logloss: 0.329126\n",
      "[48]\ttraining's binary_logloss: 0.325375\n",
      "[49]\ttraining's binary_logloss: 0.321066\n",
      "[50]\ttraining's binary_logloss: 0.317551\n",
      "[51]\ttraining's binary_logloss: 0.313404\n",
      "[52]\ttraining's binary_logloss: 0.309235\n",
      "[53]\ttraining's binary_logloss: 0.305869\n",
      "[54]\ttraining's binary_logloss: 0.301895\n",
      "[55]\ttraining's binary_logloss: 0.298002\n",
      "[56]\ttraining's binary_logloss: 0.294753\n",
      "[57]\ttraining's binary_logloss: 0.291059\n",
      "[58]\ttraining's binary_logloss: 0.28797\n",
      "[59]\ttraining's binary_logloss: 0.284929\n",
      "[60]\ttraining's binary_logloss: 0.282025\n",
      "[61]\ttraining's binary_logloss: 0.278468\n",
      "[62]\ttraining's binary_logloss: 0.274933\n",
      "[63]\ttraining's binary_logloss: 0.272195\n",
      "[64]\ttraining's binary_logloss: 0.268885\n",
      "[65]\ttraining's binary_logloss: 0.265655\n",
      "[66]\ttraining's binary_logloss: 0.262983\n",
      "[67]\ttraining's binary_logloss: 0.260381\n",
      "[68]\ttraining's binary_logloss: 0.257138\n",
      "[69]\ttraining's binary_logloss: 0.253977\n",
      "[70]\ttraining's binary_logloss: 0.251412\n",
      "[71]\ttraining's binary_logloss: 0.248524\n",
      "[72]\ttraining's binary_logloss: 0.246123\n",
      "[73]\ttraining's binary_logloss: 0.243222\n",
      "[74]\ttraining's binary_logloss: 0.240436\n",
      "[75]\ttraining's binary_logloss: 0.237646\n",
      "[76]\ttraining's binary_logloss: 0.235419\n",
      "[77]\ttraining's binary_logloss: 0.233128\n",
      "[78]\ttraining's binary_logloss: 0.230896\n",
      "[79]\ttraining's binary_logloss: 0.228234\n",
      "[80]\ttraining's binary_logloss: 0.225676\n",
      "[81]\ttraining's binary_logloss: 0.223547\n",
      "[82]\ttraining's binary_logloss: 0.221389\n",
      "[83]\ttraining's binary_logloss: 0.219321\n",
      "[84]\ttraining's binary_logloss: 0.216957\n",
      "[85]\ttraining's binary_logloss: 0.214964\n",
      "[86]\ttraining's binary_logloss: 0.2126\n",
      "[87]\ttraining's binary_logloss: 0.210673\n",
      "[88]\ttraining's binary_logloss: 0.208848\n",
      "[89]\ttraining's binary_logloss: 0.206566\n",
      "[90]\ttraining's binary_logloss: 0.204684\n",
      "[91]\ttraining's binary_logloss: 0.202782\n",
      "[92]\ttraining's binary_logloss: 0.200945\n",
      "[93]\ttraining's binary_logloss: 0.199153\n",
      "[94]\ttraining's binary_logloss: 0.197372\n",
      "[95]\ttraining's binary_logloss: 0.195579\n",
      "[96]\ttraining's binary_logloss: 0.193489\n",
      "[97]\ttraining's binary_logloss: 0.191461\n",
      "[98]\ttraining's binary_logloss: 0.189404\n",
      "[99]\ttraining's binary_logloss: 0.187745\n",
      "[100]\ttraining's binary_logloss: 0.18577\n",
      "[101]\ttraining's binary_logloss: 0.184144\n",
      "[102]\ttraining's binary_logloss: 0.182228\n",
      "[103]\ttraining's binary_logloss: 0.180646\n",
      "[104]\ttraining's binary_logloss: 0.179066\n",
      "[105]\ttraining's binary_logloss: 0.177547\n",
      "[106]\ttraining's binary_logloss: 0.175685\n",
      "[107]\ttraining's binary_logloss: 0.173863\n",
      "[108]\ttraining's binary_logloss: 0.172411\n",
      "[109]\ttraining's binary_logloss: 0.170898\n",
      "[110]\ttraining's binary_logloss: 0.169154\n",
      "[111]\ttraining's binary_logloss: 0.167372\n",
      "[112]\ttraining's binary_logloss: 0.16566\n",
      "[113]\ttraining's binary_logloss: 0.164063\n",
      "[114]\ttraining's binary_logloss: 0.162583\n",
      "[115]\ttraining's binary_logloss: 0.161207\n",
      "[116]\ttraining's binary_logloss: 0.159556\n",
      "[117]\ttraining's binary_logloss: 0.157945\n",
      "[118]\ttraining's binary_logloss: 0.156649\n",
      "[119]\ttraining's binary_logloss: 0.155091\n",
      "[120]\ttraining's binary_logloss: 0.153802\n",
      "[121]\ttraining's binary_logloss: 0.152265\n",
      "[122]\ttraining's binary_logloss: 0.151015\n",
      "[123]\ttraining's binary_logloss: 0.149507\n",
      "[124]\ttraining's binary_logloss: 0.148255\n",
      "[125]\ttraining's binary_logloss: 0.146797\n",
      "[126]\ttraining's binary_logloss: 0.14555\n",
      "[127]\ttraining's binary_logloss: 0.144185\n",
      "[128]\ttraining's binary_logloss: 0.142939\n",
      "[129]\ttraining's binary_logloss: 0.141812\n",
      "[130]\ttraining's binary_logloss: 0.140409\n",
      "[131]\ttraining's binary_logloss: 0.139231\n",
      "[132]\ttraining's binary_logloss: 0.138025\n",
      "[133]\ttraining's binary_logloss: 0.136891\n",
      "[134]\ttraining's binary_logloss: 0.135781\n",
      "[135]\ttraining's binary_logloss: 0.13452\n",
      "[136]\ttraining's binary_logloss: 0.133225\n",
      "[137]\ttraining's binary_logloss: 0.132128\n",
      "[138]\ttraining's binary_logloss: 0.130994\n",
      "[139]\ttraining's binary_logloss: 0.129713\n",
      "[140]\ttraining's binary_logloss: 0.128477\n",
      "[141]\ttraining's binary_logloss: 0.127455\n",
      "[142]\ttraining's binary_logloss: 0.126277\n",
      "[143]\ttraining's binary_logloss: 0.125246\n",
      "[144]\ttraining's binary_logloss: 0.124189\n",
      "[145]\ttraining's binary_logloss: 0.123137\n",
      "[146]\ttraining's binary_logloss: 0.121966\n",
      "[147]\ttraining's binary_logloss: 0.120761\n",
      "[148]\ttraining's binary_logloss: 0.119799\n",
      "[149]\ttraining's binary_logloss: 0.118851\n",
      "[150]\ttraining's binary_logloss: 0.117906\n",
      "[151]\ttraining's binary_logloss: 0.116812\n",
      "[152]\ttraining's binary_logloss: 0.115737\n",
      "[153]\ttraining's binary_logloss: 0.114804\n",
      "[154]\ttraining's binary_logloss: 0.113885\n",
      "[155]\ttraining's binary_logloss: 0.112927\n",
      "[156]\ttraining's binary_logloss: 0.112013\n",
      "[157]\ttraining's binary_logloss: 0.111113\n",
      "[158]\ttraining's binary_logloss: 0.11007\n",
      "[159]\ttraining's binary_logloss: 0.109017\n",
      "[160]\ttraining's binary_logloss: 0.108137\n",
      "[161]\ttraining's binary_logloss: 0.10711\n",
      "[162]\ttraining's binary_logloss: 0.106263\n",
      "[163]\ttraining's binary_logloss: 0.105385\n",
      "[164]\ttraining's binary_logloss: 0.1044\n",
      "[165]\ttraining's binary_logloss: 0.103551\n",
      "[166]\ttraining's binary_logloss: 0.102634\n",
      "[167]\ttraining's binary_logloss: 0.101702\n",
      "[168]\ttraining's binary_logloss: 0.10087\n",
      "[169]\ttraining's binary_logloss: 0.0999508\n",
      "[170]\ttraining's binary_logloss: 0.0990197\n",
      "[171]\ttraining's binary_logloss: 0.098245\n",
      "[172]\ttraining's binary_logloss: 0.0975026\n",
      "[173]\ttraining's binary_logloss: 0.0966415\n",
      "[174]\ttraining's binary_logloss: 0.0957594\n",
      "[175]\ttraining's binary_logloss: 0.0949628\n",
      "[176]\ttraining's binary_logloss: 0.0942145\n",
      "[177]\ttraining's binary_logloss: 0.0933526\n",
      "[178]\ttraining's binary_logloss: 0.092574\n",
      "[179]\ttraining's binary_logloss: 0.0918334\n",
      "[180]\ttraining's binary_logloss: 0.0909988\n",
      "[181]\ttraining's binary_logloss: 0.0901212\n",
      "[182]\ttraining's binary_logloss: 0.0892825\n",
      "[183]\ttraining's binary_logloss: 0.0884927\n",
      "[184]\ttraining's binary_logloss: 0.0877016\n",
      "[185]\ttraining's binary_logloss: 0.0870071\n",
      "[186]\ttraining's binary_logloss: 0.0862312\n",
      "[187]\ttraining's binary_logloss: 0.0855052\n",
      "[188]\ttraining's binary_logloss: 0.0847689\n",
      "[189]\ttraining's binary_logloss: 0.0840466\n",
      "[190]\ttraining's binary_logloss: 0.0834341\n",
      "[191]\ttraining's binary_logloss: 0.0826686\n",
      "[192]\ttraining's binary_logloss: 0.0819852\n",
      "[193]\ttraining's binary_logloss: 0.0812484\n",
      "[194]\ttraining's binary_logloss: 0.0805737\n",
      "[195]\ttraining's binary_logloss: 0.0798818\n",
      "[196]\ttraining's binary_logloss: 0.0791462\n",
      "[197]\ttraining's binary_logloss: 0.0785112\n",
      "[198]\ttraining's binary_logloss: 0.0778671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[199]\ttraining's binary_logloss: 0.0772638\n",
      "[200]\ttraining's binary_logloss: 0.0766379\n",
      "[201]\ttraining's binary_logloss: 0.0759774\n",
      "[202]\ttraining's binary_logloss: 0.0753103\n",
      "[203]\ttraining's binary_logloss: 0.0747256\n",
      "[204]\ttraining's binary_logloss: 0.0741488\n",
      "[205]\ttraining's binary_logloss: 0.0734999\n",
      "[206]\ttraining's binary_logloss: 0.0729097\n",
      "[207]\ttraining's binary_logloss: 0.07227\n",
      "[208]\ttraining's binary_logloss: 0.0715998\n",
      "[209]\ttraining's binary_logloss: 0.0709609\n",
      "[210]\ttraining's binary_logloss: 0.0703132\n",
      "[211]\ttraining's binary_logloss: 0.0697548\n",
      "[212]\ttraining's binary_logloss: 0.0691784\n",
      "[213]\ttraining's binary_logloss: 0.0685933\n",
      "[214]\ttraining's binary_logloss: 0.0680614\n",
      "[215]\ttraining's binary_logloss: 0.0674941\n",
      "[216]\ttraining's binary_logloss: 0.0669178\n",
      "[217]\ttraining's binary_logloss: 0.066328\n",
      "[218]\ttraining's binary_logloss: 0.0658082\n",
      "[219]\ttraining's binary_logloss: 0.0653198\n",
      "[220]\ttraining's binary_logloss: 0.0647656\n",
      "[221]\ttraining's binary_logloss: 0.0642212\n",
      "[222]\ttraining's binary_logloss: 0.0636756\n",
      "[223]\ttraining's binary_logloss: 0.0631491\n",
      "[224]\ttraining's binary_logloss: 0.062638\n",
      "[225]\ttraining's binary_logloss: 0.0621118\n",
      "[226]\ttraining's binary_logloss: 0.0616183\n",
      "[227]\ttraining's binary_logloss: 0.0611019\n",
      "[228]\ttraining's binary_logloss: 0.0606229\n",
      "[229]\ttraining's binary_logloss: 0.0600992\n",
      "[230]\ttraining's binary_logloss: 0.0596143\n",
      "[231]\ttraining's binary_logloss: 0.0591266\n",
      "[232]\ttraining's binary_logloss: 0.0586705\n",
      "[233]\ttraining's binary_logloss: 0.0581841\n",
      "[234]\ttraining's binary_logloss: 0.0577083\n",
      "[235]\ttraining's binary_logloss: 0.0572214\n",
      "[236]\ttraining's binary_logloss: 0.056758\n",
      "[237]\ttraining's binary_logloss: 0.0562983\n",
      "[238]\ttraining's binary_logloss: 0.0558459\n",
      "[239]\ttraining's binary_logloss: 0.0553963\n",
      "[240]\ttraining's binary_logloss: 0.0549271\n",
      "[241]\ttraining's binary_logloss: 0.0544738\n",
      "[242]\ttraining's binary_logloss: 0.0540053\n",
      "[243]\ttraining's binary_logloss: 0.0535628\n",
      "[244]\ttraining's binary_logloss: 0.0531533\n",
      "[245]\ttraining's binary_logloss: 0.0527112\n",
      "[246]\ttraining's binary_logloss: 0.0522844\n",
      "[247]\ttraining's binary_logloss: 0.0518874\n",
      "[248]\ttraining's binary_logloss: 0.0514647\n",
      "[249]\ttraining's binary_logloss: 0.0510556\n",
      "[250]\ttraining's binary_logloss: 0.0506682\n",
      "[251]\ttraining's binary_logloss: 0.0502696\n",
      "[252]\ttraining's binary_logloss: 0.0498742\n",
      "[253]\ttraining's binary_logloss: 0.0494613\n",
      "[254]\ttraining's binary_logloss: 0.0490746\n",
      "[255]\ttraining's binary_logloss: 0.048682\n",
      "[256]\ttraining's binary_logloss: 0.0482955\n",
      "[257]\ttraining's binary_logloss: 0.0479037\n",
      "[258]\ttraining's binary_logloss: 0.0475096\n",
      "[259]\ttraining's binary_logloss: 0.0471576\n",
      "[260]\ttraining's binary_logloss: 0.0467778\n",
      "[261]\ttraining's binary_logloss: 0.0464054\n",
      "[262]\ttraining's binary_logloss: 0.0460471\n",
      "[263]\ttraining's binary_logloss: 0.045672\n",
      "[264]\ttraining's binary_logloss: 0.045319\n",
      "[265]\ttraining's binary_logloss: 0.0449705\n",
      "[266]\ttraining's binary_logloss: 0.0446228\n",
      "[267]\ttraining's binary_logloss: 0.044261\n",
      "[268]\ttraining's binary_logloss: 0.0438791\n",
      "[269]\ttraining's binary_logloss: 0.0435181\n",
      "[270]\ttraining's binary_logloss: 0.0431746\n",
      "[271]\ttraining's binary_logloss: 0.0428168\n",
      "[272]\ttraining's binary_logloss: 0.0424875\n",
      "[273]\ttraining's binary_logloss: 0.0421553\n",
      "[274]\ttraining's binary_logloss: 0.0418083\n",
      "[275]\ttraining's binary_logloss: 0.041475\n",
      "[276]\ttraining's binary_logloss: 0.0411459\n",
      "[277]\ttraining's binary_logloss: 0.0408344\n",
      "[278]\ttraining's binary_logloss: 0.040494\n",
      "[279]\ttraining's binary_logloss: 0.0401883\n",
      "[280]\ttraining's binary_logloss: 0.0398791\n",
      "[281]\ttraining's binary_logloss: 0.0395616\n",
      "[282]\ttraining's binary_logloss: 0.0392493\n",
      "[283]\ttraining's binary_logloss: 0.0389341\n",
      "[284]\ttraining's binary_logloss: 0.0386259\n",
      "[285]\ttraining's binary_logloss: 0.038319\n",
      "[286]\ttraining's binary_logloss: 0.0380191\n",
      "[287]\ttraining's binary_logloss: 0.0377088\n",
      "[288]\ttraining's binary_logloss: 0.0374307\n",
      "[289]\ttraining's binary_logloss: 0.0371431\n",
      "[290]\ttraining's binary_logloss: 0.0368473\n",
      "[291]\ttraining's binary_logloss: 0.0365469\n",
      "[292]\ttraining's binary_logloss: 0.036274\n",
      "[293]\ttraining's binary_logloss: 0.0359971\n",
      "[294]\ttraining's binary_logloss: 0.0357139\n",
      "[295]\ttraining's binary_logloss: 0.0354357\n",
      "[296]\ttraining's binary_logloss: 0.0351663\n",
      "[297]\ttraining's binary_logloss: 0.0348798\n",
      "[298]\ttraining's binary_logloss: 0.0346154\n",
      "[299]\ttraining's binary_logloss: 0.0343329\n",
      "[300]\ttraining's binary_logloss: 0.0340559\n",
      "[301]\ttraining's binary_logloss: 0.0337888\n",
      "[302]\ttraining's binary_logloss: 0.0335231\n",
      "[303]\ttraining's binary_logloss: 0.0332643\n",
      "[304]\ttraining's binary_logloss: 0.0330167\n",
      "[305]\ttraining's binary_logloss: 0.0327656\n",
      "[306]\ttraining's binary_logloss: 0.0325011\n",
      "[307]\ttraining's binary_logloss: 0.0322418\n",
      "[308]\ttraining's binary_logloss: 0.031996\n",
      "[309]\ttraining's binary_logloss: 0.0317577\n",
      "[310]\ttraining's binary_logloss: 0.0315155\n",
      "[311]\ttraining's binary_logloss: 0.0312587\n",
      "[312]\ttraining's binary_logloss: 0.0310052\n",
      "[313]\ttraining's binary_logloss: 0.0307574\n",
      "[314]\ttraining's binary_logloss: 0.0305268\n",
      "[315]\ttraining's binary_logloss: 0.030294\n",
      "[316]\ttraining's binary_logloss: 0.0300643\n",
      "[317]\ttraining's binary_logloss: 0.0298353\n",
      "[318]\ttraining's binary_logloss: 0.0296069\n",
      "[319]\ttraining's binary_logloss: 0.0293748\n",
      "[320]\ttraining's binary_logloss: 0.029155\n",
      "[321]\ttraining's binary_logloss: 0.0289416\n",
      "[322]\ttraining's binary_logloss: 0.0287221\n",
      "[323]\ttraining's binary_logloss: 0.0284949\n",
      "[324]\ttraining's binary_logloss: 0.0282682\n",
      "[325]\ttraining's binary_logloss: 0.0280631\n",
      "[326]\ttraining's binary_logloss: 0.0278447\n",
      "[327]\ttraining's binary_logloss: 0.0276368\n",
      "[328]\ttraining's binary_logloss: 0.027427\n",
      "[329]\ttraining's binary_logloss: 0.0272156\n",
      "[330]\ttraining's binary_logloss: 0.027004\n",
      "[331]\ttraining's binary_logloss: 0.0267961\n",
      "[332]\ttraining's binary_logloss: 0.0265897\n",
      "[333]\ttraining's binary_logloss: 0.0263855\n",
      "[334]\ttraining's binary_logloss: 0.0261838\n",
      "[335]\ttraining's binary_logloss: 0.025981\n",
      "[336]\ttraining's binary_logloss: 0.0257806\n",
      "[337]\ttraining's binary_logloss: 0.0255857\n",
      "[338]\ttraining's binary_logloss: 0.0253861\n",
      "[339]\ttraining's binary_logloss: 0.0251884\n",
      "[340]\ttraining's binary_logloss: 0.0249973\n",
      "[341]\ttraining's binary_logloss: 0.0248062\n",
      "[342]\ttraining's binary_logloss: 0.0246153\n",
      "[343]\ttraining's binary_logloss: 0.0244462\n",
      "[344]\ttraining's binary_logloss: 0.0242738\n",
      "[345]\ttraining's binary_logloss: 0.0240907\n",
      "[346]\ttraining's binary_logloss: 0.0239012\n",
      "[347]\ttraining's binary_logloss: 0.02373\n",
      "[348]\ttraining's binary_logloss: 0.0235527\n",
      "[349]\ttraining's binary_logloss: 0.0233665\n",
      "[350]\ttraining's binary_logloss: 0.0231985\n",
      "[351]\ttraining's binary_logloss: 0.0230255\n",
      "[352]\ttraining's binary_logloss: 0.0228425\n",
      "[353]\ttraining's binary_logloss: 0.0226706\n",
      "[354]\ttraining's binary_logloss: 0.0224954\n",
      "[355]\ttraining's binary_logloss: 0.022318\n",
      "[356]\ttraining's binary_logloss: 0.0221549\n",
      "[357]\ttraining's binary_logloss: 0.0219782\n",
      "[358]\ttraining's binary_logloss: 0.021806\n",
      "[359]\ttraining's binary_logloss: 0.0216314\n",
      "[360]\ttraining's binary_logloss: 0.0214707\n",
      "[361]\ttraining's binary_logloss: 0.0213098\n",
      "[362]\ttraining's binary_logloss: 0.0211541\n",
      "[363]\ttraining's binary_logloss: 0.020992\n",
      "[364]\ttraining's binary_logloss: 0.0208415\n",
      "[365]\ttraining's binary_logloss: 0.02068\n",
      "[366]\ttraining's binary_logloss: 0.0205189\n",
      "[367]\ttraining's binary_logloss: 0.0203626\n",
      "[368]\ttraining's binary_logloss: 0.0202103\n",
      "[369]\ttraining's binary_logloss: 0.0200436\n",
      "[370]\ttraining's binary_logloss: 0.0198875\n",
      "[371]\ttraining's binary_logloss: 0.0197482\n",
      "[372]\ttraining's binary_logloss: 0.0195942\n",
      "[373]\ttraining's binary_logloss: 0.0194506\n",
      "[374]\ttraining's binary_logloss: 0.0193044\n",
      "[375]\ttraining's binary_logloss: 0.019162\n",
      "[376]\ttraining's binary_logloss: 0.0190129\n",
      "[377]\ttraining's binary_logloss: 0.0188638\n",
      "[378]\ttraining's binary_logloss: 0.0187253\n",
      "[379]\ttraining's binary_logloss: 0.0185813\n",
      "[380]\ttraining's binary_logloss: 0.0184323\n",
      "[381]\ttraining's binary_logloss: 0.0182838\n",
      "[382]\ttraining's binary_logloss: 0.0181414\n",
      "[383]\ttraining's binary_logloss: 0.0180054\n",
      "[384]\ttraining's binary_logloss: 0.0178645\n",
      "[385]\ttraining's binary_logloss: 0.0177298\n",
      "[386]\ttraining's binary_logloss: 0.0175903\n",
      "[387]\ttraining's binary_logloss: 0.0174592\n",
      "[388]\ttraining's binary_logloss: 0.0173305\n",
      "[389]\ttraining's binary_logloss: 0.0171948\n",
      "[390]\ttraining's binary_logloss: 0.0170689\n",
      "[391]\ttraining's binary_logloss: 0.016942\n",
      "[392]\ttraining's binary_logloss: 0.0168076\n",
      "[393]\ttraining's binary_logloss: 0.0166851\n",
      "[394]\ttraining's binary_logloss: 0.0165552\n",
      "[395]\ttraining's binary_logloss: 0.0164301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[396]\ttraining's binary_logloss: 0.0163086\n",
      "[397]\ttraining's binary_logloss: 0.0161884\n",
      "[398]\ttraining's binary_logloss: 0.0160625\n",
      "[399]\ttraining's binary_logloss: 0.0159455\n",
      "[400]\ttraining's binary_logloss: 0.0158206\n",
      "[401]\ttraining's binary_logloss: 0.0157\n",
      "[402]\ttraining's binary_logloss: 0.0155789\n",
      "[403]\ttraining's binary_logloss: 0.0154607\n",
      "[404]\ttraining's binary_logloss: 0.0153426\n",
      "[405]\ttraining's binary_logloss: 0.0152259\n",
      "[406]\ttraining's binary_logloss: 0.0151091\n",
      "[407]\ttraining's binary_logloss: 0.0149929\n",
      "[408]\ttraining's binary_logloss: 0.0148796\n",
      "[409]\ttraining's binary_logloss: 0.0147623\n",
      "[410]\ttraining's binary_logloss: 0.0146502\n",
      "[411]\ttraining's binary_logloss: 0.0145413\n",
      "[412]\ttraining's binary_logloss: 0.0144362\n",
      "[413]\ttraining's binary_logloss: 0.0143286\n",
      "[414]\ttraining's binary_logloss: 0.0142198\n",
      "[415]\ttraining's binary_logloss: 0.0141239\n",
      "[416]\ttraining's binary_logloss: 0.0140186\n",
      "[417]\ttraining's binary_logloss: 0.0139128\n",
      "[418]\ttraining's binary_logloss: 0.0138017\n",
      "[419]\ttraining's binary_logloss: 0.0137046\n",
      "[420]\ttraining's binary_logloss: 0.0136069\n",
      "[421]\ttraining's binary_logloss: 0.0135029\n",
      "[422]\ttraining's binary_logloss: 0.0134028\n",
      "[423]\ttraining's binary_logloss: 0.0132999\n",
      "[424]\ttraining's binary_logloss: 0.0131975\n",
      "[425]\ttraining's binary_logloss: 0.0130979\n",
      "[426]\ttraining's binary_logloss: 0.0129995\n",
      "[427]\ttraining's binary_logloss: 0.012904\n",
      "[428]\ttraining's binary_logloss: 0.0128033\n",
      "[429]\ttraining's binary_logloss: 0.0127136\n",
      "[430]\ttraining's binary_logloss: 0.0126146\n",
      "[431]\ttraining's binary_logloss: 0.0125212\n",
      "[432]\ttraining's binary_logloss: 0.0124241\n",
      "[433]\ttraining's binary_logloss: 0.0123305\n",
      "[434]\ttraining's binary_logloss: 0.0122348\n",
      "[435]\ttraining's binary_logloss: 0.0121236\n",
      "[436]\ttraining's binary_logloss: 0.012016\n",
      "[437]\ttraining's binary_logloss: 0.011919\n",
      "[438]\ttraining's binary_logloss: 0.0118206\n",
      "[439]\ttraining's binary_logloss: 0.0117187\n",
      "[440]\ttraining's binary_logloss: 0.0116259\n",
      "[441]\ttraining's binary_logloss: 0.0115359\n",
      "[442]\ttraining's binary_logloss: 0.0114464\n",
      "[443]\ttraining's binary_logloss: 0.0113553\n",
      "[444]\ttraining's binary_logloss: 0.011261\n",
      "[445]\ttraining's binary_logloss: 0.0111769\n",
      "[446]\ttraining's binary_logloss: 0.0110875\n",
      "[447]\ttraining's binary_logloss: 0.0109997\n",
      "[448]\ttraining's binary_logloss: 0.0109131\n",
      "[449]\ttraining's binary_logloss: 0.0108244\n",
      "[450]\ttraining's binary_logloss: 0.0107454\n",
      "[451]\ttraining's binary_logloss: 0.0106594\n",
      "[452]\ttraining's binary_logloss: 0.0105764\n",
      "[453]\ttraining's binary_logloss: 0.010495\n",
      "[454]\ttraining's binary_logloss: 0.010414\n",
      "[455]\ttraining's binary_logloss: 0.0103356\n",
      "[456]\ttraining's binary_logloss: 0.010256\n",
      "[457]\ttraining's binary_logloss: 0.0101826\n",
      "[458]\ttraining's binary_logloss: 0.0101069\n",
      "[459]\ttraining's binary_logloss: 0.0100338\n",
      "[460]\ttraining's binary_logloss: 0.00995369\n",
      "[461]\ttraining's binary_logloss: 0.00987729\n",
      "[462]\ttraining's binary_logloss: 0.00979927\n",
      "[463]\ttraining's binary_logloss: 0.00972719\n",
      "[464]\ttraining's binary_logloss: 0.00965655\n",
      "[465]\ttraining's binary_logloss: 0.00958958\n",
      "[466]\ttraining's binary_logloss: 0.00951833\n",
      "[467]\ttraining's binary_logloss: 0.00944965\n",
      "[468]\ttraining's binary_logloss: 0.0093761\n",
      "[469]\ttraining's binary_logloss: 0.00930542\n",
      "[470]\ttraining's binary_logloss: 0.00923198\n",
      "[471]\ttraining's binary_logloss: 0.00916088\n",
      "[472]\ttraining's binary_logloss: 0.00908771\n",
      "[473]\ttraining's binary_logloss: 0.00901988\n",
      "[474]\ttraining's binary_logloss: 0.00895402\n",
      "[475]\ttraining's binary_logloss: 0.00888605\n",
      "[476]\ttraining's binary_logloss: 0.00881833\n",
      "[477]\ttraining's binary_logloss: 0.00875457\n",
      "[478]\ttraining's binary_logloss: 0.00868633\n",
      "[479]\ttraining's binary_logloss: 0.00862282\n",
      "[480]\ttraining's binary_logloss: 0.0085609\n",
      "[481]\ttraining's binary_logloss: 0.00849696\n",
      "[482]\ttraining's binary_logloss: 0.00843481\n",
      "[483]\ttraining's binary_logloss: 0.00837361\n",
      "[484]\ttraining's binary_logloss: 0.00830722\n",
      "[485]\ttraining's binary_logloss: 0.00824393\n",
      "[486]\ttraining's binary_logloss: 0.0081838\n",
      "[487]\ttraining's binary_logloss: 0.00812343\n",
      "[488]\ttraining's binary_logloss: 0.00806065\n",
      "[489]\ttraining's binary_logloss: 0.00799721\n",
      "[490]\ttraining's binary_logloss: 0.00793789\n",
      "[491]\ttraining's binary_logloss: 0.00787337\n",
      "[492]\ttraining's binary_logloss: 0.00781241\n",
      "[493]\ttraining's binary_logloss: 0.00775038\n",
      "[494]\ttraining's binary_logloss: 0.00769436\n",
      "[495]\ttraining's binary_logloss: 0.00763446\n",
      "[496]\ttraining's binary_logloss: 0.00757692\n",
      "[497]\ttraining's binary_logloss: 0.0075195\n",
      "[498]\ttraining's binary_logloss: 0.00746318\n",
      "[499]\ttraining's binary_logloss: 0.00740737\n",
      "[500]\ttraining's binary_logloss: 0.00735041\n",
      "[501]\ttraining's binary_logloss: 0.00729884\n",
      "[502]\ttraining's binary_logloss: 0.00724389\n",
      "[503]\ttraining's binary_logloss: 0.00719009\n",
      "[504]\ttraining's binary_logloss: 0.00713717\n",
      "[505]\ttraining's binary_logloss: 0.00708024\n",
      "[506]\ttraining's binary_logloss: 0.00702735\n",
      "[507]\ttraining's binary_logloss: 0.00697376\n",
      "[508]\ttraining's binary_logloss: 0.00692056\n",
      "[509]\ttraining's binary_logloss: 0.00686662\n",
      "[510]\ttraining's binary_logloss: 0.00681365\n",
      "[511]\ttraining's binary_logloss: 0.00676248\n",
      "[512]\ttraining's binary_logloss: 0.00671352\n",
      "[513]\ttraining's binary_logloss: 0.00665958\n",
      "[514]\ttraining's binary_logloss: 0.0066081\n",
      "[515]\ttraining's binary_logloss: 0.00656117\n",
      "[516]\ttraining's binary_logloss: 0.00651347\n",
      "[517]\ttraining's binary_logloss: 0.00646572\n",
      "[518]\ttraining's binary_logloss: 0.00641729\n",
      "[519]\ttraining's binary_logloss: 0.00637126\n",
      "[520]\ttraining's binary_logloss: 0.00632733\n",
      "[521]\ttraining's binary_logloss: 0.00628047\n",
      "[522]\ttraining's binary_logloss: 0.00623394\n",
      "[523]\ttraining's binary_logloss: 0.00618545\n",
      "[524]\ttraining's binary_logloss: 0.00614251\n",
      "[525]\ttraining's binary_logloss: 0.00609624\n",
      "[526]\ttraining's binary_logloss: 0.00605199\n",
      "[527]\ttraining's binary_logloss: 0.00600674\n",
      "[528]\ttraining's binary_logloss: 0.00595805\n",
      "[529]\ttraining's binary_logloss: 0.00591459\n",
      "[530]\ttraining's binary_logloss: 0.00587135\n",
      "[531]\ttraining's binary_logloss: 0.0058292\n",
      "[532]\ttraining's binary_logloss: 0.00578771\n",
      "[533]\ttraining's binary_logloss: 0.00574617\n",
      "[534]\ttraining's binary_logloss: 0.00570553\n",
      "[535]\ttraining's binary_logloss: 0.00566361\n",
      "[536]\ttraining's binary_logloss: 0.00562273\n",
      "[537]\ttraining's binary_logloss: 0.00558305\n",
      "[538]\ttraining's binary_logloss: 0.00554141\n",
      "[539]\ttraining's binary_logloss: 0.0055018\n",
      "[540]\ttraining's binary_logloss: 0.00546259\n",
      "[541]\ttraining's binary_logloss: 0.00542238\n",
      "[542]\ttraining's binary_logloss: 0.00538263\n",
      "[543]\ttraining's binary_logloss: 0.00534271\n",
      "[544]\ttraining's binary_logloss: 0.00530291\n",
      "[545]\ttraining's binary_logloss: 0.0052648\n",
      "[546]\ttraining's binary_logloss: 0.00522638\n",
      "[547]\ttraining's binary_logloss: 0.00518853\n",
      "[548]\ttraining's binary_logloss: 0.00515006\n",
      "[549]\ttraining's binary_logloss: 0.00511013\n",
      "[550]\ttraining's binary_logloss: 0.00507613\n",
      "[551]\ttraining's binary_logloss: 0.0050393\n",
      "[552]\ttraining's binary_logloss: 0.00500306\n",
      "[553]\ttraining's binary_logloss: 0.00496487\n",
      "[554]\ttraining's binary_logloss: 0.00492896\n",
      "[555]\ttraining's binary_logloss: 0.00489539\n",
      "[556]\ttraining's binary_logloss: 0.00486115\n",
      "[557]\ttraining's binary_logloss: 0.00482578\n",
      "[558]\ttraining's binary_logloss: 0.00479116\n",
      "[559]\ttraining's binary_logloss: 0.00475699\n",
      "[560]\ttraining's binary_logloss: 0.00472517\n",
      "[561]\ttraining's binary_logloss: 0.00468991\n",
      "[562]\ttraining's binary_logloss: 0.00465603\n",
      "[563]\ttraining's binary_logloss: 0.0046219\n",
      "[564]\ttraining's binary_logloss: 0.00458762\n",
      "[565]\ttraining's binary_logloss: 0.00455125\n",
      "[566]\ttraining's binary_logloss: 0.00451594\n",
      "[567]\ttraining's binary_logloss: 0.00448456\n",
      "[568]\ttraining's binary_logloss: 0.00445117\n",
      "[569]\ttraining's binary_logloss: 0.00441999\n",
      "[570]\ttraining's binary_logloss: 0.00439001\n",
      "[571]\ttraining's binary_logloss: 0.00435911\n",
      "[572]\ttraining's binary_logloss: 0.00432921\n",
      "[573]\ttraining's binary_logloss: 0.00429818\n",
      "[574]\ttraining's binary_logloss: 0.00426774\n",
      "[575]\ttraining's binary_logloss: 0.00423699\n",
      "[576]\ttraining's binary_logloss: 0.00420747\n",
      "[577]\ttraining's binary_logloss: 0.00417603\n",
      "[578]\ttraining's binary_logloss: 0.00414608\n",
      "[579]\ttraining's binary_logloss: 0.00411793\n",
      "[580]\ttraining's binary_logloss: 0.00409056\n",
      "[581]\ttraining's binary_logloss: 0.00406136\n",
      "[582]\ttraining's binary_logloss: 0.00403054\n",
      "[583]\ttraining's binary_logloss: 0.004\n",
      "[584]\ttraining's binary_logloss: 0.00397183\n",
      "[585]\ttraining's binary_logloss: 0.00394187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[586]\ttraining's binary_logloss: 0.00391371\n",
      "[587]\ttraining's binary_logloss: 0.00388607\n",
      "[588]\ttraining's binary_logloss: 0.00385704\n",
      "[589]\ttraining's binary_logloss: 0.00382918\n",
      "[590]\ttraining's binary_logloss: 0.0038032\n",
      "[591]\ttraining's binary_logloss: 0.00377537\n",
      "[592]\ttraining's binary_logloss: 0.00374882\n",
      "[593]\ttraining's binary_logloss: 0.00372338\n",
      "[594]\ttraining's binary_logloss: 0.00369763\n",
      "[595]\ttraining's binary_logloss: 0.00367219\n",
      "[596]\ttraining's binary_logloss: 0.00364397\n",
      "[597]\ttraining's binary_logloss: 0.00361821\n",
      "[598]\ttraining's binary_logloss: 0.00359339\n",
      "[599]\ttraining's binary_logloss: 0.0035683\n",
      "[600]\ttraining's binary_logloss: 0.00354372\n",
      "[601]\ttraining's binary_logloss: 0.00351886\n",
      "[602]\ttraining's binary_logloss: 0.00349407\n",
      "[603]\ttraining's binary_logloss: 0.00346782\n",
      "[604]\ttraining's binary_logloss: 0.00344381\n",
      "[605]\ttraining's binary_logloss: 0.0034181\n",
      "[606]\ttraining's binary_logloss: 0.0033936\n",
      "[607]\ttraining's binary_logloss: 0.00337161\n",
      "[608]\ttraining's binary_logloss: 0.00334883\n",
      "[609]\ttraining's binary_logloss: 0.00332562\n",
      "[610]\ttraining's binary_logloss: 0.00330163\n",
      "[611]\ttraining's binary_logloss: 0.00327795\n",
      "[612]\ttraining's binary_logloss: 0.00325575\n",
      "[613]\ttraining's binary_logloss: 0.00323257\n",
      "[614]\ttraining's binary_logloss: 0.00320936\n",
      "[615]\ttraining's binary_logloss: 0.00318666\n",
      "[616]\ttraining's binary_logloss: 0.00316347\n",
      "[617]\ttraining's binary_logloss: 0.00314352\n",
      "[618]\ttraining's binary_logloss: 0.00312075\n",
      "[619]\ttraining's binary_logloss: 0.00310003\n",
      "[620]\ttraining's binary_logloss: 0.00307929\n",
      "[621]\ttraining's binary_logloss: 0.00305845\n",
      "[622]\ttraining's binary_logloss: 0.00303691\n",
      "[623]\ttraining's binary_logloss: 0.00301574\n",
      "[624]\ttraining's binary_logloss: 0.00299553\n",
      "[625]\ttraining's binary_logloss: 0.00297517\n",
      "[626]\ttraining's binary_logloss: 0.00295558\n",
      "[627]\ttraining's binary_logloss: 0.0029367\n",
      "[628]\ttraining's binary_logloss: 0.00291707\n",
      "[629]\ttraining's binary_logloss: 0.00289714\n",
      "[630]\ttraining's binary_logloss: 0.00287716\n",
      "[631]\ttraining's binary_logloss: 0.00285588\n",
      "[632]\ttraining's binary_logloss: 0.00283613\n",
      "[633]\ttraining's binary_logloss: 0.00281519\n",
      "[634]\ttraining's binary_logloss: 0.00279638\n",
      "[635]\ttraining's binary_logloss: 0.00277866\n",
      "[636]\ttraining's binary_logloss: 0.00276052\n",
      "[637]\ttraining's binary_logloss: 0.00274038\n",
      "[638]\ttraining's binary_logloss: 0.0027219\n",
      "[639]\ttraining's binary_logloss: 0.00270207\n",
      "[640]\ttraining's binary_logloss: 0.00268275\n",
      "[641]\ttraining's binary_logloss: 0.00266509\n",
      "[642]\ttraining's binary_logloss: 0.00264655\n",
      "[643]\ttraining's binary_logloss: 0.00262658\n",
      "[644]\ttraining's binary_logloss: 0.00260756\n",
      "[645]\ttraining's binary_logloss: 0.00258937\n",
      "[646]\ttraining's binary_logloss: 0.00257311\n",
      "[647]\ttraining's binary_logloss: 0.00255476\n",
      "[648]\ttraining's binary_logloss: 0.0025377\n",
      "[649]\ttraining's binary_logloss: 0.00252215\n",
      "[650]\ttraining's binary_logloss: 0.0025045\n",
      "[651]\ttraining's binary_logloss: 0.00248768\n",
      "[652]\ttraining's binary_logloss: 0.00247063\n",
      "[653]\ttraining's binary_logloss: 0.00245304\n",
      "[654]\ttraining's binary_logloss: 0.00243707\n",
      "[655]\ttraining's binary_logloss: 0.00242079\n",
      "[656]\ttraining's binary_logloss: 0.00240528\n",
      "[657]\ttraining's binary_logloss: 0.0023891\n",
      "[658]\ttraining's binary_logloss: 0.00237327\n",
      "[659]\ttraining's binary_logloss: 0.0023567\n",
      "[660]\ttraining's binary_logloss: 0.00234169\n",
      "[661]\ttraining's binary_logloss: 0.00232692\n",
      "[662]\ttraining's binary_logloss: 0.00231262\n",
      "[663]\ttraining's binary_logloss: 0.00229565\n",
      "[664]\ttraining's binary_logloss: 0.00228168\n",
      "[665]\ttraining's binary_logloss: 0.00226674\n",
      "[666]\ttraining's binary_logloss: 0.00225148\n",
      "[667]\ttraining's binary_logloss: 0.00223721\n",
      "[668]\ttraining's binary_logloss: 0.00222364\n",
      "[669]\ttraining's binary_logloss: 0.00220935\n",
      "[670]\ttraining's binary_logloss: 0.00219494\n",
      "[671]\ttraining's binary_logloss: 0.00218134\n",
      "[672]\ttraining's binary_logloss: 0.00216819\n",
      "[673]\ttraining's binary_logloss: 0.00215447\n",
      "[674]\ttraining's binary_logloss: 0.00213859\n",
      "[675]\ttraining's binary_logloss: 0.00212494\n",
      "[676]\ttraining's binary_logloss: 0.00211093\n",
      "[677]\ttraining's binary_logloss: 0.00209729\n",
      "[678]\ttraining's binary_logloss: 0.00208409\n",
      "[679]\ttraining's binary_logloss: 0.00207003\n",
      "[680]\ttraining's binary_logloss: 0.00205742\n",
      "[681]\ttraining's binary_logloss: 0.00204289\n",
      "[682]\ttraining's binary_logloss: 0.0020299\n",
      "[683]\ttraining's binary_logloss: 0.00201553\n",
      "[684]\ttraining's binary_logloss: 0.00200205\n",
      "[685]\ttraining's binary_logloss: 0.00198994\n",
      "[686]\ttraining's binary_logloss: 0.00197767\n",
      "[687]\ttraining's binary_logloss: 0.0019655\n",
      "[688]\ttraining's binary_logloss: 0.00195309\n",
      "[689]\ttraining's binary_logloss: 0.00193957\n",
      "[690]\ttraining's binary_logloss: 0.00192792\n",
      "[691]\ttraining's binary_logloss: 0.00191631\n",
      "[692]\ttraining's binary_logloss: 0.00190319\n",
      "[693]\ttraining's binary_logloss: 0.00189036\n",
      "[694]\ttraining's binary_logloss: 0.00187844\n",
      "[695]\ttraining's binary_logloss: 0.00186557\n",
      "[696]\ttraining's binary_logloss: 0.00185324\n",
      "[697]\ttraining's binary_logloss: 0.00184265\n",
      "[698]\ttraining's binary_logloss: 0.00183193\n",
      "[699]\ttraining's binary_logloss: 0.00182106\n",
      "[700]\ttraining's binary_logloss: 0.00180977\n",
      "[701]\ttraining's binary_logloss: 0.001799\n",
      "[702]\ttraining's binary_logloss: 0.00178826\n",
      "[703]\ttraining's binary_logloss: 0.00177617\n",
      "[704]\ttraining's binary_logloss: 0.0017648\n",
      "[705]\ttraining's binary_logloss: 0.00175166\n",
      "[706]\ttraining's binary_logloss: 0.00174199\n",
      "[707]\ttraining's binary_logloss: 0.00173185\n",
      "[708]\ttraining's binary_logloss: 0.00172026\n",
      "[709]\ttraining's binary_logloss: 0.00171021\n",
      "[710]\ttraining's binary_logloss: 0.00169997\n",
      "[711]\ttraining's binary_logloss: 0.00166088\n",
      "[712]\ttraining's binary_logloss: 0.00162726\n",
      "[713]\ttraining's binary_logloss: 0.00160026\n",
      "[714]\ttraining's binary_logloss: 0.00157917\n",
      "[715]\ttraining's binary_logloss: 0.00155891\n",
      "[716]\ttraining's binary_logloss: 0.00153742\n",
      "[717]\ttraining's binary_logloss: 0.00151925\n",
      "[718]\ttraining's binary_logloss: 0.00150183\n",
      "[719]\ttraining's binary_logloss: 0.0014864\n",
      "[720]\ttraining's binary_logloss: 0.00147098\n",
      "[721]\ttraining's binary_logloss: 0.00145558\n",
      "[722]\ttraining's binary_logloss: 0.001442\n",
      "[723]\ttraining's binary_logloss: 0.00142807\n",
      "[724]\ttraining's binary_logloss: 0.00141392\n",
      "[725]\ttraining's binary_logloss: 0.00140134\n",
      "[726]\ttraining's binary_logloss: 0.00138849\n",
      "[727]\ttraining's binary_logloss: 0.00137657\n",
      "[728]\ttraining's binary_logloss: 0.00136481\n",
      "[729]\ttraining's binary_logloss: 0.00135335\n",
      "[730]\ttraining's binary_logloss: 0.00134117\n",
      "[731]\ttraining's binary_logloss: 0.00132954\n",
      "[732]\ttraining's binary_logloss: 0.00131801\n",
      "[733]\ttraining's binary_logloss: 0.00130696\n",
      "[734]\ttraining's binary_logloss: 0.00129615\n",
      "[735]\ttraining's binary_logloss: 0.00128503\n",
      "[736]\ttraining's binary_logloss: 0.00127396\n",
      "[737]\ttraining's binary_logloss: 0.00126359\n",
      "[738]\ttraining's binary_logloss: 0.00125352\n",
      "[739]\ttraining's binary_logloss: 0.00124338\n",
      "[740]\ttraining's binary_logloss: 0.00123319\n",
      "[741]\ttraining's binary_logloss: 0.00122344\n",
      "[742]\ttraining's binary_logloss: 0.00121384\n",
      "[743]\ttraining's binary_logloss: 0.00120416\n",
      "[744]\ttraining's binary_logloss: 0.00119492\n",
      "[745]\ttraining's binary_logloss: 0.0011856\n",
      "[746]\ttraining's binary_logloss: 0.00117625\n",
      "[747]\ttraining's binary_logloss: 0.00116676\n",
      "[748]\ttraining's binary_logloss: 0.00115759\n",
      "[749]\ttraining's binary_logloss: 0.00114864\n",
      "[750]\ttraining's binary_logloss: 0.00114002\n",
      "[751]\ttraining's binary_logloss: 0.00113149\n",
      "[752]\ttraining's binary_logloss: 0.00112303\n",
      "[753]\ttraining's binary_logloss: 0.00111437\n",
      "[754]\ttraining's binary_logloss: 0.00110509\n",
      "[755]\ttraining's binary_logloss: 0.00109621\n",
      "[756]\ttraining's binary_logloss: 0.00108805\n",
      "[757]\ttraining's binary_logloss: 0.0010797\n",
      "[758]\ttraining's binary_logloss: 0.00107133\n",
      "[759]\ttraining's binary_logloss: 0.00106305\n",
      "[760]\ttraining's binary_logloss: 0.00105497\n",
      "[761]\ttraining's binary_logloss: 0.0010466\n",
      "[762]\ttraining's binary_logloss: 0.0010383\n",
      "[763]\ttraining's binary_logloss: 0.00103005\n",
      "[764]\ttraining's binary_logloss: 0.00102244\n",
      "[765]\ttraining's binary_logloss: 0.00101468\n",
      "[766]\ttraining's binary_logloss: 0.00100691\n",
      "[767]\ttraining's binary_logloss: 0.000999504\n",
      "[768]\ttraining's binary_logloss: 0.000991858\n",
      "[769]\ttraining's binary_logloss: 0.000984214\n",
      "[770]\ttraining's binary_logloss: 0.000976777\n",
      "[771]\ttraining's binary_logloss: 0.000968783\n",
      "[772]\ttraining's binary_logloss: 0.000961577\n",
      "[773]\ttraining's binary_logloss: 0.000954919\n",
      "[774]\ttraining's binary_logloss: 0.000947551\n",
      "[775]\ttraining's binary_logloss: 0.000939862\n",
      "[776]\ttraining's binary_logloss: 0.000932297\n",
      "[777]\ttraining's binary_logloss: 0.000924699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[778]\ttraining's binary_logloss: 0.000917744\n",
      "[779]\ttraining's binary_logloss: 0.000911321\n",
      "[780]\ttraining's binary_logloss: 0.000904474\n",
      "[781]\ttraining's binary_logloss: 0.000897863\n",
      "[782]\ttraining's binary_logloss: 0.000891265\n",
      "[783]\ttraining's binary_logloss: 0.000884333\n",
      "[784]\ttraining's binary_logloss: 0.000877636\n",
      "[785]\ttraining's binary_logloss: 0.000871198\n",
      "[786]\ttraining's binary_logloss: 0.000864699\n",
      "[787]\ttraining's binary_logloss: 0.000857901\n",
      "[788]\ttraining's binary_logloss: 0.000851647\n",
      "[789]\ttraining's binary_logloss: 0.000845216\n",
      "[790]\ttraining's binary_logloss: 0.000838978\n",
      "[791]\ttraining's binary_logloss: 0.000832331\n",
      "[792]\ttraining's binary_logloss: 0.000826494\n",
      "[793]\ttraining's binary_logloss: 0.000820733\n",
      "[794]\ttraining's binary_logloss: 0.000814784\n",
      "[795]\ttraining's binary_logloss: 0.000808437\n",
      "[796]\ttraining's binary_logloss: 0.000802418\n",
      "[797]\ttraining's binary_logloss: 0.000796565\n",
      "[798]\ttraining's binary_logloss: 0.000790911\n",
      "[799]\ttraining's binary_logloss: 0.000784638\n",
      "[800]\ttraining's binary_logloss: 0.000778713\n",
      "[801]\ttraining's binary_logloss: 0.000772973\n",
      "[802]\ttraining's binary_logloss: 0.00076701\n",
      "[803]\ttraining's binary_logloss: 0.000761176\n",
      "[804]\ttraining's binary_logloss: 0.000755599\n",
      "[805]\ttraining's binary_logloss: 0.000749759\n",
      "[806]\ttraining's binary_logloss: 0.000744452\n",
      "[807]\ttraining's binary_logloss: 0.000739323\n",
      "[808]\ttraining's binary_logloss: 0.00073385\n",
      "[809]\ttraining's binary_logloss: 0.000728736\n",
      "[810]\ttraining's binary_logloss: 0.000722985\n",
      "[811]\ttraining's binary_logloss: 0.000718112\n",
      "[812]\ttraining's binary_logloss: 0.00071334\n",
      "[813]\ttraining's binary_logloss: 0.000708243\n",
      "[814]\ttraining's binary_logloss: 0.000702684\n",
      "[815]\ttraining's binary_logloss: 0.000697325\n",
      "[816]\ttraining's binary_logloss: 0.000692405\n",
      "[817]\ttraining's binary_logloss: 0.000687453\n",
      "[818]\ttraining's binary_logloss: 0.000682462\n",
      "[819]\ttraining's binary_logloss: 0.000677327\n",
      "[820]\ttraining's binary_logloss: 0.000672635\n",
      "[821]\ttraining's binary_logloss: 0.000667608\n",
      "[822]\ttraining's binary_logloss: 0.00066288\n",
      "[823]\ttraining's binary_logloss: 0.000658221\n",
      "[824]\ttraining's binary_logloss: 0.00065338\n",
      "[825]\ttraining's binary_logloss: 0.00064861\n",
      "[826]\ttraining's binary_logloss: 0.000644019\n",
      "[827]\ttraining's binary_logloss: 0.000639143\n",
      "[828]\ttraining's binary_logloss: 0.000634421\n",
      "[829]\ttraining's binary_logloss: 0.000630201\n",
      "[830]\ttraining's binary_logloss: 0.000625477\n",
      "[831]\ttraining's binary_logloss: 0.000620447\n",
      "[832]\ttraining's binary_logloss: 0.000616003\n",
      "[833]\ttraining's binary_logloss: 0.000611747\n",
      "[834]\ttraining's binary_logloss: 0.000607026\n",
      "[835]\ttraining's binary_logloss: 0.000602484\n",
      "[836]\ttraining's binary_logloss: 0.000598051\n",
      "[837]\ttraining's binary_logloss: 0.000593345\n",
      "[838]\ttraining's binary_logloss: 0.000589302\n",
      "[839]\ttraining's binary_logloss: 0.000585161\n",
      "[840]\ttraining's binary_logloss: 0.000580567\n",
      "[841]\ttraining's binary_logloss: 0.000576252\n",
      "[842]\ttraining's binary_logloss: 0.000571955\n",
      "[843]\ttraining's binary_logloss: 0.000567972\n",
      "[844]\ttraining's binary_logloss: 0.000564017\n",
      "[845]\ttraining's binary_logloss: 0.00055966\n",
      "[846]\ttraining's binary_logloss: 0.000555725\n",
      "[847]\ttraining's binary_logloss: 0.000551606\n",
      "[848]\ttraining's binary_logloss: 0.000547293\n",
      "[849]\ttraining's binary_logloss: 0.000543114\n",
      "[850]\ttraining's binary_logloss: 0.000539148\n",
      "[851]\ttraining's binary_logloss: 0.000535376\n",
      "[852]\ttraining's binary_logloss: 0.00053135\n",
      "[853]\ttraining's binary_logloss: 0.000527699\n",
      "[854]\ttraining's binary_logloss: 0.000523941\n",
      "[855]\ttraining's binary_logloss: 0.000519949\n",
      "[856]\ttraining's binary_logloss: 0.000515916\n",
      "[857]\ttraining's binary_logloss: 0.000511905\n",
      "[858]\ttraining's binary_logloss: 0.000507825\n",
      "[859]\ttraining's binary_logloss: 0.000504474\n",
      "[860]\ttraining's binary_logloss: 0.0005009\n",
      "[861]\ttraining's binary_logloss: 0.000497022\n",
      "[862]\ttraining's binary_logloss: 0.000493305\n",
      "[863]\ttraining's binary_logloss: 0.000490132\n",
      "[864]\ttraining's binary_logloss: 0.00048681\n",
      "[865]\ttraining's binary_logloss: 0.000483234\n",
      "[866]\ttraining's binary_logloss: 0.00048003\n",
      "[867]\ttraining's binary_logloss: 0.000476749\n",
      "[868]\ttraining's binary_logloss: 0.000473258\n",
      "[869]\ttraining's binary_logloss: 0.000469671\n",
      "[870]\ttraining's binary_logloss: 0.000466161\n",
      "[871]\ttraining's binary_logloss: 0.000462991\n",
      "[872]\ttraining's binary_logloss: 0.00045941\n",
      "[873]\ttraining's binary_logloss: 0.000456185\n",
      "[874]\ttraining's binary_logloss: 0.000452731\n",
      "[875]\ttraining's binary_logloss: 0.000449778\n",
      "[876]\ttraining's binary_logloss: 0.000446368\n",
      "[877]\ttraining's binary_logloss: 0.000443031\n",
      "[878]\ttraining's binary_logloss: 0.000440004\n",
      "[879]\ttraining's binary_logloss: 0.000436703\n",
      "[880]\ttraining's binary_logloss: 0.000433447\n",
      "[881]\ttraining's binary_logloss: 0.000430577\n",
      "[882]\ttraining's binary_logloss: 0.000427592\n",
      "[883]\ttraining's binary_logloss: 0.00042445\n",
      "[884]\ttraining's binary_logloss: 0.000420946\n",
      "[885]\ttraining's binary_logloss: 0.000417693\n",
      "[886]\ttraining's binary_logloss: 0.000414996\n",
      "[887]\ttraining's binary_logloss: 0.000412251\n",
      "[888]\ttraining's binary_logloss: 0.000409453\n",
      "[889]\ttraining's binary_logloss: 0.000406656\n",
      "[890]\ttraining's binary_logloss: 0.000403647\n",
      "[891]\ttraining's binary_logloss: 0.00040048\n",
      "[892]\ttraining's binary_logloss: 0.000397256\n",
      "[893]\ttraining's binary_logloss: 0.00039452\n",
      "[894]\ttraining's binary_logloss: 0.000391409\n",
      "[895]\ttraining's binary_logloss: 0.000388487\n",
      "[896]\ttraining's binary_logloss: 0.000385862\n",
      "[897]\ttraining's binary_logloss: 0.000383004\n",
      "[898]\ttraining's binary_logloss: 0.000380455\n",
      "[899]\ttraining's binary_logloss: 0.000377607\n",
      "[900]\ttraining's binary_logloss: 0.000375149\n",
      "[901]\ttraining's binary_logloss: 0.000372606\n",
      "[902]\ttraining's binary_logloss: 0.000370192\n",
      "[903]\ttraining's binary_logloss: 0.000367834\n",
      "[904]\ttraining's binary_logloss: 0.000365632\n",
      "[905]\ttraining's binary_logloss: 0.000363218\n",
      "[906]\ttraining's binary_logloss: 0.00036048\n",
      "[907]\ttraining's binary_logloss: 0.000358135\n",
      "[908]\ttraining's binary_logloss: 0.000355512\n",
      "[909]\ttraining's binary_logloss: 0.000353182\n",
      "[910]\ttraining's binary_logloss: 0.00035043\n",
      "[911]\ttraining's binary_logloss: 0.000347701\n",
      "[912]\ttraining's binary_logloss: 0.000345516\n",
      "[913]\ttraining's binary_logloss: 0.000342875\n",
      "[914]\ttraining's binary_logloss: 0.000340628\n",
      "[915]\ttraining's binary_logloss: 0.000338504\n",
      "[916]\ttraining's binary_logloss: 0.000336038\n",
      "[917]\ttraining's binary_logloss: 0.000333332\n",
      "[918]\ttraining's binary_logloss: 0.000331141\n",
      "[919]\ttraining's binary_logloss: 0.000329207\n",
      "[920]\ttraining's binary_logloss: 0.000326972\n",
      "[921]\ttraining's binary_logloss: 0.000324642\n",
      "[922]\ttraining's binary_logloss: 0.000322146\n",
      "[923]\ttraining's binary_logloss: 0.000319782\n",
      "[924]\ttraining's binary_logloss: 0.000317598\n",
      "[925]\ttraining's binary_logloss: 0.000315179\n",
      "[926]\ttraining's binary_logloss: 0.000313192\n",
      "[927]\ttraining's binary_logloss: 0.000311033\n",
      "[928]\ttraining's binary_logloss: 0.000308732\n",
      "[929]\ttraining's binary_logloss: 0.000306521\n",
      "[930]\ttraining's binary_logloss: 0.000304546\n",
      "[931]\ttraining's binary_logloss: 0.00030266\n",
      "[932]\ttraining's binary_logloss: 0.000300747\n",
      "[933]\ttraining's binary_logloss: 0.000298449\n",
      "[934]\ttraining's binary_logloss: 0.000296555\n",
      "[935]\ttraining's binary_logloss: 0.000294369\n",
      "[936]\ttraining's binary_logloss: 0.000292591\n",
      "[937]\ttraining's binary_logloss: 0.000290401\n",
      "[938]\ttraining's binary_logloss: 0.000288247\n",
      "[939]\ttraining's binary_logloss: 0.000286485\n",
      "[940]\ttraining's binary_logloss: 0.000284362\n",
      "[941]\ttraining's binary_logloss: 0.000282199\n",
      "[942]\ttraining's binary_logloss: 0.000280158\n",
      "[943]\ttraining's binary_logloss: 0.00027857\n",
      "[944]\ttraining's binary_logloss: 0.000276653\n",
      "[945]\ttraining's binary_logloss: 0.000274936\n",
      "[946]\ttraining's binary_logloss: 0.000272895\n",
      "[947]\ttraining's binary_logloss: 0.00027124\n",
      "[948]\ttraining's binary_logloss: 0.000269126\n",
      "[949]\ttraining's binary_logloss: 0.000267523\n",
      "[950]\ttraining's binary_logloss: 0.000265377\n",
      "[951]\ttraining's binary_logloss: 0.000263492\n",
      "[952]\ttraining's binary_logloss: 0.000261398\n",
      "[953]\ttraining's binary_logloss: 0.000259519\n",
      "[954]\ttraining's binary_logloss: 0.00025756\n",
      "[955]\ttraining's binary_logloss: 0.000255683\n",
      "[956]\ttraining's binary_logloss: 0.000253662\n",
      "[957]\ttraining's binary_logloss: 0.000252104\n",
      "[958]\ttraining's binary_logloss: 0.000250617\n",
      "[959]\ttraining's binary_logloss: 0.000249074\n",
      "[960]\ttraining's binary_logloss: 0.000247431\n",
      "[961]\ttraining's binary_logloss: 0.000245759\n",
      "[962]\ttraining's binary_logloss: 0.000244181\n",
      "[963]\ttraining's binary_logloss: 0.000242473\n",
      "[964]\ttraining's binary_logloss: 0.000240642\n",
      "[965]\ttraining's binary_logloss: 0.000238839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[966]\ttraining's binary_logloss: 0.000237133\n",
      "[967]\ttraining's binary_logloss: 0.000235747\n",
      "[968]\ttraining's binary_logloss: 0.000234227\n",
      "[969]\ttraining's binary_logloss: 0.000232402\n",
      "[970]\ttraining's binary_logloss: 0.000231023\n",
      "[971]\ttraining's binary_logloss: 0.000229196\n",
      "[972]\ttraining's binary_logloss: 0.000227612\n",
      "[973]\ttraining's binary_logloss: 0.00022639\n",
      "[974]\ttraining's binary_logloss: 0.000225063\n",
      "[975]\ttraining's binary_logloss: 0.000223813\n",
      "[976]\ttraining's binary_logloss: 0.000222086\n",
      "[977]\ttraining's binary_logloss: 0.000220834\n",
      "[978]\ttraining's binary_logloss: 0.000219167\n",
      "[979]\ttraining's binary_logloss: 0.000217519\n",
      "[980]\ttraining's binary_logloss: 0.000216224\n",
      "[981]\ttraining's binary_logloss: 0.000214986\n",
      "[982]\ttraining's binary_logloss: 0.000213927\n",
      "[983]\ttraining's binary_logloss: 0.000212762\n",
      "[984]\ttraining's binary_logloss: 0.000211161\n",
      "[985]\ttraining's binary_logloss: 0.000209501\n",
      "[986]\ttraining's binary_logloss: 0.000207771\n",
      "[987]\ttraining's binary_logloss: 0.000206628\n",
      "[988]\ttraining's binary_logloss: 0.000205247\n",
      "[989]\ttraining's binary_logloss: 0.000203633\n",
      "[990]\ttraining's binary_logloss: 0.000202256\n",
      "[991]\ttraining's binary_logloss: 0.000201047\n",
      "[992]\ttraining's binary_logloss: 0.000199609\n",
      "[993]\ttraining's binary_logloss: 0.000198428\n",
      "[994]\ttraining's binary_logloss: 0.000196885\n",
      "[995]\ttraining's binary_logloss: 0.000195703\n",
      "[996]\ttraining's binary_logloss: 0.000194197\n",
      "[997]\ttraining's binary_logloss: 0.000193169\n",
      "[998]\ttraining's binary_logloss: 0.000192135\n",
      "[999]\ttraining's binary_logloss: 0.000191064\n",
      "[1000]\ttraining's binary_logloss: 0.00018982\n",
      "[1001]\ttraining's binary_logloss: 0.000188895\n",
      "[1002]\ttraining's binary_logloss: 0.000187462\n",
      "[1003]\ttraining's binary_logloss: 0.000185962\n",
      "[1004]\ttraining's binary_logloss: 0.000184683\n",
      "[1005]\ttraining's binary_logloss: 0.000183597\n",
      "[1006]\ttraining's binary_logloss: 0.00018222\n",
      "[1007]\ttraining's binary_logloss: 0.000180717\n",
      "[1008]\ttraining's binary_logloss: 0.000179688\n",
      "[1009]\ttraining's binary_logloss: 0.000178289\n",
      "[1010]\ttraining's binary_logloss: 0.000177166\n",
      "[1011]\ttraining's binary_logloss: 0.000176184\n",
      "[1012]\ttraining's binary_logloss: 0.000174946\n",
      "[1013]\ttraining's binary_logloss: 0.000173952\n",
      "[1014]\ttraining's binary_logloss: 0.000172987\n",
      "[1015]\ttraining's binary_logloss: 0.000172078\n",
      "[1016]\ttraining's binary_logloss: 0.000170934\n",
      "[1017]\ttraining's binary_logloss: 0.000169576\n",
      "[1018]\ttraining's binary_logloss: 0.00016877\n",
      "[1019]\ttraining's binary_logloss: 0.000167523\n",
      "[1020]\ttraining's binary_logloss: 0.000166785\n",
      "[1021]\ttraining's binary_logloss: 0.000165559\n",
      "[1022]\ttraining's binary_logloss: 0.000164763\n",
      "[1023]\ttraining's binary_logloss: 0.000163813\n",
      "[1024]\ttraining's binary_logloss: 0.000162712\n",
      "[1025]\ttraining's binary_logloss: 0.000161927\n",
      "[1026]\ttraining's binary_logloss: 0.000161059\n",
      "[1027]\ttraining's binary_logloss: 0.000160241\n",
      "[1028]\ttraining's binary_logloss: 0.000159293\n",
      "[1029]\ttraining's binary_logloss: 0.00015809\n",
      "[1030]\ttraining's binary_logloss: 0.000157465\n",
      "[1031]\ttraining's binary_logloss: 0.000156185\n",
      "[1032]\ttraining's binary_logloss: 0.000155452\n",
      "[1033]\ttraining's binary_logloss: 0.000154567\n",
      "[1034]\ttraining's binary_logloss: 0.000153342\n",
      "[1035]\ttraining's binary_logloss: 0.000152744\n",
      "[1036]\ttraining's binary_logloss: 0.000151865\n",
      "[1037]\ttraining's binary_logloss: 0.000150617\n",
      "[1038]\ttraining's binary_logloss: 0.000149472\n",
      "[1039]\ttraining's binary_logloss: 0.000148805\n",
      "[1040]\ttraining's binary_logloss: 0.000147942\n",
      "[1041]\ttraining's binary_logloss: 0.00014698\n",
      "[1042]\ttraining's binary_logloss: 0.000146404\n",
      "[1043]\ttraining's binary_logloss: 0.000145496\n",
      "[1044]\ttraining's binary_logloss: 0.000144661\n",
      "[1045]\ttraining's binary_logloss: 0.000143821\n",
      "[1046]\ttraining's binary_logloss: 0.000143189\n",
      "[1047]\ttraining's binary_logloss: 0.000142133\n",
      "[1048]\ttraining's binary_logloss: 0.000141208\n",
      "[1049]\ttraining's binary_logloss: 0.000140313\n",
      "[1050]\ttraining's binary_logloss: 0.000139267\n",
      "[1051]\ttraining's binary_logloss: 0.000138726\n",
      "[1052]\ttraining's binary_logloss: 0.000137814\n",
      "[1053]\ttraining's binary_logloss: 0.000137177\n",
      "[1054]\ttraining's binary_logloss: 0.000136201\n",
      "[1055]\ttraining's binary_logloss: 0.000135274\n",
      "[1056]\ttraining's binary_logloss: 0.00013419\n",
      "[1057]\ttraining's binary_logloss: 0.000133687\n",
      "[1058]\ttraining's binary_logloss: 0.000132644\n",
      "[1059]\ttraining's binary_logloss: 0.000131979\n",
      "[1060]\ttraining's binary_logloss: 0.000130848\n",
      "[1061]\ttraining's binary_logloss: 0.000129722\n",
      "[1062]\ttraining's binary_logloss: 0.000129292\n",
      "[1063]\ttraining's binary_logloss: 0.0001285\n",
      "[1064]\ttraining's binary_logloss: 0.000128057\n",
      "[1065]\ttraining's binary_logloss: 0.00012717\n",
      "[1066]\ttraining's binary_logloss: 0.00012671\n",
      "[1067]\ttraining's binary_logloss: 0.000126249\n",
      "[1068]\ttraining's binary_logloss: 0.000125332\n",
      "[1069]\ttraining's binary_logloss: 0.000124886\n",
      "[1070]\ttraining's binary_logloss: 0.000124504\n",
      "[1071]\ttraining's binary_logloss: 0.000124019\n",
      "[1072]\ttraining's binary_logloss: 0.000123596\n",
      "[1073]\ttraining's binary_logloss: 0.000123159\n",
      "[1074]\ttraining's binary_logloss: 0.000122693\n",
      "[1075]\ttraining's binary_logloss: 0.000121662\n",
      "[1076]\ttraining's binary_logloss: 0.000120922\n",
      "[1077]\ttraining's binary_logloss: 0.000120465\n",
      "[1078]\ttraining's binary_logloss: 0.00011936\n",
      "[1079]\ttraining's binary_logloss: 0.00011844\n",
      "[1080]\ttraining's binary_logloss: 0.000117949\n",
      "[1081]\ttraining's binary_logloss: 0.000117229\n",
      "[1082]\ttraining's binary_logloss: 0.000116888\n",
      "[1083]\ttraining's binary_logloss: 0.000115975\n",
      "[1084]\ttraining's binary_logloss: 0.00011557\n",
      "[1085]\ttraining's binary_logloss: 0.000115255\n",
      "[1086]\ttraining's binary_logloss: 0.000114934\n",
      "[1087]\ttraining's binary_logloss: 0.000114685\n",
      "[1088]\ttraining's binary_logloss: 0.000113702\n",
      "[1089]\ttraining's binary_logloss: 0.000112856\n",
      "[1090]\ttraining's binary_logloss: 0.000111809\n",
      "[1091]\ttraining's binary_logloss: 0.000111122\n",
      "[1092]\ttraining's binary_logloss: 0.000110345\n",
      "[1093]\ttraining's binary_logloss: 0.000109413\n",
      "[1094]\ttraining's binary_logloss: 0.000108638\n",
      "[1095]\ttraining's binary_logloss: 0.000107685\n",
      "[1096]\ttraining's binary_logloss: 0.000107159\n",
      "[1097]\ttraining's binary_logloss: 0.000106354\n",
      "[1098]\ttraining's binary_logloss: 0.000105567\n",
      "[1099]\ttraining's binary_logloss: 0.000104773\n",
      "[1100]\ttraining's binary_logloss: 0.000104478\n",
      "[1101]\ttraining's binary_logloss: 0.000103536\n",
      "[1102]\ttraining's binary_logloss: 0.000103195\n",
      "[1103]\ttraining's binary_logloss: 0.000102459\n",
      "[1104]\ttraining's binary_logloss: 0.000101619\n",
      "[1105]\ttraining's binary_logloss: 0.000101226\n",
      "[1106]\ttraining's binary_logloss: 0.000100339\n",
      "[1107]\ttraining's binary_logloss: 0.000100077\n",
      "[1108]\ttraining's binary_logloss: 9.94696e-05\n",
      "[1109]\ttraining's binary_logloss: 9.87492e-05\n",
      "[1110]\ttraining's binary_logloss: 9.78944e-05\n",
      "[1111]\ttraining's binary_logloss: 9.75052e-05\n",
      "[1112]\ttraining's binary_logloss: 9.70236e-05\n",
      "[1113]\ttraining's binary_logloss: 9.61892e-05\n",
      "[1114]\ttraining's binary_logloss: 9.56606e-05\n",
      "[1115]\ttraining's binary_logloss: 9.48396e-05\n",
      "[1116]\ttraining's binary_logloss: 9.40722e-05\n",
      "[1117]\ttraining's binary_logloss: 9.34058e-05\n",
      "[1118]\ttraining's binary_logloss: 9.255e-05\n",
      "[1119]\ttraining's binary_logloss: 9.18932e-05\n",
      "[1120]\ttraining's binary_logloss: 9.14164e-05\n",
      "[1121]\ttraining's binary_logloss: 9.1085e-05\n",
      "[1122]\ttraining's binary_logloss: 9.09619e-05\n",
      "[1123]\ttraining's binary_logloss: 9.08088e-05\n",
      "[1124]\ttraining's binary_logloss: 9.01153e-05\n",
      "[1125]\ttraining's binary_logloss: 8.94244e-05\n",
      "[1126]\ttraining's binary_logloss: 8.87134e-05\n",
      "[1127]\ttraining's binary_logloss: 8.85982e-05\n",
      "[1128]\ttraining's binary_logloss: 8.84456e-05\n",
      "[1129]\ttraining's binary_logloss: 8.76789e-05\n",
      "[1130]\ttraining's binary_logloss: 8.68932e-05\n",
      "[1131]\ttraining's binary_logloss: 8.61358e-05\n",
      "[1132]\ttraining's binary_logloss: 8.53242e-05\n",
      "[1133]\ttraining's binary_logloss: 8.46742e-05\n",
      "[1134]\ttraining's binary_logloss: 8.39233e-05\n",
      "[1135]\ttraining's binary_logloss: 8.34557e-05\n",
      "[1136]\ttraining's binary_logloss: 8.29668e-05\n",
      "[1137]\ttraining's binary_logloss: 8.2726e-05\n",
      "[1138]\ttraining's binary_logloss: 8.19687e-05\n",
      "[1139]\ttraining's binary_logloss: 8.12392e-05\n",
      "[1140]\ttraining's binary_logloss: 8.10243e-05\n",
      "[1141]\ttraining's binary_logloss: 8.07194e-05\n",
      "[1142]\ttraining's binary_logloss: 8.01353e-05\n",
      "[1143]\ttraining's binary_logloss: 7.98742e-05\n",
      "[1144]\ttraining's binary_logloss: 7.90943e-05\n",
      "[1145]\ttraining's binary_logloss: 7.81338e-05\n",
      "[1146]\ttraining's binary_logloss: 7.72333e-05\n",
      "[1147]\ttraining's binary_logloss: 7.62974e-05\n",
      "[1148]\ttraining's binary_logloss: 7.54405e-05\n",
      "[1149]\ttraining's binary_logloss: 7.45554e-05\n",
      "[1150]\ttraining's binary_logloss: 7.3704e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1151]\ttraining's binary_logloss: 7.28559e-05\n",
      "[1152]\ttraining's binary_logloss: 7.2054e-05\n",
      "[1153]\ttraining's binary_logloss: 7.12271e-05\n",
      "[1154]\ttraining's binary_logloss: 7.04427e-05\n",
      "[1155]\ttraining's binary_logloss: 6.96573e-05\n",
      "[1156]\ttraining's binary_logloss: 6.8886e-05\n",
      "[1157]\ttraining's binary_logloss: 6.81261e-05\n",
      "[1158]\ttraining's binary_logloss: 6.74114e-05\n",
      "[1159]\ttraining's binary_logloss: 6.67075e-05\n",
      "[1160]\ttraining's binary_logloss: 6.60037e-05\n",
      "[1161]\ttraining's binary_logloss: 6.53071e-05\n",
      "[1162]\ttraining's binary_logloss: 6.46151e-05\n",
      "[1163]\ttraining's binary_logloss: 6.39462e-05\n",
      "[1164]\ttraining's binary_logloss: 6.32633e-05\n",
      "[1165]\ttraining's binary_logloss: 6.25969e-05\n",
      "[1166]\ttraining's binary_logloss: 6.19462e-05\n",
      "[1167]\ttraining's binary_logloss: 6.13293e-05\n",
      "[1168]\ttraining's binary_logloss: 6.06975e-05\n",
      "[1169]\ttraining's binary_logloss: 6.00733e-05\n",
      "[1170]\ttraining's binary_logloss: 5.94693e-05\n",
      "[1171]\ttraining's binary_logloss: 5.88608e-05\n",
      "[1172]\ttraining's binary_logloss: 5.82693e-05\n",
      "[1173]\ttraining's binary_logloss: 5.76909e-05\n",
      "[1174]\ttraining's binary_logloss: 5.71327e-05\n",
      "[1175]\ttraining's binary_logloss: 5.65633e-05\n",
      "[1176]\ttraining's binary_logloss: 5.60328e-05\n",
      "[1177]\ttraining's binary_logloss: 5.55119e-05\n",
      "[1178]\ttraining's binary_logloss: 5.49711e-05\n",
      "[1179]\ttraining's binary_logloss: 5.44623e-05\n",
      "[1180]\ttraining's binary_logloss: 5.39478e-05\n",
      "[1181]\ttraining's binary_logloss: 5.34326e-05\n",
      "[1182]\ttraining's binary_logloss: 5.29374e-05\n",
      "[1183]\ttraining's binary_logloss: 5.24521e-05\n",
      "[1184]\ttraining's binary_logloss: 5.19486e-05\n",
      "[1185]\ttraining's binary_logloss: 5.14775e-05\n",
      "[1186]\ttraining's binary_logloss: 5.10039e-05\n",
      "[1187]\ttraining's binary_logloss: 5.05449e-05\n",
      "[1188]\ttraining's binary_logloss: 5.00768e-05\n",
      "[1189]\ttraining's binary_logloss: 4.96186e-05\n",
      "[1190]\ttraining's binary_logloss: 4.91684e-05\n",
      "[1191]\ttraining's binary_logloss: 4.87261e-05\n",
      "[1192]\ttraining's binary_logloss: 4.82923e-05\n",
      "[1193]\ttraining's binary_logloss: 4.78685e-05\n",
      "[1194]\ttraining's binary_logloss: 4.74448e-05\n",
      "[1195]\ttraining's binary_logloss: 4.70299e-05\n",
      "[1196]\ttraining's binary_logloss: 4.66172e-05\n",
      "[1197]\ttraining's binary_logloss: 4.6212e-05\n",
      "[1198]\ttraining's binary_logloss: 4.57995e-05\n",
      "[1199]\ttraining's binary_logloss: 4.54102e-05\n",
      "[1200]\ttraining's binary_logloss: 4.50222e-05\n",
      "[1201]\ttraining's binary_logloss: 4.46512e-05\n",
      "[1202]\ttraining's binary_logloss: 4.42796e-05\n",
      "[1203]\ttraining's binary_logloss: 4.39024e-05\n",
      "[1204]\ttraining's binary_logloss: 4.35465e-05\n",
      "[1205]\ttraining's binary_logloss: 4.31735e-05\n",
      "[1206]\ttraining's binary_logloss: 4.28058e-05\n",
      "[1207]\ttraining's binary_logloss: 4.24326e-05\n",
      "[1208]\ttraining's binary_logloss: 4.20718e-05\n",
      "[1209]\ttraining's binary_logloss: 4.17269e-05\n",
      "[1210]\ttraining's binary_logloss: 4.13774e-05\n",
      "[1211]\ttraining's binary_logloss: 4.10528e-05\n",
      "[1212]\ttraining's binary_logloss: 4.07227e-05\n",
      "[1213]\ttraining's binary_logloss: 4.03887e-05\n",
      "[1214]\ttraining's binary_logloss: 4.00509e-05\n",
      "[1215]\ttraining's binary_logloss: 3.97292e-05\n",
      "[1216]\ttraining's binary_logloss: 3.94052e-05\n",
      "[1217]\ttraining's binary_logloss: 3.90771e-05\n",
      "[1218]\ttraining's binary_logloss: 3.876e-05\n",
      "[1219]\ttraining's binary_logloss: 3.84541e-05\n",
      "[1220]\ttraining's binary_logloss: 3.81625e-05\n",
      "[1221]\ttraining's binary_logloss: 3.7872e-05\n",
      "[1222]\ttraining's binary_logloss: 3.75833e-05\n",
      "[1223]\ttraining's binary_logloss: 3.72891e-05\n",
      "[1224]\ttraining's binary_logloss: 3.69994e-05\n",
      "[1225]\ttraining's binary_logloss: 3.67186e-05\n",
      "[1226]\ttraining's binary_logloss: 3.64322e-05\n",
      "[1227]\ttraining's binary_logloss: 3.61573e-05\n",
      "[1228]\ttraining's binary_logloss: 3.58792e-05\n",
      "[1229]\ttraining's binary_logloss: 3.56231e-05\n",
      "[1230]\ttraining's binary_logloss: 3.53477e-05\n",
      "[1231]\ttraining's binary_logloss: 3.50716e-05\n",
      "[1232]\ttraining's binary_logloss: 3.48179e-05\n",
      "[1233]\ttraining's binary_logloss: 3.45483e-05\n",
      "[1234]\ttraining's binary_logloss: 3.42866e-05\n",
      "[1235]\ttraining's binary_logloss: 3.40284e-05\n",
      "[1236]\ttraining's binary_logloss: 3.37778e-05\n",
      "[1237]\ttraining's binary_logloss: 3.35366e-05\n",
      "[1238]\ttraining's binary_logloss: 3.32917e-05\n",
      "[1239]\ttraining's binary_logloss: 3.30542e-05\n",
      "[1240]\ttraining's binary_logloss: 3.2814e-05\n",
      "[1241]\ttraining's binary_logloss: 3.25822e-05\n",
      "[1242]\ttraining's binary_logloss: 3.23505e-05\n",
      "[1243]\ttraining's binary_logloss: 3.21223e-05\n",
      "[1244]\ttraining's binary_logloss: 3.18993e-05\n",
      "[1245]\ttraining's binary_logloss: 3.16738e-05\n",
      "[1246]\ttraining's binary_logloss: 3.14519e-05\n",
      "[1247]\ttraining's binary_logloss: 3.12348e-05\n",
      "[1248]\ttraining's binary_logloss: 3.10037e-05\n",
      "[1249]\ttraining's binary_logloss: 3.07882e-05\n",
      "[1250]\ttraining's binary_logloss: 3.05747e-05\n",
      "[1251]\ttraining's binary_logloss: 3.03741e-05\n",
      "[1252]\ttraining's binary_logloss: 3.01624e-05\n",
      "[1253]\ttraining's binary_logloss: 2.99561e-05\n",
      "[1254]\ttraining's binary_logloss: 2.97473e-05\n",
      "[1255]\ttraining's binary_logloss: 2.95527e-05\n",
      "[1256]\ttraining's binary_logloss: 2.93546e-05\n",
      "[1257]\ttraining's binary_logloss: 2.91539e-05\n",
      "[1258]\ttraining's binary_logloss: 2.89582e-05\n",
      "[1259]\ttraining's binary_logloss: 2.8763e-05\n",
      "[1260]\ttraining's binary_logloss: 2.85671e-05\n",
      "[1261]\ttraining's binary_logloss: 2.83706e-05\n",
      "[1262]\ttraining's binary_logloss: 2.81781e-05\n",
      "[1263]\ttraining's binary_logloss: 2.79929e-05\n",
      "[1264]\ttraining's binary_logloss: 2.78064e-05\n",
      "[1265]\ttraining's binary_logloss: 2.76251e-05\n",
      "[1266]\ttraining's binary_logloss: 2.74473e-05\n",
      "[1267]\ttraining's binary_logloss: 2.72797e-05\n",
      "[1268]\ttraining's binary_logloss: 2.71134e-05\n",
      "[1269]\ttraining's binary_logloss: 2.69423e-05\n",
      "[1270]\ttraining's binary_logloss: 2.67797e-05\n",
      "[1271]\ttraining's binary_logloss: 2.661e-05\n",
      "[1272]\ttraining's binary_logloss: 2.64562e-05\n",
      "[1273]\ttraining's binary_logloss: 2.63018e-05\n",
      "[1274]\ttraining's binary_logloss: 2.61436e-05\n",
      "[1275]\ttraining's binary_logloss: 2.59879e-05\n",
      "[1276]\ttraining's binary_logloss: 2.58372e-05\n",
      "[1277]\ttraining's binary_logloss: 2.56866e-05\n",
      "[1278]\ttraining's binary_logloss: 2.55236e-05\n",
      "[1279]\ttraining's binary_logloss: 2.53639e-05\n",
      "[1280]\ttraining's binary_logloss: 2.52121e-05\n",
      "[1281]\ttraining's binary_logloss: 2.5061e-05\n",
      "[1282]\ttraining's binary_logloss: 2.49033e-05\n",
      "[1283]\ttraining's binary_logloss: 2.47616e-05\n",
      "[1284]\ttraining's binary_logloss: 2.46235e-05\n",
      "[1285]\ttraining's binary_logloss: 2.44777e-05\n",
      "[1286]\ttraining's binary_logloss: 2.43309e-05\n",
      "[1287]\ttraining's binary_logloss: 2.41817e-05\n",
      "[1288]\ttraining's binary_logloss: 2.40528e-05\n",
      "[1289]\ttraining's binary_logloss: 2.39145e-05\n",
      "[1290]\ttraining's binary_logloss: 2.37849e-05\n",
      "[1291]\ttraining's binary_logloss: 2.36493e-05\n",
      "[1292]\ttraining's binary_logloss: 2.3519e-05\n",
      "[1293]\ttraining's binary_logloss: 2.33854e-05\n",
      "[1294]\ttraining's binary_logloss: 2.32665e-05\n",
      "[1295]\ttraining's binary_logloss: 2.31447e-05\n",
      "[1296]\ttraining's binary_logloss: 2.3013e-05\n",
      "[1297]\ttraining's binary_logloss: 2.28851e-05\n",
      "[1298]\ttraining's binary_logloss: 2.27509e-05\n",
      "[1299]\ttraining's binary_logloss: 2.26296e-05\n",
      "[1300]\ttraining's binary_logloss: 2.25037e-05\n",
      "[1301]\ttraining's binary_logloss: 2.23764e-05\n",
      "[1302]\ttraining's binary_logloss: 2.22659e-05\n",
      "[1303]\ttraining's binary_logloss: 2.21418e-05\n",
      "[1304]\ttraining's binary_logloss: 2.20267e-05\n",
      "[1305]\ttraining's binary_logloss: 2.19073e-05\n",
      "[1306]\ttraining's binary_logloss: 2.17926e-05\n",
      "[1307]\ttraining's binary_logloss: 2.16764e-05\n",
      "[1308]\ttraining's binary_logloss: 2.15645e-05\n",
      "[1309]\ttraining's binary_logloss: 2.14488e-05\n",
      "[1310]\ttraining's binary_logloss: 2.13384e-05\n",
      "[1311]\ttraining's binary_logloss: 2.12276e-05\n",
      "[1312]\ttraining's binary_logloss: 2.11203e-05\n",
      "[1313]\ttraining's binary_logloss: 2.10126e-05\n",
      "[1314]\ttraining's binary_logloss: 2.09052e-05\n",
      "[1315]\ttraining's binary_logloss: 2.07993e-05\n",
      "[1316]\ttraining's binary_logloss: 2.06886e-05\n",
      "[1317]\ttraining's binary_logloss: 2.05921e-05\n",
      "[1318]\ttraining's binary_logloss: 2.04903e-05\n",
      "[1319]\ttraining's binary_logloss: 2.03921e-05\n",
      "[1320]\ttraining's binary_logloss: 2.02983e-05\n",
      "[1321]\ttraining's binary_logloss: 2.01997e-05\n",
      "[1322]\ttraining's binary_logloss: 2.0098e-05\n",
      "[1323]\ttraining's binary_logloss: 2.00032e-05\n",
      "[1324]\ttraining's binary_logloss: 1.99097e-05\n",
      "[1325]\ttraining's binary_logloss: 1.98212e-05\n",
      "[1326]\ttraining's binary_logloss: 1.9731e-05\n",
      "[1327]\ttraining's binary_logloss: 1.96319e-05\n",
      "[1328]\ttraining's binary_logloss: 1.95388e-05\n",
      "[1329]\ttraining's binary_logloss: 1.94495e-05\n",
      "[1330]\ttraining's binary_logloss: 1.93583e-05\n",
      "[1331]\ttraining's binary_logloss: 1.92669e-05\n",
      "[1332]\ttraining's binary_logloss: 1.91781e-05\n",
      "[1333]\ttraining's binary_logloss: 1.90877e-05\n",
      "[1334]\ttraining's binary_logloss: 1.89895e-05\n",
      "[1335]\ttraining's binary_logloss: 1.89035e-05\n",
      "[1336]\ttraining's binary_logloss: 1.88156e-05\n",
      "[1337]\ttraining's binary_logloss: 1.87276e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1338]\ttraining's binary_logloss: 1.86435e-05\n",
      "[1339]\ttraining's binary_logloss: 1.85559e-05\n",
      "[1340]\ttraining's binary_logloss: 1.84692e-05\n",
      "[1341]\ttraining's binary_logloss: 1.83826e-05\n",
      "[1342]\ttraining's binary_logloss: 1.83039e-05\n",
      "[1343]\ttraining's binary_logloss: 1.82201e-05\n",
      "[1344]\ttraining's binary_logloss: 1.81407e-05\n",
      "[1345]\ttraining's binary_logloss: 1.80676e-05\n",
      "[1346]\ttraining's binary_logloss: 1.79917e-05\n",
      "[1347]\ttraining's binary_logloss: 1.79126e-05\n",
      "[1348]\ttraining's binary_logloss: 1.7833e-05\n",
      "[1349]\ttraining's binary_logloss: 1.77569e-05\n",
      "[1350]\ttraining's binary_logloss: 1.7679e-05\n",
      "[1351]\ttraining's binary_logloss: 1.75983e-05\n",
      "[1352]\ttraining's binary_logloss: 1.75279e-05\n",
      "[1353]\ttraining's binary_logloss: 1.74535e-05\n",
      "[1354]\ttraining's binary_logloss: 1.73776e-05\n",
      "[1355]\ttraining's binary_logloss: 1.7304e-05\n",
      "[1356]\ttraining's binary_logloss: 1.7228e-05\n",
      "[1357]\ttraining's binary_logloss: 1.71516e-05\n",
      "[1358]\ttraining's binary_logloss: 1.70838e-05\n",
      "[1359]\ttraining's binary_logloss: 1.70124e-05\n",
      "[1360]\ttraining's binary_logloss: 1.69455e-05\n",
      "[1361]\ttraining's binary_logloss: 1.68737e-05\n",
      "[1362]\ttraining's binary_logloss: 1.68054e-05\n",
      "[1363]\ttraining's binary_logloss: 1.67347e-05\n",
      "[1364]\ttraining's binary_logloss: 1.66698e-05\n",
      "[1365]\ttraining's binary_logloss: 1.66012e-05\n",
      "[1366]\ttraining's binary_logloss: 1.6537e-05\n",
      "[1367]\ttraining's binary_logloss: 1.647e-05\n",
      "[1368]\ttraining's binary_logloss: 1.64028e-05\n",
      "[1369]\ttraining's binary_logloss: 1.6338e-05\n",
      "[1370]\ttraining's binary_logloss: 1.62793e-05\n",
      "[1371]\ttraining's binary_logloss: 1.6217e-05\n",
      "[1372]\ttraining's binary_logloss: 1.61536e-05\n",
      "[1373]\ttraining's binary_logloss: 1.6096e-05\n",
      "[1374]\ttraining's binary_logloss: 1.60369e-05\n",
      "[1375]\ttraining's binary_logloss: 1.59726e-05\n",
      "[1376]\ttraining's binary_logloss: 1.59109e-05\n",
      "[1377]\ttraining's binary_logloss: 1.58473e-05\n",
      "[1378]\ttraining's binary_logloss: 1.57877e-05\n",
      "[1379]\ttraining's binary_logloss: 1.57238e-05\n",
      "[1380]\ttraining's binary_logloss: 1.56654e-05\n",
      "[1381]\ttraining's binary_logloss: 1.5609e-05\n",
      "[1382]\ttraining's binary_logloss: 1.55519e-05\n",
      "[1383]\ttraining's binary_logloss: 1.54921e-05\n",
      "[1384]\ttraining's binary_logloss: 1.54309e-05\n",
      "[1385]\ttraining's binary_logloss: 1.53776e-05\n",
      "[1386]\ttraining's binary_logloss: 1.53218e-05\n",
      "[1387]\ttraining's binary_logloss: 1.52696e-05\n",
      "[1388]\ttraining's binary_logloss: 1.52132e-05\n",
      "[1389]\ttraining's binary_logloss: 1.51575e-05\n",
      "[1390]\ttraining's binary_logloss: 1.51024e-05\n",
      "[1391]\ttraining's binary_logloss: 1.50449e-05\n",
      "[1392]\ttraining's binary_logloss: 1.49938e-05\n",
      "[1393]\ttraining's binary_logloss: 1.49397e-05\n",
      "[1394]\ttraining's binary_logloss: 1.48891e-05\n",
      "[1395]\ttraining's binary_logloss: 1.48321e-05\n",
      "[1396]\ttraining's binary_logloss: 1.4779e-05\n",
      "[1397]\ttraining's binary_logloss: 1.47245e-05\n",
      "[1398]\ttraining's binary_logloss: 1.46761e-05\n",
      "[1399]\ttraining's binary_logloss: 1.46259e-05\n",
      "[1400]\ttraining's binary_logloss: 1.45793e-05\n",
      "[1401]\ttraining's binary_logloss: 1.45257e-05\n",
      "[1402]\ttraining's binary_logloss: 1.44805e-05\n",
      "[1403]\ttraining's binary_logloss: 1.44329e-05\n",
      "[1404]\ttraining's binary_logloss: 1.4388e-05\n",
      "[1405]\ttraining's binary_logloss: 1.43355e-05\n",
      "[1406]\ttraining's binary_logloss: 1.42881e-05\n",
      "[1407]\ttraining's binary_logloss: 1.42388e-05\n",
      "[1408]\ttraining's binary_logloss: 1.41909e-05\n",
      "[1409]\ttraining's binary_logloss: 1.41407e-05\n",
      "[1410]\ttraining's binary_logloss: 1.40901e-05\n",
      "[1411]\ttraining's binary_logloss: 1.4044e-05\n",
      "[1412]\ttraining's binary_logloss: 1.39983e-05\n",
      "[1413]\ttraining's binary_logloss: 1.39502e-05\n",
      "[1414]\ttraining's binary_logloss: 1.39024e-05\n",
      "[1415]\ttraining's binary_logloss: 1.38534e-05\n",
      "[1416]\ttraining's binary_logloss: 1.38029e-05\n",
      "[1417]\ttraining's binary_logloss: 1.37555e-05\n",
      "[1418]\ttraining's binary_logloss: 1.3713e-05\n",
      "[1419]\ttraining's binary_logloss: 1.36651e-05\n",
      "[1420]\ttraining's binary_logloss: 1.36224e-05\n",
      "[1421]\ttraining's binary_logloss: 1.35761e-05\n",
      "[1422]\ttraining's binary_logloss: 1.3531e-05\n",
      "[1423]\ttraining's binary_logloss: 1.34861e-05\n",
      "[1424]\ttraining's binary_logloss: 1.34398e-05\n",
      "[1425]\ttraining's binary_logloss: 1.33944e-05\n",
      "[1426]\ttraining's binary_logloss: 1.33511e-05\n",
      "[1427]\ttraining's binary_logloss: 1.33145e-05\n",
      "[1428]\ttraining's binary_logloss: 1.32737e-05\n",
      "[1429]\ttraining's binary_logloss: 1.32291e-05\n",
      "[1430]\ttraining's binary_logloss: 1.31843e-05\n",
      "[1431]\ttraining's binary_logloss: 1.31435e-05\n",
      "[1432]\ttraining's binary_logloss: 1.31031e-05\n",
      "[1433]\ttraining's binary_logloss: 1.30649e-05\n",
      "[1434]\ttraining's binary_logloss: 1.30255e-05\n",
      "[1435]\ttraining's binary_logloss: 1.29857e-05\n",
      "[1436]\ttraining's binary_logloss: 1.29426e-05\n",
      "[1437]\ttraining's binary_logloss: 1.29037e-05\n",
      "[1438]\ttraining's binary_logloss: 1.28671e-05\n",
      "[1439]\ttraining's binary_logloss: 1.28315e-05\n",
      "[1440]\ttraining's binary_logloss: 1.27924e-05\n",
      "[1441]\ttraining's binary_logloss: 1.27492e-05\n",
      "[1442]\ttraining's binary_logloss: 1.27086e-05\n",
      "[1443]\ttraining's binary_logloss: 1.2669e-05\n",
      "[1444]\ttraining's binary_logloss: 1.26303e-05\n",
      "[1445]\ttraining's binary_logloss: 1.25942e-05\n",
      "[1446]\ttraining's binary_logloss: 1.25575e-05\n",
      "[1447]\ttraining's binary_logloss: 1.25217e-05\n",
      "[1448]\ttraining's binary_logloss: 1.24827e-05\n",
      "[1449]\ttraining's binary_logloss: 1.24472e-05\n",
      "[1450]\ttraining's binary_logloss: 1.24043e-05\n",
      "[1451]\ttraining's binary_logloss: 1.23675e-05\n",
      "[1452]\ttraining's binary_logloss: 1.23307e-05\n",
      "[1453]\ttraining's binary_logloss: 1.22912e-05\n",
      "[1454]\ttraining's binary_logloss: 1.22494e-05\n",
      "[1455]\ttraining's binary_logloss: 1.22072e-05\n",
      "[1456]\ttraining's binary_logloss: 1.21707e-05\n",
      "[1457]\ttraining's binary_logloss: 1.21332e-05\n",
      "[1458]\ttraining's binary_logloss: 1.20931e-05\n",
      "[1459]\ttraining's binary_logloss: 1.20585e-05\n",
      "[1460]\ttraining's binary_logloss: 1.20199e-05\n",
      "[1461]\ttraining's binary_logloss: 1.1983e-05\n",
      "[1462]\ttraining's binary_logloss: 1.19463e-05\n",
      "[1463]\ttraining's binary_logloss: 1.19099e-05\n",
      "[1464]\ttraining's binary_logloss: 1.18742e-05\n",
      "[1465]\ttraining's binary_logloss: 1.18408e-05\n",
      "[1466]\ttraining's binary_logloss: 1.18044e-05\n",
      "[1467]\ttraining's binary_logloss: 1.17701e-05\n",
      "[1468]\ttraining's binary_logloss: 1.1734e-05\n",
      "[1469]\ttraining's binary_logloss: 1.16993e-05\n",
      "[1470]\ttraining's binary_logloss: 1.16653e-05\n",
      "[1471]\ttraining's binary_logloss: 1.16315e-05\n",
      "[1472]\ttraining's binary_logloss: 1.15981e-05\n",
      "[1473]\ttraining's binary_logloss: 1.15657e-05\n",
      "[1474]\ttraining's binary_logloss: 1.15332e-05\n",
      "[1475]\ttraining's binary_logloss: 1.15009e-05\n",
      "[1476]\ttraining's binary_logloss: 1.147e-05\n",
      "[1477]\ttraining's binary_logloss: 1.14349e-05\n",
      "[1478]\ttraining's binary_logloss: 1.14017e-05\n",
      "[1479]\ttraining's binary_logloss: 1.13664e-05\n",
      "[1480]\ttraining's binary_logloss: 1.13333e-05\n",
      "[1481]\ttraining's binary_logloss: 1.12997e-05\n",
      "[1482]\ttraining's binary_logloss: 1.12624e-05\n",
      "[1483]\ttraining's binary_logloss: 1.12303e-05\n",
      "[1484]\ttraining's binary_logloss: 1.11964e-05\n",
      "[1485]\ttraining's binary_logloss: 1.11645e-05\n",
      "[1486]\ttraining's binary_logloss: 1.11326e-05\n",
      "[1487]\ttraining's binary_logloss: 1.11021e-05\n",
      "[1488]\ttraining's binary_logloss: 1.10721e-05\n",
      "[1489]\ttraining's binary_logloss: 1.10407e-05\n",
      "[1490]\ttraining's binary_logloss: 1.1012e-05\n",
      "[1491]\ttraining's binary_logloss: 1.09824e-05\n",
      "[1492]\ttraining's binary_logloss: 1.09542e-05\n",
      "[1493]\ttraining's binary_logloss: 1.09251e-05\n",
      "[1494]\ttraining's binary_logloss: 1.08937e-05\n",
      "[1495]\ttraining's binary_logloss: 1.08635e-05\n",
      "[1496]\ttraining's binary_logloss: 1.08351e-05\n",
      "[1497]\ttraining's binary_logloss: 1.08041e-05\n",
      "[1498]\ttraining's binary_logloss: 1.0777e-05\n",
      "[1499]\ttraining's binary_logloss: 1.07495e-05\n",
      "[1500]\ttraining's binary_logloss: 1.07218e-05\n",
      "[1501]\ttraining's binary_logloss: 1.06933e-05\n",
      "[1502]\ttraining's binary_logloss: 1.06666e-05\n",
      "[1503]\ttraining's binary_logloss: 1.0641e-05\n",
      "[1504]\ttraining's binary_logloss: 1.06126e-05\n",
      "[1505]\ttraining's binary_logloss: 1.05858e-05\n",
      "[1506]\ttraining's binary_logloss: 1.05586e-05\n",
      "[1507]\ttraining's binary_logloss: 1.05323e-05\n",
      "[1508]\ttraining's binary_logloss: 1.05065e-05\n",
      "[1509]\ttraining's binary_logloss: 1.04786e-05\n",
      "[1510]\ttraining's binary_logloss: 1.04551e-05\n",
      "[1511]\ttraining's binary_logloss: 1.04279e-05\n",
      "[1512]\ttraining's binary_logloss: 1.04012e-05\n",
      "[1513]\ttraining's binary_logloss: 1.03738e-05\n",
      "[1514]\ttraining's binary_logloss: 1.0347e-05\n",
      "[1515]\ttraining's binary_logloss: 1.03201e-05\n",
      "[1516]\ttraining's binary_logloss: 1.02923e-05\n",
      "[1517]\ttraining's binary_logloss: 1.0265e-05\n",
      "[1518]\ttraining's binary_logloss: 1.02366e-05\n",
      "[1519]\ttraining's binary_logloss: 1.02108e-05\n",
      "[1520]\ttraining's binary_logloss: 1.01859e-05\n",
      "[1521]\ttraining's binary_logloss: 1.01615e-05\n",
      "[1522]\ttraining's binary_logloss: 1.01358e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1523]\ttraining's binary_logloss: 1.01089e-05\n",
      "[1524]\ttraining's binary_logloss: 1.00826e-05\n",
      "[1525]\ttraining's binary_logloss: 1.00551e-05\n",
      "[1526]\ttraining's binary_logloss: 1.0032e-05\n",
      "[1527]\ttraining's binary_logloss: 1.00089e-05\n",
      "[1528]\ttraining's binary_logloss: 9.98494e-06\n",
      "[1529]\ttraining's binary_logloss: 9.961e-06\n",
      "[1530]\ttraining's binary_logloss: 9.93624e-06\n",
      "[1531]\ttraining's binary_logloss: 9.91411e-06\n",
      "[1532]\ttraining's binary_logloss: 9.89048e-06\n",
      "[1533]\ttraining's binary_logloss: 9.86731e-06\n",
      "[1534]\ttraining's binary_logloss: 9.84421e-06\n",
      "[1535]\ttraining's binary_logloss: 9.82192e-06\n",
      "[1536]\ttraining's binary_logloss: 9.79646e-06\n",
      "[1537]\ttraining's binary_logloss: 9.77435e-06\n",
      "[1538]\ttraining's binary_logloss: 9.75123e-06\n",
      "[1539]\ttraining's binary_logloss: 9.72864e-06\n",
      "[1540]\ttraining's binary_logloss: 9.70609e-06\n",
      "[1541]\ttraining's binary_logloss: 9.68156e-06\n",
      "[1542]\ttraining's binary_logloss: 9.65961e-06\n",
      "[1543]\ttraining's binary_logloss: 9.63833e-06\n",
      "[1544]\ttraining's binary_logloss: 9.61808e-06\n",
      "[1545]\ttraining's binary_logloss: 9.59662e-06\n",
      "[1546]\ttraining's binary_logloss: 9.57293e-06\n",
      "[1547]\ttraining's binary_logloss: 9.5495e-06\n",
      "[1548]\ttraining's binary_logloss: 9.52765e-06\n",
      "[1549]\ttraining's binary_logloss: 9.50714e-06\n",
      "[1550]\ttraining's binary_logloss: 9.48744e-06\n",
      "[1551]\ttraining's binary_logloss: 9.46827e-06\n",
      "[1552]\ttraining's binary_logloss: 9.44662e-06\n",
      "[1553]\ttraining's binary_logloss: 9.42582e-06\n",
      "[1554]\ttraining's binary_logloss: 9.40259e-06\n",
      "[1555]\ttraining's binary_logloss: 9.38044e-06\n",
      "[1556]\ttraining's binary_logloss: 9.3574e-06\n",
      "[1557]\ttraining's binary_logloss: 9.33604e-06\n",
      "[1558]\ttraining's binary_logloss: 9.31287e-06\n",
      "[1559]\ttraining's binary_logloss: 9.29365e-06\n",
      "[1560]\ttraining's binary_logloss: 9.27472e-06\n",
      "[1561]\ttraining's binary_logloss: 9.2571e-06\n",
      "[1562]\ttraining's binary_logloss: 9.23868e-06\n",
      "[1563]\ttraining's binary_logloss: 9.2169e-06\n",
      "[1564]\ttraining's binary_logloss: 9.19652e-06\n",
      "[1565]\ttraining's binary_logloss: 9.17515e-06\n",
      "[1566]\ttraining's binary_logloss: 9.15703e-06\n",
      "[1567]\ttraining's binary_logloss: 9.13912e-06\n",
      "[1568]\ttraining's binary_logloss: 9.12025e-06\n",
      "[1569]\ttraining's binary_logloss: 9.10297e-06\n",
      "[1570]\ttraining's binary_logloss: 9.08436e-06\n",
      "[1571]\ttraining's binary_logloss: 9.0654e-06\n",
      "[1572]\ttraining's binary_logloss: 9.04566e-06\n",
      "[1573]\ttraining's binary_logloss: 9.02581e-06\n",
      "[1574]\ttraining's binary_logloss: 9.00657e-06\n",
      "[1575]\ttraining's binary_logloss: 8.98714e-06\n",
      "[1576]\ttraining's binary_logloss: 8.96817e-06\n",
      "[1577]\ttraining's binary_logloss: 8.94909e-06\n",
      "[1578]\ttraining's binary_logloss: 8.92942e-06\n",
      "[1579]\ttraining's binary_logloss: 8.90936e-06\n",
      "[1580]\ttraining's binary_logloss: 8.89107e-06\n",
      "[1581]\ttraining's binary_logloss: 8.87195e-06\n",
      "[1582]\ttraining's binary_logloss: 8.85173e-06\n",
      "[1583]\ttraining's binary_logloss: 8.83328e-06\n",
      "[1584]\ttraining's binary_logloss: 8.81421e-06\n",
      "[1585]\ttraining's binary_logloss: 8.79501e-06\n",
      "[1586]\ttraining's binary_logloss: 8.77643e-06\n",
      "[1587]\ttraining's binary_logloss: 8.75849e-06\n",
      "[1588]\ttraining's binary_logloss: 8.74042e-06\n",
      "[1589]\ttraining's binary_logloss: 8.72356e-06\n",
      "[1590]\ttraining's binary_logloss: 8.70341e-06\n",
      "[1591]\ttraining's binary_logloss: 8.68685e-06\n",
      "[1592]\ttraining's binary_logloss: 8.66925e-06\n",
      "[1593]\ttraining's binary_logloss: 8.65285e-06\n",
      "[1594]\ttraining's binary_logloss: 8.63464e-06\n",
      "[1595]\ttraining's binary_logloss: 8.61848e-06\n",
      "[1596]\ttraining's binary_logloss: 8.59951e-06\n",
      "[1597]\ttraining's binary_logloss: 8.58142e-06\n",
      "[1598]\ttraining's binary_logloss: 8.56457e-06\n",
      "[1599]\ttraining's binary_logloss: 8.54725e-06\n",
      "[1600]\ttraining's binary_logloss: 8.53093e-06\n",
      "[1601]\ttraining's binary_logloss: 8.5148e-06\n",
      "[1602]\ttraining's binary_logloss: 8.49755e-06\n",
      "[1603]\ttraining's binary_logloss: 8.48037e-06\n",
      "[1604]\ttraining's binary_logloss: 8.46246e-06\n",
      "[1605]\ttraining's binary_logloss: 8.44324e-06\n",
      "[1606]\ttraining's binary_logloss: 8.42817e-06\n",
      "[1607]\ttraining's binary_logloss: 8.41263e-06\n",
      "[1608]\ttraining's binary_logloss: 8.39621e-06\n",
      "[1609]\ttraining's binary_logloss: 8.37881e-06\n",
      "[1610]\ttraining's binary_logloss: 8.3642e-06\n",
      "[1611]\ttraining's binary_logloss: 8.34741e-06\n",
      "[1612]\ttraining's binary_logloss: 8.33129e-06\n",
      "[1613]\ttraining's binary_logloss: 8.31666e-06\n",
      "[1614]\ttraining's binary_logloss: 8.29986e-06\n",
      "[1615]\ttraining's binary_logloss: 8.28339e-06\n",
      "[1616]\ttraining's binary_logloss: 8.2688e-06\n",
      "[1617]\ttraining's binary_logloss: 8.25168e-06\n",
      "[1618]\ttraining's binary_logloss: 8.23588e-06\n",
      "[1619]\ttraining's binary_logloss: 8.21992e-06\n",
      "[1620]\ttraining's binary_logloss: 8.20301e-06\n",
      "[1621]\ttraining's binary_logloss: 8.18708e-06\n",
      "[1622]\ttraining's binary_logloss: 8.17177e-06\n",
      "[1623]\ttraining's binary_logloss: 8.15503e-06\n",
      "[1624]\ttraining's binary_logloss: 8.13854e-06\n",
      "[1625]\ttraining's binary_logloss: 8.12256e-06\n",
      "[1626]\ttraining's binary_logloss: 8.1072e-06\n",
      "[1627]\ttraining's binary_logloss: 8.09416e-06\n",
      "[1628]\ttraining's binary_logloss: 8.07898e-06\n",
      "[1629]\ttraining's binary_logloss: 8.06525e-06\n",
      "[1630]\ttraining's binary_logloss: 8.05051e-06\n",
      "[1631]\ttraining's binary_logloss: 8.03322e-06\n",
      "[1632]\ttraining's binary_logloss: 8.01646e-06\n",
      "[1633]\ttraining's binary_logloss: 8.00107e-06\n",
      "[1634]\ttraining's binary_logloss: 7.98582e-06\n",
      "[1635]\ttraining's binary_logloss: 7.9719e-06\n",
      "[1636]\ttraining's binary_logloss: 7.95781e-06\n",
      "[1637]\ttraining's binary_logloss: 7.94379e-06\n",
      "[1638]\ttraining's binary_logloss: 7.92873e-06\n",
      "[1639]\ttraining's binary_logloss: 7.91572e-06\n",
      "[1640]\ttraining's binary_logloss: 7.90109e-06\n",
      "[1641]\ttraining's binary_logloss: 7.88629e-06\n",
      "[1642]\ttraining's binary_logloss: 7.8723e-06\n",
      "[1643]\ttraining's binary_logloss: 7.85922e-06\n",
      "[1644]\ttraining's binary_logloss: 7.8444e-06\n",
      "[1645]\ttraining's binary_logloss: 7.83017e-06\n",
      "[1646]\ttraining's binary_logloss: 7.81588e-06\n",
      "[1647]\ttraining's binary_logloss: 7.80182e-06\n",
      "[1648]\ttraining's binary_logloss: 7.78755e-06\n",
      "[1649]\ttraining's binary_logloss: 7.77367e-06\n",
      "[1650]\ttraining's binary_logloss: 7.75826e-06\n",
      "[1651]\ttraining's binary_logloss: 7.74267e-06\n",
      "[1652]\ttraining's binary_logloss: 7.72907e-06\n",
      "[1653]\ttraining's binary_logloss: 7.71523e-06\n",
      "[1654]\ttraining's binary_logloss: 7.7011e-06\n",
      "[1655]\ttraining's binary_logloss: 7.68684e-06\n",
      "[1656]\ttraining's binary_logloss: 7.67276e-06\n",
      "[1657]\ttraining's binary_logloss: 7.65796e-06\n",
      "[1658]\ttraining's binary_logloss: 7.644e-06\n",
      "[1659]\ttraining's binary_logloss: 7.63152e-06\n",
      "[1660]\ttraining's binary_logloss: 7.61918e-06\n",
      "[1661]\ttraining's binary_logloss: 7.60553e-06\n",
      "[1662]\ttraining's binary_logloss: 7.59404e-06\n",
      "[1663]\ttraining's binary_logloss: 7.58126e-06\n",
      "[1664]\ttraining's binary_logloss: 7.56798e-06\n",
      "[1665]\ttraining's binary_logloss: 7.55492e-06\n",
      "[1666]\ttraining's binary_logloss: 7.54147e-06\n",
      "[1667]\ttraining's binary_logloss: 7.52778e-06\n",
      "[1668]\ttraining's binary_logloss: 7.51541e-06\n",
      "[1669]\ttraining's binary_logloss: 7.50255e-06\n",
      "[1670]\ttraining's binary_logloss: 7.48862e-06\n",
      "[1671]\ttraining's binary_logloss: 7.47625e-06\n",
      "[1672]\ttraining's binary_logloss: 7.46257e-06\n",
      "[1673]\ttraining's binary_logloss: 7.45062e-06\n",
      "[1674]\ttraining's binary_logloss: 7.43809e-06\n",
      "[1675]\ttraining's binary_logloss: 7.42562e-06\n",
      "[1676]\ttraining's binary_logloss: 7.41285e-06\n",
      "[1677]\ttraining's binary_logloss: 7.40046e-06\n",
      "[1678]\ttraining's binary_logloss: 7.38678e-06\n",
      "[1679]\ttraining's binary_logloss: 7.37308e-06\n",
      "[1680]\ttraining's binary_logloss: 7.36098e-06\n",
      "[1681]\ttraining's binary_logloss: 7.34919e-06\n",
      "[1682]\ttraining's binary_logloss: 7.33698e-06\n",
      "[1683]\ttraining's binary_logloss: 7.32545e-06\n",
      "[1684]\ttraining's binary_logloss: 7.31138e-06\n",
      "[1685]\ttraining's binary_logloss: 7.29892e-06\n",
      "[1686]\ttraining's binary_logloss: 7.28662e-06\n",
      "[1687]\ttraining's binary_logloss: 7.27482e-06\n",
      "[1688]\ttraining's binary_logloss: 7.2615e-06\n",
      "[1689]\ttraining's binary_logloss: 7.25017e-06\n",
      "[1690]\ttraining's binary_logloss: 7.23756e-06\n",
      "[1691]\ttraining's binary_logloss: 7.22688e-06\n",
      "[1692]\ttraining's binary_logloss: 7.21594e-06\n",
      "[1693]\ttraining's binary_logloss: 7.20541e-06\n",
      "[1694]\ttraining's binary_logloss: 7.19251e-06\n",
      "[1695]\ttraining's binary_logloss: 7.18094e-06\n",
      "[1696]\ttraining's binary_logloss: 7.16984e-06\n",
      "[1697]\ttraining's binary_logloss: 7.15763e-06\n",
      "[1698]\ttraining's binary_logloss: 7.14585e-06\n",
      "[1699]\ttraining's binary_logloss: 7.13356e-06\n",
      "[1700]\ttraining's binary_logloss: 7.12143e-06\n",
      "[1701]\ttraining's binary_logloss: 7.10916e-06\n",
      "[1702]\ttraining's binary_logloss: 7.09756e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1703]\ttraining's binary_logloss: 7.0865e-06\n",
      "[1704]\ttraining's binary_logloss: 7.07601e-06\n",
      "[1705]\ttraining's binary_logloss: 7.06373e-06\n",
      "[1706]\ttraining's binary_logloss: 7.05289e-06\n",
      "[1707]\ttraining's binary_logloss: 7.04251e-06\n",
      "[1708]\ttraining's binary_logloss: 7.03189e-06\n",
      "[1709]\ttraining's binary_logloss: 7.02024e-06\n",
      "[1710]\ttraining's binary_logloss: 7.00908e-06\n",
      "[1711]\ttraining's binary_logloss: 6.99807e-06\n",
      "[1712]\ttraining's binary_logloss: 6.98759e-06\n",
      "[1713]\ttraining's binary_logloss: 6.97678e-06\n",
      "[1714]\ttraining's binary_logloss: 6.96561e-06\n",
      "[1715]\ttraining's binary_logloss: 6.95475e-06\n",
      "[1716]\ttraining's binary_logloss: 6.94468e-06\n",
      "[1717]\ttraining's binary_logloss: 6.93301e-06\n",
      "[1718]\ttraining's binary_logloss: 6.92261e-06\n",
      "[1719]\ttraining's binary_logloss: 6.91172e-06\n",
      "[1720]\ttraining's binary_logloss: 6.90023e-06\n",
      "[1721]\ttraining's binary_logloss: 6.8906e-06\n",
      "[1722]\ttraining's binary_logloss: 6.88054e-06\n",
      "[1723]\ttraining's binary_logloss: 6.8698e-06\n",
      "[1724]\ttraining's binary_logloss: 6.85886e-06\n",
      "[1725]\ttraining's binary_logloss: 6.84741e-06\n",
      "[1726]\ttraining's binary_logloss: 6.83575e-06\n",
      "[1727]\ttraining's binary_logloss: 6.82454e-06\n",
      "[1728]\ttraining's binary_logloss: 6.8146e-06\n",
      "[1729]\ttraining's binary_logloss: 6.80454e-06\n",
      "[1730]\ttraining's binary_logloss: 6.79422e-06\n",
      "[1731]\ttraining's binary_logloss: 6.78403e-06\n",
      "[1732]\ttraining's binary_logloss: 6.77386e-06\n",
      "[1733]\ttraining's binary_logloss: 6.76284e-06\n",
      "[1734]\ttraining's binary_logloss: 6.75246e-06\n",
      "[1735]\ttraining's binary_logloss: 6.74308e-06\n",
      "[1736]\ttraining's binary_logloss: 6.73361e-06\n",
      "[1737]\ttraining's binary_logloss: 6.7242e-06\n",
      "[1738]\ttraining's binary_logloss: 6.71368e-06\n",
      "[1739]\ttraining's binary_logloss: 6.70389e-06\n",
      "[1740]\ttraining's binary_logloss: 6.69408e-06\n",
      "[1741]\ttraining's binary_logloss: 6.68482e-06\n",
      "[1742]\ttraining's binary_logloss: 6.67537e-06\n",
      "[1743]\ttraining's binary_logloss: 6.66578e-06\n",
      "[1744]\ttraining's binary_logloss: 6.65654e-06\n",
      "[1745]\ttraining's binary_logloss: 6.64629e-06\n",
      "[1746]\ttraining's binary_logloss: 6.638e-06\n",
      "[1747]\ttraining's binary_logloss: 6.62828e-06\n",
      "[1748]\ttraining's binary_logloss: 6.61887e-06\n",
      "[1749]\ttraining's binary_logloss: 6.60843e-06\n",
      "[1750]\ttraining's binary_logloss: 6.59889e-06\n",
      "[1751]\ttraining's binary_logloss: 6.58881e-06\n",
      "[1752]\ttraining's binary_logloss: 6.57878e-06\n",
      "[1753]\ttraining's binary_logloss: 6.5688e-06\n",
      "[1754]\ttraining's binary_logloss: 6.55866e-06\n",
      "[1755]\ttraining's binary_logloss: 6.54962e-06\n",
      "[1756]\ttraining's binary_logloss: 6.53998e-06\n",
      "[1757]\ttraining's binary_logloss: 6.52985e-06\n",
      "[1758]\ttraining's binary_logloss: 6.52068e-06\n",
      "[1759]\ttraining's binary_logloss: 6.51152e-06\n",
      "[1760]\ttraining's binary_logloss: 6.503e-06\n",
      "[1761]\ttraining's binary_logloss: 6.49335e-06\n",
      "[1762]\ttraining's binary_logloss: 6.48393e-06\n",
      "[1763]\ttraining's binary_logloss: 6.4747e-06\n",
      "[1764]\ttraining's binary_logloss: 6.46505e-06\n",
      "[1765]\ttraining's binary_logloss: 6.45512e-06\n",
      "[1766]\ttraining's binary_logloss: 6.44587e-06\n",
      "[1767]\ttraining's binary_logloss: 6.43646e-06\n",
      "[1768]\ttraining's binary_logloss: 6.42635e-06\n",
      "[1769]\ttraining's binary_logloss: 6.41704e-06\n",
      "[1770]\ttraining's binary_logloss: 6.40702e-06\n",
      "[1771]\ttraining's binary_logloss: 6.39819e-06\n",
      "[1772]\ttraining's binary_logloss: 6.38944e-06\n",
      "[1773]\ttraining's binary_logloss: 6.38073e-06\n",
      "[1774]\ttraining's binary_logloss: 6.37071e-06\n",
      "[1775]\ttraining's binary_logloss: 6.36173e-06\n",
      "[1776]\ttraining's binary_logloss: 6.35259e-06\n",
      "[1777]\ttraining's binary_logloss: 6.34316e-06\n",
      "[1778]\ttraining's binary_logloss: 6.33327e-06\n",
      "[1779]\ttraining's binary_logloss: 6.32398e-06\n",
      "[1780]\ttraining's binary_logloss: 6.31455e-06\n",
      "[1781]\ttraining's binary_logloss: 6.30545e-06\n",
      "[1782]\ttraining's binary_logloss: 6.29622e-06\n",
      "[1783]\ttraining's binary_logloss: 6.28821e-06\n",
      "[1784]\ttraining's binary_logloss: 6.28006e-06\n",
      "[1785]\ttraining's binary_logloss: 6.27058e-06\n",
      "[1786]\ttraining's binary_logloss: 6.26233e-06\n",
      "[1787]\ttraining's binary_logloss: 6.25469e-06\n",
      "[1788]\ttraining's binary_logloss: 6.24597e-06\n",
      "[1789]\ttraining's binary_logloss: 6.23619e-06\n",
      "[1790]\ttraining's binary_logloss: 6.22863e-06\n",
      "[1791]\ttraining's binary_logloss: 6.22071e-06\n",
      "[1792]\ttraining's binary_logloss: 6.21224e-06\n",
      "[1793]\ttraining's binary_logloss: 6.20312e-06\n",
      "[1794]\ttraining's binary_logloss: 6.19469e-06\n",
      "[1795]\ttraining's binary_logloss: 6.18594e-06\n",
      "[1796]\ttraining's binary_logloss: 6.17836e-06\n",
      "[1797]\ttraining's binary_logloss: 6.16908e-06\n",
      "[1798]\ttraining's binary_logloss: 6.16211e-06\n",
      "[1799]\ttraining's binary_logloss: 6.15432e-06\n",
      "[1800]\ttraining's binary_logloss: 6.14582e-06\n",
      "[1801]\ttraining's binary_logloss: 6.13757e-06\n",
      "[1802]\ttraining's binary_logloss: 6.12916e-06\n",
      "[1803]\ttraining's binary_logloss: 6.12135e-06\n",
      "[1804]\ttraining's binary_logloss: 6.11381e-06\n",
      "[1805]\ttraining's binary_logloss: 6.10483e-06\n",
      "[1806]\ttraining's binary_logloss: 6.09708e-06\n",
      "[1807]\ttraining's binary_logloss: 6.0887e-06\n",
      "[1808]\ttraining's binary_logloss: 6.08122e-06\n",
      "[1809]\ttraining's binary_logloss: 6.07299e-06\n",
      "[1810]\ttraining's binary_logloss: 6.06526e-06\n",
      "[1811]\ttraining's binary_logloss: 6.05724e-06\n",
      "[1812]\ttraining's binary_logloss: 6.04951e-06\n",
      "[1813]\ttraining's binary_logloss: 6.04165e-06\n",
      "[1814]\ttraining's binary_logloss: 6.03403e-06\n",
      "[1815]\ttraining's binary_logloss: 6.02648e-06\n",
      "[1816]\ttraining's binary_logloss: 6.01869e-06\n",
      "[1817]\ttraining's binary_logloss: 6.01148e-06\n",
      "[1818]\ttraining's binary_logloss: 6.0038e-06\n",
      "[1819]\ttraining's binary_logloss: 5.99748e-06\n",
      "[1820]\ttraining's binary_logloss: 5.98949e-06\n",
      "[1821]\ttraining's binary_logloss: 5.98137e-06\n",
      "[1822]\ttraining's binary_logloss: 5.97379e-06\n",
      "[1823]\ttraining's binary_logloss: 5.96659e-06\n",
      "[1824]\ttraining's binary_logloss: 5.95916e-06\n",
      "[1825]\ttraining's binary_logloss: 5.95171e-06\n",
      "[1826]\ttraining's binary_logloss: 5.94384e-06\n",
      "[1827]\ttraining's binary_logloss: 5.93598e-06\n",
      "[1828]\ttraining's binary_logloss: 5.92839e-06\n",
      "[1829]\ttraining's binary_logloss: 5.9204e-06\n",
      "[1830]\ttraining's binary_logloss: 5.91266e-06\n",
      "[1831]\ttraining's binary_logloss: 5.9055e-06\n",
      "[1832]\ttraining's binary_logloss: 5.898e-06\n",
      "[1833]\ttraining's binary_logloss: 5.88979e-06\n",
      "[1834]\ttraining's binary_logloss: 5.88177e-06\n",
      "[1835]\ttraining's binary_logloss: 5.87418e-06\n",
      "[1836]\ttraining's binary_logloss: 5.86667e-06\n",
      "[1837]\ttraining's binary_logloss: 5.85835e-06\n",
      "[1838]\ttraining's binary_logloss: 5.85056e-06\n",
      "[1839]\ttraining's binary_logloss: 5.84375e-06\n",
      "[1840]\ttraining's binary_logloss: 5.83696e-06\n",
      "[1841]\ttraining's binary_logloss: 5.82892e-06\n",
      "[1842]\ttraining's binary_logloss: 5.82128e-06\n",
      "[1843]\ttraining's binary_logloss: 5.81338e-06\n",
      "[1844]\ttraining's binary_logloss: 5.80591e-06\n",
      "[1845]\ttraining's binary_logloss: 5.7984e-06\n",
      "[1846]\ttraining's binary_logloss: 5.79109e-06\n",
      "[1847]\ttraining's binary_logloss: 5.78436e-06\n",
      "[1848]\ttraining's binary_logloss: 5.77714e-06\n",
      "[1849]\ttraining's binary_logloss: 5.77076e-06\n",
      "[1850]\ttraining's binary_logloss: 5.76374e-06\n",
      "[1851]\ttraining's binary_logloss: 5.7564e-06\n",
      "[1852]\ttraining's binary_logloss: 5.74997e-06\n",
      "[1853]\ttraining's binary_logloss: 5.74345e-06\n",
      "[1854]\ttraining's binary_logloss: 5.73751e-06\n",
      "[1855]\ttraining's binary_logloss: 5.72982e-06\n",
      "[1856]\ttraining's binary_logloss: 5.72254e-06\n",
      "[1857]\ttraining's binary_logloss: 5.71612e-06\n",
      "[1858]\ttraining's binary_logloss: 5.70851e-06\n",
      "[1859]\ttraining's binary_logloss: 5.70109e-06\n",
      "[1860]\ttraining's binary_logloss: 5.69381e-06\n",
      "[1861]\ttraining's binary_logloss: 5.68674e-06\n",
      "[1862]\ttraining's binary_logloss: 5.68029e-06\n",
      "[1863]\ttraining's binary_logloss: 5.67409e-06\n",
      "[1864]\ttraining's binary_logloss: 5.66721e-06\n",
      "[1865]\ttraining's binary_logloss: 5.66045e-06\n",
      "[1866]\ttraining's binary_logloss: 5.65272e-06\n",
      "[1867]\ttraining's binary_logloss: 5.64559e-06\n",
      "[1868]\ttraining's binary_logloss: 5.63835e-06\n",
      "[1869]\ttraining's binary_logloss: 5.6316e-06\n",
      "[1870]\ttraining's binary_logloss: 5.62524e-06\n",
      "[1871]\ttraining's binary_logloss: 5.61919e-06\n",
      "[1872]\ttraining's binary_logloss: 5.61278e-06\n",
      "[1873]\ttraining's binary_logloss: 5.60641e-06\n",
      "[1874]\ttraining's binary_logloss: 5.60006e-06\n",
      "[1875]\ttraining's binary_logloss: 5.59301e-06\n",
      "[1876]\ttraining's binary_logloss: 5.58651e-06\n",
      "[1877]\ttraining's binary_logloss: 5.57962e-06\n",
      "[1878]\ttraining's binary_logloss: 5.57232e-06\n",
      "[1879]\ttraining's binary_logloss: 5.56543e-06\n",
      "[1880]\ttraining's binary_logloss: 5.5586e-06\n",
      "[1881]\ttraining's binary_logloss: 5.55192e-06\n",
      "[1882]\ttraining's binary_logloss: 5.54491e-06\n",
      "[1883]\ttraining's binary_logloss: 5.53811e-06\n",
      "[1884]\ttraining's binary_logloss: 5.53191e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1885]\ttraining's binary_logloss: 5.52485e-06\n",
      "[1886]\ttraining's binary_logloss: 5.51804e-06\n",
      "[1887]\ttraining's binary_logloss: 5.51168e-06\n",
      "[1888]\ttraining's binary_logloss: 5.50587e-06\n",
      "[1889]\ttraining's binary_logloss: 5.49901e-06\n",
      "[1890]\ttraining's binary_logloss: 5.49267e-06\n",
      "[1891]\ttraining's binary_logloss: 5.48657e-06\n",
      "[1892]\ttraining's binary_logloss: 5.47892e-06\n",
      "[1893]\ttraining's binary_logloss: 5.47216e-06\n",
      "[1894]\ttraining's binary_logloss: 5.466e-06\n",
      "[1895]\ttraining's binary_logloss: 5.4598e-06\n",
      "[1896]\ttraining's binary_logloss: 5.45356e-06\n",
      "[1897]\ttraining's binary_logloss: 5.44636e-06\n",
      "[1898]\ttraining's binary_logloss: 5.43952e-06\n",
      "[1899]\ttraining's binary_logloss: 5.43297e-06\n",
      "[1900]\ttraining's binary_logloss: 5.42741e-06\n",
      "[1901]\ttraining's binary_logloss: 5.42125e-06\n",
      "[1902]\ttraining's binary_logloss: 5.4146e-06\n",
      "[1903]\ttraining's binary_logloss: 5.40882e-06\n",
      "[1904]\ttraining's binary_logloss: 5.40225e-06\n",
      "[1905]\ttraining's binary_logloss: 5.39626e-06\n",
      "[1906]\ttraining's binary_logloss: 5.39025e-06\n",
      "[1907]\ttraining's binary_logloss: 5.38434e-06\n",
      "[1908]\ttraining's binary_logloss: 5.37813e-06\n",
      "[1909]\ttraining's binary_logloss: 5.37191e-06\n",
      "[1910]\ttraining's binary_logloss: 5.36511e-06\n",
      "[1911]\ttraining's binary_logloss: 5.35761e-06\n",
      "[1912]\ttraining's binary_logloss: 5.35133e-06\n",
      "[1913]\ttraining's binary_logloss: 5.34519e-06\n",
      "[1914]\ttraining's binary_logloss: 5.33917e-06\n",
      "[1915]\ttraining's binary_logloss: 5.33341e-06\n",
      "[1916]\ttraining's binary_logloss: 5.32793e-06\n",
      "[1917]\ttraining's binary_logloss: 5.32176e-06\n",
      "[1918]\ttraining's binary_logloss: 5.31614e-06\n",
      "[1919]\ttraining's binary_logloss: 5.30983e-06\n",
      "[1920]\ttraining's binary_logloss: 5.30381e-06\n",
      "[1921]\ttraining's binary_logloss: 5.29804e-06\n",
      "[1922]\ttraining's binary_logloss: 5.29266e-06\n",
      "[1923]\ttraining's binary_logloss: 5.28709e-06\n",
      "[1924]\ttraining's binary_logloss: 5.28136e-06\n",
      "[1925]\ttraining's binary_logloss: 5.27549e-06\n",
      "[1926]\ttraining's binary_logloss: 5.26938e-06\n",
      "[1927]\ttraining's binary_logloss: 5.26373e-06\n",
      "[1928]\ttraining's binary_logloss: 5.25777e-06\n",
      "[1929]\ttraining's binary_logloss: 5.25205e-06\n",
      "[1930]\ttraining's binary_logloss: 5.24599e-06\n",
      "[1931]\ttraining's binary_logloss: 5.24066e-06\n",
      "[1932]\ttraining's binary_logloss: 5.23468e-06\n",
      "[1933]\ttraining's binary_logloss: 5.22822e-06\n",
      "[1934]\ttraining's binary_logloss: 5.2224e-06\n",
      "[1935]\ttraining's binary_logloss: 5.21638e-06\n",
      "[1936]\ttraining's binary_logloss: 5.21085e-06\n",
      "[1937]\ttraining's binary_logloss: 5.20547e-06\n",
      "[1938]\ttraining's binary_logloss: 5.19981e-06\n",
      "[1939]\ttraining's binary_logloss: 5.19434e-06\n",
      "[1940]\ttraining's binary_logloss: 5.18847e-06\n",
      "[1941]\ttraining's binary_logloss: 5.18245e-06\n",
      "[1942]\ttraining's binary_logloss: 5.17639e-06\n",
      "[1943]\ttraining's binary_logloss: 5.1712e-06\n",
      "[1944]\ttraining's binary_logloss: 5.16446e-06\n",
      "[1945]\ttraining's binary_logloss: 5.15829e-06\n",
      "[1946]\ttraining's binary_logloss: 5.15281e-06\n",
      "[1947]\ttraining's binary_logloss: 5.14727e-06\n",
      "[1948]\ttraining's binary_logloss: 5.1425e-06\n",
      "[1949]\ttraining's binary_logloss: 5.13792e-06\n",
      "[1950]\ttraining's binary_logloss: 5.13326e-06\n",
      "[1951]\ttraining's binary_logloss: 5.12788e-06\n",
      "[1952]\ttraining's binary_logloss: 5.12316e-06\n",
      "[1953]\ttraining's binary_logloss: 5.11806e-06\n",
      "[1954]\ttraining's binary_logloss: 5.11309e-06\n",
      "[1955]\ttraining's binary_logloss: 5.10749e-06\n",
      "[1956]\ttraining's binary_logloss: 5.10194e-06\n",
      "[1957]\ttraining's binary_logloss: 5.09701e-06\n",
      "[1958]\ttraining's binary_logloss: 5.09173e-06\n",
      "[1959]\ttraining's binary_logloss: 5.08641e-06\n",
      "[1960]\ttraining's binary_logloss: 5.0806e-06\n",
      "[1961]\ttraining's binary_logloss: 5.07532e-06\n",
      "[1962]\ttraining's binary_logloss: 5.06982e-06\n",
      "[1963]\ttraining's binary_logloss: 5.06381e-06\n",
      "[1964]\ttraining's binary_logloss: 5.05772e-06\n",
      "[1965]\ttraining's binary_logloss: 5.05202e-06\n",
      "[1966]\ttraining's binary_logloss: 5.04662e-06\n",
      "[1967]\ttraining's binary_logloss: 5.04113e-06\n",
      "[1968]\ttraining's binary_logloss: 5.03587e-06\n",
      "[1969]\ttraining's binary_logloss: 5.03049e-06\n",
      "[1970]\ttraining's binary_logloss: 5.02537e-06\n",
      "[1971]\ttraining's binary_logloss: 5.01967e-06\n",
      "[1972]\ttraining's binary_logloss: 5.01496e-06\n",
      "[1973]\ttraining's binary_logloss: 5.00959e-06\n",
      "[1974]\ttraining's binary_logloss: 5.00479e-06\n",
      "[1975]\ttraining's binary_logloss: 4.99947e-06\n",
      "[1976]\ttraining's binary_logloss: 4.99412e-06\n",
      "[1977]\ttraining's binary_logloss: 4.98893e-06\n",
      "[1978]\ttraining's binary_logloss: 4.98344e-06\n",
      "[1979]\ttraining's binary_logloss: 4.97827e-06\n",
      "[1980]\ttraining's binary_logloss: 4.9735e-06\n",
      "[1981]\ttraining's binary_logloss: 4.96911e-06\n",
      "[1982]\ttraining's binary_logloss: 4.964e-06\n",
      "[1983]\ttraining's binary_logloss: 4.95876e-06\n",
      "[1984]\ttraining's binary_logloss: 4.95298e-06\n",
      "[1985]\ttraining's binary_logloss: 4.94838e-06\n",
      "[1986]\ttraining's binary_logloss: 4.94294e-06\n",
      "[1987]\ttraining's binary_logloss: 4.93774e-06\n",
      "[1988]\ttraining's binary_logloss: 4.93282e-06\n",
      "[1989]\ttraining's binary_logloss: 4.92834e-06\n",
      "[1990]\ttraining's binary_logloss: 4.92286e-06\n",
      "[1991]\ttraining's binary_logloss: 4.91781e-06\n",
      "[1992]\ttraining's binary_logloss: 4.91314e-06\n",
      "[1993]\ttraining's binary_logloss: 4.90819e-06\n",
      "[1994]\ttraining's binary_logloss: 4.90324e-06\n",
      "[1995]\ttraining's binary_logloss: 4.89736e-06\n",
      "[1996]\ttraining's binary_logloss: 4.89241e-06\n",
      "[1997]\ttraining's binary_logloss: 4.88727e-06\n",
      "[1998]\ttraining's binary_logloss: 4.88254e-06\n",
      "[1999]\ttraining's binary_logloss: 4.87814e-06\n",
      "[2000]\ttraining's binary_logloss: 4.87306e-06\n"
     ]
    }
   ],
   "source": [
    "# deploy model\n",
    "lgtrain = lgb.Dataset(X_res, y_res)\n",
    "\n",
    "final_lgb = lgb.train(\n",
    "    lgbm_params,\n",
    "    lgtrain,\n",
    "    valid_sets=lgtrain,\n",
    "    num_boost_round=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the final model to the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "preprocess = DataPreprocess(label_encoder)\n",
    "processed_payment_test = preprocess.preprocess_payment(payment_test)\n",
    "billing_test = preprocess.initialize_billing(billing_test)\n",
    "processed_billing_test = preprocess.preprocess_billing(billing_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test = preprocess.merge(processed_payment_test, processed_billing_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in transaction_col:\n",
    "    replace_value = processed_test[processed_test[col].notna()][col].mean()\n",
    "    processed_test[col] = processed_test[col].fillna(replace_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test = processed_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_01_month</th>\n",
       "      <th>transaction_02_month</th>\n",
       "      <th>transaction_03_month</th>\n",
       "      <th>transaction_04_month</th>\n",
       "      <th>transaction_05_month</th>\n",
       "      <th>transaction_06_month</th>\n",
       "      <th>transaction_07_month</th>\n",
       "      <th>transaction_08_month</th>\n",
       "      <th>transaction_09_month</th>\n",
       "      <th>transaction_10_month</th>\n",
       "      <th>...</th>\n",
       "      <th>cash_balance_06_month</th>\n",
       "      <th>cash_balance_07_month</th>\n",
       "      <th>cash_balance_08_month</th>\n",
       "      <th>cash_balance_09_month</th>\n",
       "      <th>cash_balance_10_month</th>\n",
       "      <th>cash_balance_11_month</th>\n",
       "      <th>cash_balance_12_month</th>\n",
       "      <th>MaxDelqCycle</th>\n",
       "      <th>AvgDelqCycle</th>\n",
       "      <th>LateCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10074849</th>\n",
       "      <td>411.00</td>\n",
       "      <td>340.26</td>\n",
       "      <td>993.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>906.38</td>\n",
       "      <td>363.00</td>\n",
       "      <td>915.54</td>\n",
       "      <td>609.50</td>\n",
       "      <td>626.85</td>\n",
       "      <td>396.93</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10086539</th>\n",
       "      <td>0.00</td>\n",
       "      <td>556.92</td>\n",
       "      <td>832.00</td>\n",
       "      <td>642.0</td>\n",
       "      <td>661.26</td>\n",
       "      <td>1880.00</td>\n",
       "      <td>950.86</td>\n",
       "      <td>1591.00</td>\n",
       "      <td>1048.60</td>\n",
       "      <td>500.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10140908</th>\n",
       "      <td>214.10</td>\n",
       "      <td>88.36</td>\n",
       "      <td>200.00</td>\n",
       "      <td>206.0</td>\n",
       "      <td>239.99</td>\n",
       "      <td>160.50</td>\n",
       "      <td>418.00</td>\n",
       "      <td>428.72</td>\n",
       "      <td>202.00</td>\n",
       "      <td>163.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10147994</th>\n",
       "      <td>38.11</td>\n",
       "      <td>39.52</td>\n",
       "      <td>218.40</td>\n",
       "      <td>227.9</td>\n",
       "      <td>224.70</td>\n",
       "      <td>229.69</td>\n",
       "      <td>226.00</td>\n",
       "      <td>504.29</td>\n",
       "      <td>4.24</td>\n",
       "      <td>256.20</td>\n",
       "      <td>...</td>\n",
       "      <td>17.85</td>\n",
       "      <td>55.12</td>\n",
       "      <td>28.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10152808</th>\n",
       "      <td>420.00</td>\n",
       "      <td>1030.00</td>\n",
       "      <td>510.00</td>\n",
       "      <td>423.3</td>\n",
       "      <td>877.50</td>\n",
       "      <td>1157.44</td>\n",
       "      <td>709.00</td>\n",
       "      <td>995.00</td>\n",
       "      <td>1015.00</td>\n",
       "      <td>515.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          transaction_01_month  transaction_02_month  transaction_03_month  \\\n",
       "ID_CPTE                                                                      \n",
       "10074849                411.00                340.26                993.92   \n",
       "10086539                  0.00                556.92                832.00   \n",
       "10140908                214.10                 88.36                200.00   \n",
       "10147994                 38.11                 39.52                218.40   \n",
       "10152808                420.00               1030.00                510.00   \n",
       "\n",
       "          transaction_04_month  transaction_05_month  transaction_06_month  \\\n",
       "ID_CPTE                                                                      \n",
       "10074849                   0.0                906.38                363.00   \n",
       "10086539                 642.0                661.26               1880.00   \n",
       "10140908                 206.0                239.99                160.50   \n",
       "10147994                 227.9                224.70                229.69   \n",
       "10152808                 423.3                877.50               1157.44   \n",
       "\n",
       "          transaction_07_month  transaction_08_month  transaction_09_month  \\\n",
       "ID_CPTE                                                                      \n",
       "10074849                915.54                609.50                626.85   \n",
       "10086539                950.86               1591.00               1048.60   \n",
       "10140908                418.00                428.72                202.00   \n",
       "10147994                226.00                504.29                  4.24   \n",
       "10152808                709.00                995.00               1015.00   \n",
       "\n",
       "          transaction_10_month    ...      cash_balance_06_month  \\\n",
       "ID_CPTE                           ...                              \n",
       "10074849                396.93    ...                       0.00   \n",
       "10086539                500.00    ...                       0.00   \n",
       "10140908                163.20    ...                       1.03   \n",
       "10147994                256.20    ...                      17.85   \n",
       "10152808                515.00    ...                       0.00   \n",
       "\n",
       "          cash_balance_07_month  cash_balance_08_month  cash_balance_09_month  \\\n",
       "ID_CPTE                                                                         \n",
       "10074849                   0.00                   0.00                    0.0   \n",
       "10086539                   0.00                   0.00                    0.0   \n",
       "10140908                   0.00                   0.00                    0.0   \n",
       "10147994                  55.12                  28.35                    0.0   \n",
       "10152808                   0.00                   0.00                    0.0   \n",
       "\n",
       "          cash_balance_10_month  cash_balance_11_month  cash_balance_12_month  \\\n",
       "ID_CPTE                                                                         \n",
       "10074849                   0.00                   0.00                    0.0   \n",
       "10086539                   0.00                   0.00                    0.0   \n",
       "10140908                   3.06                   2.04                    0.0   \n",
       "10147994                   0.00                   0.00                    0.0   \n",
       "10152808                   0.00                   0.00                    0.0   \n",
       "\n",
       "          MaxDelqCycle  AvgDelqCycle  LateCount  \n",
       "ID_CPTE                                          \n",
       "10074849             0           0.0          0  \n",
       "10086539             0           0.0          0  \n",
       "10140908             2           1.0         12  \n",
       "10147994             0           0.0         10  \n",
       "10152808             0           0.0         12  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(processed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp = normalize(X_test[:, :-3])\n",
    "X_test = np.hstack((X_tmp, X_test[:, -3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5100, 40)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lgb = rf.predict(X_test)\n",
    "#predict_lgb = np.array([0 if i < 0.6 else 1 for i in predict_lgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test['Default'] = predict_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = processed_test.reset_index()[['ID_CPTE', 'Default']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../raw_data/performance_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71424379</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64887111</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69431075</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31823308</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39407834</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE PERIODID_MY  Default\n",
       "0  71424379  2014-12-01      NaN\n",
       "1  64887111  2015-12-01      NaN\n",
       "2  69431075  2014-12-01      NaN\n",
       "3  31823308  2016-12-01      NaN\n",
       "4  39407834  2012-12-01      NaN"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10074849</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10086539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10140908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10147994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10152808</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  Default\n",
       "0  10074849        0\n",
       "1  10086539        0\n",
       "2  10140908        0\n",
       "3  10147994        0\n",
       "4  10152808        0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission[['ID_CPTE', 'Default']].merge(results, on='ID_CPTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission[['ID_CPTE', 'Default_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission.rename(columns={'Default_y': 'Default'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71424379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64887111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69431075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31823308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39407834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  Default\n",
       "0  71424379        0\n",
       "1  64887111        0\n",
       "2  69431075        0\n",
       "3  31823308        0\n",
       "4  39407834        0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71424379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64887111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69431075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31823308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39407834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  Default\n",
       "0  71424379        0\n",
       "1  64887111        0\n",
       "2  69431075        0\n",
       "3  31823308        0\n",
       "4  39407834        0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5100"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71424379</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64887111</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69431075</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31823308</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39407834</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE PERIODID_MY  Default\n",
       "0  71424379  2014-12-01      NaN\n",
       "1  64887111  2015-12-01      NaN\n",
       "2  69431075  2014-12-01      NaN\n",
       "3  31823308  2016-12-01      NaN\n",
       "4  39407834  2012-12-01      NaN"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
