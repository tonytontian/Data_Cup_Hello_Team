{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Test(Logistic regression, random forest, LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\futai\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# import the relevant computational modules\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd #data processing\n",
    "import numpy as np #linear algebra\n",
    "\n",
    "# Models Packages\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Gradient Boosting\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Basic Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "# Oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# visualization \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "transaction_training = pd.read_csv('../raw_data/transactions_train.csv')\n",
    "payment_training = pd.read_csv('../raw_data/paiements_train.csv')\n",
    "billing_training = pd.read_csv('../raw_data/facturation_train.csv')\n",
    "performance_training = pd.read_csv('../raw_data/performance_train.csv')\n",
    "\n",
    "\n",
    "transaction_test = pd.read_csv('../raw_data/transactions_test.csv')\n",
    "payment_test = pd.read_csv('../raw_data/paiements_test.csv')\n",
    "billing_test = pd.read_csv('../raw_data/facturation_test.csv')\n",
    "performance_test = pd.read_csv('../raw_data/performance_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>TRANSACTION_AMT</th>\n",
       "      <th>TRANSACTION_DTTM</th>\n",
       "      <th>PAYMENT_REVERSAL_XFLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99690111</td>\n",
       "      <td>208.0</td>\n",
       "      <td>2015-04-26 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99690111</td>\n",
       "      <td>176.8</td>\n",
       "      <td>2015-05-28 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99690111</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2015-03-27 04:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99690111</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2015-04-02 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99690111</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2015-11-24 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  TRANSACTION_AMT     TRANSACTION_DTTM PAYMENT_REVERSAL_XFLG\n",
       "0  99690111            208.0  2015-04-26 00:00:00                     Q\n",
       "1  99690111            176.8  2015-05-28 00:00:00                     Q\n",
       "2  99690111            200.0  2015-03-27 04:00:00                     Q\n",
       "3  99690111             80.8  2015-04-02 00:00:00                     Q\n",
       "4  99690111            250.0  2015-11-24 00:00:00                     Q"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payment_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>StatementDate</th>\n",
       "      <th>CurrentTotalBalance</th>\n",
       "      <th>CashBalance</th>\n",
       "      <th>CreditLimit</th>\n",
       "      <th>DelqCycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>2015-05-03</td>\n",
       "      <td>8497.84</td>\n",
       "      <td>4293.12</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>2014-11-03</td>\n",
       "      <td>866.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>2015-05-31</td>\n",
       "      <td>10790.95</td>\n",
       "      <td>5224.44</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>2015-10-04</td>\n",
       "      <td>12388.46</td>\n",
       "      <td>4786.08</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>2015-11-02</td>\n",
       "      <td>12746.50</td>\n",
       "      <td>4818.48</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE PERIODID_MY StatementDate  CurrentTotalBalance  CashBalance  \\\n",
       "0  99690111  2015-05-01    2015-05-03              8497.84      4293.12   \n",
       "1  99690111  2014-11-01    2014-11-03               866.00         0.00   \n",
       "2  99690111  2015-06-01    2015-05-31             10790.95      5224.44   \n",
       "3  99690111  2015-10-01    2015-10-04             12388.46      4786.08   \n",
       "4  99690111  2015-11-01    2015-11-02             12746.50      4818.48   \n",
       "\n",
       "   CreditLimit  DelqCycle  \n",
       "0      16200.0          0  \n",
       "1      12000.0          0  \n",
       "2      16200.0          0  \n",
       "3      16200.0          0  \n",
       "4      16200.0          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billing_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99690111</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57427180</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29617912</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61632809</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14117855</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE PERIODID_MY  Default\n",
       "0  99690111  2015-12-01        0\n",
       "1  57427180  2012-12-01        0\n",
       "2  29617912  2015-12-01        0\n",
       "3  61632809  2015-12-01        0\n",
       "4  14117855  2013-12-01        0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basic scikit-learn wrapper model class\n",
    "class SklearnWrapper:\n",
    "    def __init__(self, clf, seed=0, params=None, seed_bool=True):\n",
    "        if (seed_bool == True):\n",
    "            params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "    \n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create basic xgboost wrapper model class\n",
    "class XgbWrapper:\n",
    "    def __init__(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 250)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(xgb.DMatrix(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create basic lightGBM wrapper model class\n",
    "class LightGbmWrapper:\n",
    "    def __init(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 1550)\n",
    "        self.verbose_eval = params.pop('verbose_eval', 100)\n",
    "        \n",
    "    def train(self, x_train, y_train):\n",
    "        lgtrain = lgb.Dataset(x_train, y_train)\n",
    "        self.lgbm = lgb.train(self.param, lgtrain, num_boost_round=self.nrounds, verbose_eval=self.verbose_eval)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.lgbm.predict(lgb.Dataset(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create out-of-fold predictions \n",
    "# make good use of k-fold CV's result \n",
    "# serving for the staking alogrithm \n",
    "# create a new column generated from model's score\n",
    "\n",
    "def get_oof(clf, x_train, y, x_test):\n",
    "    '''\n",
    "    clf: the classifer, which can be logistic regression, SVM regression, Bayes classifier, etc.\n",
    "    x_train: the training x in training dataset\n",
    "    y: the training y in training dataset\n",
    "    x_test: the testing x in training dataset \n",
    "    '''\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        print('\\nFold {}'.format(i))\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "        \n",
    "        clf.fit(x_tr, y_tr)\n",
    "        \n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "    \n",
    "    m = stats.mode(oof_test_skf, axis=1)\n",
    "    oof_test[:] = m[0][0]\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocess\n",
    "\n",
    "class DataPreprocess:\n",
    "    def __init__(self, label_encoder):\n",
    "        self.lbl = label_encoder\n",
    "    \n",
    "    def convert_date(self, statement_date, period_date):\n",
    "        statement_day = statement_date.split('-')[-1]\n",
    "        period_day = period_date.split('-')[-1]\n",
    "        statement_month = statement_date.split('-')[-2]\n",
    "        period_month = period_date.split('-')[-2]\n",
    "        if int(statement_month) < int(period_month):\n",
    "            tmp = 0\n",
    "        else:\n",
    "            if int(statement_day) > 20:\n",
    "                tmp = 1\n",
    "            else:\n",
    "                tmp = 0\n",
    "        return tmp\n",
    "    \n",
    "    \n",
    "    def initialize_billing(self, billing_df):\n",
    "        tmp = []\n",
    "        for index, row in billing_df.iterrows():\n",
    "            tmp.append(self.convert_date(row['StatementDate'], row['PERIODID_MY']))\n",
    "\n",
    "        billing_df['statement_time'] = tmp\n",
    "        \n",
    "        return billing_df\n",
    "    \n",
    "    def preprocess_transcation(self, transaction_df):\n",
    "        categorical_columns = ['MERCHANT_CATEGORY_XCD', 'MERCHANT_CITY_NAME', 'MERCHANT_COUNTRY_XCD', \n",
    "                               'DECISION_XCD', 'TRANSACTION_CATEGORY_XCD', 'TRANSACTION_TYPE_XCD', 'SICGROUP']\n",
    "        \n",
    "        for col in categorical_columns:\n",
    "            transaction_df[col].fillna('unknown')\n",
    "            transaction_df[col] = self.lbl.fit_transform(transaction_df[col].astype(str))\n",
    "        \n",
    "        transaction_df = transaction_df.groupby(['ID_CPTE', 'MERCHANT_CATEGORY_XCD'])['TRANSACTION_AMT'].sum()\n",
    "        transaction_df = transaction_df.reset_index()\n",
    "        transaction_df = transaction_df.pivot_table('TRANSACTION_AMT', ['ID_CPTE'], 'MERCHANT_CATEGORY_XCD')\n",
    "        transaction_df.columns = ['MERCHANT_CATEGORY_' + str(i) for i in transaction_df.columns]\n",
    "        transaction_df = transaction_df.fillna(0)\n",
    "        \n",
    "        return transaction_df\n",
    "    \n",
    "    def preprocess_payment(self, payment_df, billing_df):\n",
    "        payment_df = payment_df.fillna(0)\n",
    "        payment_df['TRANSACTION_DTTM'] = payment_df['TRANSACTION_DTTM'].apply(lambda x: str(x).split(' ')[0][:-3])\n",
    "        payment_df = payment_df.sort_values(['ID_CPTE', 'TRANSACTION_DTTM'])\n",
    "        payment_df['PAYMENT_N_COUNT'] = payment_df['PAYMENT_REVERSAL_XFLG'] == 'N'\n",
    "        payment_df = payment_df.groupby(['ID_CPTE', 'TRANSACTION_DTTM'])[['TRANSACTION_AMT', 'PAYMENT_N_COUNT']].sum().reset_index()\n",
    "        payment_df = payment_df.groupby('ID_CPTE').tail(12)\n",
    "        \n",
    "        billing_df['PERIODID_MY'] = billing_df['PERIODID_MY'].apply(lambda x: x[:-3])\n",
    "        billing_df = billing_df.sort_values(['ID_CPTE', 'PERIODID_MY'])\n",
    "        billing_df = billing_df.reset_index(drop=True)\n",
    "        billing_df = billing_df.groupby('ID_CPTE').tail(12)\n",
    "        billing_df = billing_df.rename(columns={'PERIODID_MY': 'TRANSACTION_DTTM'})\n",
    "        \n",
    "        payment_df = payment_df.merge(billing_df[['ID_CPTE', 'TRANSACTION_DTTM', 'CurrentTotalBalance']], on=['ID_CPTE', 'TRANSACTION_DTTM'])\n",
    "        payment_df['PaymentRatio'] = (payment_df['TRANSACTION_AMT'] + 1) / (payment_df['CurrentTotalBalance'] + 1)\n",
    "        \n",
    "        tmp = payment_df.groupby(['ID_CPTE'])['PAYMENT_N_COUNT'].sum().reset_index()\n",
    "        \n",
    "        payment_df['TRANSACTION_DTTM'] = payment_df['TRANSACTION_DTTM'].apply(lambda x: x.split('-')[1])\n",
    "        payment_df = payment_df.pivot_table('PaymentRatio', ['ID_CPTE'], 'TRANSACTION_DTTM')\n",
    "        payment_df.columns = ['payment_ratio_' + str(i) for i in payment_df.columns + '_month']\n",
    "        payment_df = payment_df.reset_index()\n",
    "        payment_df = payment_df.fillna(0)\n",
    "        \n",
    "        payment_df = payment_df.merge(tmp, on='ID_CPTE')\n",
    "        \n",
    "        return payment_df\n",
    "    \n",
    "    def preprocess_billing(self, billing_df):\n",
    "        billing_df['PERIODID_MY'] = billing_df['PERIODID_MY'].apply(lambda x: x[:-3])\n",
    "        billing_df = billing_df.sort_values(['ID_CPTE', 'PERIODID_MY'])\n",
    "        billing_df = billing_df.reset_index(drop=True)\n",
    "        billing_df = billing_df.groupby('ID_CPTE').tail(12)\n",
    "        billing_df = billing_df.reset_index(drop=True)\n",
    "        billing_df['CreditLeft'] = billing_df['CreditLimit'] - billing_df['CurrentTotalBalance']\n",
    "        billing_df['CashRatio'] = billing_df['CashBalance'] / billing_df['CurrentTotalBalance']\n",
    "#         billing_df['tmp'] = np.append(np.array(billing_df['CreditLeft'][1:]), billing_df['CreditLeft'].tail(1).values)\n",
    "#         billing_df['ConsecutiveLeft'] = billing_df['tmp'] - billing_df['CreditLeft']\n",
    "#         billing_df['ConsecutiveLeft'] = np.append(np.array([0]), np.array(billing_df['ConsecutiveLeft'][:-1]))\n",
    "        \n",
    "        billing_df['PERIODID_MY'] = billing_df['PERIODID_MY'].apply(lambda x: x[-2:])\n",
    "        credit_left = billing_df.pivot_table('CreditLeft', ['ID_CPTE'], 'PERIODID_MY')\n",
    "        credit_left.columns = ['credit_left_' + str(i) for i in credit_left.columns + '_month']\n",
    "        \n",
    "#         consecutive_left = billing_df.pivot_table('ConsecutiveLeft', ['ID_CPTE'], 'PERIODID_MY')\n",
    "#         consecutive_left.columns = ['consecutive_left_' + str(i) for i in consecutive_left.columns + '_month']\n",
    "        \n",
    "        cash_ratio = billing_df.pivot_table('CashRatio', ['ID_CPTE'], 'PERIODID_MY')\n",
    "        cash_ratio.columns = ['cash_ratio_' + str(i) for i in cash_ratio.columns + '_month']\n",
    "        \n",
    "        credit_left_avg = billing_df.groupby(['ID_CPTE'])['CreditLeft'].mean().reset_index()\n",
    "        credit_left_avg = credit_left_avg.rename(columns={'CreditLeft': 'AvgCreditLeft'})\n",
    "        \n",
    "        delq_cycle_avg = billing_df.groupby(['ID_CPTE'])['DelqCycle'].mean().reset_index()\n",
    "        delq_cycle_avg = delq_cycle_avg.rename(columns={'DelqCycle': 'AvgDelqCycle'})\n",
    "        \n",
    "        delq_cycle = billing_df.groupby(['ID_CPTE'])['DelqCycle'].max().reset_index()\n",
    "        delq_cycle = delq_cycle.rename(columns={'DelqCycle': 'MaxDelqCycle'})\n",
    "        \n",
    "        total_balance_avg = billing_df.groupby(['ID_CPTE'])['CurrentTotalBalance'].mean().reset_index()\n",
    "        total_balance_avg = total_balance_avg.rename(columns={'CurrentTotalBalance': 'AvgTotalBalance'})\n",
    "        \n",
    "        cash_avg = billing_df.groupby(['ID_CPTE'])['CashBalance'].mean().reset_index()\n",
    "        cash_avg = cash_avg.rename(columns={'CashBalance': 'AvgCashBalance'})\n",
    "        \n",
    "        max_limit = billing_df.groupby(['ID_CPTE'])['CreditLimit'].mean().reset_index()\n",
    "        max_limit = max_limit.rename(columns={'CreditLimit': 'AvgCreditLimit'})\n",
    "        \n",
    "        late_count = billing_df.groupby(['ID_CPTE'])['statement_time'].sum().reset_index()\n",
    "        late_count = late_count.rename(columns={'statement_time': 'LateCount'})\n",
    "        \n",
    "#         tmp1 = billing_df.groupby(['ID_CPTE'])[['ID_CPTE', 'CreditLimit']].head(1).set_index('ID_CPTE')\n",
    "#         tmp2 = billing_df.groupby(['ID_CPTE'])[['ID_CPTE', 'CreditLimit']].tail(1).set_index('ID_CPTE')\n",
    "#         credit_change = tmp2 - tmp1\n",
    "#         credit_change = credit_change.reset_index()\n",
    "#         credit_change = credit_change.rename(columns={'CreditLimit': 'CreditChange'})\n",
    "        \n",
    "        credit_left = credit_left.reset_index()\n",
    "#         consecutive_left = consecutive_left.reset_index()\n",
    "        cash_ratio = cash_ratio.reset_index() \n",
    "        \n",
    "        tmp = credit_left.merge(cash_ratio, on='ID_CPTE')\n",
    "#         tmp = tmp.merge(credit_change, on='ID_CPTE')\n",
    "#         tmp = tmp.merge(consecutive_left, on='ID_CPTE')\n",
    "        tmp = tmp.merge(delq_cycle, on='ID_CPTE')\n",
    "        tmp = tmp.merge(delq_cycle_avg, on='ID_CPTE')\n",
    "        tmp = tmp.merge(credit_left_avg, on='ID_CPTE')\n",
    "        tmp = tmp.merge(total_balance_avg, on='ID_CPTE')\n",
    "        tmp = tmp.merge(cash_avg, on='ID_CPTE')\n",
    "        tmp = tmp.merge(max_limit, on='ID_CPTE')\n",
    "        \n",
    "        tmp = tmp.merge(late_count, on='ID_CPTE')\n",
    "        \n",
    "        return tmp\n",
    "    \n",
    "    def merge(self, payment, billing):\n",
    "        merge_df = payment.merge(billing, on='ID_CPTE', how='right')\n",
    "        return merge_df.set_index(['ID_CPTE']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>TRANSACTION_AMT</th>\n",
       "      <th>TRANSACTION_DTTM</th>\n",
       "      <th>PAYMENT_REVERSAL_XFLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99690111</td>\n",
       "      <td>208.0</td>\n",
       "      <td>2015-04-26 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99690111</td>\n",
       "      <td>176.8</td>\n",
       "      <td>2015-05-28 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99690111</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2015-03-27 04:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99690111</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2015-04-02 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99690111</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2015-11-24 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  TRANSACTION_AMT     TRANSACTION_DTTM PAYMENT_REVERSAL_XFLG\n",
       "0  99690111            208.0  2015-04-26 00:00:00                     Q\n",
       "1  99690111            176.8  2015-05-28 00:00:00                     Q\n",
       "2  99690111            200.0  2015-03-27 04:00:00                     Q\n",
       "3  99690111             80.8  2015-04-02 00:00:00                     Q\n",
       "4  99690111            250.0  2015-11-24 00:00:00                     Q"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payment_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "billing_training_cp = billing_training.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = DataPreprocess(label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "billing_training = preprocess.initialize_billing(billing_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_payment = preprocess.preprocess_payment(payment_training, billing_training_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_billing = preprocess.preprocess_billing(billing_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>credit_left_01_month</th>\n",
       "      <th>credit_left_02_month</th>\n",
       "      <th>credit_left_03_month</th>\n",
       "      <th>credit_left_04_month</th>\n",
       "      <th>credit_left_05_month</th>\n",
       "      <th>credit_left_06_month</th>\n",
       "      <th>credit_left_07_month</th>\n",
       "      <th>credit_left_08_month</th>\n",
       "      <th>credit_left_09_month</th>\n",
       "      <th>...</th>\n",
       "      <th>cash_ratio_10_month</th>\n",
       "      <th>cash_ratio_11_month</th>\n",
       "      <th>cash_ratio_12_month</th>\n",
       "      <th>MaxDelqCycle</th>\n",
       "      <th>AvgDelqCycle</th>\n",
       "      <th>AvgCreditLeft</th>\n",
       "      <th>AvgTotalBalance</th>\n",
       "      <th>AvgCashBalance</th>\n",
       "      <th>AvgCreditLimit</th>\n",
       "      <th>LateCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001822</td>\n",
       "      <td>20.34</td>\n",
       "      <td>18.88</td>\n",
       "      <td>300.40</td>\n",
       "      <td>482.92</td>\n",
       "      <td>3420.58</td>\n",
       "      <td>2110.03</td>\n",
       "      <td>2184.77</td>\n",
       "      <td>1669.00</td>\n",
       "      <td>1246.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>983.845000</td>\n",
       "      <td>10516.155000</td>\n",
       "      <td>8.416667</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10007972</td>\n",
       "      <td>140.00</td>\n",
       "      <td>700.00</td>\n",
       "      <td>662.00</td>\n",
       "      <td>139.26</td>\n",
       "      <td>256.30</td>\n",
       "      <td>258.00</td>\n",
       "      <td>128.66</td>\n",
       "      <td>299.95</td>\n",
       "      <td>180.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>364.455000</td>\n",
       "      <td>335.545000</td>\n",
       "      <td>0.257500</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10012520</td>\n",
       "      <td>565.04</td>\n",
       "      <td>353.05</td>\n",
       "      <td>771.55</td>\n",
       "      <td>1186.48</td>\n",
       "      <td>1580.97</td>\n",
       "      <td>1789.45</td>\n",
       "      <td>1704.09</td>\n",
       "      <td>1558.32</td>\n",
       "      <td>2323.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.754583</td>\n",
       "      <td>0.767928</td>\n",
       "      <td>0.608871</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1452.930833</td>\n",
       "      <td>1080.402500</td>\n",
       "      <td>431.599167</td>\n",
       "      <td>2533.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10025534</td>\n",
       "      <td>-7.90</td>\n",
       "      <td>-253.91</td>\n",
       "      <td>-177.08</td>\n",
       "      <td>-289.28</td>\n",
       "      <td>4825.89</td>\n",
       "      <td>1550.35</td>\n",
       "      <td>817.41</td>\n",
       "      <td>-212.78</td>\n",
       "      <td>-301.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>434.606667</td>\n",
       "      <td>5665.393333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6100.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10033579</td>\n",
       "      <td>90.24</td>\n",
       "      <td>248.55</td>\n",
       "      <td>68.00</td>\n",
       "      <td>83.42</td>\n",
       "      <td>114.16</td>\n",
       "      <td>25.12</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-24.28</td>\n",
       "      <td>-52.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>29.752500</td>\n",
       "      <td>470.247500</td>\n",
       "      <td>5.453333</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  credit_left_01_month  credit_left_02_month  credit_left_03_month  \\\n",
       "0  10001822                 20.34                 18.88                300.40   \n",
       "1  10007972                140.00                700.00                662.00   \n",
       "2  10012520                565.04                353.05                771.55   \n",
       "3  10025534                 -7.90               -253.91               -177.08   \n",
       "4  10033579                 90.24                248.55                 68.00   \n",
       "\n",
       "   credit_left_04_month  credit_left_05_month  credit_left_06_month  \\\n",
       "0                482.92               3420.58               2110.03   \n",
       "1                139.26                256.30                258.00   \n",
       "2               1186.48               1580.97               1789.45   \n",
       "3               -289.28               4825.89               1550.35   \n",
       "4                 83.42                114.16                 25.12   \n",
       "\n",
       "   credit_left_07_month  credit_left_08_month  credit_left_09_month  \\\n",
       "0               2184.77               1669.00               1246.00   \n",
       "1                128.66                299.95                180.25   \n",
       "2               1704.09               1558.32               2323.32   \n",
       "3                817.41               -212.78               -301.85   \n",
       "4                  5.00                -24.28                -52.12   \n",
       "\n",
       "     ...      cash_ratio_10_month  cash_ratio_11_month  cash_ratio_12_month  \\\n",
       "0    ...                 0.000000             0.008646             0.000000   \n",
       "1    ...                 0.000000             0.000000                  NaN   \n",
       "2    ...                 0.754583             0.767928             0.608871   \n",
       "3    ...                 0.000000             0.000000             0.000000   \n",
       "4    ...                 0.000000             0.000000             0.000000   \n",
       "\n",
       "   MaxDelqCycle  AvgDelqCycle  AvgCreditLeft  AvgTotalBalance  AvgCashBalance  \\\n",
       "0             0      0.000000     983.845000     10516.155000        8.416667   \n",
       "1             0      0.000000     364.455000       335.545000        0.257500   \n",
       "2             0      0.000000    1452.930833      1080.402500      431.599167   \n",
       "3             1      0.416667     434.606667      5665.393333        0.000000   \n",
       "4             1      0.083333      29.752500       470.247500        5.453333   \n",
       "\n",
       "   AvgCreditLimit  LateCount  \n",
       "0    11500.000000          0  \n",
       "1      700.000000          1  \n",
       "2     2533.333333          0  \n",
       "3     6100.000000         12  \n",
       "4      500.000000          0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_billing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>credit_left_01_month</th>\n",
       "      <th>credit_left_02_month</th>\n",
       "      <th>credit_left_03_month</th>\n",
       "      <th>credit_left_04_month</th>\n",
       "      <th>credit_left_05_month</th>\n",
       "      <th>credit_left_06_month</th>\n",
       "      <th>credit_left_07_month</th>\n",
       "      <th>credit_left_08_month</th>\n",
       "      <th>credit_left_09_month</th>\n",
       "      <th>credit_left_10_month</th>\n",
       "      <th>credit_left_11_month</th>\n",
       "      <th>credit_left_12_month</th>\n",
       "      <th>cash_ratio_01_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001822</td>\n",
       "      <td>20.34</td>\n",
       "      <td>18.88</td>\n",
       "      <td>300.40</td>\n",
       "      <td>482.92</td>\n",
       "      <td>3420.58</td>\n",
       "      <td>2110.03</td>\n",
       "      <td>2184.77</td>\n",
       "      <td>1669.00</td>\n",
       "      <td>1246.00</td>\n",
       "      <td>967.72</td>\n",
       "      <td>-182.30</td>\n",
       "      <td>-432.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10007972</td>\n",
       "      <td>140.00</td>\n",
       "      <td>700.00</td>\n",
       "      <td>662.00</td>\n",
       "      <td>139.26</td>\n",
       "      <td>256.30</td>\n",
       "      <td>258.00</td>\n",
       "      <td>128.66</td>\n",
       "      <td>299.95</td>\n",
       "      <td>180.25</td>\n",
       "      <td>299.14</td>\n",
       "      <td>609.90</td>\n",
       "      <td>700.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10012520</td>\n",
       "      <td>565.04</td>\n",
       "      <td>353.05</td>\n",
       "      <td>771.55</td>\n",
       "      <td>1186.48</td>\n",
       "      <td>1580.97</td>\n",
       "      <td>1789.45</td>\n",
       "      <td>1704.09</td>\n",
       "      <td>1558.32</td>\n",
       "      <td>2323.32</td>\n",
       "      <td>2074.00</td>\n",
       "      <td>1606.10</td>\n",
       "      <td>1922.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10025534</td>\n",
       "      <td>-7.90</td>\n",
       "      <td>-253.91</td>\n",
       "      <td>-177.08</td>\n",
       "      <td>-289.28</td>\n",
       "      <td>4825.89</td>\n",
       "      <td>1550.35</td>\n",
       "      <td>817.41</td>\n",
       "      <td>-212.78</td>\n",
       "      <td>-301.85</td>\n",
       "      <td>-222.98</td>\n",
       "      <td>-169.94</td>\n",
       "      <td>-342.65</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10033579</td>\n",
       "      <td>90.24</td>\n",
       "      <td>248.55</td>\n",
       "      <td>68.00</td>\n",
       "      <td>83.42</td>\n",
       "      <td>114.16</td>\n",
       "      <td>25.12</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-24.28</td>\n",
       "      <td>-52.12</td>\n",
       "      <td>-38.21</td>\n",
       "      <td>-33.52</td>\n",
       "      <td>-129.33</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  credit_left_01_month  credit_left_02_month  credit_left_03_month  \\\n",
       "0  10001822                 20.34                 18.88                300.40   \n",
       "1  10007972                140.00                700.00                662.00   \n",
       "2  10012520                565.04                353.05                771.55   \n",
       "3  10025534                 -7.90               -253.91               -177.08   \n",
       "4  10033579                 90.24                248.55                 68.00   \n",
       "\n",
       "   credit_left_04_month  credit_left_05_month  credit_left_06_month  \\\n",
       "0                482.92               3420.58               2110.03   \n",
       "1                139.26                256.30                258.00   \n",
       "2               1186.48               1580.97               1789.45   \n",
       "3               -289.28               4825.89               1550.35   \n",
       "4                 83.42                114.16                 25.12   \n",
       "\n",
       "   credit_left_07_month  credit_left_08_month  credit_left_09_month  \\\n",
       "0               2184.77               1669.00               1246.00   \n",
       "1                128.66                299.95                180.25   \n",
       "2               1704.09               1558.32               2323.32   \n",
       "3                817.41               -212.78               -301.85   \n",
       "4                  5.00                -24.28                -52.12   \n",
       "\n",
       "   credit_left_10_month  credit_left_11_month  credit_left_12_month  \\\n",
       "0                967.72               -182.30               -432.20   \n",
       "1                299.14                609.90                700.00   \n",
       "2               2074.00               1606.10               1922.80   \n",
       "3               -222.98               -169.94               -342.65   \n",
       "4                -38.21                -33.52               -129.33   \n",
       "\n",
       "   cash_ratio_01_month  \n",
       "0                  0.0  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "3                  0.0  \n",
       "4                  0.0  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_billing.iloc[:, :14].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = preprocess.merge(processed_payment, processed_billing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_col = processed_data.iloc[:, :12].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with missing value in payment\n",
    "for col in transaction_col:\n",
    "    replace_value = processed_data[processed_data[col].notna()][col].mean()\n",
    "    processed_data[col] = processed_data[col].fillna(replace_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.merge(performance_training[['ID_CPTE', 'Default']], on='ID_CPTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.set_index('ID_CPTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features correlation and distribution analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>payment_ratio_01_month</th>\n",
       "      <th>payment_ratio_02_month</th>\n",
       "      <th>payment_ratio_03_month</th>\n",
       "      <th>payment_ratio_04_month</th>\n",
       "      <th>payment_ratio_05_month</th>\n",
       "      <th>payment_ratio_06_month</th>\n",
       "      <th>payment_ratio_07_month</th>\n",
       "      <th>payment_ratio_08_month</th>\n",
       "      <th>payment_ratio_09_month</th>\n",
       "      <th>payment_ratio_10_month</th>\n",
       "      <th>...</th>\n",
       "      <th>cash_ratio_11_month</th>\n",
       "      <th>cash_ratio_12_month</th>\n",
       "      <th>MaxDelqCycle</th>\n",
       "      <th>AvgDelqCycle</th>\n",
       "      <th>AvgCreditLeft</th>\n",
       "      <th>AvgTotalBalance</th>\n",
       "      <th>AvgCashBalance</th>\n",
       "      <th>AvgCreditLimit</th>\n",
       "      <th>LateCount</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10001822</th>\n",
       "      <td>0.027786</td>\n",
       "      <td>0.045593</td>\n",
       "      <td>0.033525</td>\n",
       "      <td>0.381282</td>\n",
       "      <td>0.032610</td>\n",
       "      <td>0.028325</td>\n",
       "      <td>0.028821</td>\n",
       "      <td>0.030614</td>\n",
       "      <td>0.024476</td>\n",
       "      <td>0.022097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>983.845000</td>\n",
       "      <td>10516.155000</td>\n",
       "      <td>8.416667</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10007972</th>\n",
       "      <td>1.399893</td>\n",
       "      <td>169.280000</td>\n",
       "      <td>26.948718</td>\n",
       "      <td>0.997793</td>\n",
       "      <td>1.495390</td>\n",
       "      <td>0.709932</td>\n",
       "      <td>1.475888</td>\n",
       "      <td>0.480987</td>\n",
       "      <td>1.818339</td>\n",
       "      <td>1.748047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>364.455000</td>\n",
       "      <td>335.545000</td>\n",
       "      <td>0.257500</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012520</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047133</td>\n",
       "      <td>0.321103</td>\n",
       "      <td>1.161446</td>\n",
       "      <td>0.509653</td>\n",
       "      <td>1.278095</td>\n",
       "      <td>1.018293</td>\n",
       "      <td>0.080133</td>\n",
       "      <td>1.271534</td>\n",
       "      <td>0.543922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.767928</td>\n",
       "      <td>0.608871</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1452.930833</td>\n",
       "      <td>1080.402500</td>\n",
       "      <td>431.599167</td>\n",
       "      <td>2533.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10025534</th>\n",
       "      <td>0.021657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.913302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.393861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>434.606667</td>\n",
       "      <td>5665.393333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6100.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10033579</th>\n",
       "      <td>1.401183</td>\n",
       "      <td>1.553971</td>\n",
       "      <td>0.954342</td>\n",
       "      <td>1.129197</td>\n",
       "      <td>1.416089</td>\n",
       "      <td>0.883857</td>\n",
       "      <td>0.574435</td>\n",
       "      <td>0.203701</td>\n",
       "      <td>0.153674</td>\n",
       "      <td>0.409117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>29.752500</td>\n",
       "      <td>470.247500</td>\n",
       "      <td>5.453333</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          payment_ratio_01_month  payment_ratio_02_month  \\\n",
       "ID_CPTE                                                    \n",
       "10001822                0.027786                0.045593   \n",
       "10007972                1.399893              169.280000   \n",
       "10012520                0.000000                0.047133   \n",
       "10025534                0.021657                0.000000   \n",
       "10033579                1.401183                1.553971   \n",
       "\n",
       "          payment_ratio_03_month  payment_ratio_04_month  \\\n",
       "ID_CPTE                                                    \n",
       "10001822                0.033525                0.381282   \n",
       "10007972               26.948718                0.997793   \n",
       "10012520                0.321103                1.161446   \n",
       "10025534                0.041573                0.000000   \n",
       "10033579                0.954342                1.129197   \n",
       "\n",
       "          payment_ratio_05_month  payment_ratio_06_month  \\\n",
       "ID_CPTE                                                    \n",
       "10001822                0.032610                0.028325   \n",
       "10007972                1.495390                0.709932   \n",
       "10012520                0.509653                1.278095   \n",
       "10025534                4.913302                0.000000   \n",
       "10033579                1.416089                0.883857   \n",
       "\n",
       "          payment_ratio_07_month  payment_ratio_08_month  \\\n",
       "ID_CPTE                                                    \n",
       "10001822                0.028821                0.030614   \n",
       "10007972                1.475888                0.480987   \n",
       "10012520                1.018293                0.080133   \n",
       "10025534                0.393861                0.000000   \n",
       "10033579                0.574435                0.203701   \n",
       "\n",
       "          payment_ratio_09_month  payment_ratio_10_month   ...     \\\n",
       "ID_CPTE                                                    ...      \n",
       "10001822                0.024476                0.022097   ...      \n",
       "10007972                1.818339                1.748047   ...      \n",
       "10012520                1.271534                0.543922   ...      \n",
       "10025534                0.049822                0.000000   ...      \n",
       "10033579                0.153674                0.409117   ...      \n",
       "\n",
       "          cash_ratio_11_month  cash_ratio_12_month  MaxDelqCycle  \\\n",
       "ID_CPTE                                                            \n",
       "10001822             0.008646             0.000000             0   \n",
       "10007972             0.000000             0.000000             0   \n",
       "10012520             0.767928             0.608871             0   \n",
       "10025534             0.000000             0.000000             1   \n",
       "10033579             0.000000             0.000000             1   \n",
       "\n",
       "          AvgDelqCycle  AvgCreditLeft  AvgTotalBalance  AvgCashBalance  \\\n",
       "ID_CPTE                                                                  \n",
       "10001822      0.000000     983.845000     10516.155000        8.416667   \n",
       "10007972      0.000000     364.455000       335.545000        0.257500   \n",
       "10012520      0.000000    1452.930833      1080.402500      431.599167   \n",
       "10025534      0.416667     434.606667      5665.393333        0.000000   \n",
       "10033579      0.083333      29.752500       470.247500        5.453333   \n",
       "\n",
       "          AvgCreditLimit  LateCount  Default  \n",
       "ID_CPTE                                       \n",
       "10001822    11500.000000          0        0  \n",
       "10007972      700.000000          1        0  \n",
       "10012520     2533.333333          0        0  \n",
       "10025534     6100.000000         12        1  \n",
       "10033579      500.000000          0        0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tmp1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-9f44717ea491>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprocessed_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tmp1' is not defined"
     ]
    }
   ],
   "source": [
    "#processed_data = pd.concat((tmp1, tmp2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed_data = processed_data.drop(['Default'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed_data = processed_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#other_features = pd.read_csv('../intermidiate_data/20180716_2_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11900, 11900)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(processed_data), len(other_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#other_features = other_features.rename(columns={'id_cpte': 'ID_CPTE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed_data = processed_data.merge(other_features, on=['ID_CPTE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed_data = processed_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_y = processed_data['Default'].copy()\n",
    "processed_X = processed_data.drop(['Default'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(processed_y)\n",
    "X = np.array(processed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\futai\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29d017da390>"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(processed_X['delqcycle1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\futai\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29d01855278>"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(processed_X['lag_pay1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.array(processed_data.iloc[:, :-1])\n",
    "# y = np.array(processed_data.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_tmp = normalize(X[:, 13:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_tmp = np.hstack((X[:, :13], X_tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.hstack((X_tmp, X[:, -3:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sm = SMOTE(random_state=42, ratio=1)\n",
    "#X_res, y_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    " \n",
    "clf = LogisticRegression()\n",
    "rf = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_clf = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7741109574920463"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(predict_clf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7794504181600955"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(predict_rf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9926946188158088"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(predict_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>credit_left_08_month</th>\n",
       "      <td>0.084728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_10_month</th>\n",
       "      <td>0.064033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_ratio_12_month</th>\n",
       "      <td>0.051795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_09_month</th>\n",
       "      <td>0.046571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_12_month</th>\n",
       "      <td>0.046148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AvgCreditLeft</th>\n",
       "      <td>0.041167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_07_month</th>\n",
       "      <td>0.040314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_11_month</th>\n",
       "      <td>0.035728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_03_month</th>\n",
       "      <td>0.033311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AvgDelqCycle</th>\n",
       "      <td>0.030576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_ratio_11_month</th>\n",
       "      <td>0.030485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_ratio_10_month</th>\n",
       "      <td>0.028144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AvgCashBalance</th>\n",
       "      <td>0.025560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_ratio_09_month</th>\n",
       "      <td>0.022196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_ratio_07_month</th>\n",
       "      <td>0.021762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_ratio_08_month</th>\n",
       "      <td>0.021331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_01_month</th>\n",
       "      <td>0.020568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_05_month</th>\n",
       "      <td>0.020280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_06_month</th>\n",
       "      <td>0.020220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxDelqCycle</th>\n",
       "      <td>0.020196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_ratio_01_month</th>\n",
       "      <td>0.019750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AvgTotalBalance</th>\n",
       "      <td>0.018995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_ratio_05_month</th>\n",
       "      <td>0.018776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_ratio_04_month</th>\n",
       "      <td>0.018614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_ratio_02_month</th>\n",
       "      <td>0.018327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_ratio_03_month</th>\n",
       "      <td>0.018005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_ratio_06_month</th>\n",
       "      <td>0.017818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_02_month</th>\n",
       "      <td>0.017465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_left_04_month</th>\n",
       "      <td>0.016756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AvgCreditLimit</th>\n",
       "      <td>0.016587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_ratio_11_month</th>\n",
       "      <td>0.015101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_ratio_09_month</th>\n",
       "      <td>0.013511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_ratio_10_month</th>\n",
       "      <td>0.011920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_ratio_12_month</th>\n",
       "      <td>0.011261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_ratio_02_month</th>\n",
       "      <td>0.008839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_ratio_06_month</th>\n",
       "      <td>0.007848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LateCount</th>\n",
       "      <td>0.007546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_ratio_01_month</th>\n",
       "      <td>0.007327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_ratio_03_month</th>\n",
       "      <td>0.006690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_ratio_05_month</th>\n",
       "      <td>0.006332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_ratio_08_month</th>\n",
       "      <td>0.006223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_ratio_04_month</th>\n",
       "      <td>0.005637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_ratio_07_month</th>\n",
       "      <td>0.005474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAYMENT_N_COUNT</th>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Importance\n",
       "credit_left_08_month      0.084728\n",
       "credit_left_10_month      0.064033\n",
       "payment_ratio_12_month    0.051795\n",
       "credit_left_09_month      0.046571\n",
       "credit_left_12_month      0.046148\n",
       "AvgCreditLeft             0.041167\n",
       "credit_left_07_month      0.040314\n",
       "credit_left_11_month      0.035728\n",
       "credit_left_03_month      0.033311\n",
       "AvgDelqCycle              0.030576\n",
       "payment_ratio_11_month    0.030485\n",
       "payment_ratio_10_month    0.028144\n",
       "AvgCashBalance            0.025560\n",
       "payment_ratio_09_month    0.022196\n",
       "payment_ratio_07_month    0.021762\n",
       "payment_ratio_08_month    0.021331\n",
       "credit_left_01_month      0.020568\n",
       "credit_left_05_month      0.020280\n",
       "credit_left_06_month      0.020220\n",
       "MaxDelqCycle              0.020196\n",
       "payment_ratio_01_month    0.019750\n",
       "AvgTotalBalance           0.018995\n",
       "payment_ratio_05_month    0.018776\n",
       "payment_ratio_04_month    0.018614\n",
       "payment_ratio_02_month    0.018327\n",
       "payment_ratio_03_month    0.018005\n",
       "payment_ratio_06_month    0.017818\n",
       "credit_left_02_month      0.017465\n",
       "credit_left_04_month      0.016756\n",
       "AvgCreditLimit            0.016587\n",
       "cash_ratio_11_month       0.015101\n",
       "cash_ratio_09_month       0.013511\n",
       "cash_ratio_10_month       0.011920\n",
       "cash_ratio_12_month       0.011261\n",
       "cash_ratio_02_month       0.008839\n",
       "cash_ratio_06_month       0.007848\n",
       "LateCount                 0.007546\n",
       "cash_ratio_01_month       0.007327\n",
       "cash_ratio_03_month       0.006690\n",
       "cash_ratio_05_month       0.006332\n",
       "cash_ratio_08_month       0.006223\n",
       "cash_ratio_04_month       0.005637\n",
       "cash_ratio_07_month       0.005474\n",
       "PAYMENT_N_COUNT           0.000082"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = rf.feature_importances_\n",
    "importance = pd.DataFrame(importance, index=processed_X.columns, columns=[\"Importance\"])\n",
    "importance.sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# L1-based feature selection\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 35)\n",
    "fit = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False,  True, False, False,  True,  True,  True,\n",
       "        True, False, False, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_features = processed_X.columns[fit.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rfe = np.array(processed_X[select_features])\n",
    "y_rfe = np.array(processed_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_rfe, y_rfe, test_size=0.3, random_state=102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "rf = RandomForestClassifier(min_samples_split=200, max_depth=20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=200,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.757081509980033"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_clf = clf.predict(X_test)\n",
    "roc_auc_score(predict_clf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7868063575867569"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rf = rf.predict(X_test)\n",
    "roc_auc_score(predict_rf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=40)\n",
    "fit = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11900, 30)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-233-b29ec06382b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#X_train, X_test, y_train, y_test = train_test_split(fit, y, test_size=0.3, random_state=102)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#rf.fit(X_train, y_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mscore_pca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
     ]
    }
   ],
   "source": [
    "score_pca = []\n",
    "for i in [20, 30, 40, 50, 60]:\n",
    "    pca = PCA(n_components=i)\n",
    "    fit = pca.fit_transform(X)\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(fit, y, test_size=0.3, random_state=102)\n",
    "    #rf.fit(X_train, y_train)\n",
    "    scores = cross_val_score(rf, fit, y, cv=10, scoring='roc_auc')\n",
    "    score_pca.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=200,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(fit, y, test_size=0.3, random_state=102)\n",
    "clf.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7370900417412045"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_clf = clf.predict(X_test)\n",
    "roc_auc_score(predict_clf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7753043958526848"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rf = rf.predict(X_test)\n",
    "roc_auc_score(predict_rf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-244-3b31360bdfb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(rf, X, y, cv=10, scoring='roc_auc')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11900, 40)"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(fit, y, test_size=0.3, random_state=102)\n",
    "clf.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8056648243124367"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_clf = clf.predict(X_test)\n",
    "roc_auc_score(predict_clf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7642525337837839"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rf = rf.predict(X_test)\n",
    "roc_auc_score(predict_rf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8563294921033338"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(rf, X, y, cv=10, scoring='roc_auc')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "pca = PCA(n_components=50)\n",
    "fit = pca.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(fit, y, test_size=0.3, random_state=102)\n",
    "\n",
    "svm_clf = svm.SVC(kernel='linear')\n",
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predict = svm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(svm_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params =  {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    #'max_depth': 15,\n",
    "    'num_leaves': 270,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 2,\n",
    "    'learning_rate': 0.0175,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgtrain = lgb.Dataset(X_train, y_train)\n",
    "lgtest = lgb.Dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.682303\n",
      "[2]\ttraining's binary_logloss: 0.671499\n",
      "[3]\ttraining's binary_logloss: 0.661148\n",
      "[4]\ttraining's binary_logloss: 0.651024\n",
      "[5]\ttraining's binary_logloss: 0.641215\n",
      "[6]\ttraining's binary_logloss: 0.632217\n",
      "[7]\ttraining's binary_logloss: 0.62282\n",
      "[8]\ttraining's binary_logloss: 0.614372\n",
      "[9]\ttraining's binary_logloss: 0.605316\n",
      "[10]\ttraining's binary_logloss: 0.596594\n",
      "[11]\ttraining's binary_logloss: 0.588315\n",
      "[12]\ttraining's binary_logloss: 0.580296\n",
      "[13]\ttraining's binary_logloss: 0.57206\n",
      "[14]\ttraining's binary_logloss: 0.564489\n",
      "[15]\ttraining's binary_logloss: 0.557064\n",
      "[16]\ttraining's binary_logloss: 0.54963\n",
      "[17]\ttraining's binary_logloss: 0.542837\n",
      "[18]\ttraining's binary_logloss: 0.536194\n",
      "[19]\ttraining's binary_logloss: 0.529462\n",
      "[20]\ttraining's binary_logloss: 0.522654\n",
      "[21]\ttraining's binary_logloss: 0.516343\n",
      "[22]\ttraining's binary_logloss: 0.50993\n",
      "[23]\ttraining's binary_logloss: 0.503637\n",
      "[24]\ttraining's binary_logloss: 0.497436\n",
      "[25]\ttraining's binary_logloss: 0.491473\n",
      "[26]\ttraining's binary_logloss: 0.486015\n",
      "[27]\ttraining's binary_logloss: 0.480462\n",
      "[28]\ttraining's binary_logloss: 0.474966\n",
      "[29]\ttraining's binary_logloss: 0.469594\n",
      "[30]\ttraining's binary_logloss: 0.464391\n",
      "[31]\ttraining's binary_logloss: 0.459014\n",
      "[32]\ttraining's binary_logloss: 0.454275\n",
      "[33]\ttraining's binary_logloss: 0.449364\n",
      "[34]\ttraining's binary_logloss: 0.444361\n",
      "[35]\ttraining's binary_logloss: 0.439538\n",
      "[36]\ttraining's binary_logloss: 0.434871\n",
      "[37]\ttraining's binary_logloss: 0.430113\n",
      "[38]\ttraining's binary_logloss: 0.425383\n",
      "[39]\ttraining's binary_logloss: 0.420826\n",
      "[40]\ttraining's binary_logloss: 0.416524\n",
      "[41]\ttraining's binary_logloss: 0.412183\n",
      "[42]\ttraining's binary_logloss: 0.408246\n",
      "[43]\ttraining's binary_logloss: 0.40418\n",
      "[44]\ttraining's binary_logloss: 0.400052\n",
      "[45]\ttraining's binary_logloss: 0.395952\n",
      "[46]\ttraining's binary_logloss: 0.392415\n",
      "[47]\ttraining's binary_logloss: 0.388875\n",
      "[48]\ttraining's binary_logloss: 0.385042\n",
      "[49]\ttraining's binary_logloss: 0.381324\n",
      "[50]\ttraining's binary_logloss: 0.377856\n",
      "[51]\ttraining's binary_logloss: 0.374243\n",
      "[52]\ttraining's binary_logloss: 0.370708\n",
      "[53]\ttraining's binary_logloss: 0.367323\n",
      "[54]\ttraining's binary_logloss: 0.364002\n",
      "[55]\ttraining's binary_logloss: 0.360812\n",
      "[56]\ttraining's binary_logloss: 0.357533\n",
      "[57]\ttraining's binary_logloss: 0.354275\n",
      "[58]\ttraining's binary_logloss: 0.35122\n",
      "[59]\ttraining's binary_logloss: 0.348244\n",
      "[60]\ttraining's binary_logloss: 0.345439\n",
      "[61]\ttraining's binary_logloss: 0.342493\n",
      "[62]\ttraining's binary_logloss: 0.339619\n",
      "[63]\ttraining's binary_logloss: 0.336745\n",
      "[64]\ttraining's binary_logloss: 0.333941\n",
      "[65]\ttraining's binary_logloss: 0.331085\n",
      "[66]\ttraining's binary_logloss: 0.328236\n",
      "[67]\ttraining's binary_logloss: 0.32546\n",
      "[68]\ttraining's binary_logloss: 0.322709\n",
      "[69]\ttraining's binary_logloss: 0.320147\n",
      "[70]\ttraining's binary_logloss: 0.3175\n",
      "[71]\ttraining's binary_logloss: 0.314988\n",
      "[72]\ttraining's binary_logloss: 0.312511\n",
      "[73]\ttraining's binary_logloss: 0.310156\n",
      "[74]\ttraining's binary_logloss: 0.307704\n",
      "[75]\ttraining's binary_logloss: 0.305209\n",
      "[76]\ttraining's binary_logloss: 0.302767\n",
      "[77]\ttraining's binary_logloss: 0.30044\n",
      "[78]\ttraining's binary_logloss: 0.2981\n",
      "[79]\ttraining's binary_logloss: 0.295742\n",
      "[80]\ttraining's binary_logloss: 0.293485\n",
      "[81]\ttraining's binary_logloss: 0.291274\n",
      "[82]\ttraining's binary_logloss: 0.289114\n",
      "[83]\ttraining's binary_logloss: 0.287026\n",
      "[84]\ttraining's binary_logloss: 0.284805\n",
      "[85]\ttraining's binary_logloss: 0.282792\n",
      "[86]\ttraining's binary_logloss: 0.2808\n",
      "[87]\ttraining's binary_logloss: 0.278864\n",
      "[88]\ttraining's binary_logloss: 0.27675\n",
      "[89]\ttraining's binary_logloss: 0.274811\n",
      "[90]\ttraining's binary_logloss: 0.272847\n",
      "[91]\ttraining's binary_logloss: 0.270889\n",
      "[92]\ttraining's binary_logloss: 0.26894\n",
      "[93]\ttraining's binary_logloss: 0.266963\n",
      "[94]\ttraining's binary_logloss: 0.265051\n",
      "[95]\ttraining's binary_logloss: 0.26315\n",
      "[96]\ttraining's binary_logloss: 0.261284\n",
      "[97]\ttraining's binary_logloss: 0.259394\n",
      "[98]\ttraining's binary_logloss: 0.257633\n",
      "[99]\ttraining's binary_logloss: 0.255837\n",
      "[100]\ttraining's binary_logloss: 0.254151\n",
      "[101]\ttraining's binary_logloss: 0.252455\n",
      "[102]\ttraining's binary_logloss: 0.250799\n",
      "[103]\ttraining's binary_logloss: 0.249038\n",
      "[104]\ttraining's binary_logloss: 0.247343\n",
      "[105]\ttraining's binary_logloss: 0.245695\n",
      "[106]\ttraining's binary_logloss: 0.244041\n",
      "[107]\ttraining's binary_logloss: 0.242354\n",
      "[108]\ttraining's binary_logloss: 0.240712\n",
      "[109]\ttraining's binary_logloss: 0.23906\n",
      "[110]\ttraining's binary_logloss: 0.237523\n",
      "[111]\ttraining's binary_logloss: 0.235886\n",
      "[112]\ttraining's binary_logloss: 0.234327\n",
      "[113]\ttraining's binary_logloss: 0.232744\n",
      "[114]\ttraining's binary_logloss: 0.231199\n",
      "[115]\ttraining's binary_logloss: 0.229655\n",
      "[116]\ttraining's binary_logloss: 0.228105\n",
      "[117]\ttraining's binary_logloss: 0.226561\n",
      "[118]\ttraining's binary_logloss: 0.225122\n",
      "[119]\ttraining's binary_logloss: 0.22368\n",
      "[120]\ttraining's binary_logloss: 0.22221\n",
      "[121]\ttraining's binary_logloss: 0.22075\n",
      "[122]\ttraining's binary_logloss: 0.219361\n",
      "[123]\ttraining's binary_logloss: 0.217995\n",
      "[124]\ttraining's binary_logloss: 0.21656\n",
      "[125]\ttraining's binary_logloss: 0.21522\n",
      "[126]\ttraining's binary_logloss: 0.213841\n",
      "[127]\ttraining's binary_logloss: 0.212513\n",
      "[128]\ttraining's binary_logloss: 0.211215\n",
      "[129]\ttraining's binary_logloss: 0.209891\n",
      "[130]\ttraining's binary_logloss: 0.208625\n",
      "[131]\ttraining's binary_logloss: 0.207353\n",
      "[132]\ttraining's binary_logloss: 0.206045\n",
      "[133]\ttraining's binary_logloss: 0.20477\n",
      "[134]\ttraining's binary_logloss: 0.203483\n",
      "[135]\ttraining's binary_logloss: 0.202241\n",
      "[136]\ttraining's binary_logloss: 0.200983\n",
      "[137]\ttraining's binary_logloss: 0.199726\n",
      "[138]\ttraining's binary_logloss: 0.198497\n",
      "[139]\ttraining's binary_logloss: 0.197279\n",
      "[140]\ttraining's binary_logloss: 0.196118\n",
      "[141]\ttraining's binary_logloss: 0.194937\n",
      "[142]\ttraining's binary_logloss: 0.193788\n",
      "[143]\ttraining's binary_logloss: 0.192606\n",
      "[144]\ttraining's binary_logloss: 0.191454\n",
      "[145]\ttraining's binary_logloss: 0.19029\n",
      "[146]\ttraining's binary_logloss: 0.189173\n",
      "[147]\ttraining's binary_logloss: 0.188053\n",
      "[148]\ttraining's binary_logloss: 0.186924\n",
      "[149]\ttraining's binary_logloss: 0.185816\n",
      "[150]\ttraining's binary_logloss: 0.184736\n",
      "[151]\ttraining's binary_logloss: 0.183619\n",
      "[152]\ttraining's binary_logloss: 0.182468\n",
      "[153]\ttraining's binary_logloss: 0.181361\n",
      "[154]\ttraining's binary_logloss: 0.1803\n",
      "[155]\ttraining's binary_logloss: 0.179274\n",
      "[156]\ttraining's binary_logloss: 0.178213\n",
      "[157]\ttraining's binary_logloss: 0.177189\n",
      "[158]\ttraining's binary_logloss: 0.176128\n",
      "[159]\ttraining's binary_logloss: 0.175081\n",
      "[160]\ttraining's binary_logloss: 0.174036\n",
      "[161]\ttraining's binary_logloss: 0.173047\n",
      "[162]\ttraining's binary_logloss: 0.171997\n",
      "[163]\ttraining's binary_logloss: 0.170923\n",
      "[164]\ttraining's binary_logloss: 0.169894\n",
      "[165]\ttraining's binary_logloss: 0.16891\n",
      "[166]\ttraining's binary_logloss: 0.167965\n",
      "[167]\ttraining's binary_logloss: 0.167033\n",
      "[168]\ttraining's binary_logloss: 0.166032\n",
      "[169]\ttraining's binary_logloss: 0.165062\n",
      "[170]\ttraining's binary_logloss: 0.164139\n",
      "[171]\ttraining's binary_logloss: 0.163161\n",
      "[172]\ttraining's binary_logloss: 0.162205\n",
      "[173]\ttraining's binary_logloss: 0.161233\n",
      "[174]\ttraining's binary_logloss: 0.160276\n",
      "[175]\ttraining's binary_logloss: 0.15938\n",
      "[176]\ttraining's binary_logloss: 0.158528\n",
      "[177]\ttraining's binary_logloss: 0.157594\n",
      "[178]\ttraining's binary_logloss: 0.15672\n",
      "[179]\ttraining's binary_logloss: 0.155855\n",
      "[180]\ttraining's binary_logloss: 0.155036\n",
      "[181]\ttraining's binary_logloss: 0.15415\n",
      "[182]\ttraining's binary_logloss: 0.1533\n",
      "[183]\ttraining's binary_logloss: 0.152425\n",
      "[184]\ttraining's binary_logloss: 0.15154\n",
      "[185]\ttraining's binary_logloss: 0.150692\n",
      "[186]\ttraining's binary_logloss: 0.149793\n",
      "[187]\ttraining's binary_logloss: 0.148914\n",
      "[188]\ttraining's binary_logloss: 0.148024\n",
      "[189]\ttraining's binary_logloss: 0.147158\n",
      "[190]\ttraining's binary_logloss: 0.146258\n",
      "[191]\ttraining's binary_logloss: 0.145394\n",
      "[192]\ttraining's binary_logloss: 0.144544\n",
      "[193]\ttraining's binary_logloss: 0.143775\n",
      "[194]\ttraining's binary_logloss: 0.142923\n",
      "[195]\ttraining's binary_logloss: 0.142063\n",
      "[196]\ttraining's binary_logloss: 0.141252\n",
      "[197]\ttraining's binary_logloss: 0.14042\n",
      "[198]\ttraining's binary_logloss: 0.139583\n",
      "[199]\ttraining's binary_logloss: 0.138698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's binary_logloss: 0.137901\n",
      "[201]\ttraining's binary_logloss: 0.137111\n",
      "[202]\ttraining's binary_logloss: 0.13632\n",
      "[203]\ttraining's binary_logloss: 0.1355\n",
      "[204]\ttraining's binary_logloss: 0.134693\n",
      "[205]\ttraining's binary_logloss: 0.133922\n",
      "[206]\ttraining's binary_logloss: 0.133174\n",
      "[207]\ttraining's binary_logloss: 0.132426\n",
      "[208]\ttraining's binary_logloss: 0.131686\n",
      "[209]\ttraining's binary_logloss: 0.130901\n",
      "[210]\ttraining's binary_logloss: 0.130124\n",
      "[211]\ttraining's binary_logloss: 0.129345\n",
      "[212]\ttraining's binary_logloss: 0.128602\n",
      "[213]\ttraining's binary_logloss: 0.127917\n",
      "[214]\ttraining's binary_logloss: 0.12715\n",
      "[215]\ttraining's binary_logloss: 0.126421\n",
      "[216]\ttraining's binary_logloss: 0.125728\n",
      "[217]\ttraining's binary_logloss: 0.124962\n",
      "[218]\ttraining's binary_logloss: 0.124137\n",
      "[219]\ttraining's binary_logloss: 0.123436\n",
      "[220]\ttraining's binary_logloss: 0.122712\n",
      "[221]\ttraining's binary_logloss: 0.122017\n",
      "[222]\ttraining's binary_logloss: 0.121319\n",
      "[223]\ttraining's binary_logloss: 0.120611\n",
      "[224]\ttraining's binary_logloss: 0.119906\n",
      "[225]\ttraining's binary_logloss: 0.119219\n",
      "[226]\ttraining's binary_logloss: 0.118525\n",
      "[227]\ttraining's binary_logloss: 0.117824\n",
      "[228]\ttraining's binary_logloss: 0.117178\n",
      "[229]\ttraining's binary_logloss: 0.116503\n",
      "[230]\ttraining's binary_logloss: 0.115836\n",
      "[231]\ttraining's binary_logloss: 0.115139\n",
      "[232]\ttraining's binary_logloss: 0.114467\n",
      "[233]\ttraining's binary_logloss: 0.11382\n",
      "[234]\ttraining's binary_logloss: 0.113146\n",
      "[235]\ttraining's binary_logloss: 0.112531\n",
      "[236]\ttraining's binary_logloss: 0.111955\n",
      "[237]\ttraining's binary_logloss: 0.111303\n",
      "[238]\ttraining's binary_logloss: 0.11071\n",
      "[239]\ttraining's binary_logloss: 0.110047\n",
      "[240]\ttraining's binary_logloss: 0.109413\n",
      "[241]\ttraining's binary_logloss: 0.108845\n",
      "[242]\ttraining's binary_logloss: 0.108245\n",
      "[243]\ttraining's binary_logloss: 0.107603\n",
      "[244]\ttraining's binary_logloss: 0.10699\n",
      "[245]\ttraining's binary_logloss: 0.106321\n",
      "[246]\ttraining's binary_logloss: 0.10571\n",
      "[247]\ttraining's binary_logloss: 0.105121\n",
      "[248]\ttraining's binary_logloss: 0.104535\n",
      "[249]\ttraining's binary_logloss: 0.103939\n",
      "[250]\ttraining's binary_logloss: 0.103357\n",
      "[251]\ttraining's binary_logloss: 0.102702\n",
      "[252]\ttraining's binary_logloss: 0.102094\n",
      "[253]\ttraining's binary_logloss: 0.101496\n",
      "[254]\ttraining's binary_logloss: 0.100938\n",
      "[255]\ttraining's binary_logloss: 0.100344\n",
      "[256]\ttraining's binary_logloss: 0.0997892\n",
      "[257]\ttraining's binary_logloss: 0.0992084\n",
      "[258]\ttraining's binary_logloss: 0.098623\n",
      "[259]\ttraining's binary_logloss: 0.0980872\n",
      "[260]\ttraining's binary_logloss: 0.0975732\n",
      "[261]\ttraining's binary_logloss: 0.097008\n",
      "[262]\ttraining's binary_logloss: 0.0964385\n",
      "[263]\ttraining's binary_logloss: 0.095876\n",
      "[264]\ttraining's binary_logloss: 0.0953178\n",
      "[265]\ttraining's binary_logloss: 0.0947692\n",
      "[266]\ttraining's binary_logloss: 0.0942303\n",
      "[267]\ttraining's binary_logloss: 0.0936838\n",
      "[268]\ttraining's binary_logloss: 0.0931701\n",
      "[269]\ttraining's binary_logloss: 0.0926609\n",
      "[270]\ttraining's binary_logloss: 0.0921536\n",
      "[271]\ttraining's binary_logloss: 0.0916526\n",
      "[272]\ttraining's binary_logloss: 0.0911412\n",
      "[273]\ttraining's binary_logloss: 0.0905943\n",
      "[274]\ttraining's binary_logloss: 0.0900825\n",
      "[275]\ttraining's binary_logloss: 0.0895612\n",
      "[276]\ttraining's binary_logloss: 0.0890279\n",
      "[277]\ttraining's binary_logloss: 0.0885199\n",
      "[278]\ttraining's binary_logloss: 0.0880409\n",
      "[279]\ttraining's binary_logloss: 0.0875761\n",
      "[280]\ttraining's binary_logloss: 0.0870789\n",
      "[281]\ttraining's binary_logloss: 0.0865952\n",
      "[282]\ttraining's binary_logloss: 0.086136\n",
      "[283]\ttraining's binary_logloss: 0.085651\n",
      "[284]\ttraining's binary_logloss: 0.0852008\n",
      "[285]\ttraining's binary_logloss: 0.0847002\n",
      "[286]\ttraining's binary_logloss: 0.0842197\n",
      "[287]\ttraining's binary_logloss: 0.0837075\n",
      "[288]\ttraining's binary_logloss: 0.0832259\n",
      "[289]\ttraining's binary_logloss: 0.0827623\n",
      "[290]\ttraining's binary_logloss: 0.0822671\n",
      "[291]\ttraining's binary_logloss: 0.081794\n",
      "[292]\ttraining's binary_logloss: 0.0813563\n",
      "[293]\ttraining's binary_logloss: 0.0808888\n",
      "[294]\ttraining's binary_logloss: 0.0803802\n",
      "[295]\ttraining's binary_logloss: 0.0799216\n",
      "[296]\ttraining's binary_logloss: 0.0794464\n",
      "[297]\ttraining's binary_logloss: 0.0789912\n",
      "[298]\ttraining's binary_logloss: 0.078539\n",
      "[299]\ttraining's binary_logloss: 0.0781263\n",
      "[300]\ttraining's binary_logloss: 0.0776774\n",
      "[301]\ttraining's binary_logloss: 0.0772312\n",
      "[302]\ttraining's binary_logloss: 0.0767916\n",
      "[303]\ttraining's binary_logloss: 0.076374\n",
      "[304]\ttraining's binary_logloss: 0.0759207\n",
      "[305]\ttraining's binary_logloss: 0.0755016\n",
      "[306]\ttraining's binary_logloss: 0.0750827\n",
      "[307]\ttraining's binary_logloss: 0.0746176\n",
      "[308]\ttraining's binary_logloss: 0.0741798\n",
      "[309]\ttraining's binary_logloss: 0.0737546\n",
      "[310]\ttraining's binary_logloss: 0.0733289\n",
      "[311]\ttraining's binary_logloss: 0.0729122\n",
      "[312]\ttraining's binary_logloss: 0.0725207\n",
      "[313]\ttraining's binary_logloss: 0.0720802\n",
      "[314]\ttraining's binary_logloss: 0.0716876\n",
      "[315]\ttraining's binary_logloss: 0.0712385\n",
      "[316]\ttraining's binary_logloss: 0.0708296\n",
      "[317]\ttraining's binary_logloss: 0.0704317\n",
      "[318]\ttraining's binary_logloss: 0.0700197\n",
      "[319]\ttraining's binary_logloss: 0.0695995\n",
      "[320]\ttraining's binary_logloss: 0.0692213\n",
      "[321]\ttraining's binary_logloss: 0.0688447\n",
      "[322]\ttraining's binary_logloss: 0.0684417\n",
      "[323]\ttraining's binary_logloss: 0.0680527\n",
      "[324]\ttraining's binary_logloss: 0.0676698\n",
      "[325]\ttraining's binary_logloss: 0.0673062\n",
      "[326]\ttraining's binary_logloss: 0.0669449\n",
      "[327]\ttraining's binary_logloss: 0.0665564\n",
      "[328]\ttraining's binary_logloss: 0.0661813\n",
      "[329]\ttraining's binary_logloss: 0.0657975\n",
      "[330]\ttraining's binary_logloss: 0.0654468\n",
      "[331]\ttraining's binary_logloss: 0.0651011\n",
      "[332]\ttraining's binary_logloss: 0.0647481\n",
      "[333]\ttraining's binary_logloss: 0.0643634\n",
      "[334]\ttraining's binary_logloss: 0.0640305\n",
      "[335]\ttraining's binary_logloss: 0.0636727\n",
      "[336]\ttraining's binary_logloss: 0.0632981\n",
      "[337]\ttraining's binary_logloss: 0.0629573\n",
      "[338]\ttraining's binary_logloss: 0.0626168\n",
      "[339]\ttraining's binary_logloss: 0.0622351\n",
      "[340]\ttraining's binary_logloss: 0.0618789\n",
      "[341]\ttraining's binary_logloss: 0.0614971\n",
      "[342]\ttraining's binary_logloss: 0.0611397\n",
      "[343]\ttraining's binary_logloss: 0.0607663\n",
      "[344]\ttraining's binary_logloss: 0.0604259\n",
      "[345]\ttraining's binary_logloss: 0.0600805\n",
      "[346]\ttraining's binary_logloss: 0.05974\n",
      "[347]\ttraining's binary_logloss: 0.0593839\n",
      "[348]\ttraining's binary_logloss: 0.059051\n",
      "[349]\ttraining's binary_logloss: 0.0587256\n",
      "[350]\ttraining's binary_logloss: 0.0583932\n",
      "[351]\ttraining's binary_logloss: 0.0580664\n",
      "[352]\ttraining's binary_logloss: 0.0577471\n",
      "[353]\ttraining's binary_logloss: 0.0574145\n",
      "[354]\ttraining's binary_logloss: 0.057122\n",
      "[355]\ttraining's binary_logloss: 0.056771\n",
      "[356]\ttraining's binary_logloss: 0.0564483\n",
      "[357]\ttraining's binary_logloss: 0.0561285\n",
      "[358]\ttraining's binary_logloss: 0.0557952\n",
      "[359]\ttraining's binary_logloss: 0.0554718\n",
      "[360]\ttraining's binary_logloss: 0.0551598\n",
      "[361]\ttraining's binary_logloss: 0.0548308\n",
      "[362]\ttraining's binary_logloss: 0.0545082\n",
      "[363]\ttraining's binary_logloss: 0.0542001\n",
      "[364]\ttraining's binary_logloss: 0.0539092\n",
      "[365]\ttraining's binary_logloss: 0.0535797\n",
      "[366]\ttraining's binary_logloss: 0.0532693\n",
      "[367]\ttraining's binary_logloss: 0.0529768\n",
      "[368]\ttraining's binary_logloss: 0.0526731\n",
      "[369]\ttraining's binary_logloss: 0.0523583\n",
      "[370]\ttraining's binary_logloss: 0.0520657\n",
      "[371]\ttraining's binary_logloss: 0.0517871\n",
      "[372]\ttraining's binary_logloss: 0.0514911\n",
      "[373]\ttraining's binary_logloss: 0.051191\n",
      "[374]\ttraining's binary_logloss: 0.0508927\n",
      "[375]\ttraining's binary_logloss: 0.0506285\n",
      "[376]\ttraining's binary_logloss: 0.0503625\n",
      "[377]\ttraining's binary_logloss: 0.0500911\n",
      "[378]\ttraining's binary_logloss: 0.0497967\n",
      "[379]\ttraining's binary_logloss: 0.049532\n",
      "[380]\ttraining's binary_logloss: 0.0492728\n",
      "[381]\ttraining's binary_logloss: 0.0490074\n",
      "[382]\ttraining's binary_logloss: 0.0487381\n",
      "[383]\ttraining's binary_logloss: 0.0484795\n",
      "[384]\ttraining's binary_logloss: 0.0482102\n",
      "[385]\ttraining's binary_logloss: 0.0479464\n",
      "[386]\ttraining's binary_logloss: 0.04769\n",
      "[387]\ttraining's binary_logloss: 0.0474071\n",
      "[388]\ttraining's binary_logloss: 0.0471356\n",
      "[389]\ttraining's binary_logloss: 0.0468649\n",
      "[390]\ttraining's binary_logloss: 0.046601\n",
      "[391]\ttraining's binary_logloss: 0.0463291\n",
      "[392]\ttraining's binary_logloss: 0.0460757\n",
      "[393]\ttraining's binary_logloss: 0.045839\n",
      "[394]\ttraining's binary_logloss: 0.0455832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[395]\ttraining's binary_logloss: 0.045312\n",
      "[396]\ttraining's binary_logloss: 0.0450628\n",
      "[397]\ttraining's binary_logloss: 0.044814\n",
      "[398]\ttraining's binary_logloss: 0.0445831\n",
      "[399]\ttraining's binary_logloss: 0.0443306\n",
      "[400]\ttraining's binary_logloss: 0.0440934\n",
      "[401]\ttraining's binary_logloss: 0.0438524\n",
      "[402]\ttraining's binary_logloss: 0.0436058\n",
      "[403]\ttraining's binary_logloss: 0.0433567\n",
      "[404]\ttraining's binary_logloss: 0.043099\n",
      "[405]\ttraining's binary_logloss: 0.0428718\n",
      "[406]\ttraining's binary_logloss: 0.0426396\n",
      "[407]\ttraining's binary_logloss: 0.0423994\n",
      "[408]\ttraining's binary_logloss: 0.0421781\n",
      "[409]\ttraining's binary_logloss: 0.0419458\n",
      "[410]\ttraining's binary_logloss: 0.041687\n",
      "[411]\ttraining's binary_logloss: 0.0414486\n",
      "[412]\ttraining's binary_logloss: 0.0412048\n",
      "[413]\ttraining's binary_logloss: 0.0409647\n",
      "[414]\ttraining's binary_logloss: 0.0407373\n",
      "[415]\ttraining's binary_logloss: 0.0405087\n",
      "[416]\ttraining's binary_logloss: 0.0402864\n",
      "[417]\ttraining's binary_logloss: 0.0400799\n",
      "[418]\ttraining's binary_logloss: 0.0398611\n",
      "[419]\ttraining's binary_logloss: 0.0396387\n",
      "[420]\ttraining's binary_logloss: 0.0394219\n",
      "[421]\ttraining's binary_logloss: 0.0391911\n",
      "[422]\ttraining's binary_logloss: 0.0389825\n",
      "[423]\ttraining's binary_logloss: 0.0387555\n",
      "[424]\ttraining's binary_logloss: 0.0385418\n",
      "[425]\ttraining's binary_logloss: 0.0383193\n",
      "[426]\ttraining's binary_logloss: 0.0381002\n",
      "[427]\ttraining's binary_logloss: 0.0378851\n",
      "[428]\ttraining's binary_logloss: 0.0376734\n",
      "[429]\ttraining's binary_logloss: 0.0374787\n",
      "[430]\ttraining's binary_logloss: 0.0372817\n",
      "[431]\ttraining's binary_logloss: 0.0370609\n",
      "[432]\ttraining's binary_logloss: 0.0368604\n",
      "[433]\ttraining's binary_logloss: 0.0366537\n",
      "[434]\ttraining's binary_logloss: 0.0364439\n",
      "[435]\ttraining's binary_logloss: 0.036235\n",
      "[436]\ttraining's binary_logloss: 0.0360326\n",
      "[437]\ttraining's binary_logloss: 0.0358263\n",
      "[438]\ttraining's binary_logloss: 0.0356332\n",
      "[439]\ttraining's binary_logloss: 0.0354419\n",
      "[440]\ttraining's binary_logloss: 0.0352455\n",
      "[441]\ttraining's binary_logloss: 0.0350379\n",
      "[442]\ttraining's binary_logloss: 0.0348507\n",
      "[443]\ttraining's binary_logloss: 0.0346457\n",
      "[444]\ttraining's binary_logloss: 0.0344552\n",
      "[445]\ttraining's binary_logloss: 0.0342498\n",
      "[446]\ttraining's binary_logloss: 0.0340772\n",
      "[447]\ttraining's binary_logloss: 0.0338905\n",
      "[448]\ttraining's binary_logloss: 0.0336952\n",
      "[449]\ttraining's binary_logloss: 0.0335009\n",
      "[450]\ttraining's binary_logloss: 0.0333236\n",
      "[451]\ttraining's binary_logloss: 0.0331243\n",
      "[452]\ttraining's binary_logloss: 0.032941\n",
      "[453]\ttraining's binary_logloss: 0.0327505\n",
      "[454]\ttraining's binary_logloss: 0.032566\n",
      "[455]\ttraining's binary_logloss: 0.0323861\n",
      "[456]\ttraining's binary_logloss: 0.0322134\n",
      "[457]\ttraining's binary_logloss: 0.0320428\n",
      "[458]\ttraining's binary_logloss: 0.0318732\n",
      "[459]\ttraining's binary_logloss: 0.0316841\n",
      "[460]\ttraining's binary_logloss: 0.0315059\n",
      "[461]\ttraining's binary_logloss: 0.0313403\n",
      "[462]\ttraining's binary_logloss: 0.0311761\n",
      "[463]\ttraining's binary_logloss: 0.0310009\n",
      "[464]\ttraining's binary_logloss: 0.0308215\n",
      "[465]\ttraining's binary_logloss: 0.0306409\n",
      "[466]\ttraining's binary_logloss: 0.030477\n",
      "[467]\ttraining's binary_logloss: 0.0303297\n",
      "[468]\ttraining's binary_logloss: 0.0301754\n",
      "[469]\ttraining's binary_logloss: 0.0300125\n",
      "[470]\ttraining's binary_logloss: 0.0298478\n",
      "[471]\ttraining's binary_logloss: 0.0296687\n",
      "[472]\ttraining's binary_logloss: 0.0295024\n",
      "[473]\ttraining's binary_logloss: 0.0293448\n",
      "[474]\ttraining's binary_logloss: 0.0291824\n",
      "[475]\ttraining's binary_logloss: 0.0290189\n",
      "[476]\ttraining's binary_logloss: 0.0288692\n",
      "[477]\ttraining's binary_logloss: 0.0287239\n",
      "[478]\ttraining's binary_logloss: 0.0285599\n",
      "[479]\ttraining's binary_logloss: 0.0284052\n",
      "[480]\ttraining's binary_logloss: 0.0282437\n",
      "[481]\ttraining's binary_logloss: 0.0281026\n",
      "[482]\ttraining's binary_logloss: 0.0279338\n",
      "[483]\ttraining's binary_logloss: 0.0277751\n",
      "[484]\ttraining's binary_logloss: 0.0276224\n",
      "[485]\ttraining's binary_logloss: 0.0274736\n",
      "[486]\ttraining's binary_logloss: 0.0273269\n",
      "[487]\ttraining's binary_logloss: 0.0271597\n",
      "[488]\ttraining's binary_logloss: 0.0270077\n",
      "[489]\ttraining's binary_logloss: 0.0268548\n",
      "[490]\ttraining's binary_logloss: 0.0266935\n",
      "[491]\ttraining's binary_logloss: 0.0265331\n",
      "[492]\ttraining's binary_logloss: 0.0263708\n",
      "[493]\ttraining's binary_logloss: 0.0262195\n",
      "[494]\ttraining's binary_logloss: 0.0260738\n",
      "[495]\ttraining's binary_logloss: 0.0259427\n",
      "[496]\ttraining's binary_logloss: 0.0258134\n",
      "[497]\ttraining's binary_logloss: 0.0256666\n",
      "[498]\ttraining's binary_logloss: 0.0255258\n",
      "[499]\ttraining's binary_logloss: 0.0253822\n",
      "[500]\ttraining's binary_logloss: 0.0252461\n",
      "[501]\ttraining's binary_logloss: 0.0250926\n",
      "[502]\ttraining's binary_logloss: 0.0249602\n",
      "[503]\ttraining's binary_logloss: 0.024814\n",
      "[504]\ttraining's binary_logloss: 0.0246655\n",
      "[505]\ttraining's binary_logloss: 0.0245332\n",
      "[506]\ttraining's binary_logloss: 0.0243922\n",
      "[507]\ttraining's binary_logloss: 0.0242575\n",
      "[508]\ttraining's binary_logloss: 0.0241174\n",
      "[509]\ttraining's binary_logloss: 0.0239874\n",
      "[510]\ttraining's binary_logloss: 0.023848\n",
      "[511]\ttraining's binary_logloss: 0.0237115\n",
      "[512]\ttraining's binary_logloss: 0.0235775\n",
      "[513]\ttraining's binary_logloss: 0.0234429\n",
      "[514]\ttraining's binary_logloss: 0.0233141\n",
      "[515]\ttraining's binary_logloss: 0.0231801\n",
      "[516]\ttraining's binary_logloss: 0.0230518\n",
      "[517]\ttraining's binary_logloss: 0.0229205\n",
      "[518]\ttraining's binary_logloss: 0.0228024\n",
      "[519]\ttraining's binary_logloss: 0.0226799\n",
      "[520]\ttraining's binary_logloss: 0.0225568\n",
      "[521]\ttraining's binary_logloss: 0.0224342\n",
      "[522]\ttraining's binary_logloss: 0.0223081\n",
      "[523]\ttraining's binary_logloss: 0.0221928\n",
      "[524]\ttraining's binary_logloss: 0.0220757\n",
      "[525]\ttraining's binary_logloss: 0.0219497\n",
      "[526]\ttraining's binary_logloss: 0.0218322\n",
      "[527]\ttraining's binary_logloss: 0.0217122\n",
      "[528]\ttraining's binary_logloss: 0.0215947\n",
      "[529]\ttraining's binary_logloss: 0.021478\n",
      "[530]\ttraining's binary_logloss: 0.0213554\n",
      "[531]\ttraining's binary_logloss: 0.021242\n",
      "[532]\ttraining's binary_logloss: 0.0211209\n",
      "[533]\ttraining's binary_logloss: 0.0210024\n",
      "[534]\ttraining's binary_logloss: 0.0208874\n",
      "[535]\ttraining's binary_logloss: 0.0207659\n",
      "[536]\ttraining's binary_logloss: 0.020655\n",
      "[537]\ttraining's binary_logloss: 0.020535\n",
      "[538]\ttraining's binary_logloss: 0.0204231\n",
      "[539]\ttraining's binary_logloss: 0.0203063\n",
      "[540]\ttraining's binary_logloss: 0.0201956\n",
      "[541]\ttraining's binary_logloss: 0.0200884\n",
      "[542]\ttraining's binary_logloss: 0.0199855\n",
      "[543]\ttraining's binary_logloss: 0.0198725\n",
      "[544]\ttraining's binary_logloss: 0.0197589\n",
      "[545]\ttraining's binary_logloss: 0.0196536\n",
      "[546]\ttraining's binary_logloss: 0.0195506\n",
      "[547]\ttraining's binary_logloss: 0.0194397\n",
      "[548]\ttraining's binary_logloss: 0.019331\n",
      "[549]\ttraining's binary_logloss: 0.0192259\n",
      "[550]\ttraining's binary_logloss: 0.019117\n",
      "[551]\ttraining's binary_logloss: 0.0190165\n",
      "[552]\ttraining's binary_logloss: 0.01892\n",
      "[553]\ttraining's binary_logloss: 0.0188219\n",
      "[554]\ttraining's binary_logloss: 0.018719\n",
      "[555]\ttraining's binary_logloss: 0.0186167\n",
      "[556]\ttraining's binary_logloss: 0.0185054\n",
      "[557]\ttraining's binary_logloss: 0.0183995\n",
      "[558]\ttraining's binary_logloss: 0.0183014\n",
      "[559]\ttraining's binary_logloss: 0.0181923\n",
      "[560]\ttraining's binary_logloss: 0.0180883\n",
      "[561]\ttraining's binary_logloss: 0.0179898\n",
      "[562]\ttraining's binary_logloss: 0.0178913\n",
      "[563]\ttraining's binary_logloss: 0.0177897\n",
      "[564]\ttraining's binary_logloss: 0.0176906\n",
      "[565]\ttraining's binary_logloss: 0.0175954\n",
      "[566]\ttraining's binary_logloss: 0.0175078\n",
      "[567]\ttraining's binary_logloss: 0.0174204\n",
      "[568]\ttraining's binary_logloss: 0.0173284\n",
      "[569]\ttraining's binary_logloss: 0.0172323\n",
      "[570]\ttraining's binary_logloss: 0.0171403\n",
      "[571]\ttraining's binary_logloss: 0.017042\n",
      "[572]\ttraining's binary_logloss: 0.0169493\n",
      "[573]\ttraining's binary_logloss: 0.0168484\n",
      "[574]\ttraining's binary_logloss: 0.0167548\n",
      "[575]\ttraining's binary_logloss: 0.0166634\n",
      "[576]\ttraining's binary_logloss: 0.0165842\n",
      "[577]\ttraining's binary_logloss: 0.0164903\n",
      "[578]\ttraining's binary_logloss: 0.016398\n",
      "[579]\ttraining's binary_logloss: 0.0163044\n",
      "[580]\ttraining's binary_logloss: 0.0162163\n",
      "[581]\ttraining's binary_logloss: 0.0161252\n",
      "[582]\ttraining's binary_logloss: 0.0160357\n",
      "[583]\ttraining's binary_logloss: 0.0159449\n",
      "[584]\ttraining's binary_logloss: 0.015856\n",
      "[585]\ttraining's binary_logloss: 0.0157644\n",
      "[586]\ttraining's binary_logloss: 0.0156748\n",
      "[587]\ttraining's binary_logloss: 0.0155934\n",
      "[588]\ttraining's binary_logloss: 0.0155081\n",
      "[589]\ttraining's binary_logloss: 0.0154217\n",
      "[590]\ttraining's binary_logloss: 0.0153318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[591]\ttraining's binary_logloss: 0.0152494\n",
      "[592]\ttraining's binary_logloss: 0.0151645\n",
      "[593]\ttraining's binary_logloss: 0.015079\n",
      "[594]\ttraining's binary_logloss: 0.0149972\n",
      "[595]\ttraining's binary_logloss: 0.0149063\n",
      "[596]\ttraining's binary_logloss: 0.0148173\n",
      "[597]\ttraining's binary_logloss: 0.0147349\n",
      "[598]\ttraining's binary_logloss: 0.0146535\n",
      "[599]\ttraining's binary_logloss: 0.014576\n",
      "[600]\ttraining's binary_logloss: 0.014494\n",
      "[601]\ttraining's binary_logloss: 0.0144117\n",
      "[602]\ttraining's binary_logloss: 0.0143405\n",
      "[603]\ttraining's binary_logloss: 0.0142637\n",
      "[604]\ttraining's binary_logloss: 0.0141848\n",
      "[605]\ttraining's binary_logloss: 0.0141105\n",
      "[606]\ttraining's binary_logloss: 0.0140404\n",
      "[607]\ttraining's binary_logloss: 0.013958\n",
      "[608]\ttraining's binary_logloss: 0.0138739\n",
      "[609]\ttraining's binary_logloss: 0.0137967\n",
      "[610]\ttraining's binary_logloss: 0.0137223\n",
      "[611]\ttraining's binary_logloss: 0.013647\n",
      "[612]\ttraining's binary_logloss: 0.0135723\n",
      "[613]\ttraining's binary_logloss: 0.0134933\n",
      "[614]\ttraining's binary_logloss: 0.0134185\n",
      "[615]\ttraining's binary_logloss: 0.0133495\n",
      "[616]\ttraining's binary_logloss: 0.0132759\n",
      "[617]\ttraining's binary_logloss: 0.0132004\n",
      "[618]\ttraining's binary_logloss: 0.013125\n",
      "[619]\ttraining's binary_logloss: 0.0130543\n",
      "[620]\ttraining's binary_logloss: 0.0129817\n",
      "[621]\ttraining's binary_logloss: 0.0129056\n",
      "[622]\ttraining's binary_logloss: 0.0128319\n",
      "[623]\ttraining's binary_logloss: 0.0127609\n",
      "[624]\ttraining's binary_logloss: 0.0126904\n",
      "[625]\ttraining's binary_logloss: 0.0126185\n",
      "[626]\ttraining's binary_logloss: 0.012548\n",
      "[627]\ttraining's binary_logloss: 0.0124752\n",
      "[628]\ttraining's binary_logloss: 0.0124028\n",
      "[629]\ttraining's binary_logloss: 0.0123382\n",
      "[630]\ttraining's binary_logloss: 0.0122714\n",
      "[631]\ttraining's binary_logloss: 0.0122039\n",
      "[632]\ttraining's binary_logloss: 0.0121431\n",
      "[633]\ttraining's binary_logloss: 0.0120742\n",
      "[634]\ttraining's binary_logloss: 0.01201\n",
      "[635]\ttraining's binary_logloss: 0.0119499\n",
      "[636]\ttraining's binary_logloss: 0.0118831\n",
      "[637]\ttraining's binary_logloss: 0.0118188\n",
      "[638]\ttraining's binary_logloss: 0.0117507\n",
      "[639]\ttraining's binary_logloss: 0.0116858\n",
      "[640]\ttraining's binary_logloss: 0.011623\n",
      "[641]\ttraining's binary_logloss: 0.01156\n",
      "[642]\ttraining's binary_logloss: 0.0114933\n",
      "[643]\ttraining's binary_logloss: 0.0114292\n",
      "[644]\ttraining's binary_logloss: 0.0113658\n",
      "[645]\ttraining's binary_logloss: 0.0112978\n",
      "[646]\ttraining's binary_logloss: 0.0112367\n",
      "[647]\ttraining's binary_logloss: 0.0111702\n",
      "[648]\ttraining's binary_logloss: 0.0111083\n",
      "[649]\ttraining's binary_logloss: 0.0110425\n",
      "[650]\ttraining's binary_logloss: 0.0109787\n",
      "[651]\ttraining's binary_logloss: 0.0109178\n",
      "[652]\ttraining's binary_logloss: 0.0108594\n",
      "[653]\ttraining's binary_logloss: 0.0108001\n",
      "[654]\ttraining's binary_logloss: 0.0107438\n",
      "[655]\ttraining's binary_logloss: 0.0106827\n",
      "[656]\ttraining's binary_logloss: 0.0106264\n",
      "[657]\ttraining's binary_logloss: 0.0105678\n",
      "[658]\ttraining's binary_logloss: 0.0105118\n",
      "[659]\ttraining's binary_logloss: 0.0104518\n",
      "[660]\ttraining's binary_logloss: 0.010395\n",
      "[661]\ttraining's binary_logloss: 0.010339\n",
      "[662]\ttraining's binary_logloss: 0.0102822\n",
      "[663]\ttraining's binary_logloss: 0.0102259\n",
      "[664]\ttraining's binary_logloss: 0.0101678\n",
      "[665]\ttraining's binary_logloss: 0.0101102\n",
      "[666]\ttraining's binary_logloss: 0.0100536\n",
      "[667]\ttraining's binary_logloss: 0.0099987\n",
      "[668]\ttraining's binary_logloss: 0.00994249\n",
      "[669]\ttraining's binary_logloss: 0.00989337\n",
      "[670]\ttraining's binary_logloss: 0.00983834\n",
      "[671]\ttraining's binary_logloss: 0.00978537\n",
      "[672]\ttraining's binary_logloss: 0.00973082\n",
      "[673]\ttraining's binary_logloss: 0.00967785\n",
      "[674]\ttraining's binary_logloss: 0.00962526\n",
      "[675]\ttraining's binary_logloss: 0.00956967\n",
      "[676]\ttraining's binary_logloss: 0.00951806\n",
      "[677]\ttraining's binary_logloss: 0.0094652\n",
      "[678]\ttraining's binary_logloss: 0.00941213\n",
      "[679]\ttraining's binary_logloss: 0.00935697\n",
      "[680]\ttraining's binary_logloss: 0.00930816\n",
      "[681]\ttraining's binary_logloss: 0.00925751\n",
      "[682]\ttraining's binary_logloss: 0.00920887\n",
      "[683]\ttraining's binary_logloss: 0.00915597\n",
      "[684]\ttraining's binary_logloss: 0.00910495\n",
      "[685]\ttraining's binary_logloss: 0.00905865\n",
      "[686]\ttraining's binary_logloss: 0.00901389\n",
      "[687]\ttraining's binary_logloss: 0.00896479\n",
      "[688]\ttraining's binary_logloss: 0.00891611\n",
      "[689]\ttraining's binary_logloss: 0.00886645\n",
      "[690]\ttraining's binary_logloss: 0.00881487\n",
      "[691]\ttraining's binary_logloss: 0.00876544\n",
      "[692]\ttraining's binary_logloss: 0.00871822\n",
      "[693]\ttraining's binary_logloss: 0.00866494\n",
      "[694]\ttraining's binary_logloss: 0.00861741\n",
      "[695]\ttraining's binary_logloss: 0.00856948\n",
      "[696]\ttraining's binary_logloss: 0.00852098\n",
      "[697]\ttraining's binary_logloss: 0.00847024\n",
      "[698]\ttraining's binary_logloss: 0.00842104\n",
      "[699]\ttraining's binary_logloss: 0.00837328\n",
      "[700]\ttraining's binary_logloss: 0.00832801\n",
      "[701]\ttraining's binary_logloss: 0.00828045\n",
      "[702]\ttraining's binary_logloss: 0.00823694\n",
      "[703]\ttraining's binary_logloss: 0.00819811\n",
      "[704]\ttraining's binary_logloss: 0.0081511\n",
      "[705]\ttraining's binary_logloss: 0.00810941\n",
      "[706]\ttraining's binary_logloss: 0.00806901\n",
      "[707]\ttraining's binary_logloss: 0.00802571\n",
      "[708]\ttraining's binary_logloss: 0.00797757\n",
      "[709]\ttraining's binary_logloss: 0.00793252\n",
      "[710]\ttraining's binary_logloss: 0.00788931\n",
      "[711]\ttraining's binary_logloss: 0.00784326\n",
      "[712]\ttraining's binary_logloss: 0.0078031\n",
      "[713]\ttraining's binary_logloss: 0.00776041\n",
      "[714]\ttraining's binary_logloss: 0.00771571\n",
      "[715]\ttraining's binary_logloss: 0.00767162\n",
      "[716]\ttraining's binary_logloss: 0.00762934\n",
      "[717]\ttraining's binary_logloss: 0.007587\n",
      "[718]\ttraining's binary_logloss: 0.00754461\n",
      "[719]\ttraining's binary_logloss: 0.00750245\n",
      "[720]\ttraining's binary_logloss: 0.00745819\n",
      "[721]\ttraining's binary_logloss: 0.00741849\n",
      "[722]\ttraining's binary_logloss: 0.00737888\n",
      "[723]\ttraining's binary_logloss: 0.00733604\n",
      "[724]\ttraining's binary_logloss: 0.00729392\n",
      "[725]\ttraining's binary_logloss: 0.00725351\n",
      "[726]\ttraining's binary_logloss: 0.00721476\n",
      "[727]\ttraining's binary_logloss: 0.00717401\n",
      "[728]\ttraining's binary_logloss: 0.00713488\n",
      "[729]\ttraining's binary_logloss: 0.00709355\n",
      "[730]\ttraining's binary_logloss: 0.00705176\n",
      "[731]\ttraining's binary_logloss: 0.00701432\n",
      "[732]\ttraining's binary_logloss: 0.00697564\n",
      "[733]\ttraining's binary_logloss: 0.00693386\n",
      "[734]\ttraining's binary_logloss: 0.00689529\n",
      "[735]\ttraining's binary_logloss: 0.00685901\n",
      "[736]\ttraining's binary_logloss: 0.00682082\n",
      "[737]\ttraining's binary_logloss: 0.00678528\n",
      "[738]\ttraining's binary_logloss: 0.00674932\n",
      "[739]\ttraining's binary_logloss: 0.00671212\n",
      "[740]\ttraining's binary_logloss: 0.00667564\n",
      "[741]\ttraining's binary_logloss: 0.00663839\n",
      "[742]\ttraining's binary_logloss: 0.0066019\n",
      "[743]\ttraining's binary_logloss: 0.00656487\n",
      "[744]\ttraining's binary_logloss: 0.00652945\n",
      "[745]\ttraining's binary_logloss: 0.00649432\n",
      "[746]\ttraining's binary_logloss: 0.00646054\n",
      "[747]\ttraining's binary_logloss: 0.00642226\n",
      "[748]\ttraining's binary_logloss: 0.00638714\n",
      "[749]\ttraining's binary_logloss: 0.00635389\n",
      "[750]\ttraining's binary_logloss: 0.00631677\n",
      "[751]\ttraining's binary_logloss: 0.00628181\n",
      "[752]\ttraining's binary_logloss: 0.00624747\n",
      "[753]\ttraining's binary_logloss: 0.00621271\n",
      "[754]\ttraining's binary_logloss: 0.00617954\n",
      "[755]\ttraining's binary_logloss: 0.00614727\n",
      "[756]\ttraining's binary_logloss: 0.00611245\n",
      "[757]\ttraining's binary_logloss: 0.00607747\n",
      "[758]\ttraining's binary_logloss: 0.00604538\n",
      "[759]\ttraining's binary_logloss: 0.00601311\n",
      "[760]\ttraining's binary_logloss: 0.0059802\n",
      "[761]\ttraining's binary_logloss: 0.00594654\n",
      "[762]\ttraining's binary_logloss: 0.00591306\n",
      "[763]\ttraining's binary_logloss: 0.00587886\n",
      "[764]\ttraining's binary_logloss: 0.0058452\n",
      "[765]\ttraining's binary_logloss: 0.00581251\n",
      "[766]\ttraining's binary_logloss: 0.00578082\n",
      "[767]\ttraining's binary_logloss: 0.00575197\n",
      "[768]\ttraining's binary_logloss: 0.00571942\n",
      "[769]\ttraining's binary_logloss: 0.00568589\n",
      "[770]\ttraining's binary_logloss: 0.00565621\n",
      "[771]\ttraining's binary_logloss: 0.00562595\n",
      "[772]\ttraining's binary_logloss: 0.00559447\n",
      "[773]\ttraining's binary_logloss: 0.00556013\n",
      "[774]\ttraining's binary_logloss: 0.00552831\n",
      "[775]\ttraining's binary_logloss: 0.00549729\n",
      "[776]\ttraining's binary_logloss: 0.00546729\n",
      "[777]\ttraining's binary_logloss: 0.005435\n",
      "[778]\ttraining's binary_logloss: 0.00540442\n",
      "[779]\ttraining's binary_logloss: 0.00537307\n",
      "[780]\ttraining's binary_logloss: 0.00534629\n",
      "[781]\ttraining's binary_logloss: 0.00531713\n",
      "[782]\ttraining's binary_logloss: 0.00528876\n",
      "[783]\ttraining's binary_logloss: 0.00525874\n",
      "[784]\ttraining's binary_logloss: 0.00523033\n",
      "[785]\ttraining's binary_logloss: 0.00519943\n",
      "[786]\ttraining's binary_logloss: 0.00516977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[787]\ttraining's binary_logloss: 0.00513995\n",
      "[788]\ttraining's binary_logloss: 0.00510965\n",
      "[789]\ttraining's binary_logloss: 0.00508169\n",
      "[790]\ttraining's binary_logloss: 0.0050543\n",
      "[791]\ttraining's binary_logloss: 0.00502707\n",
      "[792]\ttraining's binary_logloss: 0.00500038\n",
      "[793]\ttraining's binary_logloss: 0.00497384\n",
      "[794]\ttraining's binary_logloss: 0.00494711\n",
      "[795]\ttraining's binary_logloss: 0.00492119\n",
      "[796]\ttraining's binary_logloss: 0.00489532\n",
      "[797]\ttraining's binary_logloss: 0.00486775\n",
      "[798]\ttraining's binary_logloss: 0.00483956\n",
      "[799]\ttraining's binary_logloss: 0.00481335\n",
      "[800]\ttraining's binary_logloss: 0.00478949\n",
      "[801]\ttraining's binary_logloss: 0.00476614\n",
      "[802]\ttraining's binary_logloss: 0.0047418\n",
      "[803]\ttraining's binary_logloss: 0.00471666\n",
      "[804]\ttraining's binary_logloss: 0.00469152\n",
      "[805]\ttraining's binary_logloss: 0.00466608\n",
      "[806]\ttraining's binary_logloss: 0.00464079\n",
      "[807]\ttraining's binary_logloss: 0.00461485\n",
      "[808]\ttraining's binary_logloss: 0.00459218\n",
      "[809]\ttraining's binary_logloss: 0.00456593\n",
      "[810]\ttraining's binary_logloss: 0.00453994\n",
      "[811]\ttraining's binary_logloss: 0.00451239\n",
      "[812]\ttraining's binary_logloss: 0.00448726\n",
      "[813]\ttraining's binary_logloss: 0.004464\n",
      "[814]\ttraining's binary_logloss: 0.00444016\n",
      "[815]\ttraining's binary_logloss: 0.00441522\n",
      "[816]\ttraining's binary_logloss: 0.00439096\n",
      "[817]\ttraining's binary_logloss: 0.00436712\n",
      "[818]\ttraining's binary_logloss: 0.00434121\n",
      "[819]\ttraining's binary_logloss: 0.00431665\n",
      "[820]\ttraining's binary_logloss: 0.00429231\n",
      "[821]\ttraining's binary_logloss: 0.00426803\n",
      "[822]\ttraining's binary_logloss: 0.00424364\n",
      "[823]\ttraining's binary_logloss: 0.00421953\n",
      "[824]\ttraining's binary_logloss: 0.00419532\n",
      "[825]\ttraining's binary_logloss: 0.00417304\n",
      "[826]\ttraining's binary_logloss: 0.00414931\n",
      "[827]\ttraining's binary_logloss: 0.00412751\n",
      "[828]\ttraining's binary_logloss: 0.00410445\n",
      "[829]\ttraining's binary_logloss: 0.0040841\n",
      "[830]\ttraining's binary_logloss: 0.00406321\n",
      "[831]\ttraining's binary_logloss: 0.00404225\n",
      "[832]\ttraining's binary_logloss: 0.00401874\n",
      "[833]\ttraining's binary_logloss: 0.00399753\n",
      "[834]\ttraining's binary_logloss: 0.0039767\n",
      "[835]\ttraining's binary_logloss: 0.00395557\n",
      "[836]\ttraining's binary_logloss: 0.00393306\n",
      "[837]\ttraining's binary_logloss: 0.00391251\n",
      "[838]\ttraining's binary_logloss: 0.0038907\n",
      "[839]\ttraining's binary_logloss: 0.00386786\n",
      "[840]\ttraining's binary_logloss: 0.00384727\n",
      "[841]\ttraining's binary_logloss: 0.00382766\n",
      "[842]\ttraining's binary_logloss: 0.00380668\n",
      "[843]\ttraining's binary_logloss: 0.00378594\n",
      "[844]\ttraining's binary_logloss: 0.0037651\n",
      "[845]\ttraining's binary_logloss: 0.0037453\n",
      "[846]\ttraining's binary_logloss: 0.00372732\n",
      "[847]\ttraining's binary_logloss: 0.00370821\n",
      "[848]\ttraining's binary_logloss: 0.00368924\n",
      "[849]\ttraining's binary_logloss: 0.00366898\n",
      "[850]\ttraining's binary_logloss: 0.00365063\n",
      "[851]\ttraining's binary_logloss: 0.00363109\n",
      "[852]\ttraining's binary_logloss: 0.00361173\n",
      "[853]\ttraining's binary_logloss: 0.00359208\n",
      "[854]\ttraining's binary_logloss: 0.00357112\n",
      "[855]\ttraining's binary_logloss: 0.00355131\n",
      "[856]\ttraining's binary_logloss: 0.00353336\n",
      "[857]\ttraining's binary_logloss: 0.0035139\n",
      "[858]\ttraining's binary_logloss: 0.00349689\n",
      "[859]\ttraining's binary_logloss: 0.00347715\n",
      "[860]\ttraining's binary_logloss: 0.00345664\n",
      "[861]\ttraining's binary_logloss: 0.00343597\n",
      "[862]\ttraining's binary_logloss: 0.00341735\n",
      "[863]\ttraining's binary_logloss: 0.003399\n",
      "[864]\ttraining's binary_logloss: 0.00337952\n",
      "[865]\ttraining's binary_logloss: 0.00336137\n",
      "[866]\ttraining's binary_logloss: 0.00334427\n",
      "[867]\ttraining's binary_logloss: 0.00332558\n",
      "[868]\ttraining's binary_logloss: 0.00330647\n",
      "[869]\ttraining's binary_logloss: 0.00328826\n",
      "[870]\ttraining's binary_logloss: 0.00326962\n",
      "[871]\ttraining's binary_logloss: 0.00325287\n",
      "[872]\ttraining's binary_logloss: 0.00323614\n",
      "[873]\ttraining's binary_logloss: 0.00321832\n",
      "[874]\ttraining's binary_logloss: 0.0032009\n",
      "[875]\ttraining's binary_logloss: 0.00318434\n",
      "[876]\ttraining's binary_logloss: 0.00316829\n",
      "[877]\ttraining's binary_logloss: 0.0031506\n",
      "[878]\ttraining's binary_logloss: 0.00313277\n",
      "[879]\ttraining's binary_logloss: 0.00311537\n",
      "[880]\ttraining's binary_logloss: 0.0030981\n",
      "[881]\ttraining's binary_logloss: 0.00308144\n",
      "[882]\ttraining's binary_logloss: 0.00306577\n",
      "[883]\ttraining's binary_logloss: 0.0030489\n",
      "[884]\ttraining's binary_logloss: 0.00303156\n",
      "[885]\ttraining's binary_logloss: 0.00301429\n",
      "[886]\ttraining's binary_logloss: 0.002998\n",
      "[887]\ttraining's binary_logloss: 0.00298311\n",
      "[888]\ttraining's binary_logloss: 0.00296736\n",
      "[889]\ttraining's binary_logloss: 0.00295191\n",
      "[890]\ttraining's binary_logloss: 0.00293634\n",
      "[891]\ttraining's binary_logloss: 0.00292273\n",
      "[892]\ttraining's binary_logloss: 0.00290796\n",
      "[893]\ttraining's binary_logloss: 0.00289311\n",
      "[894]\ttraining's binary_logloss: 0.00287767\n",
      "[895]\ttraining's binary_logloss: 0.00286215\n",
      "[896]\ttraining's binary_logloss: 0.00284863\n",
      "[897]\ttraining's binary_logloss: 0.00283311\n",
      "[898]\ttraining's binary_logloss: 0.0028166\n",
      "[899]\ttraining's binary_logloss: 0.00280108\n",
      "[900]\ttraining's binary_logloss: 0.0027858\n",
      "[901]\ttraining's binary_logloss: 0.00277053\n",
      "[902]\ttraining's binary_logloss: 0.00275413\n",
      "[903]\ttraining's binary_logloss: 0.00273883\n",
      "[904]\ttraining's binary_logloss: 0.00272352\n",
      "[905]\ttraining's binary_logloss: 0.0027081\n",
      "[906]\ttraining's binary_logloss: 0.00269304\n",
      "[907]\ttraining's binary_logloss: 0.00267918\n",
      "[908]\ttraining's binary_logloss: 0.00266517\n",
      "[909]\ttraining's binary_logloss: 0.0026516\n",
      "[910]\ttraining's binary_logloss: 0.00263766\n",
      "[911]\ttraining's binary_logloss: 0.00262291\n",
      "[912]\ttraining's binary_logloss: 0.00260816\n",
      "[913]\ttraining's binary_logloss: 0.00259239\n",
      "[914]\ttraining's binary_logloss: 0.00257909\n",
      "[915]\ttraining's binary_logloss: 0.0025662\n",
      "[916]\ttraining's binary_logloss: 0.00255245\n",
      "[917]\ttraining's binary_logloss: 0.00253836\n",
      "[918]\ttraining's binary_logloss: 0.00252474\n",
      "[919]\ttraining's binary_logloss: 0.00251014\n",
      "[920]\ttraining's binary_logloss: 0.00249636\n",
      "[921]\ttraining's binary_logloss: 0.00248271\n",
      "[922]\ttraining's binary_logloss: 0.00246865\n",
      "[923]\ttraining's binary_logloss: 0.00245487\n",
      "[924]\ttraining's binary_logloss: 0.00244068\n",
      "[925]\ttraining's binary_logloss: 0.00242847\n",
      "[926]\ttraining's binary_logloss: 0.00241518\n",
      "[927]\ttraining's binary_logloss: 0.00240169\n",
      "[928]\ttraining's binary_logloss: 0.00238948\n",
      "[929]\ttraining's binary_logloss: 0.00237616\n",
      "[930]\ttraining's binary_logloss: 0.00236306\n",
      "[931]\ttraining's binary_logloss: 0.00235103\n",
      "[932]\ttraining's binary_logloss: 0.00233734\n",
      "[933]\ttraining's binary_logloss: 0.00232418\n",
      "[934]\ttraining's binary_logloss: 0.00231128\n",
      "[935]\ttraining's binary_logloss: 0.00229862\n",
      "[936]\ttraining's binary_logloss: 0.00228668\n",
      "[937]\ttraining's binary_logloss: 0.00227537\n",
      "[938]\ttraining's binary_logloss: 0.00226411\n",
      "[939]\ttraining's binary_logloss: 0.00225088\n",
      "[940]\ttraining's binary_logloss: 0.00223882\n",
      "[941]\ttraining's binary_logloss: 0.00222763\n",
      "[942]\ttraining's binary_logloss: 0.00221576\n",
      "[943]\ttraining's binary_logloss: 0.0022026\n",
      "[944]\ttraining's binary_logloss: 0.00219102\n",
      "[945]\ttraining's binary_logloss: 0.00217927\n",
      "[946]\ttraining's binary_logloss: 0.00216663\n",
      "[947]\ttraining's binary_logloss: 0.00215409\n",
      "[948]\ttraining's binary_logloss: 0.00214224\n",
      "[949]\ttraining's binary_logloss: 0.00213022\n",
      "[950]\ttraining's binary_logloss: 0.00211928\n",
      "[951]\ttraining's binary_logloss: 0.00210744\n",
      "[952]\ttraining's binary_logloss: 0.00209664\n",
      "[953]\ttraining's binary_logloss: 0.00208581\n",
      "[954]\ttraining's binary_logloss: 0.00207557\n",
      "[955]\ttraining's binary_logloss: 0.00206408\n",
      "[956]\ttraining's binary_logloss: 0.00205192\n",
      "[957]\ttraining's binary_logloss: 0.00204098\n",
      "[958]\ttraining's binary_logloss: 0.0020302\n",
      "[959]\ttraining's binary_logloss: 0.00202006\n",
      "[960]\ttraining's binary_logloss: 0.00200946\n",
      "[961]\ttraining's binary_logloss: 0.00199838\n",
      "[962]\ttraining's binary_logloss: 0.00198792\n",
      "[963]\ttraining's binary_logloss: 0.00197725\n",
      "[964]\ttraining's binary_logloss: 0.00196712\n",
      "[965]\ttraining's binary_logloss: 0.00195607\n",
      "[966]\ttraining's binary_logloss: 0.00194451\n",
      "[967]\ttraining's binary_logloss: 0.00193381\n",
      "[968]\ttraining's binary_logloss: 0.00192296\n",
      "[969]\ttraining's binary_logloss: 0.00191244\n",
      "[970]\ttraining's binary_logloss: 0.00190264\n",
      "[971]\ttraining's binary_logloss: 0.00189247\n",
      "[972]\ttraining's binary_logloss: 0.00188206\n",
      "[973]\ttraining's binary_logloss: 0.00187135\n",
      "[974]\ttraining's binary_logloss: 0.00186079\n",
      "[975]\ttraining's binary_logloss: 0.00185014\n",
      "[976]\ttraining's binary_logloss: 0.00184142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[977]\ttraining's binary_logloss: 0.00183093\n",
      "[978]\ttraining's binary_logloss: 0.00182092\n",
      "[979]\ttraining's binary_logloss: 0.00181132\n",
      "[980]\ttraining's binary_logloss: 0.00180074\n",
      "[981]\ttraining's binary_logloss: 0.00179085\n",
      "[982]\ttraining's binary_logloss: 0.00178167\n",
      "[983]\ttraining's binary_logloss: 0.00177205\n",
      "[984]\ttraining's binary_logloss: 0.00176237\n",
      "[985]\ttraining's binary_logloss: 0.00175279\n",
      "[986]\ttraining's binary_logloss: 0.00174256\n",
      "[987]\ttraining's binary_logloss: 0.00173412\n",
      "[988]\ttraining's binary_logloss: 0.00172458\n",
      "[989]\ttraining's binary_logloss: 0.00171559\n",
      "[990]\ttraining's binary_logloss: 0.00170629\n",
      "[991]\ttraining's binary_logloss: 0.00169766\n",
      "[992]\ttraining's binary_logloss: 0.00168813\n",
      "[993]\ttraining's binary_logloss: 0.00167852\n",
      "[994]\ttraining's binary_logloss: 0.00166912\n",
      "[995]\ttraining's binary_logloss: 0.00165985\n",
      "[996]\ttraining's binary_logloss: 0.00165104\n",
      "[997]\ttraining's binary_logloss: 0.00164175\n",
      "[998]\ttraining's binary_logloss: 0.00163268\n",
      "[999]\ttraining's binary_logloss: 0.00162329\n",
      "[1000]\ttraining's binary_logloss: 0.00161373\n",
      "[1001]\ttraining's binary_logloss: 0.00160429\n",
      "[1002]\ttraining's binary_logloss: 0.00159517\n",
      "[1003]\ttraining's binary_logloss: 0.00158591\n",
      "[1004]\ttraining's binary_logloss: 0.00157676\n",
      "[1005]\ttraining's binary_logloss: 0.00156768\n",
      "[1006]\ttraining's binary_logloss: 0.00155961\n",
      "[1007]\ttraining's binary_logloss: 0.001551\n",
      "[1008]\ttraining's binary_logloss: 0.00154249\n",
      "[1009]\ttraining's binary_logloss: 0.00153374\n",
      "[1010]\ttraining's binary_logloss: 0.00152515\n",
      "[1011]\ttraining's binary_logloss: 0.00151732\n",
      "[1012]\ttraining's binary_logloss: 0.00150895\n",
      "[1013]\ttraining's binary_logloss: 0.00150073\n",
      "[1014]\ttraining's binary_logloss: 0.00149234\n",
      "[1015]\ttraining's binary_logloss: 0.00148387\n",
      "[1016]\ttraining's binary_logloss: 0.00147539\n",
      "[1017]\ttraining's binary_logloss: 0.00146724\n",
      "[1018]\ttraining's binary_logloss: 0.00145945\n",
      "[1019]\ttraining's binary_logloss: 0.00145107\n",
      "[1020]\ttraining's binary_logloss: 0.00144342\n",
      "[1021]\ttraining's binary_logloss: 0.00143509\n",
      "[1022]\ttraining's binary_logloss: 0.00142779\n",
      "[1023]\ttraining's binary_logloss: 0.00141949\n",
      "[1024]\ttraining's binary_logloss: 0.0014116\n",
      "[1025]\ttraining's binary_logloss: 0.00140345\n",
      "[1026]\ttraining's binary_logloss: 0.00139552\n",
      "[1027]\ttraining's binary_logloss: 0.00138833\n",
      "[1028]\ttraining's binary_logloss: 0.00138084\n",
      "[1029]\ttraining's binary_logloss: 0.00137301\n",
      "[1030]\ttraining's binary_logloss: 0.00136562\n",
      "[1031]\ttraining's binary_logloss: 0.00135775\n",
      "[1032]\ttraining's binary_logloss: 0.0013496\n",
      "[1033]\ttraining's binary_logloss: 0.00134257\n",
      "[1034]\ttraining's binary_logloss: 0.00133571\n",
      "[1035]\ttraining's binary_logloss: 0.00132825\n",
      "[1036]\ttraining's binary_logloss: 0.00132207\n",
      "[1037]\ttraining's binary_logloss: 0.00131533\n",
      "[1038]\ttraining's binary_logloss: 0.00130775\n",
      "[1039]\ttraining's binary_logloss: 0.00130056\n",
      "[1040]\ttraining's binary_logloss: 0.00129419\n",
      "[1041]\ttraining's binary_logloss: 0.00128669\n",
      "[1042]\ttraining's binary_logloss: 0.0012795\n",
      "[1043]\ttraining's binary_logloss: 0.00127217\n",
      "[1044]\ttraining's binary_logloss: 0.00126528\n",
      "[1045]\ttraining's binary_logloss: 0.00125885\n",
      "[1046]\ttraining's binary_logloss: 0.00125235\n",
      "[1047]\ttraining's binary_logloss: 0.00124554\n",
      "[1048]\ttraining's binary_logloss: 0.00123939\n",
      "[1049]\ttraining's binary_logloss: 0.00123246\n",
      "[1050]\ttraining's binary_logloss: 0.00122638\n",
      "[1051]\ttraining's binary_logloss: 0.00121952\n",
      "[1052]\ttraining's binary_logloss: 0.00121261\n",
      "[1053]\ttraining's binary_logloss: 0.00120605\n",
      "[1054]\ttraining's binary_logloss: 0.00119947\n",
      "[1055]\ttraining's binary_logloss: 0.0011931\n",
      "[1056]\ttraining's binary_logloss: 0.00118693\n",
      "[1057]\ttraining's binary_logloss: 0.00118048\n",
      "[1058]\ttraining's binary_logloss: 0.00117371\n",
      "[1059]\ttraining's binary_logloss: 0.00116739\n",
      "[1060]\ttraining's binary_logloss: 0.00116139\n",
      "[1061]\ttraining's binary_logloss: 0.00115491\n",
      "[1062]\ttraining's binary_logloss: 0.001149\n",
      "[1063]\ttraining's binary_logloss: 0.00114284\n",
      "[1064]\ttraining's binary_logloss: 0.00113667\n",
      "[1065]\ttraining's binary_logloss: 0.00113062\n",
      "[1066]\ttraining's binary_logloss: 0.0011244\n",
      "[1067]\ttraining's binary_logloss: 0.00111841\n",
      "[1068]\ttraining's binary_logloss: 0.00111213\n",
      "[1069]\ttraining's binary_logloss: 0.00110604\n",
      "[1070]\ttraining's binary_logloss: 0.00109986\n",
      "[1071]\ttraining's binary_logloss: 0.00109426\n",
      "[1072]\ttraining's binary_logloss: 0.00108825\n",
      "[1073]\ttraining's binary_logloss: 0.00108224\n",
      "[1074]\ttraining's binary_logloss: 0.00107619\n",
      "[1075]\ttraining's binary_logloss: 0.00107008\n",
      "[1076]\ttraining's binary_logloss: 0.00106439\n",
      "[1077]\ttraining's binary_logloss: 0.00105833\n",
      "[1078]\ttraining's binary_logloss: 0.0010527\n",
      "[1079]\ttraining's binary_logloss: 0.00104643\n",
      "[1080]\ttraining's binary_logloss: 0.00104079\n",
      "[1081]\ttraining's binary_logloss: 0.00103489\n",
      "[1082]\ttraining's binary_logloss: 0.00102937\n",
      "[1083]\ttraining's binary_logloss: 0.00102426\n",
      "[1084]\ttraining's binary_logloss: 0.00101859\n",
      "[1085]\ttraining's binary_logloss: 0.00101288\n",
      "[1086]\ttraining's binary_logloss: 0.00100735\n",
      "[1087]\ttraining's binary_logloss: 0.00100187\n",
      "[1088]\ttraining's binary_logloss: 0.000996485\n",
      "[1089]\ttraining's binary_logloss: 0.000991194\n",
      "[1090]\ttraining's binary_logloss: 0.000985229\n",
      "[1091]\ttraining's binary_logloss: 0.000979864\n",
      "[1092]\ttraining's binary_logloss: 0.000974415\n",
      "[1093]\ttraining's binary_logloss: 0.000969025\n",
      "[1094]\ttraining's binary_logloss: 0.000963573\n",
      "[1095]\ttraining's binary_logloss: 0.000957923\n",
      "[1096]\ttraining's binary_logloss: 0.000952982\n",
      "[1097]\ttraining's binary_logloss: 0.000947522\n",
      "[1098]\ttraining's binary_logloss: 0.000942266\n",
      "[1099]\ttraining's binary_logloss: 0.000937112\n",
      "[1100]\ttraining's binary_logloss: 0.000932112\n",
      "[1101]\ttraining's binary_logloss: 0.000926599\n",
      "[1102]\ttraining's binary_logloss: 0.000921255\n",
      "[1103]\ttraining's binary_logloss: 0.000916414\n",
      "[1104]\ttraining's binary_logloss: 0.000911234\n",
      "[1105]\ttraining's binary_logloss: 0.000906942\n",
      "[1106]\ttraining's binary_logloss: 0.000902004\n",
      "[1107]\ttraining's binary_logloss: 0.000897389\n",
      "[1108]\ttraining's binary_logloss: 0.000892424\n",
      "[1109]\ttraining's binary_logloss: 0.000887195\n",
      "[1110]\ttraining's binary_logloss: 0.000882181\n",
      "[1111]\ttraining's binary_logloss: 0.000877344\n",
      "[1112]\ttraining's binary_logloss: 0.000872583\n",
      "[1113]\ttraining's binary_logloss: 0.000867579\n",
      "[1114]\ttraining's binary_logloss: 0.00086276\n",
      "[1115]\ttraining's binary_logloss: 0.000858188\n",
      "[1116]\ttraining's binary_logloss: 0.000853364\n",
      "[1117]\ttraining's binary_logloss: 0.000849064\n",
      "[1118]\ttraining's binary_logloss: 0.000844536\n",
      "[1119]\ttraining's binary_logloss: 0.00084005\n",
      "[1120]\ttraining's binary_logloss: 0.000835732\n",
      "[1121]\ttraining's binary_logloss: 0.000830968\n",
      "[1122]\ttraining's binary_logloss: 0.000826135\n",
      "[1123]\ttraining's binary_logloss: 0.000821452\n",
      "[1124]\ttraining's binary_logloss: 0.000817067\n",
      "[1125]\ttraining's binary_logloss: 0.000813042\n",
      "[1126]\ttraining's binary_logloss: 0.000808816\n",
      "[1127]\ttraining's binary_logloss: 0.00080451\n",
      "[1128]\ttraining's binary_logloss: 0.000800451\n",
      "[1129]\ttraining's binary_logloss: 0.000796363\n",
      "[1130]\ttraining's binary_logloss: 0.000791854\n",
      "[1131]\ttraining's binary_logloss: 0.000787719\n",
      "[1132]\ttraining's binary_logloss: 0.000783269\n",
      "[1133]\ttraining's binary_logloss: 0.000778594\n",
      "[1134]\ttraining's binary_logloss: 0.000774399\n",
      "[1135]\ttraining's binary_logloss: 0.000769968\n",
      "[1136]\ttraining's binary_logloss: 0.0007657\n",
      "[1137]\ttraining's binary_logloss: 0.000761589\n",
      "[1138]\ttraining's binary_logloss: 0.000757375\n",
      "[1139]\ttraining's binary_logloss: 0.000753322\n",
      "[1140]\ttraining's binary_logloss: 0.000748828\n",
      "[1141]\ttraining's binary_logloss: 0.000744634\n",
      "[1142]\ttraining's binary_logloss: 0.000740524\n",
      "[1143]\ttraining's binary_logloss: 0.000736621\n",
      "[1144]\ttraining's binary_logloss: 0.000732445\n",
      "[1145]\ttraining's binary_logloss: 0.000728232\n",
      "[1146]\ttraining's binary_logloss: 0.000724206\n",
      "[1147]\ttraining's binary_logloss: 0.000719938\n",
      "[1148]\ttraining's binary_logloss: 0.000716379\n",
      "[1149]\ttraining's binary_logloss: 0.000712473\n",
      "[1150]\ttraining's binary_logloss: 0.000708383\n",
      "[1151]\ttraining's binary_logloss: 0.00070427\n",
      "[1152]\ttraining's binary_logloss: 0.000700462\n",
      "[1153]\ttraining's binary_logloss: 0.000696829\n",
      "[1154]\ttraining's binary_logloss: 0.000693238\n",
      "[1155]\ttraining's binary_logloss: 0.000689288\n",
      "[1156]\ttraining's binary_logloss: 0.00068546\n",
      "[1157]\ttraining's binary_logloss: 0.000681747\n",
      "[1158]\ttraining's binary_logloss: 0.000677925\n",
      "[1159]\ttraining's binary_logloss: 0.000673857\n",
      "[1160]\ttraining's binary_logloss: 0.000670328\n",
      "[1161]\ttraining's binary_logloss: 0.000666589\n",
      "[1162]\ttraining's binary_logloss: 0.000663108\n",
      "[1163]\ttraining's binary_logloss: 0.000659818\n",
      "[1164]\ttraining's binary_logloss: 0.000656337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1165]\ttraining's binary_logloss: 0.00065289\n",
      "[1166]\ttraining's binary_logloss: 0.000649111\n",
      "[1167]\ttraining's binary_logloss: 0.000645394\n",
      "[1168]\ttraining's binary_logloss: 0.000641936\n",
      "[1169]\ttraining's binary_logloss: 0.00063835\n",
      "[1170]\ttraining's binary_logloss: 0.000634817\n",
      "[1171]\ttraining's binary_logloss: 0.000630976\n",
      "[1172]\ttraining's binary_logloss: 0.000627347\n",
      "[1173]\ttraining's binary_logloss: 0.000623838\n",
      "[1174]\ttraining's binary_logloss: 0.000620399\n",
      "[1175]\ttraining's binary_logloss: 0.000617244\n",
      "[1176]\ttraining's binary_logloss: 0.000614049\n",
      "[1177]\ttraining's binary_logloss: 0.000610974\n",
      "[1178]\ttraining's binary_logloss: 0.000607667\n",
      "[1179]\ttraining's binary_logloss: 0.000604431\n",
      "[1180]\ttraining's binary_logloss: 0.000601024\n",
      "[1181]\ttraining's binary_logloss: 0.000597726\n",
      "[1182]\ttraining's binary_logloss: 0.000594504\n",
      "[1183]\ttraining's binary_logloss: 0.00059115\n",
      "[1184]\ttraining's binary_logloss: 0.000587804\n",
      "[1185]\ttraining's binary_logloss: 0.000584784\n",
      "[1186]\ttraining's binary_logloss: 0.000581542\n",
      "[1187]\ttraining's binary_logloss: 0.00057827\n",
      "[1188]\ttraining's binary_logloss: 0.000575258\n",
      "[1189]\ttraining's binary_logloss: 0.000572057\n",
      "[1190]\ttraining's binary_logloss: 0.000568983\n",
      "[1191]\ttraining's binary_logloss: 0.000565784\n",
      "[1192]\ttraining's binary_logloss: 0.00056268\n",
      "[1193]\ttraining's binary_logloss: 0.000559388\n",
      "[1194]\ttraining's binary_logloss: 0.000556239\n",
      "[1195]\ttraining's binary_logloss: 0.000553381\n",
      "[1196]\ttraining's binary_logloss: 0.000550475\n",
      "[1197]\ttraining's binary_logloss: 0.000547716\n",
      "[1198]\ttraining's binary_logloss: 0.000544628\n",
      "[1199]\ttraining's binary_logloss: 0.000541646\n",
      "[1200]\ttraining's binary_logloss: 0.000538719\n",
      "[1201]\ttraining's binary_logloss: 0.000535598\n",
      "[1202]\ttraining's binary_logloss: 0.000532665\n",
      "[1203]\ttraining's binary_logloss: 0.000529725\n",
      "[1204]\ttraining's binary_logloss: 0.000526965\n",
      "[1205]\ttraining's binary_logloss: 0.000524247\n",
      "[1206]\ttraining's binary_logloss: 0.000521392\n",
      "[1207]\ttraining's binary_logloss: 0.000518776\n",
      "[1208]\ttraining's binary_logloss: 0.000515919\n",
      "[1209]\ttraining's binary_logloss: 0.000512825\n",
      "[1210]\ttraining's binary_logloss: 0.00051017\n",
      "[1211]\ttraining's binary_logloss: 0.000507618\n",
      "[1212]\ttraining's binary_logloss: 0.0005047\n",
      "[1213]\ttraining's binary_logloss: 0.000501745\n",
      "[1214]\ttraining's binary_logloss: 0.000498973\n",
      "[1215]\ttraining's binary_logloss: 0.000496505\n",
      "[1216]\ttraining's binary_logloss: 0.000493711\n",
      "[1217]\ttraining's binary_logloss: 0.000490976\n",
      "[1218]\ttraining's binary_logloss: 0.000488023\n",
      "[1219]\ttraining's binary_logloss: 0.000485512\n",
      "[1220]\ttraining's binary_logloss: 0.000482867\n",
      "[1221]\ttraining's binary_logloss: 0.000480502\n",
      "[1222]\ttraining's binary_logloss: 0.000477964\n",
      "[1223]\ttraining's binary_logloss: 0.000475432\n",
      "[1224]\ttraining's binary_logloss: 0.000472748\n",
      "[1225]\ttraining's binary_logloss: 0.000470241\n",
      "[1226]\ttraining's binary_logloss: 0.000467864\n",
      "[1227]\ttraining's binary_logloss: 0.000465095\n",
      "[1228]\ttraining's binary_logloss: 0.000462429\n",
      "[1229]\ttraining's binary_logloss: 0.000460121\n",
      "[1230]\ttraining's binary_logloss: 0.000457459\n",
      "[1231]\ttraining's binary_logloss: 0.000455238\n",
      "[1232]\ttraining's binary_logloss: 0.000452965\n",
      "[1233]\ttraining's binary_logloss: 0.000450794\n",
      "[1234]\ttraining's binary_logloss: 0.000448126\n",
      "[1235]\ttraining's binary_logloss: 0.000445666\n",
      "[1236]\ttraining's binary_logloss: 0.00044323\n",
      "[1237]\ttraining's binary_logloss: 0.000440927\n",
      "[1238]\ttraining's binary_logloss: 0.000438558\n",
      "[1239]\ttraining's binary_logloss: 0.000436116\n",
      "[1240]\ttraining's binary_logloss: 0.000433842\n",
      "[1241]\ttraining's binary_logloss: 0.000431766\n",
      "[1242]\ttraining's binary_logloss: 0.000429587\n",
      "[1243]\ttraining's binary_logloss: 0.000426996\n",
      "[1244]\ttraining's binary_logloss: 0.000424648\n",
      "[1245]\ttraining's binary_logloss: 0.000422266\n",
      "[1246]\ttraining's binary_logloss: 0.000419803\n",
      "[1247]\ttraining's binary_logloss: 0.000417611\n",
      "[1248]\ttraining's binary_logloss: 0.00041547\n",
      "[1249]\ttraining's binary_logloss: 0.000413173\n",
      "[1250]\ttraining's binary_logloss: 0.000410905\n",
      "[1251]\ttraining's binary_logloss: 0.000408764\n",
      "[1252]\ttraining's binary_logloss: 0.000406232\n",
      "[1253]\ttraining's binary_logloss: 0.000404065\n",
      "[1254]\ttraining's binary_logloss: 0.000401932\n",
      "[1255]\ttraining's binary_logloss: 0.000399634\n",
      "[1256]\ttraining's binary_logloss: 0.000397318\n",
      "[1257]\ttraining's binary_logloss: 0.000395093\n",
      "[1258]\ttraining's binary_logloss: 0.000393183\n",
      "[1259]\ttraining's binary_logloss: 0.000391157\n",
      "[1260]\ttraining's binary_logloss: 0.000388896\n",
      "[1261]\ttraining's binary_logloss: 0.000386887\n",
      "[1262]\ttraining's binary_logloss: 0.000384789\n",
      "[1263]\ttraining's binary_logloss: 0.000382846\n",
      "[1264]\ttraining's binary_logloss: 0.000380925\n",
      "[1265]\ttraining's binary_logloss: 0.000378845\n",
      "[1266]\ttraining's binary_logloss: 0.00037694\n",
      "[1267]\ttraining's binary_logloss: 0.000375046\n",
      "[1268]\ttraining's binary_logloss: 0.000373138\n",
      "[1269]\ttraining's binary_logloss: 0.000371068\n",
      "[1270]\ttraining's binary_logloss: 0.000368981\n",
      "[1271]\ttraining's binary_logloss: 0.000366943\n",
      "[1272]\ttraining's binary_logloss: 0.00036479\n",
      "[1273]\ttraining's binary_logloss: 0.000362806\n",
      "[1274]\ttraining's binary_logloss: 0.000360891\n",
      "[1275]\ttraining's binary_logloss: 0.000358782\n",
      "[1276]\ttraining's binary_logloss: 0.000356868\n",
      "[1277]\ttraining's binary_logloss: 0.000354787\n",
      "[1278]\ttraining's binary_logloss: 0.000352813\n",
      "[1279]\ttraining's binary_logloss: 0.000350809\n",
      "[1280]\ttraining's binary_logloss: 0.00034879\n",
      "[1281]\ttraining's binary_logloss: 0.000346859\n",
      "[1282]\ttraining's binary_logloss: 0.000345019\n",
      "[1283]\ttraining's binary_logloss: 0.000343208\n",
      "[1284]\ttraining's binary_logloss: 0.000341154\n",
      "[1285]\ttraining's binary_logloss: 0.000339258\n",
      "[1286]\ttraining's binary_logloss: 0.000337469\n",
      "[1287]\ttraining's binary_logloss: 0.000335603\n",
      "[1288]\ttraining's binary_logloss: 0.000333747\n",
      "[1289]\ttraining's binary_logloss: 0.000331882\n",
      "[1290]\ttraining's binary_logloss: 0.000330055\n",
      "[1291]\ttraining's binary_logloss: 0.000328261\n",
      "[1292]\ttraining's binary_logloss: 0.000326334\n",
      "[1293]\ttraining's binary_logloss: 0.000324553\n",
      "[1294]\ttraining's binary_logloss: 0.00032267\n",
      "[1295]\ttraining's binary_logloss: 0.000320854\n",
      "[1296]\ttraining's binary_logloss: 0.000319236\n",
      "[1297]\ttraining's binary_logloss: 0.000317329\n",
      "[1298]\ttraining's binary_logloss: 0.000315441\n",
      "[1299]\ttraining's binary_logloss: 0.0003137\n",
      "[1300]\ttraining's binary_logloss: 0.000312035\n",
      "[1301]\ttraining's binary_logloss: 0.000310297\n",
      "[1302]\ttraining's binary_logloss: 0.000308582\n",
      "[1303]\ttraining's binary_logloss: 0.000306892\n",
      "[1304]\ttraining's binary_logloss: 0.000305235\n",
      "[1305]\ttraining's binary_logloss: 0.000303619\n",
      "[1306]\ttraining's binary_logloss: 0.000301844\n",
      "[1307]\ttraining's binary_logloss: 0.000300422\n",
      "[1308]\ttraining's binary_logloss: 0.000298909\n",
      "[1309]\ttraining's binary_logloss: 0.000297458\n",
      "[1310]\ttraining's binary_logloss: 0.000295932\n",
      "[1311]\ttraining's binary_logloss: 0.000294356\n",
      "[1312]\ttraining's binary_logloss: 0.000292737\n",
      "[1313]\ttraining's binary_logloss: 0.000291081\n",
      "[1314]\ttraining's binary_logloss: 0.000289365\n",
      "[1315]\ttraining's binary_logloss: 0.000287826\n",
      "[1316]\ttraining's binary_logloss: 0.000286195\n",
      "[1317]\ttraining's binary_logloss: 0.000284609\n",
      "[1318]\ttraining's binary_logloss: 0.000283228\n",
      "[1319]\ttraining's binary_logloss: 0.000281578\n",
      "[1320]\ttraining's binary_logloss: 0.000280037\n",
      "[1321]\ttraining's binary_logloss: 0.000278632\n",
      "[1322]\ttraining's binary_logloss: 0.000277151\n",
      "[1323]\ttraining's binary_logloss: 0.00027558\n",
      "[1324]\ttraining's binary_logloss: 0.000274006\n",
      "[1325]\ttraining's binary_logloss: 0.000272585\n",
      "[1326]\ttraining's binary_logloss: 0.000271163\n",
      "[1327]\ttraining's binary_logloss: 0.000269645\n",
      "[1328]\ttraining's binary_logloss: 0.000268307\n",
      "[1329]\ttraining's binary_logloss: 0.000266909\n",
      "[1330]\ttraining's binary_logloss: 0.000265504\n",
      "[1331]\ttraining's binary_logloss: 0.000264209\n",
      "[1332]\ttraining's binary_logloss: 0.000262819\n",
      "[1333]\ttraining's binary_logloss: 0.000261498\n",
      "[1334]\ttraining's binary_logloss: 0.000260093\n",
      "[1335]\ttraining's binary_logloss: 0.000258675\n",
      "[1336]\ttraining's binary_logloss: 0.000257238\n",
      "[1337]\ttraining's binary_logloss: 0.000255885\n",
      "[1338]\ttraining's binary_logloss: 0.000254607\n",
      "[1339]\ttraining's binary_logloss: 0.000253214\n",
      "[1340]\ttraining's binary_logloss: 0.000251872\n",
      "[1341]\ttraining's binary_logloss: 0.00025042\n",
      "[1342]\ttraining's binary_logloss: 0.000249122\n",
      "[1343]\ttraining's binary_logloss: 0.000247773\n",
      "[1344]\ttraining's binary_logloss: 0.000246416\n",
      "[1345]\ttraining's binary_logloss: 0.000245096\n",
      "[1346]\ttraining's binary_logloss: 0.000243815\n",
      "[1347]\ttraining's binary_logloss: 0.000242569\n",
      "[1348]\ttraining's binary_logloss: 0.000241201\n",
      "[1349]\ttraining's binary_logloss: 0.000239868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1350]\ttraining's binary_logloss: 0.000238693\n",
      "[1351]\ttraining's binary_logloss: 0.000237371\n",
      "[1352]\ttraining's binary_logloss: 0.00023598\n",
      "[1353]\ttraining's binary_logloss: 0.00023471\n",
      "[1354]\ttraining's binary_logloss: 0.000233384\n",
      "[1355]\ttraining's binary_logloss: 0.000232135\n",
      "[1356]\ttraining's binary_logloss: 0.000230998\n",
      "[1357]\ttraining's binary_logloss: 0.000229724\n",
      "[1358]\ttraining's binary_logloss: 0.000228616\n",
      "[1359]\ttraining's binary_logloss: 0.000227391\n",
      "[1360]\ttraining's binary_logloss: 0.000226033\n",
      "[1361]\ttraining's binary_logloss: 0.000224861\n",
      "[1362]\ttraining's binary_logloss: 0.000223729\n",
      "[1363]\ttraining's binary_logloss: 0.000222426\n",
      "[1364]\ttraining's binary_logloss: 0.000221214\n",
      "[1365]\ttraining's binary_logloss: 0.000220059\n",
      "[1366]\ttraining's binary_logloss: 0.000218894\n",
      "[1367]\ttraining's binary_logloss: 0.000217611\n",
      "[1368]\ttraining's binary_logloss: 0.00021635\n",
      "[1369]\ttraining's binary_logloss: 0.000215138\n",
      "[1370]\ttraining's binary_logloss: 0.000213928\n",
      "[1371]\ttraining's binary_logloss: 0.000212701\n",
      "[1372]\ttraining's binary_logloss: 0.00021148\n",
      "[1373]\ttraining's binary_logloss: 0.000210348\n",
      "[1374]\ttraining's binary_logloss: 0.000209288\n",
      "[1375]\ttraining's binary_logloss: 0.00020815\n",
      "[1376]\ttraining's binary_logloss: 0.000207141\n",
      "[1377]\ttraining's binary_logloss: 0.000206046\n",
      "[1378]\ttraining's binary_logloss: 0.000204976\n",
      "[1379]\ttraining's binary_logloss: 0.000203918\n",
      "[1380]\ttraining's binary_logloss: 0.000202834\n",
      "[1381]\ttraining's binary_logloss: 0.000201769\n",
      "[1382]\ttraining's binary_logloss: 0.000200676\n",
      "[1383]\ttraining's binary_logloss: 0.000199659\n",
      "[1384]\ttraining's binary_logloss: 0.000198547\n",
      "[1385]\ttraining's binary_logloss: 0.000197488\n",
      "[1386]\ttraining's binary_logloss: 0.000196472\n",
      "[1387]\ttraining's binary_logloss: 0.000195418\n",
      "[1388]\ttraining's binary_logloss: 0.000194439\n",
      "[1389]\ttraining's binary_logloss: 0.000193437\n",
      "[1390]\ttraining's binary_logloss: 0.000192363\n",
      "[1391]\ttraining's binary_logloss: 0.000191293\n",
      "[1392]\ttraining's binary_logloss: 0.000190336\n",
      "[1393]\ttraining's binary_logloss: 0.000189316\n",
      "[1394]\ttraining's binary_logloss: 0.000188206\n",
      "[1395]\ttraining's binary_logloss: 0.00018714\n",
      "[1396]\ttraining's binary_logloss: 0.000186158\n",
      "[1397]\ttraining's binary_logloss: 0.000185241\n",
      "[1398]\ttraining's binary_logloss: 0.000184364\n",
      "[1399]\ttraining's binary_logloss: 0.000183433\n",
      "[1400]\ttraining's binary_logloss: 0.000182496\n",
      "[1401]\ttraining's binary_logloss: 0.000181505\n",
      "[1402]\ttraining's binary_logloss: 0.000180466\n",
      "[1403]\ttraining's binary_logloss: 0.000179558\n",
      "[1404]\ttraining's binary_logloss: 0.000178511\n",
      "[1405]\ttraining's binary_logloss: 0.00017753\n",
      "[1406]\ttraining's binary_logloss: 0.000176613\n",
      "[1407]\ttraining's binary_logloss: 0.000175793\n",
      "[1408]\ttraining's binary_logloss: 0.000174888\n",
      "[1409]\ttraining's binary_logloss: 0.000173915\n",
      "[1410]\ttraining's binary_logloss: 0.000172991\n",
      "[1411]\ttraining's binary_logloss: 0.000172019\n",
      "[1412]\ttraining's binary_logloss: 0.000171129\n",
      "[1413]\ttraining's binary_logloss: 0.000170314\n",
      "[1414]\ttraining's binary_logloss: 0.00016945\n",
      "[1415]\ttraining's binary_logloss: 0.000168548\n",
      "[1416]\ttraining's binary_logloss: 0.000167579\n",
      "[1417]\ttraining's binary_logloss: 0.000166687\n",
      "[1418]\ttraining's binary_logloss: 0.000165737\n",
      "[1419]\ttraining's binary_logloss: 0.000164865\n",
      "[1420]\ttraining's binary_logloss: 0.000163976\n",
      "[1421]\ttraining's binary_logloss: 0.000163185\n",
      "[1422]\ttraining's binary_logloss: 0.000162302\n",
      "[1423]\ttraining's binary_logloss: 0.000161467\n",
      "[1424]\ttraining's binary_logloss: 0.000160607\n",
      "[1425]\ttraining's binary_logloss: 0.000159824\n",
      "[1426]\ttraining's binary_logloss: 0.000158932\n",
      "[1427]\ttraining's binary_logloss: 0.000158071\n",
      "[1428]\ttraining's binary_logloss: 0.000157212\n",
      "[1429]\ttraining's binary_logloss: 0.000156404\n",
      "[1430]\ttraining's binary_logloss: 0.000155558\n",
      "[1431]\ttraining's binary_logloss: 0.000154734\n",
      "[1432]\ttraining's binary_logloss: 0.000153992\n",
      "[1433]\ttraining's binary_logloss: 0.000153253\n",
      "[1434]\ttraining's binary_logloss: 0.000152505\n",
      "[1435]\ttraining's binary_logloss: 0.000151737\n",
      "[1436]\ttraining's binary_logloss: 0.00015101\n",
      "[1437]\ttraining's binary_logloss: 0.000150195\n",
      "[1438]\ttraining's binary_logloss: 0.000149377\n",
      "[1439]\ttraining's binary_logloss: 0.000148567\n",
      "[1440]\ttraining's binary_logloss: 0.000147774\n",
      "[1441]\ttraining's binary_logloss: 0.000147025\n",
      "[1442]\ttraining's binary_logloss: 0.000146244\n",
      "[1443]\ttraining's binary_logloss: 0.000145409\n",
      "[1444]\ttraining's binary_logloss: 0.000144702\n",
      "[1445]\ttraining's binary_logloss: 0.00014405\n",
      "[1446]\ttraining's binary_logloss: 0.000143232\n",
      "[1447]\ttraining's binary_logloss: 0.000142422\n",
      "[1448]\ttraining's binary_logloss: 0.000141704\n",
      "[1449]\ttraining's binary_logloss: 0.000140983\n",
      "[1450]\ttraining's binary_logloss: 0.000140197\n",
      "[1451]\ttraining's binary_logloss: 0.000139438\n",
      "[1452]\ttraining's binary_logloss: 0.000138722\n",
      "[1453]\ttraining's binary_logloss: 0.000137917\n",
      "[1454]\ttraining's binary_logloss: 0.000137216\n",
      "[1455]\ttraining's binary_logloss: 0.000136552\n",
      "[1456]\ttraining's binary_logloss: 0.000135823\n",
      "[1457]\ttraining's binary_logloss: 0.000135042\n",
      "[1458]\ttraining's binary_logloss: 0.000134278\n",
      "[1459]\ttraining's binary_logloss: 0.000133517\n",
      "[1460]\ttraining's binary_logloss: 0.000132849\n",
      "[1461]\ttraining's binary_logloss: 0.000132178\n",
      "[1462]\ttraining's binary_logloss: 0.000131526\n",
      "[1463]\ttraining's binary_logloss: 0.000130896\n",
      "[1464]\ttraining's binary_logloss: 0.000130327\n",
      "[1465]\ttraining's binary_logloss: 0.000129692\n",
      "[1466]\ttraining's binary_logloss: 0.000128985\n",
      "[1467]\ttraining's binary_logloss: 0.000128306\n",
      "[1468]\ttraining's binary_logloss: 0.00012767\n",
      "[1469]\ttraining's binary_logloss: 0.00012709\n",
      "[1470]\ttraining's binary_logloss: 0.000126506\n",
      "[1471]\ttraining's binary_logloss: 0.000125828\n",
      "[1472]\ttraining's binary_logloss: 0.000125194\n",
      "[1473]\ttraining's binary_logloss: 0.000124481\n",
      "[1474]\ttraining's binary_logloss: 0.000123832\n",
      "[1475]\ttraining's binary_logloss: 0.000123206\n",
      "[1476]\ttraining's binary_logloss: 0.000122521\n",
      "[1477]\ttraining's binary_logloss: 0.00012196\n",
      "[1478]\ttraining's binary_logloss: 0.000121401\n",
      "[1479]\ttraining's binary_logloss: 0.000120768\n",
      "[1480]\ttraining's binary_logloss: 0.000120084\n",
      "[1481]\ttraining's binary_logloss: 0.000119562\n",
      "[1482]\ttraining's binary_logloss: 0.000119032\n",
      "[1483]\ttraining's binary_logloss: 0.000118392\n",
      "[1484]\ttraining's binary_logloss: 0.000117744\n",
      "[1485]\ttraining's binary_logloss: 0.000117064\n",
      "[1486]\ttraining's binary_logloss: 0.000116483\n",
      "[1487]\ttraining's binary_logloss: 0.000115812\n",
      "[1488]\ttraining's binary_logloss: 0.000115234\n",
      "[1489]\ttraining's binary_logloss: 0.000114673\n",
      "[1490]\ttraining's binary_logloss: 0.000114081\n",
      "[1491]\ttraining's binary_logloss: 0.000113521\n",
      "[1492]\ttraining's binary_logloss: 0.000112948\n",
      "[1493]\ttraining's binary_logloss: 0.000112418\n",
      "[1494]\ttraining's binary_logloss: 0.000111865\n",
      "[1495]\ttraining's binary_logloss: 0.000111241\n",
      "[1496]\ttraining's binary_logloss: 0.000110733\n",
      "[1497]\ttraining's binary_logloss: 0.000110169\n",
      "[1498]\ttraining's binary_logloss: 0.000109617\n",
      "[1499]\ttraining's binary_logloss: 0.000109062\n",
      "[1500]\ttraining's binary_logloss: 0.000108483\n",
      "[1501]\ttraining's binary_logloss: 0.000107955\n",
      "[1502]\ttraining's binary_logloss: 0.000107347\n",
      "[1503]\ttraining's binary_logloss: 0.000106824\n",
      "[1504]\ttraining's binary_logloss: 0.000106264\n",
      "[1505]\ttraining's binary_logloss: 0.000105689\n",
      "[1506]\ttraining's binary_logloss: 0.000105196\n",
      "[1507]\ttraining's binary_logloss: 0.000104699\n",
      "[1508]\ttraining's binary_logloss: 0.000104124\n",
      "[1509]\ttraining's binary_logloss: 0.0001036\n",
      "[1510]\ttraining's binary_logloss: 0.000103087\n",
      "[1511]\ttraining's binary_logloss: 0.000102543\n",
      "[1512]\ttraining's binary_logloss: 0.000102007\n",
      "[1513]\ttraining's binary_logloss: 0.000101465\n",
      "[1514]\ttraining's binary_logloss: 0.000100954\n",
      "[1515]\ttraining's binary_logloss: 0.000100454\n",
      "[1516]\ttraining's binary_logloss: 9.994e-05\n",
      "[1517]\ttraining's binary_logloss: 9.94529e-05\n",
      "[1518]\ttraining's binary_logloss: 9.89235e-05\n",
      "[1519]\ttraining's binary_logloss: 9.84921e-05\n",
      "[1520]\ttraining's binary_logloss: 9.80502e-05\n",
      "[1521]\ttraining's binary_logloss: 9.75681e-05\n",
      "[1522]\ttraining's binary_logloss: 9.70843e-05\n",
      "[1523]\ttraining's binary_logloss: 9.66153e-05\n",
      "[1524]\ttraining's binary_logloss: 9.61773e-05\n",
      "[1525]\ttraining's binary_logloss: 9.56872e-05\n",
      "[1526]\ttraining's binary_logloss: 9.51328e-05\n",
      "[1527]\ttraining's binary_logloss: 9.46809e-05\n",
      "[1528]\ttraining's binary_logloss: 9.41848e-05\n",
      "[1529]\ttraining's binary_logloss: 9.36539e-05\n",
      "[1530]\ttraining's binary_logloss: 9.31733e-05\n",
      "[1531]\ttraining's binary_logloss: 9.26797e-05\n",
      "[1532]\ttraining's binary_logloss: 9.22724e-05\n",
      "[1533]\ttraining's binary_logloss: 9.18479e-05\n",
      "[1534]\ttraining's binary_logloss: 9.14002e-05\n",
      "[1535]\ttraining's binary_logloss: 9.09398e-05\n",
      "[1536]\ttraining's binary_logloss: 9.04543e-05\n",
      "[1537]\ttraining's binary_logloss: 8.99488e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1538]\ttraining's binary_logloss: 8.94799e-05\n",
      "[1539]\ttraining's binary_logloss: 8.90288e-05\n",
      "[1540]\ttraining's binary_logloss: 8.85594e-05\n",
      "[1541]\ttraining's binary_logloss: 8.80982e-05\n",
      "[1542]\ttraining's binary_logloss: 8.76292e-05\n",
      "[1543]\ttraining's binary_logloss: 8.71546e-05\n",
      "[1544]\ttraining's binary_logloss: 8.67583e-05\n",
      "[1545]\ttraining's binary_logloss: 8.62852e-05\n",
      "[1546]\ttraining's binary_logloss: 8.58064e-05\n",
      "[1547]\ttraining's binary_logloss: 8.54152e-05\n",
      "[1548]\ttraining's binary_logloss: 8.49764e-05\n",
      "[1549]\ttraining's binary_logloss: 8.45466e-05\n",
      "[1550]\ttraining's binary_logloss: 8.41101e-05\n",
      "[1551]\ttraining's binary_logloss: 8.36664e-05\n",
      "[1552]\ttraining's binary_logloss: 8.32187e-05\n",
      "[1553]\ttraining's binary_logloss: 8.27706e-05\n",
      "[1554]\ttraining's binary_logloss: 8.23729e-05\n",
      "[1555]\ttraining's binary_logloss: 8.19483e-05\n",
      "[1556]\ttraining's binary_logloss: 8.15124e-05\n",
      "[1557]\ttraining's binary_logloss: 8.10559e-05\n",
      "[1558]\ttraining's binary_logloss: 8.06717e-05\n",
      "[1559]\ttraining's binary_logloss: 8.02224e-05\n",
      "[1560]\ttraining's binary_logloss: 7.98858e-05\n",
      "[1561]\ttraining's binary_logloss: 7.94719e-05\n",
      "[1562]\ttraining's binary_logloss: 7.90864e-05\n",
      "[1563]\ttraining's binary_logloss: 7.86313e-05\n",
      "[1564]\ttraining's binary_logloss: 7.82339e-05\n",
      "[1565]\ttraining's binary_logloss: 7.78358e-05\n",
      "[1566]\ttraining's binary_logloss: 7.73949e-05\n",
      "[1567]\ttraining's binary_logloss: 7.7048e-05\n",
      "[1568]\ttraining's binary_logloss: 7.67064e-05\n",
      "[1569]\ttraining's binary_logloss: 7.63619e-05\n",
      "[1570]\ttraining's binary_logloss: 7.59851e-05\n",
      "[1571]\ttraining's binary_logloss: 7.56649e-05\n",
      "[1572]\ttraining's binary_logloss: 7.53579e-05\n",
      "[1573]\ttraining's binary_logloss: 7.49651e-05\n",
      "[1574]\ttraining's binary_logloss: 7.45972e-05\n",
      "[1575]\ttraining's binary_logloss: 7.42362e-05\n",
      "[1576]\ttraining's binary_logloss: 7.38832e-05\n",
      "[1577]\ttraining's binary_logloss: 7.35467e-05\n",
      "[1578]\ttraining's binary_logloss: 7.31946e-05\n",
      "[1579]\ttraining's binary_logloss: 7.28038e-05\n",
      "[1580]\ttraining's binary_logloss: 7.24163e-05\n",
      "[1581]\ttraining's binary_logloss: 7.2054e-05\n",
      "[1582]\ttraining's binary_logloss: 7.17282e-05\n",
      "[1583]\ttraining's binary_logloss: 7.1355e-05\n",
      "[1584]\ttraining's binary_logloss: 7.10312e-05\n",
      "[1585]\ttraining's binary_logloss: 7.07118e-05\n",
      "[1586]\ttraining's binary_logloss: 7.03584e-05\n",
      "[1587]\ttraining's binary_logloss: 7.0041e-05\n",
      "[1588]\ttraining's binary_logloss: 6.97239e-05\n",
      "[1589]\ttraining's binary_logloss: 6.93862e-05\n",
      "[1590]\ttraining's binary_logloss: 6.90815e-05\n",
      "[1591]\ttraining's binary_logloss: 6.87303e-05\n",
      "[1592]\ttraining's binary_logloss: 6.83973e-05\n",
      "[1593]\ttraining's binary_logloss: 6.80687e-05\n",
      "[1594]\ttraining's binary_logloss: 6.77493e-05\n",
      "[1595]\ttraining's binary_logloss: 6.74693e-05\n",
      "[1596]\ttraining's binary_logloss: 6.71519e-05\n",
      "[1597]\ttraining's binary_logloss: 6.68009e-05\n",
      "[1598]\ttraining's binary_logloss: 6.64706e-05\n",
      "[1599]\ttraining's binary_logloss: 6.61262e-05\n",
      "[1600]\ttraining's binary_logloss: 6.57627e-05\n",
      "[1601]\ttraining's binary_logloss: 6.53855e-05\n",
      "[1602]\ttraining's binary_logloss: 6.5068e-05\n",
      "[1603]\ttraining's binary_logloss: 6.47337e-05\n",
      "[1604]\ttraining's binary_logloss: 6.43819e-05\n",
      "[1605]\ttraining's binary_logloss: 6.41081e-05\n",
      "[1606]\ttraining's binary_logloss: 6.37822e-05\n",
      "[1607]\ttraining's binary_logloss: 6.34583e-05\n",
      "[1608]\ttraining's binary_logloss: 6.31216e-05\n",
      "[1609]\ttraining's binary_logloss: 6.2818e-05\n",
      "[1610]\ttraining's binary_logloss: 6.25219e-05\n",
      "[1611]\ttraining's binary_logloss: 6.22048e-05\n",
      "[1612]\ttraining's binary_logloss: 6.18801e-05\n",
      "[1613]\ttraining's binary_logloss: 6.15837e-05\n",
      "[1614]\ttraining's binary_logloss: 6.13189e-05\n",
      "[1615]\ttraining's binary_logloss: 6.10256e-05\n",
      "[1616]\ttraining's binary_logloss: 6.07411e-05\n",
      "[1617]\ttraining's binary_logloss: 6.04607e-05\n",
      "[1618]\ttraining's binary_logloss: 6.01868e-05\n",
      "[1619]\ttraining's binary_logloss: 5.99112e-05\n",
      "[1620]\ttraining's binary_logloss: 5.96131e-05\n",
      "[1621]\ttraining's binary_logloss: 5.93179e-05\n",
      "[1622]\ttraining's binary_logloss: 5.90243e-05\n",
      "[1623]\ttraining's binary_logloss: 5.87458e-05\n",
      "[1624]\ttraining's binary_logloss: 5.84983e-05\n",
      "[1625]\ttraining's binary_logloss: 5.82039e-05\n",
      "[1626]\ttraining's binary_logloss: 5.79146e-05\n",
      "[1627]\ttraining's binary_logloss: 5.76538e-05\n",
      "[1628]\ttraining's binary_logloss: 5.74091e-05\n",
      "[1629]\ttraining's binary_logloss: 5.71107e-05\n",
      "[1630]\ttraining's binary_logloss: 5.68357e-05\n",
      "[1631]\ttraining's binary_logloss: 5.65673e-05\n",
      "[1632]\ttraining's binary_logloss: 5.63222e-05\n",
      "[1633]\ttraining's binary_logloss: 5.60209e-05\n",
      "[1634]\ttraining's binary_logloss: 5.57301e-05\n",
      "[1635]\ttraining's binary_logloss: 5.54419e-05\n",
      "[1636]\ttraining's binary_logloss: 5.51623e-05\n",
      "[1637]\ttraining's binary_logloss: 5.491e-05\n",
      "[1638]\ttraining's binary_logloss: 5.46434e-05\n",
      "[1639]\ttraining's binary_logloss: 5.43944e-05\n",
      "[1640]\ttraining's binary_logloss: 5.41472e-05\n",
      "[1641]\ttraining's binary_logloss: 5.3909e-05\n",
      "[1642]\ttraining's binary_logloss: 5.36705e-05\n",
      "[1643]\ttraining's binary_logloss: 5.34029e-05\n",
      "[1644]\ttraining's binary_logloss: 5.31555e-05\n",
      "[1645]\ttraining's binary_logloss: 5.2889e-05\n",
      "[1646]\ttraining's binary_logloss: 5.26483e-05\n",
      "[1647]\ttraining's binary_logloss: 5.24041e-05\n",
      "[1648]\ttraining's binary_logloss: 5.21837e-05\n",
      "[1649]\ttraining's binary_logloss: 5.1932e-05\n",
      "[1650]\ttraining's binary_logloss: 5.17041e-05\n",
      "[1651]\ttraining's binary_logloss: 5.14651e-05\n",
      "[1652]\ttraining's binary_logloss: 5.1208e-05\n",
      "[1653]\ttraining's binary_logloss: 5.09736e-05\n",
      "[1654]\ttraining's binary_logloss: 5.07359e-05\n",
      "[1655]\ttraining's binary_logloss: 5.0517e-05\n",
      "[1656]\ttraining's binary_logloss: 5.02859e-05\n",
      "[1657]\ttraining's binary_logloss: 5.00454e-05\n",
      "[1658]\ttraining's binary_logloss: 4.9783e-05\n",
      "[1659]\ttraining's binary_logloss: 4.9534e-05\n",
      "[1660]\ttraining's binary_logloss: 4.93033e-05\n",
      "[1661]\ttraining's binary_logloss: 4.90689e-05\n",
      "[1662]\ttraining's binary_logloss: 4.88568e-05\n",
      "[1663]\ttraining's binary_logloss: 4.86454e-05\n",
      "[1664]\ttraining's binary_logloss: 4.84104e-05\n",
      "[1665]\ttraining's binary_logloss: 4.81902e-05\n",
      "[1666]\ttraining's binary_logloss: 4.79535e-05\n",
      "[1667]\ttraining's binary_logloss: 4.77287e-05\n",
      "[1668]\ttraining's binary_logloss: 4.75054e-05\n",
      "[1669]\ttraining's binary_logloss: 4.72744e-05\n",
      "[1670]\ttraining's binary_logloss: 4.70652e-05\n",
      "[1671]\ttraining's binary_logloss: 4.68335e-05\n",
      "[1672]\ttraining's binary_logloss: 4.66162e-05\n",
      "[1673]\ttraining's binary_logloss: 4.63964e-05\n",
      "[1674]\ttraining's binary_logloss: 4.617e-05\n",
      "[1675]\ttraining's binary_logloss: 4.59547e-05\n",
      "[1676]\ttraining's binary_logloss: 4.57311e-05\n",
      "[1677]\ttraining's binary_logloss: 4.55102e-05\n",
      "[1678]\ttraining's binary_logloss: 4.53011e-05\n",
      "[1679]\ttraining's binary_logloss: 4.50834e-05\n",
      "[1680]\ttraining's binary_logloss: 4.48656e-05\n",
      "[1681]\ttraining's binary_logloss: 4.46644e-05\n",
      "[1682]\ttraining's binary_logloss: 4.44653e-05\n",
      "[1683]\ttraining's binary_logloss: 4.42819e-05\n",
      "[1684]\ttraining's binary_logloss: 4.40805e-05\n",
      "[1685]\ttraining's binary_logloss: 4.38678e-05\n",
      "[1686]\ttraining's binary_logloss: 4.36533e-05\n",
      "[1687]\ttraining's binary_logloss: 4.34631e-05\n",
      "[1688]\ttraining's binary_logloss: 4.3258e-05\n",
      "[1689]\ttraining's binary_logloss: 4.3065e-05\n",
      "[1690]\ttraining's binary_logloss: 4.28689e-05\n",
      "[1691]\ttraining's binary_logloss: 4.2673e-05\n",
      "[1692]\ttraining's binary_logloss: 4.24939e-05\n",
      "[1693]\ttraining's binary_logloss: 4.23127e-05\n",
      "[1694]\ttraining's binary_logloss: 4.21276e-05\n",
      "[1695]\ttraining's binary_logloss: 4.19282e-05\n",
      "[1696]\ttraining's binary_logloss: 4.17401e-05\n",
      "[1697]\ttraining's binary_logloss: 4.15386e-05\n",
      "[1698]\ttraining's binary_logloss: 4.1344e-05\n",
      "[1699]\ttraining's binary_logloss: 4.11486e-05\n",
      "[1700]\ttraining's binary_logloss: 4.09699e-05\n",
      "[1701]\ttraining's binary_logloss: 4.07857e-05\n",
      "[1702]\ttraining's binary_logloss: 4.06068e-05\n",
      "[1703]\ttraining's binary_logloss: 4.04412e-05\n",
      "[1704]\ttraining's binary_logloss: 4.02593e-05\n",
      "[1705]\ttraining's binary_logloss: 4.00825e-05\n",
      "[1706]\ttraining's binary_logloss: 3.98869e-05\n",
      "[1707]\ttraining's binary_logloss: 3.97138e-05\n",
      "[1708]\ttraining's binary_logloss: 3.95458e-05\n",
      "[1709]\ttraining's binary_logloss: 3.93524e-05\n",
      "[1710]\ttraining's binary_logloss: 3.91621e-05\n",
      "[1711]\ttraining's binary_logloss: 3.8994e-05\n",
      "[1712]\ttraining's binary_logloss: 3.88201e-05\n",
      "[1713]\ttraining's binary_logloss: 3.86618e-05\n",
      "[1714]\ttraining's binary_logloss: 3.84953e-05\n",
      "[1715]\ttraining's binary_logloss: 3.83276e-05\n",
      "[1716]\ttraining's binary_logloss: 3.81727e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1717]\ttraining's binary_logloss: 3.80203e-05\n",
      "[1718]\ttraining's binary_logloss: 3.78403e-05\n",
      "[1719]\ttraining's binary_logloss: 3.76746e-05\n",
      "[1720]\ttraining's binary_logloss: 3.75014e-05\n",
      "[1721]\ttraining's binary_logloss: 3.73321e-05\n",
      "[1722]\ttraining's binary_logloss: 3.71639e-05\n",
      "[1723]\ttraining's binary_logloss: 3.70097e-05\n",
      "[1724]\ttraining's binary_logloss: 3.68495e-05\n",
      "[1725]\ttraining's binary_logloss: 3.66983e-05\n",
      "[1726]\ttraining's binary_logloss: 3.65476e-05\n",
      "[1727]\ttraining's binary_logloss: 3.63908e-05\n",
      "[1728]\ttraining's binary_logloss: 3.62517e-05\n",
      "[1729]\ttraining's binary_logloss: 3.61084e-05\n",
      "[1730]\ttraining's binary_logloss: 3.59572e-05\n",
      "[1731]\ttraining's binary_logloss: 3.58027e-05\n",
      "[1732]\ttraining's binary_logloss: 3.56653e-05\n",
      "[1733]\ttraining's binary_logloss: 3.55222e-05\n",
      "[1734]\ttraining's binary_logloss: 3.53647e-05\n",
      "[1735]\ttraining's binary_logloss: 3.52199e-05\n",
      "[1736]\ttraining's binary_logloss: 3.50693e-05\n",
      "[1737]\ttraining's binary_logloss: 3.49055e-05\n",
      "[1738]\ttraining's binary_logloss: 3.47475e-05\n",
      "[1739]\ttraining's binary_logloss: 3.4603e-05\n",
      "[1740]\ttraining's binary_logloss: 3.44613e-05\n",
      "[1741]\ttraining's binary_logloss: 3.43202e-05\n",
      "[1742]\ttraining's binary_logloss: 3.41878e-05\n",
      "[1743]\ttraining's binary_logloss: 3.40477e-05\n",
      "[1744]\ttraining's binary_logloss: 3.3905e-05\n",
      "[1745]\ttraining's binary_logloss: 3.37714e-05\n",
      "[1746]\ttraining's binary_logloss: 3.36381e-05\n",
      "[1747]\ttraining's binary_logloss: 3.35035e-05\n",
      "[1748]\ttraining's binary_logloss: 3.33581e-05\n",
      "[1749]\ttraining's binary_logloss: 3.32248e-05\n",
      "[1750]\ttraining's binary_logloss: 3.30989e-05\n",
      "[1751]\ttraining's binary_logloss: 3.29687e-05\n",
      "[1752]\ttraining's binary_logloss: 3.28361e-05\n",
      "[1753]\ttraining's binary_logloss: 3.26941e-05\n",
      "[1754]\ttraining's binary_logloss: 3.25544e-05\n",
      "[1755]\ttraining's binary_logloss: 3.24268e-05\n",
      "[1756]\ttraining's binary_logloss: 3.22993e-05\n",
      "[1757]\ttraining's binary_logloss: 3.2173e-05\n",
      "[1758]\ttraining's binary_logloss: 3.20468e-05\n",
      "[1759]\ttraining's binary_logloss: 3.1916e-05\n",
      "[1760]\ttraining's binary_logloss: 3.1772e-05\n",
      "[1761]\ttraining's binary_logloss: 3.16439e-05\n",
      "[1762]\ttraining's binary_logloss: 3.15122e-05\n",
      "[1763]\ttraining's binary_logloss: 3.1393e-05\n",
      "[1764]\ttraining's binary_logloss: 3.1264e-05\n",
      "[1765]\ttraining's binary_logloss: 3.11342e-05\n",
      "[1766]\ttraining's binary_logloss: 3.10052e-05\n",
      "[1767]\ttraining's binary_logloss: 3.08804e-05\n",
      "[1768]\ttraining's binary_logloss: 3.07623e-05\n",
      "[1769]\ttraining's binary_logloss: 3.0646e-05\n",
      "[1770]\ttraining's binary_logloss: 3.05275e-05\n",
      "[1771]\ttraining's binary_logloss: 3.04055e-05\n",
      "[1772]\ttraining's binary_logloss: 3.02891e-05\n",
      "[1773]\ttraining's binary_logloss: 3.01723e-05\n",
      "[1774]\ttraining's binary_logloss: 3.00505e-05\n",
      "[1775]\ttraining's binary_logloss: 2.99362e-05\n",
      "[1776]\ttraining's binary_logloss: 2.98251e-05\n",
      "[1777]\ttraining's binary_logloss: 2.97126e-05\n",
      "[1778]\ttraining's binary_logloss: 2.96003e-05\n",
      "[1779]\ttraining's binary_logloss: 2.94811e-05\n",
      "[1780]\ttraining's binary_logloss: 2.93716e-05\n",
      "[1781]\ttraining's binary_logloss: 2.92525e-05\n",
      "[1782]\ttraining's binary_logloss: 2.91403e-05\n",
      "[1783]\ttraining's binary_logloss: 2.90268e-05\n",
      "[1784]\ttraining's binary_logloss: 2.89205e-05\n",
      "[1785]\ttraining's binary_logloss: 2.88018e-05\n",
      "[1786]\ttraining's binary_logloss: 2.8698e-05\n",
      "[1787]\ttraining's binary_logloss: 2.85918e-05\n",
      "[1788]\ttraining's binary_logloss: 2.84813e-05\n",
      "[1789]\ttraining's binary_logloss: 2.83723e-05\n",
      "[1790]\ttraining's binary_logloss: 2.82593e-05\n",
      "[1791]\ttraining's binary_logloss: 2.81501e-05\n",
      "[1792]\ttraining's binary_logloss: 2.80447e-05\n",
      "[1793]\ttraining's binary_logloss: 2.79425e-05\n",
      "[1794]\ttraining's binary_logloss: 2.78394e-05\n",
      "[1795]\ttraining's binary_logloss: 2.77358e-05\n",
      "[1796]\ttraining's binary_logloss: 2.76371e-05\n",
      "[1797]\ttraining's binary_logloss: 2.75361e-05\n",
      "[1798]\ttraining's binary_logloss: 2.74395e-05\n",
      "[1799]\ttraining's binary_logloss: 2.73334e-05\n",
      "[1800]\ttraining's binary_logloss: 2.72305e-05\n",
      "[1801]\ttraining's binary_logloss: 2.71353e-05\n",
      "[1802]\ttraining's binary_logloss: 2.70313e-05\n",
      "[1803]\ttraining's binary_logloss: 2.6933e-05\n",
      "[1804]\ttraining's binary_logloss: 2.68342e-05\n",
      "[1805]\ttraining's binary_logloss: 2.6739e-05\n",
      "[1806]\ttraining's binary_logloss: 2.66416e-05\n",
      "[1807]\ttraining's binary_logloss: 2.65489e-05\n",
      "[1808]\ttraining's binary_logloss: 2.646e-05\n",
      "[1809]\ttraining's binary_logloss: 2.63744e-05\n",
      "[1810]\ttraining's binary_logloss: 2.62839e-05\n",
      "[1811]\ttraining's binary_logloss: 2.61905e-05\n",
      "[1812]\ttraining's binary_logloss: 2.60984e-05\n",
      "[1813]\ttraining's binary_logloss: 2.60123e-05\n",
      "[1814]\ttraining's binary_logloss: 2.59178e-05\n",
      "[1815]\ttraining's binary_logloss: 2.58228e-05\n",
      "[1816]\ttraining's binary_logloss: 2.5737e-05\n",
      "[1817]\ttraining's binary_logloss: 2.56519e-05\n",
      "[1818]\ttraining's binary_logloss: 2.55596e-05\n",
      "[1819]\ttraining's binary_logloss: 2.5467e-05\n",
      "[1820]\ttraining's binary_logloss: 2.53835e-05\n",
      "[1821]\ttraining's binary_logloss: 2.52973e-05\n",
      "[1822]\ttraining's binary_logloss: 2.52081e-05\n",
      "[1823]\ttraining's binary_logloss: 2.51177e-05\n",
      "[1824]\ttraining's binary_logloss: 2.50344e-05\n",
      "[1825]\ttraining's binary_logloss: 2.49434e-05\n",
      "[1826]\ttraining's binary_logloss: 2.48556e-05\n",
      "[1827]\ttraining's binary_logloss: 2.47708e-05\n",
      "[1828]\ttraining's binary_logloss: 2.46866e-05\n",
      "[1829]\ttraining's binary_logloss: 2.45946e-05\n",
      "[1830]\ttraining's binary_logloss: 2.45114e-05\n",
      "[1831]\ttraining's binary_logloss: 2.44307e-05\n",
      "[1832]\ttraining's binary_logloss: 2.43451e-05\n",
      "[1833]\ttraining's binary_logloss: 2.42643e-05\n",
      "[1834]\ttraining's binary_logloss: 2.4183e-05\n",
      "[1835]\ttraining's binary_logloss: 2.40915e-05\n",
      "[1836]\ttraining's binary_logloss: 2.40051e-05\n",
      "[1837]\ttraining's binary_logloss: 2.39241e-05\n",
      "[1838]\ttraining's binary_logloss: 2.38452e-05\n",
      "[1839]\ttraining's binary_logloss: 2.3766e-05\n",
      "[1840]\ttraining's binary_logloss: 2.36827e-05\n",
      "[1841]\ttraining's binary_logloss: 2.35998e-05\n",
      "[1842]\ttraining's binary_logloss: 2.35261e-05\n",
      "[1843]\ttraining's binary_logloss: 2.34484e-05\n",
      "[1844]\ttraining's binary_logloss: 2.33781e-05\n",
      "[1845]\ttraining's binary_logloss: 2.33041e-05\n",
      "[1846]\ttraining's binary_logloss: 2.32278e-05\n",
      "[1847]\ttraining's binary_logloss: 2.31515e-05\n",
      "[1848]\ttraining's binary_logloss: 2.30704e-05\n",
      "[1849]\ttraining's binary_logloss: 2.29974e-05\n",
      "[1850]\ttraining's binary_logloss: 2.29264e-05\n",
      "[1851]\ttraining's binary_logloss: 2.28532e-05\n",
      "[1852]\ttraining's binary_logloss: 2.27819e-05\n",
      "[1853]\ttraining's binary_logloss: 2.27119e-05\n",
      "[1854]\ttraining's binary_logloss: 2.26417e-05\n",
      "[1855]\ttraining's binary_logloss: 2.25672e-05\n",
      "[1856]\ttraining's binary_logloss: 2.2499e-05\n",
      "[1857]\ttraining's binary_logloss: 2.24314e-05\n",
      "[1858]\ttraining's binary_logloss: 2.23632e-05\n",
      "[1859]\ttraining's binary_logloss: 2.22916e-05\n",
      "[1860]\ttraining's binary_logloss: 2.22235e-05\n",
      "[1861]\ttraining's binary_logloss: 2.21595e-05\n",
      "[1862]\ttraining's binary_logloss: 2.20911e-05\n",
      "[1863]\ttraining's binary_logloss: 2.20247e-05\n",
      "[1864]\ttraining's binary_logloss: 2.19545e-05\n",
      "[1865]\ttraining's binary_logloss: 2.18922e-05\n",
      "[1866]\ttraining's binary_logloss: 2.18181e-05\n",
      "[1867]\ttraining's binary_logloss: 2.17536e-05\n",
      "[1868]\ttraining's binary_logloss: 2.16868e-05\n",
      "[1869]\ttraining's binary_logloss: 2.16211e-05\n",
      "[1870]\ttraining's binary_logloss: 2.15565e-05\n",
      "[1871]\ttraining's binary_logloss: 2.14922e-05\n",
      "[1872]\ttraining's binary_logloss: 2.14243e-05\n",
      "[1873]\ttraining's binary_logloss: 2.13598e-05\n",
      "[1874]\ttraining's binary_logloss: 2.12953e-05\n",
      "[1875]\ttraining's binary_logloss: 2.12319e-05\n",
      "[1876]\ttraining's binary_logloss: 2.11793e-05\n",
      "[1877]\ttraining's binary_logloss: 2.11181e-05\n",
      "[1878]\ttraining's binary_logloss: 2.10544e-05\n",
      "[1879]\ttraining's binary_logloss: 2.09921e-05\n",
      "[1880]\ttraining's binary_logloss: 2.0929e-05\n",
      "[1881]\ttraining's binary_logloss: 2.08727e-05\n",
      "[1882]\ttraining's binary_logloss: 2.08071e-05\n",
      "[1883]\ttraining's binary_logloss: 2.07479e-05\n",
      "[1884]\ttraining's binary_logloss: 2.06872e-05\n",
      "[1885]\ttraining's binary_logloss: 2.06263e-05\n",
      "[1886]\ttraining's binary_logloss: 2.05618e-05\n",
      "[1887]\ttraining's binary_logloss: 2.04979e-05\n",
      "[1888]\ttraining's binary_logloss: 2.04319e-05\n",
      "[1889]\ttraining's binary_logloss: 2.03697e-05\n",
      "[1890]\ttraining's binary_logloss: 2.03114e-05\n",
      "[1891]\ttraining's binary_logloss: 2.02563e-05\n",
      "[1892]\ttraining's binary_logloss: 2.02016e-05\n",
      "[1893]\ttraining's binary_logloss: 2.01501e-05\n",
      "[1894]\ttraining's binary_logloss: 2.00909e-05\n",
      "[1895]\ttraining's binary_logloss: 2.00355e-05\n",
      "[1896]\ttraining's binary_logloss: 1.99766e-05\n",
      "[1897]\ttraining's binary_logloss: 1.99217e-05\n",
      "[1898]\ttraining's binary_logloss: 1.98642e-05\n",
      "[1899]\ttraining's binary_logloss: 1.98096e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1900]\ttraining's binary_logloss: 1.97578e-05\n",
      "[1901]\ttraining's binary_logloss: 1.96994e-05\n",
      "[1902]\ttraining's binary_logloss: 1.96502e-05\n",
      "[1903]\ttraining's binary_logloss: 1.95908e-05\n",
      "[1904]\ttraining's binary_logloss: 1.95347e-05\n",
      "[1905]\ttraining's binary_logloss: 1.94796e-05\n",
      "[1906]\ttraining's binary_logloss: 1.94232e-05\n",
      "[1907]\ttraining's binary_logloss: 1.9369e-05\n",
      "[1908]\ttraining's binary_logloss: 1.93116e-05\n",
      "[1909]\ttraining's binary_logloss: 1.92561e-05\n",
      "[1910]\ttraining's binary_logloss: 1.92012e-05\n",
      "[1911]\ttraining's binary_logloss: 1.91506e-05\n",
      "[1912]\ttraining's binary_logloss: 1.90975e-05\n",
      "[1913]\ttraining's binary_logloss: 1.90464e-05\n",
      "[1914]\ttraining's binary_logloss: 1.89908e-05\n",
      "[1915]\ttraining's binary_logloss: 1.89452e-05\n",
      "[1916]\ttraining's binary_logloss: 1.88943e-05\n",
      "[1917]\ttraining's binary_logloss: 1.88466e-05\n",
      "[1918]\ttraining's binary_logloss: 1.87987e-05\n",
      "[1919]\ttraining's binary_logloss: 1.87478e-05\n",
      "[1920]\ttraining's binary_logloss: 1.8698e-05\n",
      "[1921]\ttraining's binary_logloss: 1.8649e-05\n",
      "[1922]\ttraining's binary_logloss: 1.86005e-05\n",
      "[1923]\ttraining's binary_logloss: 1.85488e-05\n",
      "[1924]\ttraining's binary_logloss: 1.85016e-05\n",
      "[1925]\ttraining's binary_logloss: 1.84507e-05\n",
      "[1926]\ttraining's binary_logloss: 1.8404e-05\n",
      "[1927]\ttraining's binary_logloss: 1.835e-05\n",
      "[1928]\ttraining's binary_logloss: 1.83019e-05\n",
      "[1929]\ttraining's binary_logloss: 1.82513e-05\n",
      "[1930]\ttraining's binary_logloss: 1.82103e-05\n",
      "[1931]\ttraining's binary_logloss: 1.81654e-05\n",
      "[1932]\ttraining's binary_logloss: 1.81197e-05\n",
      "[1933]\ttraining's binary_logloss: 1.80716e-05\n",
      "[1934]\ttraining's binary_logloss: 1.80243e-05\n",
      "[1935]\ttraining's binary_logloss: 1.79808e-05\n",
      "[1936]\ttraining's binary_logloss: 1.79341e-05\n",
      "[1937]\ttraining's binary_logloss: 1.7882e-05\n",
      "[1938]\ttraining's binary_logloss: 1.78358e-05\n",
      "[1939]\ttraining's binary_logloss: 1.77937e-05\n",
      "[1940]\ttraining's binary_logloss: 1.77529e-05\n",
      "[1941]\ttraining's binary_logloss: 1.77104e-05\n",
      "[1942]\ttraining's binary_logloss: 1.76632e-05\n",
      "[1943]\ttraining's binary_logloss: 1.76178e-05\n",
      "[1944]\ttraining's binary_logloss: 1.75751e-05\n",
      "[1945]\ttraining's binary_logloss: 1.75282e-05\n",
      "[1946]\ttraining's binary_logloss: 1.74826e-05\n",
      "[1947]\ttraining's binary_logloss: 1.74365e-05\n",
      "[1948]\ttraining's binary_logloss: 1.73946e-05\n",
      "[1949]\ttraining's binary_logloss: 1.73525e-05\n",
      "[1950]\ttraining's binary_logloss: 1.7307e-05\n",
      "[1951]\ttraining's binary_logloss: 1.72637e-05\n",
      "[1952]\ttraining's binary_logloss: 1.72185e-05\n",
      "[1953]\ttraining's binary_logloss: 1.71778e-05\n",
      "[1954]\ttraining's binary_logloss: 1.7135e-05\n",
      "[1955]\ttraining's binary_logloss: 1.70974e-05\n",
      "[1956]\ttraining's binary_logloss: 1.70577e-05\n",
      "[1957]\ttraining's binary_logloss: 1.7015e-05\n",
      "[1958]\ttraining's binary_logloss: 1.69729e-05\n",
      "[1959]\ttraining's binary_logloss: 1.69323e-05\n",
      "[1960]\ttraining's binary_logloss: 1.68913e-05\n",
      "[1961]\ttraining's binary_logloss: 1.68518e-05\n",
      "[1962]\ttraining's binary_logloss: 1.68091e-05\n",
      "[1963]\ttraining's binary_logloss: 1.6769e-05\n",
      "[1964]\ttraining's binary_logloss: 1.67308e-05\n",
      "[1965]\ttraining's binary_logloss: 1.66907e-05\n",
      "[1966]\ttraining's binary_logloss: 1.66524e-05\n",
      "[1967]\ttraining's binary_logloss: 1.66107e-05\n",
      "[1968]\ttraining's binary_logloss: 1.65691e-05\n",
      "[1969]\ttraining's binary_logloss: 1.65296e-05\n",
      "[1970]\ttraining's binary_logloss: 1.64871e-05\n",
      "[1971]\ttraining's binary_logloss: 1.64491e-05\n",
      "[1972]\ttraining's binary_logloss: 1.64107e-05\n",
      "[1973]\ttraining's binary_logloss: 1.63712e-05\n",
      "[1974]\ttraining's binary_logloss: 1.63312e-05\n",
      "[1975]\ttraining's binary_logloss: 1.62945e-05\n",
      "[1976]\ttraining's binary_logloss: 1.62587e-05\n",
      "[1977]\ttraining's binary_logloss: 1.62241e-05\n",
      "[1978]\ttraining's binary_logloss: 1.61913e-05\n",
      "[1979]\ttraining's binary_logloss: 1.61523e-05\n",
      "[1980]\ttraining's binary_logloss: 1.61196e-05\n",
      "[1981]\ttraining's binary_logloss: 1.60792e-05\n",
      "[1982]\ttraining's binary_logloss: 1.60427e-05\n",
      "[1983]\ttraining's binary_logloss: 1.60071e-05\n",
      "[1984]\ttraining's binary_logloss: 1.59739e-05\n",
      "[1985]\ttraining's binary_logloss: 1.59382e-05\n",
      "[1986]\ttraining's binary_logloss: 1.59011e-05\n",
      "[1987]\ttraining's binary_logloss: 1.58651e-05\n",
      "[1988]\ttraining's binary_logloss: 1.58285e-05\n",
      "[1989]\ttraining's binary_logloss: 1.57929e-05\n",
      "[1990]\ttraining's binary_logloss: 1.57573e-05\n",
      "[1991]\ttraining's binary_logloss: 1.57208e-05\n",
      "[1992]\ttraining's binary_logloss: 1.56852e-05\n",
      "[1993]\ttraining's binary_logloss: 1.56515e-05\n",
      "[1994]\ttraining's binary_logloss: 1.56211e-05\n",
      "[1995]\ttraining's binary_logloss: 1.55898e-05\n",
      "[1996]\ttraining's binary_logloss: 1.55568e-05\n",
      "[1997]\ttraining's binary_logloss: 1.55248e-05\n",
      "[1998]\ttraining's binary_logloss: 1.54876e-05\n",
      "[1999]\ttraining's binary_logloss: 1.54509e-05\n",
      "[2000]\ttraining's binary_logloss: 1.54168e-05\n",
      "[2001]\ttraining's binary_logloss: 1.53837e-05\n",
      "[2002]\ttraining's binary_logloss: 1.53516e-05\n",
      "[2003]\ttraining's binary_logloss: 1.53176e-05\n",
      "[2004]\ttraining's binary_logloss: 1.52797e-05\n",
      "[2005]\ttraining's binary_logloss: 1.52441e-05\n",
      "[2006]\ttraining's binary_logloss: 1.52102e-05\n",
      "[2007]\ttraining's binary_logloss: 1.51767e-05\n",
      "[2008]\ttraining's binary_logloss: 1.51433e-05\n",
      "[2009]\ttraining's binary_logloss: 1.51136e-05\n",
      "[2010]\ttraining's binary_logloss: 1.50843e-05\n",
      "[2011]\ttraining's binary_logloss: 1.50545e-05\n",
      "[2012]\ttraining's binary_logloss: 1.50217e-05\n",
      "[2013]\ttraining's binary_logloss: 1.49919e-05\n",
      "[2014]\ttraining's binary_logloss: 1.49605e-05\n",
      "[2015]\ttraining's binary_logloss: 1.49295e-05\n",
      "[2016]\ttraining's binary_logloss: 1.48984e-05\n",
      "[2017]\ttraining's binary_logloss: 1.48667e-05\n",
      "[2018]\ttraining's binary_logloss: 1.48354e-05\n",
      "[2019]\ttraining's binary_logloss: 1.48049e-05\n",
      "[2020]\ttraining's binary_logloss: 1.47742e-05\n",
      "[2021]\ttraining's binary_logloss: 1.47397e-05\n",
      "[2022]\ttraining's binary_logloss: 1.47105e-05\n",
      "[2023]\ttraining's binary_logloss: 1.46797e-05\n",
      "[2024]\ttraining's binary_logloss: 1.46508e-05\n",
      "[2025]\ttraining's binary_logloss: 1.46187e-05\n",
      "[2026]\ttraining's binary_logloss: 1.45888e-05\n",
      "[2027]\ttraining's binary_logloss: 1.45615e-05\n",
      "[2028]\ttraining's binary_logloss: 1.45303e-05\n",
      "[2029]\ttraining's binary_logloss: 1.45e-05\n",
      "[2030]\ttraining's binary_logloss: 1.44704e-05\n",
      "[2031]\ttraining's binary_logloss: 1.44434e-05\n",
      "[2032]\ttraining's binary_logloss: 1.44156e-05\n",
      "[2033]\ttraining's binary_logloss: 1.43853e-05\n",
      "[2034]\ttraining's binary_logloss: 1.43564e-05\n",
      "[2035]\ttraining's binary_logloss: 1.4327e-05\n",
      "[2036]\ttraining's binary_logloss: 1.42978e-05\n",
      "[2037]\ttraining's binary_logloss: 1.42701e-05\n",
      "[2038]\ttraining's binary_logloss: 1.42385e-05\n",
      "[2039]\ttraining's binary_logloss: 1.42069e-05\n",
      "[2040]\ttraining's binary_logloss: 1.41778e-05\n",
      "[2041]\ttraining's binary_logloss: 1.41481e-05\n",
      "[2042]\ttraining's binary_logloss: 1.41182e-05\n",
      "[2043]\ttraining's binary_logloss: 1.40903e-05\n",
      "[2044]\ttraining's binary_logloss: 1.40625e-05\n",
      "[2045]\ttraining's binary_logloss: 1.40352e-05\n",
      "[2046]\ttraining's binary_logloss: 1.40085e-05\n",
      "[2047]\ttraining's binary_logloss: 1.39835e-05\n",
      "[2048]\ttraining's binary_logloss: 1.39557e-05\n",
      "[2049]\ttraining's binary_logloss: 1.39285e-05\n",
      "[2050]\ttraining's binary_logloss: 1.39004e-05\n",
      "[2051]\ttraining's binary_logloss: 1.38715e-05\n",
      "[2052]\ttraining's binary_logloss: 1.38471e-05\n",
      "[2053]\ttraining's binary_logloss: 1.3818e-05\n",
      "[2054]\ttraining's binary_logloss: 1.37916e-05\n",
      "[2055]\ttraining's binary_logloss: 1.37656e-05\n",
      "[2056]\ttraining's binary_logloss: 1.3738e-05\n",
      "[2057]\ttraining's binary_logloss: 1.37111e-05\n",
      "[2058]\ttraining's binary_logloss: 1.36825e-05\n",
      "[2059]\ttraining's binary_logloss: 1.36559e-05\n",
      "[2060]\ttraining's binary_logloss: 1.36285e-05\n",
      "[2061]\ttraining's binary_logloss: 1.3604e-05\n",
      "[2062]\ttraining's binary_logloss: 1.35798e-05\n",
      "[2063]\ttraining's binary_logloss: 1.35519e-05\n",
      "[2064]\ttraining's binary_logloss: 1.35259e-05\n",
      "[2065]\ttraining's binary_logloss: 1.35021e-05\n",
      "[2066]\ttraining's binary_logloss: 1.34764e-05\n",
      "[2067]\ttraining's binary_logloss: 1.34542e-05\n",
      "[2068]\ttraining's binary_logloss: 1.34295e-05\n",
      "[2069]\ttraining's binary_logloss: 1.34037e-05\n",
      "[2070]\ttraining's binary_logloss: 1.33799e-05\n",
      "[2071]\ttraining's binary_logloss: 1.33578e-05\n",
      "[2072]\ttraining's binary_logloss: 1.33354e-05\n",
      "[2073]\ttraining's binary_logloss: 1.33123e-05\n",
      "[2074]\ttraining's binary_logloss: 1.32887e-05\n",
      "[2075]\ttraining's binary_logloss: 1.3261e-05\n",
      "[2076]\ttraining's binary_logloss: 1.32393e-05\n",
      "[2077]\ttraining's binary_logloss: 1.32146e-05\n",
      "[2078]\ttraining's binary_logloss: 1.31882e-05\n",
      "[2079]\ttraining's binary_logloss: 1.3164e-05\n",
      "[2080]\ttraining's binary_logloss: 1.31403e-05\n",
      "[2081]\ttraining's binary_logloss: 1.31169e-05\n",
      "[2082]\ttraining's binary_logloss: 1.30909e-05\n",
      "[2083]\ttraining's binary_logloss: 1.30687e-05\n",
      "[2084]\ttraining's binary_logloss: 1.30444e-05\n",
      "[2085]\ttraining's binary_logloss: 1.30221e-05\n",
      "[2086]\ttraining's binary_logloss: 1.29996e-05\n",
      "[2087]\ttraining's binary_logloss: 1.2976e-05\n",
      "[2088]\ttraining's binary_logloss: 1.29517e-05\n",
      "[2089]\ttraining's binary_logloss: 1.29278e-05\n",
      "[2090]\ttraining's binary_logloss: 1.2905e-05\n",
      "[2091]\ttraining's binary_logloss: 1.28799e-05\n",
      "[2092]\ttraining's binary_logloss: 1.28584e-05\n",
      "[2093]\ttraining's binary_logloss: 1.28349e-05\n",
      "[2094]\ttraining's binary_logloss: 1.28118e-05\n",
      "[2095]\ttraining's binary_logloss: 1.27891e-05\n",
      "[2096]\ttraining's binary_logloss: 1.27655e-05\n",
      "[2097]\ttraining's binary_logloss: 1.27439e-05\n",
      "[2098]\ttraining's binary_logloss: 1.27215e-05\n",
      "[2099]\ttraining's binary_logloss: 1.26988e-05\n",
      "[2100]\ttraining's binary_logloss: 1.26768e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2101]\ttraining's binary_logloss: 1.26542e-05\n",
      "[2102]\ttraining's binary_logloss: 1.26324e-05\n",
      "[2103]\ttraining's binary_logloss: 1.26119e-05\n",
      "[2104]\ttraining's binary_logloss: 1.25916e-05\n",
      "[2105]\ttraining's binary_logloss: 1.2567e-05\n",
      "[2106]\ttraining's binary_logloss: 1.25456e-05\n",
      "[2107]\ttraining's binary_logloss: 1.25208e-05\n",
      "[2108]\ttraining's binary_logloss: 1.24997e-05\n",
      "[2109]\ttraining's binary_logloss: 1.24785e-05\n",
      "[2110]\ttraining's binary_logloss: 1.24564e-05\n",
      "[2111]\ttraining's binary_logloss: 1.24358e-05\n",
      "[2112]\ttraining's binary_logloss: 1.24135e-05\n",
      "[2113]\ttraining's binary_logloss: 1.23934e-05\n",
      "[2114]\ttraining's binary_logloss: 1.23718e-05\n",
      "[2115]\ttraining's binary_logloss: 1.23514e-05\n",
      "[2116]\ttraining's binary_logloss: 1.23306e-05\n",
      "[2117]\ttraining's binary_logloss: 1.23066e-05\n",
      "[2118]\ttraining's binary_logloss: 1.22856e-05\n",
      "[2119]\ttraining's binary_logloss: 1.2267e-05\n",
      "[2120]\ttraining's binary_logloss: 1.22439e-05\n",
      "[2121]\ttraining's binary_logloss: 1.22219e-05\n",
      "[2122]\ttraining's binary_logloss: 1.22007e-05\n",
      "[2123]\ttraining's binary_logloss: 1.21793e-05\n",
      "[2124]\ttraining's binary_logloss: 1.21607e-05\n",
      "[2125]\ttraining's binary_logloss: 1.21387e-05\n",
      "[2126]\ttraining's binary_logloss: 1.21191e-05\n",
      "[2127]\ttraining's binary_logloss: 1.20976e-05\n",
      "[2128]\ttraining's binary_logloss: 1.20758e-05\n",
      "[2129]\ttraining's binary_logloss: 1.20569e-05\n",
      "[2130]\ttraining's binary_logloss: 1.20367e-05\n",
      "[2131]\ttraining's binary_logloss: 1.20164e-05\n",
      "[2132]\ttraining's binary_logloss: 1.19957e-05\n",
      "[2133]\ttraining's binary_logloss: 1.19767e-05\n",
      "[2134]\ttraining's binary_logloss: 1.19587e-05\n",
      "[2135]\ttraining's binary_logloss: 1.19391e-05\n",
      "[2136]\ttraining's binary_logloss: 1.19193e-05\n",
      "[2137]\ttraining's binary_logloss: 1.1901e-05\n",
      "[2138]\ttraining's binary_logloss: 1.18806e-05\n",
      "[2139]\ttraining's binary_logloss: 1.18581e-05\n",
      "[2140]\ttraining's binary_logloss: 1.184e-05\n",
      "[2141]\ttraining's binary_logloss: 1.18208e-05\n",
      "[2142]\ttraining's binary_logloss: 1.18028e-05\n",
      "[2143]\ttraining's binary_logloss: 1.17829e-05\n",
      "[2144]\ttraining's binary_logloss: 1.17629e-05\n",
      "[2145]\ttraining's binary_logloss: 1.1741e-05\n",
      "[2146]\ttraining's binary_logloss: 1.17201e-05\n",
      "[2147]\ttraining's binary_logloss: 1.17017e-05\n",
      "[2148]\ttraining's binary_logloss: 1.16844e-05\n",
      "[2149]\ttraining's binary_logloss: 1.16642e-05\n",
      "[2150]\ttraining's binary_logloss: 1.16454e-05\n",
      "[2151]\ttraining's binary_logloss: 1.16273e-05\n",
      "[2152]\ttraining's binary_logloss: 1.16092e-05\n",
      "[2153]\ttraining's binary_logloss: 1.15897e-05\n",
      "[2154]\ttraining's binary_logloss: 1.15715e-05\n",
      "[2155]\ttraining's binary_logloss: 1.15536e-05\n",
      "[2156]\ttraining's binary_logloss: 1.15356e-05\n",
      "[2157]\ttraining's binary_logloss: 1.1521e-05\n",
      "[2158]\ttraining's binary_logloss: 1.15056e-05\n",
      "[2159]\ttraining's binary_logloss: 1.14866e-05\n",
      "[2160]\ttraining's binary_logloss: 1.14691e-05\n",
      "[2161]\ttraining's binary_logloss: 1.1452e-05\n",
      "[2162]\ttraining's binary_logloss: 1.14351e-05\n",
      "[2163]\ttraining's binary_logloss: 1.14174e-05\n",
      "[2164]\ttraining's binary_logloss: 1.13983e-05\n",
      "[2165]\ttraining's binary_logloss: 1.13803e-05\n",
      "[2166]\ttraining's binary_logloss: 1.13626e-05\n",
      "[2167]\ttraining's binary_logloss: 1.13441e-05\n",
      "[2168]\ttraining's binary_logloss: 1.13283e-05\n",
      "[2169]\ttraining's binary_logloss: 1.131e-05\n",
      "[2170]\ttraining's binary_logloss: 1.12903e-05\n",
      "[2171]\ttraining's binary_logloss: 1.12712e-05\n",
      "[2172]\ttraining's binary_logloss: 1.12551e-05\n",
      "[2173]\ttraining's binary_logloss: 1.12391e-05\n",
      "[2174]\ttraining's binary_logloss: 1.12209e-05\n",
      "[2175]\ttraining's binary_logloss: 1.12033e-05\n",
      "[2176]\ttraining's binary_logloss: 1.11871e-05\n",
      "[2177]\ttraining's binary_logloss: 1.11704e-05\n",
      "[2178]\ttraining's binary_logloss: 1.11531e-05\n",
      "[2179]\ttraining's binary_logloss: 1.11373e-05\n",
      "[2180]\ttraining's binary_logloss: 1.112e-05\n",
      "[2181]\ttraining's binary_logloss: 1.11013e-05\n",
      "[2182]\ttraining's binary_logloss: 1.1085e-05\n",
      "[2183]\ttraining's binary_logloss: 1.10659e-05\n",
      "[2184]\ttraining's binary_logloss: 1.1048e-05\n",
      "[2185]\ttraining's binary_logloss: 1.103e-05\n",
      "[2186]\ttraining's binary_logloss: 1.10133e-05\n",
      "[2187]\ttraining's binary_logloss: 1.09977e-05\n",
      "[2188]\ttraining's binary_logloss: 1.09809e-05\n",
      "[2189]\ttraining's binary_logloss: 1.09629e-05\n",
      "[2190]\ttraining's binary_logloss: 1.09459e-05\n",
      "[2191]\ttraining's binary_logloss: 1.09303e-05\n",
      "[2192]\ttraining's binary_logloss: 1.09144e-05\n",
      "[2193]\ttraining's binary_logloss: 1.09004e-05\n",
      "[2194]\ttraining's binary_logloss: 1.08853e-05\n",
      "[2195]\ttraining's binary_logloss: 1.08693e-05\n",
      "[2196]\ttraining's binary_logloss: 1.08547e-05\n",
      "[2197]\ttraining's binary_logloss: 1.08386e-05\n",
      "[2198]\ttraining's binary_logloss: 1.08225e-05\n",
      "[2199]\ttraining's binary_logloss: 1.08077e-05\n",
      "[2200]\ttraining's binary_logloss: 1.07914e-05\n",
      "[2201]\ttraining's binary_logloss: 1.07769e-05\n",
      "[2202]\ttraining's binary_logloss: 1.07622e-05\n",
      "[2203]\ttraining's binary_logloss: 1.07462e-05\n",
      "[2204]\ttraining's binary_logloss: 1.07298e-05\n",
      "[2205]\ttraining's binary_logloss: 1.07133e-05\n",
      "[2206]\ttraining's binary_logloss: 1.06986e-05\n",
      "[2207]\ttraining's binary_logloss: 1.06817e-05\n",
      "[2208]\ttraining's binary_logloss: 1.06674e-05\n",
      "[2209]\ttraining's binary_logloss: 1.06526e-05\n",
      "[2210]\ttraining's binary_logloss: 1.06351e-05\n",
      "[2211]\ttraining's binary_logloss: 1.06201e-05\n",
      "[2212]\ttraining's binary_logloss: 1.06039e-05\n",
      "[2213]\ttraining's binary_logloss: 1.05889e-05\n",
      "[2214]\ttraining's binary_logloss: 1.05745e-05\n",
      "[2215]\ttraining's binary_logloss: 1.05594e-05\n",
      "[2216]\ttraining's binary_logloss: 1.05447e-05\n",
      "[2217]\ttraining's binary_logloss: 1.05321e-05\n",
      "[2218]\ttraining's binary_logloss: 1.05179e-05\n",
      "[2219]\ttraining's binary_logloss: 1.05042e-05\n",
      "[2220]\ttraining's binary_logloss: 1.04896e-05\n",
      "[2221]\ttraining's binary_logloss: 1.04741e-05\n",
      "[2222]\ttraining's binary_logloss: 1.04586e-05\n",
      "[2223]\ttraining's binary_logloss: 1.0446e-05\n",
      "[2224]\ttraining's binary_logloss: 1.04301e-05\n",
      "[2225]\ttraining's binary_logloss: 1.04152e-05\n",
      "[2226]\ttraining's binary_logloss: 1.04009e-05\n",
      "[2227]\ttraining's binary_logloss: 1.0386e-05\n",
      "[2228]\ttraining's binary_logloss: 1.03717e-05\n",
      "[2229]\ttraining's binary_logloss: 1.0357e-05\n",
      "[2230]\ttraining's binary_logloss: 1.0341e-05\n",
      "[2231]\ttraining's binary_logloss: 1.03276e-05\n",
      "[2232]\ttraining's binary_logloss: 1.0315e-05\n",
      "[2233]\ttraining's binary_logloss: 1.03009e-05\n",
      "[2234]\ttraining's binary_logloss: 1.0287e-05\n",
      "[2235]\ttraining's binary_logloss: 1.02726e-05\n",
      "[2236]\ttraining's binary_logloss: 1.02594e-05\n",
      "[2237]\ttraining's binary_logloss: 1.02457e-05\n",
      "[2238]\ttraining's binary_logloss: 1.02334e-05\n",
      "[2239]\ttraining's binary_logloss: 1.0219e-05\n",
      "[2240]\ttraining's binary_logloss: 1.02046e-05\n",
      "[2241]\ttraining's binary_logloss: 1.01913e-05\n",
      "[2242]\ttraining's binary_logloss: 1.01777e-05\n",
      "[2243]\ttraining's binary_logloss: 1.01638e-05\n",
      "[2244]\ttraining's binary_logloss: 1.01491e-05\n",
      "[2245]\ttraining's binary_logloss: 1.01365e-05\n",
      "[2246]\ttraining's binary_logloss: 1.01236e-05\n",
      "[2247]\ttraining's binary_logloss: 1.01103e-05\n",
      "[2248]\ttraining's binary_logloss: 1.00948e-05\n",
      "[2249]\ttraining's binary_logloss: 1.008e-05\n",
      "[2250]\ttraining's binary_logloss: 1.00674e-05\n",
      "[2251]\ttraining's binary_logloss: 1.00548e-05\n",
      "[2252]\ttraining's binary_logloss: 1.00398e-05\n",
      "[2253]\ttraining's binary_logloss: 1.00273e-05\n",
      "[2254]\ttraining's binary_logloss: 1.00129e-05\n",
      "[2255]\ttraining's binary_logloss: 1.00006e-05\n",
      "[2256]\ttraining's binary_logloss: 9.98794e-06\n",
      "[2257]\ttraining's binary_logloss: 9.97228e-06\n",
      "[2258]\ttraining's binary_logloss: 9.95888e-06\n",
      "[2259]\ttraining's binary_logloss: 9.94502e-06\n",
      "[2260]\ttraining's binary_logloss: 9.93292e-06\n",
      "[2261]\ttraining's binary_logloss: 9.91957e-06\n",
      "[2262]\ttraining's binary_logloss: 9.90725e-06\n",
      "[2263]\ttraining's binary_logloss: 9.89288e-06\n",
      "[2264]\ttraining's binary_logloss: 9.87936e-06\n",
      "[2265]\ttraining's binary_logloss: 9.86625e-06\n",
      "[2266]\ttraining's binary_logloss: 9.85351e-06\n",
      "[2267]\ttraining's binary_logloss: 9.83967e-06\n",
      "[2268]\ttraining's binary_logloss: 9.8263e-06\n",
      "[2269]\ttraining's binary_logloss: 9.81389e-06\n",
      "[2270]\ttraining's binary_logloss: 9.80262e-06\n",
      "[2271]\ttraining's binary_logloss: 9.78995e-06\n",
      "[2272]\ttraining's binary_logloss: 9.77657e-06\n",
      "[2273]\ttraining's binary_logloss: 9.7647e-06\n",
      "[2274]\ttraining's binary_logloss: 9.75302e-06\n",
      "[2275]\ttraining's binary_logloss: 9.74069e-06\n",
      "[2276]\ttraining's binary_logloss: 9.729e-06\n",
      "[2277]\ttraining's binary_logloss: 9.71722e-06\n",
      "[2278]\ttraining's binary_logloss: 9.70409e-06\n",
      "[2279]\ttraining's binary_logloss: 9.69117e-06\n",
      "[2280]\ttraining's binary_logloss: 9.67919e-06\n",
      "[2281]\ttraining's binary_logloss: 9.66686e-06\n",
      "[2282]\ttraining's binary_logloss: 9.65541e-06\n",
      "[2283]\ttraining's binary_logloss: 9.64324e-06\n",
      "[2284]\ttraining's binary_logloss: 9.63244e-06\n",
      "[2285]\ttraining's binary_logloss: 9.62211e-06\n",
      "[2286]\ttraining's binary_logloss: 9.60867e-06\n",
      "[2287]\ttraining's binary_logloss: 9.59719e-06\n",
      "[2288]\ttraining's binary_logloss: 9.58486e-06\n",
      "[2289]\ttraining's binary_logloss: 9.57284e-06\n",
      "[2290]\ttraining's binary_logloss: 9.56056e-06\n",
      "[2291]\ttraining's binary_logloss: 9.54657e-06\n",
      "[2292]\ttraining's binary_logloss: 9.53537e-06\n",
      "[2293]\ttraining's binary_logloss: 9.52327e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2294]\ttraining's binary_logloss: 9.50943e-06\n",
      "[2295]\ttraining's binary_logloss: 9.49631e-06\n",
      "[2296]\ttraining's binary_logloss: 9.48588e-06\n",
      "[2297]\ttraining's binary_logloss: 9.4747e-06\n",
      "[2298]\ttraining's binary_logloss: 9.46329e-06\n",
      "[2299]\ttraining's binary_logloss: 9.45104e-06\n",
      "[2300]\ttraining's binary_logloss: 9.43806e-06\n",
      "[2301]\ttraining's binary_logloss: 9.42582e-06\n",
      "[2302]\ttraining's binary_logloss: 9.41329e-06\n",
      "[2303]\ttraining's binary_logloss: 9.40338e-06\n",
      "[2304]\ttraining's binary_logloss: 9.38973e-06\n",
      "[2305]\ttraining's binary_logloss: 9.37886e-06\n",
      "[2306]\ttraining's binary_logloss: 9.36853e-06\n",
      "[2307]\ttraining's binary_logloss: 9.35698e-06\n",
      "[2308]\ttraining's binary_logloss: 9.34461e-06\n",
      "[2309]\ttraining's binary_logloss: 9.33314e-06\n",
      "[2310]\ttraining's binary_logloss: 9.32256e-06\n",
      "[2311]\ttraining's binary_logloss: 9.31063e-06\n",
      "[2312]\ttraining's binary_logloss: 9.29943e-06\n",
      "[2313]\ttraining's binary_logloss: 9.2874e-06\n",
      "[2314]\ttraining's binary_logloss: 9.27607e-06\n",
      "[2315]\ttraining's binary_logloss: 9.26715e-06\n",
      "[2316]\ttraining's binary_logloss: 9.25573e-06\n",
      "[2317]\ttraining's binary_logloss: 9.24592e-06\n",
      "[2318]\ttraining's binary_logloss: 9.23491e-06\n",
      "[2319]\ttraining's binary_logloss: 9.22375e-06\n",
      "[2320]\ttraining's binary_logloss: 9.2136e-06\n",
      "[2321]\ttraining's binary_logloss: 9.20129e-06\n",
      "[2322]\ttraining's binary_logloss: 9.19039e-06\n",
      "[2323]\ttraining's binary_logloss: 9.17815e-06\n",
      "[2324]\ttraining's binary_logloss: 9.16543e-06\n",
      "[2325]\ttraining's binary_logloss: 9.15332e-06\n",
      "[2326]\ttraining's binary_logloss: 9.14387e-06\n",
      "[2327]\ttraining's binary_logloss: 9.13378e-06\n",
      "[2328]\ttraining's binary_logloss: 9.12193e-06\n",
      "[2329]\ttraining's binary_logloss: 9.11164e-06\n",
      "[2330]\ttraining's binary_logloss: 9.10038e-06\n",
      "[2331]\ttraining's binary_logloss: 9.08951e-06\n",
      "[2332]\ttraining's binary_logloss: 9.07956e-06\n",
      "[2333]\ttraining's binary_logloss: 9.06879e-06\n",
      "[2334]\ttraining's binary_logloss: 9.05832e-06\n",
      "[2335]\ttraining's binary_logloss: 9.04843e-06\n",
      "[2336]\ttraining's binary_logloss: 9.0384e-06\n",
      "[2337]\ttraining's binary_logloss: 9.02583e-06\n",
      "[2338]\ttraining's binary_logloss: 9.0155e-06\n",
      "[2339]\ttraining's binary_logloss: 9.00466e-06\n",
      "[2340]\ttraining's binary_logloss: 8.99453e-06\n",
      "[2341]\ttraining's binary_logloss: 8.98242e-06\n",
      "[2342]\ttraining's binary_logloss: 8.97244e-06\n",
      "[2343]\ttraining's binary_logloss: 8.96088e-06\n",
      "[2344]\ttraining's binary_logloss: 8.95134e-06\n",
      "[2345]\ttraining's binary_logloss: 8.93959e-06\n",
      "[2346]\ttraining's binary_logloss: 8.92904e-06\n",
      "[2347]\ttraining's binary_logloss: 8.91706e-06\n",
      "[2348]\ttraining's binary_logloss: 8.90812e-06\n",
      "[2349]\ttraining's binary_logloss: 8.89813e-06\n",
      "[2350]\ttraining's binary_logloss: 8.88761e-06\n",
      "[2351]\ttraining's binary_logloss: 8.87586e-06\n",
      "[2352]\ttraining's binary_logloss: 8.86657e-06\n",
      "[2353]\ttraining's binary_logloss: 8.85596e-06\n",
      "[2354]\ttraining's binary_logloss: 8.84611e-06\n",
      "[2355]\ttraining's binary_logloss: 8.83522e-06\n",
      "[2356]\ttraining's binary_logloss: 8.82507e-06\n",
      "[2357]\ttraining's binary_logloss: 8.81435e-06\n",
      "[2358]\ttraining's binary_logloss: 8.80422e-06\n",
      "[2359]\ttraining's binary_logloss: 8.79406e-06\n",
      "[2360]\ttraining's binary_logloss: 8.78478e-06\n",
      "[2361]\ttraining's binary_logloss: 8.77385e-06\n",
      "[2362]\ttraining's binary_logloss: 8.76422e-06\n",
      "[2363]\ttraining's binary_logloss: 8.75452e-06\n",
      "[2364]\ttraining's binary_logloss: 8.74429e-06\n",
      "[2365]\ttraining's binary_logloss: 8.7345e-06\n",
      "[2366]\ttraining's binary_logloss: 8.72289e-06\n",
      "[2367]\ttraining's binary_logloss: 8.71258e-06\n",
      "[2368]\ttraining's binary_logloss: 8.70255e-06\n",
      "[2369]\ttraining's binary_logloss: 8.69269e-06\n",
      "[2370]\ttraining's binary_logloss: 8.68234e-06\n",
      "[2371]\ttraining's binary_logloss: 8.67279e-06\n",
      "[2372]\ttraining's binary_logloss: 8.66425e-06\n",
      "[2373]\ttraining's binary_logloss: 8.655e-06\n",
      "[2374]\ttraining's binary_logloss: 8.64581e-06\n",
      "[2375]\ttraining's binary_logloss: 8.63534e-06\n",
      "[2376]\ttraining's binary_logloss: 8.6261e-06\n",
      "[2377]\ttraining's binary_logloss: 8.61604e-06\n",
      "[2378]\ttraining's binary_logloss: 8.60626e-06\n",
      "[2379]\ttraining's binary_logloss: 8.59546e-06\n",
      "[2380]\ttraining's binary_logloss: 8.58603e-06\n",
      "[2381]\ttraining's binary_logloss: 8.57474e-06\n",
      "[2382]\ttraining's binary_logloss: 8.56504e-06\n",
      "[2383]\ttraining's binary_logloss: 8.55501e-06\n",
      "[2384]\ttraining's binary_logloss: 8.54451e-06\n",
      "[2385]\ttraining's binary_logloss: 8.53433e-06\n",
      "[2386]\ttraining's binary_logloss: 8.52448e-06\n",
      "[2387]\ttraining's binary_logloss: 8.51438e-06\n",
      "[2388]\ttraining's binary_logloss: 8.50467e-06\n",
      "[2389]\ttraining's binary_logloss: 8.4954e-06\n",
      "[2390]\ttraining's binary_logloss: 8.48611e-06\n",
      "[2391]\ttraining's binary_logloss: 8.47637e-06\n",
      "[2392]\ttraining's binary_logloss: 8.46697e-06\n",
      "[2393]\ttraining's binary_logloss: 8.45824e-06\n",
      "[2394]\ttraining's binary_logloss: 8.44826e-06\n",
      "[2395]\ttraining's binary_logloss: 8.4389e-06\n",
      "[2396]\ttraining's binary_logloss: 8.42882e-06\n",
      "[2397]\ttraining's binary_logloss: 8.41875e-06\n",
      "[2398]\ttraining's binary_logloss: 8.40947e-06\n",
      "[2399]\ttraining's binary_logloss: 8.3995e-06\n",
      "[2400]\ttraining's binary_logloss: 8.38982e-06\n",
      "[2401]\ttraining's binary_logloss: 8.38086e-06\n",
      "[2402]\ttraining's binary_logloss: 8.37165e-06\n",
      "[2403]\ttraining's binary_logloss: 8.36282e-06\n",
      "[2404]\ttraining's binary_logloss: 8.35397e-06\n",
      "[2405]\ttraining's binary_logloss: 8.34464e-06\n",
      "[2406]\ttraining's binary_logloss: 8.33579e-06\n",
      "[2407]\ttraining's binary_logloss: 8.32557e-06\n",
      "[2408]\ttraining's binary_logloss: 8.31809e-06\n",
      "[2409]\ttraining's binary_logloss: 8.30747e-06\n",
      "[2410]\ttraining's binary_logloss: 8.29878e-06\n",
      "[2411]\ttraining's binary_logloss: 8.28869e-06\n",
      "[2412]\ttraining's binary_logloss: 8.28167e-06\n",
      "[2413]\ttraining's binary_logloss: 8.27279e-06\n",
      "[2414]\ttraining's binary_logloss: 8.26364e-06\n",
      "[2415]\ttraining's binary_logloss: 8.25513e-06\n",
      "[2416]\ttraining's binary_logloss: 8.24613e-06\n",
      "[2417]\ttraining's binary_logloss: 8.23782e-06\n",
      "[2418]\ttraining's binary_logloss: 8.23001e-06\n",
      "[2419]\ttraining's binary_logloss: 8.22177e-06\n",
      "[2420]\ttraining's binary_logloss: 8.21139e-06\n",
      "[2421]\ttraining's binary_logloss: 8.20319e-06\n",
      "[2422]\ttraining's binary_logloss: 8.19532e-06\n",
      "[2423]\ttraining's binary_logloss: 8.18706e-06\n",
      "[2424]\ttraining's binary_logloss: 8.17866e-06\n",
      "[2425]\ttraining's binary_logloss: 8.17002e-06\n",
      "[2426]\ttraining's binary_logloss: 8.16243e-06\n",
      "[2427]\ttraining's binary_logloss: 8.15341e-06\n",
      "[2428]\ttraining's binary_logloss: 8.14397e-06\n",
      "[2429]\ttraining's binary_logloss: 8.1354e-06\n",
      "[2430]\ttraining's binary_logloss: 8.12636e-06\n",
      "[2431]\ttraining's binary_logloss: 8.11911e-06\n",
      "[2432]\ttraining's binary_logloss: 8.11117e-06\n",
      "[2433]\ttraining's binary_logloss: 8.10192e-06\n",
      "[2434]\ttraining's binary_logloss: 8.09373e-06\n",
      "[2435]\ttraining's binary_logloss: 8.08578e-06\n",
      "[2436]\ttraining's binary_logloss: 8.077e-06\n",
      "[2437]\ttraining's binary_logloss: 8.06742e-06\n",
      "[2438]\ttraining's binary_logloss: 8.05874e-06\n",
      "[2439]\ttraining's binary_logloss: 8.05026e-06\n",
      "[2440]\ttraining's binary_logloss: 8.04145e-06\n",
      "[2441]\ttraining's binary_logloss: 8.03372e-06\n",
      "[2442]\ttraining's binary_logloss: 8.02433e-06\n",
      "[2443]\ttraining's binary_logloss: 8.01619e-06\n",
      "[2444]\ttraining's binary_logloss: 8.00757e-06\n",
      "[2445]\ttraining's binary_logloss: 7.99852e-06\n",
      "[2446]\ttraining's binary_logloss: 7.98939e-06\n",
      "[2447]\ttraining's binary_logloss: 7.98098e-06\n",
      "[2448]\ttraining's binary_logloss: 7.9725e-06\n",
      "[2449]\ttraining's binary_logloss: 7.96489e-06\n",
      "[2450]\ttraining's binary_logloss: 7.95736e-06\n",
      "[2451]\ttraining's binary_logloss: 7.94935e-06\n",
      "[2452]\ttraining's binary_logloss: 7.94083e-06\n",
      "[2453]\ttraining's binary_logloss: 7.93289e-06\n",
      "[2454]\ttraining's binary_logloss: 7.92611e-06\n",
      "[2455]\ttraining's binary_logloss: 7.91817e-06\n",
      "[2456]\ttraining's binary_logloss: 7.91053e-06\n",
      "[2457]\ttraining's binary_logloss: 7.90248e-06\n",
      "[2458]\ttraining's binary_logloss: 7.89432e-06\n",
      "[2459]\ttraining's binary_logloss: 7.88557e-06\n",
      "[2460]\ttraining's binary_logloss: 7.87822e-06\n",
      "[2461]\ttraining's binary_logloss: 7.86999e-06\n",
      "[2462]\ttraining's binary_logloss: 7.86161e-06\n",
      "[2463]\ttraining's binary_logloss: 7.85441e-06\n",
      "[2464]\ttraining's binary_logloss: 7.84566e-06\n",
      "[2465]\ttraining's binary_logloss: 7.83765e-06\n",
      "[2466]\ttraining's binary_logloss: 7.82959e-06\n",
      "[2467]\ttraining's binary_logloss: 7.82204e-06\n",
      "[2468]\ttraining's binary_logloss: 7.81561e-06\n",
      "[2469]\ttraining's binary_logloss: 7.8077e-06\n",
      "[2470]\ttraining's binary_logloss: 7.80014e-06\n",
      "[2471]\ttraining's binary_logloss: 7.79178e-06\n",
      "[2472]\ttraining's binary_logloss: 7.78365e-06\n",
      "[2473]\ttraining's binary_logloss: 7.77558e-06\n",
      "[2474]\ttraining's binary_logloss: 7.76692e-06\n",
      "[2475]\ttraining's binary_logloss: 7.75997e-06\n",
      "[2476]\ttraining's binary_logloss: 7.75046e-06\n",
      "[2477]\ttraining's binary_logloss: 7.74145e-06\n",
      "[2478]\ttraining's binary_logloss: 7.7335e-06\n",
      "[2479]\ttraining's binary_logloss: 7.72421e-06\n",
      "[2480]\ttraining's binary_logloss: 7.71646e-06\n",
      "[2481]\ttraining's binary_logloss: 7.70877e-06\n",
      "[2482]\ttraining's binary_logloss: 7.70116e-06\n",
      "[2483]\ttraining's binary_logloss: 7.6931e-06\n",
      "[2484]\ttraining's binary_logloss: 7.686e-06\n",
      "[2485]\ttraining's binary_logloss: 7.67899e-06\n",
      "[2486]\ttraining's binary_logloss: 7.67174e-06\n",
      "[2487]\ttraining's binary_logloss: 7.66544e-06\n",
      "[2488]\ttraining's binary_logloss: 7.65794e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2489]\ttraining's binary_logloss: 7.64957e-06\n",
      "[2490]\ttraining's binary_logloss: 7.64211e-06\n",
      "[2491]\ttraining's binary_logloss: 7.63466e-06\n",
      "[2492]\ttraining's binary_logloss: 7.62666e-06\n",
      "[2493]\ttraining's binary_logloss: 7.61885e-06\n",
      "[2494]\ttraining's binary_logloss: 7.61075e-06\n",
      "[2495]\ttraining's binary_logloss: 7.60375e-06\n",
      "[2496]\ttraining's binary_logloss: 7.59602e-06\n",
      "[2497]\ttraining's binary_logloss: 7.58858e-06\n",
      "[2498]\ttraining's binary_logloss: 7.58105e-06\n",
      "[2499]\ttraining's binary_logloss: 7.57301e-06\n",
      "[2500]\ttraining's binary_logloss: 7.56439e-06\n",
      "[2501]\ttraining's binary_logloss: 7.55608e-06\n",
      "[2502]\ttraining's binary_logloss: 7.54947e-06\n",
      "[2503]\ttraining's binary_logloss: 7.54243e-06\n",
      "[2504]\ttraining's binary_logloss: 7.53503e-06\n",
      "[2505]\ttraining's binary_logloss: 7.52711e-06\n",
      "[2506]\ttraining's binary_logloss: 7.51952e-06\n",
      "[2507]\ttraining's binary_logloss: 7.51219e-06\n",
      "[2508]\ttraining's binary_logloss: 7.50654e-06\n",
      "[2509]\ttraining's binary_logloss: 7.49881e-06\n",
      "[2510]\ttraining's binary_logloss: 7.4917e-06\n",
      "[2511]\ttraining's binary_logloss: 7.48343e-06\n",
      "[2512]\ttraining's binary_logloss: 7.47587e-06\n",
      "[2513]\ttraining's binary_logloss: 7.4686e-06\n",
      "[2514]\ttraining's binary_logloss: 7.46161e-06\n",
      "[2515]\ttraining's binary_logloss: 7.45362e-06\n",
      "[2516]\ttraining's binary_logloss: 7.4469e-06\n",
      "[2517]\ttraining's binary_logloss: 7.43945e-06\n",
      "[2518]\ttraining's binary_logloss: 7.4325e-06\n",
      "[2519]\ttraining's binary_logloss: 7.42546e-06\n",
      "[2520]\ttraining's binary_logloss: 7.41813e-06\n",
      "[2521]\ttraining's binary_logloss: 7.41109e-06\n",
      "[2522]\ttraining's binary_logloss: 7.40356e-06\n",
      "[2523]\ttraining's binary_logloss: 7.39676e-06\n",
      "[2524]\ttraining's binary_logloss: 7.38919e-06\n",
      "[2525]\ttraining's binary_logloss: 7.38209e-06\n",
      "[2526]\ttraining's binary_logloss: 7.37331e-06\n",
      "[2527]\ttraining's binary_logloss: 7.3671e-06\n",
      "[2528]\ttraining's binary_logloss: 7.36038e-06\n",
      "[2529]\ttraining's binary_logloss: 7.35401e-06\n",
      "[2530]\ttraining's binary_logloss: 7.34681e-06\n",
      "[2531]\ttraining's binary_logloss: 7.33999e-06\n",
      "[2532]\ttraining's binary_logloss: 7.33314e-06\n",
      "[2533]\ttraining's binary_logloss: 7.32538e-06\n",
      "[2534]\ttraining's binary_logloss: 7.31838e-06\n",
      "[2535]\ttraining's binary_logloss: 7.31158e-06\n",
      "[2536]\ttraining's binary_logloss: 7.30505e-06\n",
      "[2537]\ttraining's binary_logloss: 7.29769e-06\n",
      "[2538]\ttraining's binary_logloss: 7.29156e-06\n",
      "[2539]\ttraining's binary_logloss: 7.28488e-06\n",
      "[2540]\ttraining's binary_logloss: 7.27778e-06\n",
      "[2541]\ttraining's binary_logloss: 7.27116e-06\n",
      "[2542]\ttraining's binary_logloss: 7.26471e-06\n",
      "[2543]\ttraining's binary_logloss: 7.25835e-06\n",
      "[2544]\ttraining's binary_logloss: 7.25148e-06\n",
      "[2545]\ttraining's binary_logloss: 7.24519e-06\n",
      "[2546]\ttraining's binary_logloss: 7.2387e-06\n",
      "[2547]\ttraining's binary_logloss: 7.23276e-06\n",
      "[2548]\ttraining's binary_logloss: 7.22564e-06\n",
      "[2549]\ttraining's binary_logloss: 7.21908e-06\n",
      "[2550]\ttraining's binary_logloss: 7.21229e-06\n",
      "[2551]\ttraining's binary_logloss: 7.20611e-06\n",
      "[2552]\ttraining's binary_logloss: 7.20002e-06\n",
      "[2553]\ttraining's binary_logloss: 7.1927e-06\n",
      "[2554]\ttraining's binary_logloss: 7.18524e-06\n",
      "[2555]\ttraining's binary_logloss: 7.17879e-06\n",
      "[2556]\ttraining's binary_logloss: 7.17185e-06\n",
      "[2557]\ttraining's binary_logloss: 7.16545e-06\n",
      "[2558]\ttraining's binary_logloss: 7.15842e-06\n",
      "[2559]\ttraining's binary_logloss: 7.15273e-06\n",
      "[2560]\ttraining's binary_logloss: 7.14573e-06\n",
      "[2561]\ttraining's binary_logloss: 7.13799e-06\n",
      "[2562]\ttraining's binary_logloss: 7.13108e-06\n",
      "[2563]\ttraining's binary_logloss: 7.12516e-06\n",
      "[2564]\ttraining's binary_logloss: 7.11825e-06\n",
      "[2565]\ttraining's binary_logloss: 7.11258e-06\n",
      "[2566]\ttraining's binary_logloss: 7.10606e-06\n",
      "[2567]\ttraining's binary_logloss: 7.09954e-06\n",
      "[2568]\ttraining's binary_logloss: 7.09238e-06\n",
      "[2569]\ttraining's binary_logloss: 7.08586e-06\n",
      "[2570]\ttraining's binary_logloss: 7.07955e-06\n",
      "[2571]\ttraining's binary_logloss: 7.07353e-06\n",
      "[2572]\ttraining's binary_logloss: 7.06784e-06\n",
      "[2573]\ttraining's binary_logloss: 7.06145e-06\n",
      "[2574]\ttraining's binary_logloss: 7.05524e-06\n",
      "[2575]\ttraining's binary_logloss: 7.04874e-06\n",
      "[2576]\ttraining's binary_logloss: 7.04264e-06\n",
      "[2577]\ttraining's binary_logloss: 7.03644e-06\n",
      "[2578]\ttraining's binary_logloss: 7.03114e-06\n",
      "[2579]\ttraining's binary_logloss: 7.02443e-06\n",
      "[2580]\ttraining's binary_logloss: 7.01931e-06\n",
      "[2581]\ttraining's binary_logloss: 7.01298e-06\n",
      "[2582]\ttraining's binary_logloss: 7.00681e-06\n",
      "[2583]\ttraining's binary_logloss: 7.00091e-06\n",
      "[2584]\ttraining's binary_logloss: 6.99459e-06\n",
      "[2585]\ttraining's binary_logloss: 6.98819e-06\n",
      "[2586]\ttraining's binary_logloss: 6.98238e-06\n",
      "[2587]\ttraining's binary_logloss: 6.97735e-06\n",
      "[2588]\ttraining's binary_logloss: 6.97189e-06\n",
      "[2589]\ttraining's binary_logloss: 6.96672e-06\n",
      "[2590]\ttraining's binary_logloss: 6.96153e-06\n",
      "[2591]\ttraining's binary_logloss: 6.95487e-06\n",
      "[2592]\ttraining's binary_logloss: 6.94883e-06\n",
      "[2593]\ttraining's binary_logloss: 6.94214e-06\n",
      "[2594]\ttraining's binary_logloss: 6.93627e-06\n",
      "[2595]\ttraining's binary_logloss: 6.93149e-06\n",
      "[2596]\ttraining's binary_logloss: 6.92585e-06\n",
      "[2597]\ttraining's binary_logloss: 6.91999e-06\n",
      "[2598]\ttraining's binary_logloss: 6.91379e-06\n",
      "[2599]\ttraining's binary_logloss: 6.90793e-06\n",
      "[2600]\ttraining's binary_logloss: 6.90113e-06\n",
      "[2601]\ttraining's binary_logloss: 6.89514e-06\n",
      "[2602]\ttraining's binary_logloss: 6.88882e-06\n",
      "[2603]\ttraining's binary_logloss: 6.88253e-06\n",
      "[2604]\ttraining's binary_logloss: 6.87721e-06\n",
      "[2605]\ttraining's binary_logloss: 6.87171e-06\n",
      "[2606]\ttraining's binary_logloss: 6.86595e-06\n",
      "[2607]\ttraining's binary_logloss: 6.86058e-06\n",
      "[2608]\ttraining's binary_logloss: 6.85545e-06\n",
      "[2609]\ttraining's binary_logloss: 6.84971e-06\n",
      "[2610]\ttraining's binary_logloss: 6.84405e-06\n",
      "[2611]\ttraining's binary_logloss: 6.83763e-06\n",
      "[2612]\ttraining's binary_logloss: 6.8319e-06\n",
      "[2613]\ttraining's binary_logloss: 6.82627e-06\n",
      "[2614]\ttraining's binary_logloss: 6.82111e-06\n",
      "[2615]\ttraining's binary_logloss: 6.81603e-06\n",
      "[2616]\ttraining's binary_logloss: 6.81073e-06\n",
      "[2617]\ttraining's binary_logloss: 6.80483e-06\n",
      "[2618]\ttraining's binary_logloss: 6.79944e-06\n",
      "[2619]\ttraining's binary_logloss: 6.79285e-06\n",
      "[2620]\ttraining's binary_logloss: 6.78734e-06\n",
      "[2621]\ttraining's binary_logloss: 6.78172e-06\n",
      "[2622]\ttraining's binary_logloss: 6.77676e-06\n",
      "[2623]\ttraining's binary_logloss: 6.77095e-06\n",
      "[2624]\ttraining's binary_logloss: 6.76471e-06\n",
      "[2625]\ttraining's binary_logloss: 6.75777e-06\n",
      "[2626]\ttraining's binary_logloss: 6.75158e-06\n",
      "[2627]\ttraining's binary_logloss: 6.74598e-06\n",
      "[2628]\ttraining's binary_logloss: 6.74029e-06\n",
      "[2629]\ttraining's binary_logloss: 6.73505e-06\n",
      "[2630]\ttraining's binary_logloss: 6.72957e-06\n",
      "[2631]\ttraining's binary_logloss: 6.72412e-06\n",
      "[2632]\ttraining's binary_logloss: 6.71783e-06\n",
      "[2633]\ttraining's binary_logloss: 6.71213e-06\n",
      "[2634]\ttraining's binary_logloss: 6.7069e-06\n",
      "[2635]\ttraining's binary_logloss: 6.70138e-06\n",
      "[2636]\ttraining's binary_logloss: 6.69607e-06\n",
      "[2637]\ttraining's binary_logloss: 6.69083e-06\n",
      "[2638]\ttraining's binary_logloss: 6.68534e-06\n",
      "[2639]\ttraining's binary_logloss: 6.67933e-06\n",
      "[2640]\ttraining's binary_logloss: 6.67479e-06\n",
      "[2641]\ttraining's binary_logloss: 6.66897e-06\n",
      "[2642]\ttraining's binary_logloss: 6.66317e-06\n",
      "[2643]\ttraining's binary_logloss: 6.65804e-06\n",
      "[2644]\ttraining's binary_logloss: 6.652e-06\n",
      "[2645]\ttraining's binary_logloss: 6.64702e-06\n",
      "[2646]\ttraining's binary_logloss: 6.64156e-06\n",
      "[2647]\ttraining's binary_logloss: 6.63543e-06\n",
      "[2648]\ttraining's binary_logloss: 6.62886e-06\n",
      "[2649]\ttraining's binary_logloss: 6.62297e-06\n",
      "[2650]\ttraining's binary_logloss: 6.61756e-06\n",
      "[2651]\ttraining's binary_logloss: 6.61265e-06\n",
      "[2652]\ttraining's binary_logloss: 6.60742e-06\n",
      "[2653]\ttraining's binary_logloss: 6.60208e-06\n",
      "[2654]\ttraining's binary_logloss: 6.59766e-06\n",
      "[2655]\ttraining's binary_logloss: 6.59225e-06\n",
      "[2656]\ttraining's binary_logloss: 6.58735e-06\n",
      "[2657]\ttraining's binary_logloss: 6.58198e-06\n",
      "[2658]\ttraining's binary_logloss: 6.57664e-06\n",
      "[2659]\ttraining's binary_logloss: 6.57102e-06\n",
      "[2660]\ttraining's binary_logloss: 6.56488e-06\n",
      "[2661]\ttraining's binary_logloss: 6.55955e-06\n",
      "[2662]\ttraining's binary_logloss: 6.55305e-06\n",
      "[2663]\ttraining's binary_logloss: 6.54828e-06\n",
      "[2664]\ttraining's binary_logloss: 6.54321e-06\n",
      "[2665]\ttraining's binary_logloss: 6.53818e-06\n",
      "[2666]\ttraining's binary_logloss: 6.53222e-06\n",
      "[2667]\ttraining's binary_logloss: 6.52728e-06\n",
      "[2668]\ttraining's binary_logloss: 6.52189e-06\n",
      "[2669]\ttraining's binary_logloss: 6.51603e-06\n",
      "[2670]\ttraining's binary_logloss: 6.51046e-06\n",
      "[2671]\ttraining's binary_logloss: 6.50521e-06\n",
      "[2672]\ttraining's binary_logloss: 6.50029e-06\n",
      "[2673]\ttraining's binary_logloss: 6.49636e-06\n",
      "[2674]\ttraining's binary_logloss: 6.49154e-06\n",
      "[2675]\ttraining's binary_logloss: 6.48592e-06\n",
      "[2676]\ttraining's binary_logloss: 6.4811e-06\n",
      "[2677]\ttraining's binary_logloss: 6.47538e-06\n",
      "[2678]\ttraining's binary_logloss: 6.46991e-06\n",
      "[2679]\ttraining's binary_logloss: 6.46458e-06\n",
      "[2680]\ttraining's binary_logloss: 6.45933e-06\n",
      "[2681]\ttraining's binary_logloss: 6.45463e-06\n",
      "[2682]\ttraining's binary_logloss: 6.45073e-06\n",
      "[2683]\ttraining's binary_logloss: 6.44564e-06\n",
      "[2684]\ttraining's binary_logloss: 6.44095e-06\n",
      "[2685]\ttraining's binary_logloss: 6.43573e-06\n",
      "[2686]\ttraining's binary_logloss: 6.4309e-06\n",
      "[2687]\ttraining's binary_logloss: 6.42639e-06\n",
      "[2688]\ttraining's binary_logloss: 6.42109e-06\n",
      "[2689]\ttraining's binary_logloss: 6.41512e-06\n",
      "[2690]\ttraining's binary_logloss: 6.41011e-06\n",
      "[2691]\ttraining's binary_logloss: 6.40483e-06\n",
      "[2692]\ttraining's binary_logloss: 6.39973e-06\n",
      "[2693]\ttraining's binary_logloss: 6.39497e-06\n",
      "[2694]\ttraining's binary_logloss: 6.38959e-06\n",
      "[2695]\ttraining's binary_logloss: 6.3841e-06\n",
      "[2696]\ttraining's binary_logloss: 6.37847e-06\n",
      "[2697]\ttraining's binary_logloss: 6.37329e-06\n",
      "[2698]\ttraining's binary_logloss: 6.36889e-06\n",
      "[2699]\ttraining's binary_logloss: 6.36308e-06\n",
      "[2700]\ttraining's binary_logloss: 6.35775e-06\n",
      "[2701]\ttraining's binary_logloss: 6.3525e-06\n",
      "[2702]\ttraining's binary_logloss: 6.34707e-06\n",
      "[2703]\ttraining's binary_logloss: 6.34263e-06\n",
      "[2704]\ttraining's binary_logloss: 6.33823e-06\n",
      "[2705]\ttraining's binary_logloss: 6.33336e-06\n",
      "[2706]\ttraining's binary_logloss: 6.32827e-06\n",
      "[2707]\ttraining's binary_logloss: 6.32292e-06\n",
      "[2708]\ttraining's binary_logloss: 6.31874e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2709]\ttraining's binary_logloss: 6.3139e-06\n",
      "[2710]\ttraining's binary_logloss: 6.30945e-06\n",
      "[2711]\ttraining's binary_logloss: 6.30477e-06\n",
      "[2712]\ttraining's binary_logloss: 6.29925e-06\n",
      "[2713]\ttraining's binary_logloss: 6.2939e-06\n",
      "[2714]\ttraining's binary_logloss: 6.28865e-06\n",
      "[2715]\ttraining's binary_logloss: 6.28341e-06\n",
      "[2716]\ttraining's binary_logloss: 6.27827e-06\n",
      "[2717]\ttraining's binary_logloss: 6.27369e-06\n",
      "[2718]\ttraining's binary_logloss: 6.26911e-06\n",
      "[2719]\ttraining's binary_logloss: 6.2635e-06\n",
      "[2720]\ttraining's binary_logloss: 6.25872e-06\n",
      "[2721]\ttraining's binary_logloss: 6.25389e-06\n",
      "[2722]\ttraining's binary_logloss: 6.24856e-06\n",
      "[2723]\ttraining's binary_logloss: 6.24258e-06\n",
      "[2724]\ttraining's binary_logloss: 6.23745e-06\n",
      "[2725]\ttraining's binary_logloss: 6.23268e-06\n",
      "[2726]\ttraining's binary_logloss: 6.22825e-06\n",
      "[2727]\ttraining's binary_logloss: 6.22298e-06\n",
      "[2728]\ttraining's binary_logloss: 6.21829e-06\n",
      "[2729]\ttraining's binary_logloss: 6.21372e-06\n",
      "[2730]\ttraining's binary_logloss: 6.20888e-06\n",
      "[2731]\ttraining's binary_logloss: 6.2039e-06\n",
      "[2732]\ttraining's binary_logloss: 6.19987e-06\n",
      "[2733]\ttraining's binary_logloss: 6.19569e-06\n",
      "[2734]\ttraining's binary_logloss: 6.19127e-06\n",
      "[2735]\ttraining's binary_logloss: 6.1866e-06\n",
      "[2736]\ttraining's binary_logloss: 6.18249e-06\n",
      "[2737]\ttraining's binary_logloss: 6.17815e-06\n",
      "[2738]\ttraining's binary_logloss: 6.17347e-06\n",
      "[2739]\ttraining's binary_logloss: 6.1691e-06\n",
      "[2740]\ttraining's binary_logloss: 6.16416e-06\n",
      "[2741]\ttraining's binary_logloss: 6.15889e-06\n",
      "[2742]\ttraining's binary_logloss: 6.15463e-06\n",
      "[2743]\ttraining's binary_logloss: 6.14901e-06\n",
      "[2744]\ttraining's binary_logloss: 6.14406e-06\n",
      "[2745]\ttraining's binary_logloss: 6.13992e-06\n",
      "[2746]\ttraining's binary_logloss: 6.13581e-06\n",
      "[2747]\ttraining's binary_logloss: 6.13083e-06\n",
      "[2748]\ttraining's binary_logloss: 6.1263e-06\n",
      "[2749]\ttraining's binary_logloss: 6.12206e-06\n",
      "[2750]\ttraining's binary_logloss: 6.11788e-06\n",
      "[2751]\ttraining's binary_logloss: 6.11387e-06\n",
      "[2752]\ttraining's binary_logloss: 6.10887e-06\n",
      "[2753]\ttraining's binary_logloss: 6.10455e-06\n",
      "[2754]\ttraining's binary_logloss: 6.10033e-06\n",
      "[2755]\ttraining's binary_logloss: 6.09507e-06\n",
      "[2756]\ttraining's binary_logloss: 6.09105e-06\n",
      "[2757]\ttraining's binary_logloss: 6.08693e-06\n",
      "[2758]\ttraining's binary_logloss: 6.08245e-06\n",
      "[2759]\ttraining's binary_logloss: 6.07731e-06\n",
      "[2760]\ttraining's binary_logloss: 6.07239e-06\n",
      "[2761]\ttraining's binary_logloss: 6.06737e-06\n",
      "[2762]\ttraining's binary_logloss: 6.06227e-06\n",
      "[2763]\ttraining's binary_logloss: 6.05806e-06\n",
      "[2764]\ttraining's binary_logloss: 6.05394e-06\n",
      "[2765]\ttraining's binary_logloss: 6.05032e-06\n",
      "[2766]\ttraining's binary_logloss: 6.0456e-06\n",
      "[2767]\ttraining's binary_logloss: 6.04072e-06\n",
      "[2768]\ttraining's binary_logloss: 6.03603e-06\n",
      "[2769]\ttraining's binary_logloss: 6.03171e-06\n",
      "[2770]\ttraining's binary_logloss: 6.0277e-06\n",
      "[2771]\ttraining's binary_logloss: 6.02274e-06\n",
      "[2772]\ttraining's binary_logloss: 6.01817e-06\n",
      "[2773]\ttraining's binary_logloss: 6.01354e-06\n",
      "[2774]\ttraining's binary_logloss: 6.00911e-06\n",
      "[2775]\ttraining's binary_logloss: 6.00479e-06\n",
      "[2776]\ttraining's binary_logloss: 6.00035e-06\n",
      "[2777]\ttraining's binary_logloss: 5.99558e-06\n",
      "[2778]\ttraining's binary_logloss: 5.99108e-06\n",
      "[2779]\ttraining's binary_logloss: 5.98681e-06\n",
      "[2780]\ttraining's binary_logloss: 5.98246e-06\n",
      "[2781]\ttraining's binary_logloss: 5.97811e-06\n",
      "[2782]\ttraining's binary_logloss: 5.97315e-06\n",
      "[2783]\ttraining's binary_logloss: 5.96919e-06\n",
      "[2784]\ttraining's binary_logloss: 5.96497e-06\n",
      "[2785]\ttraining's binary_logloss: 5.96037e-06\n",
      "[2786]\ttraining's binary_logloss: 5.95651e-06\n",
      "[2787]\ttraining's binary_logloss: 5.95276e-06\n",
      "[2788]\ttraining's binary_logloss: 5.94845e-06\n",
      "[2789]\ttraining's binary_logloss: 5.94325e-06\n",
      "[2790]\ttraining's binary_logloss: 5.93903e-06\n",
      "[2791]\ttraining's binary_logloss: 5.93456e-06\n",
      "[2792]\ttraining's binary_logloss: 5.93005e-06\n",
      "[2793]\ttraining's binary_logloss: 5.92532e-06\n",
      "[2794]\ttraining's binary_logloss: 5.92037e-06\n",
      "[2795]\ttraining's binary_logloss: 5.91628e-06\n",
      "[2796]\ttraining's binary_logloss: 5.91129e-06\n",
      "[2797]\ttraining's binary_logloss: 5.90789e-06\n",
      "[2798]\ttraining's binary_logloss: 5.90406e-06\n",
      "[2799]\ttraining's binary_logloss: 5.90023e-06\n",
      "[2800]\ttraining's binary_logloss: 5.89573e-06\n",
      "[2801]\ttraining's binary_logloss: 5.89169e-06\n",
      "[2802]\ttraining's binary_logloss: 5.88754e-06\n",
      "[2803]\ttraining's binary_logloss: 5.8837e-06\n",
      "[2804]\ttraining's binary_logloss: 5.87986e-06\n",
      "[2805]\ttraining's binary_logloss: 5.87515e-06\n",
      "[2806]\ttraining's binary_logloss: 5.87089e-06\n",
      "[2807]\ttraining's binary_logloss: 5.86643e-06\n",
      "[2808]\ttraining's binary_logloss: 5.8628e-06\n",
      "[2809]\ttraining's binary_logloss: 5.85884e-06\n",
      "[2810]\ttraining's binary_logloss: 5.85458e-06\n",
      "[2811]\ttraining's binary_logloss: 5.85022e-06\n",
      "[2812]\ttraining's binary_logloss: 5.84597e-06\n",
      "[2813]\ttraining's binary_logloss: 5.84126e-06\n",
      "[2814]\ttraining's binary_logloss: 5.83637e-06\n",
      "[2815]\ttraining's binary_logloss: 5.8321e-06\n",
      "[2816]\ttraining's binary_logloss: 5.82786e-06\n",
      "[2817]\ttraining's binary_logloss: 5.82434e-06\n",
      "[2818]\ttraining's binary_logloss: 5.82e-06\n",
      "[2819]\ttraining's binary_logloss: 5.81662e-06\n",
      "[2820]\ttraining's binary_logloss: 5.81303e-06\n",
      "[2821]\ttraining's binary_logloss: 5.80917e-06\n",
      "[2822]\ttraining's binary_logloss: 5.80551e-06\n",
      "[2823]\ttraining's binary_logloss: 5.80163e-06\n",
      "[2824]\ttraining's binary_logloss: 5.79707e-06\n",
      "[2825]\ttraining's binary_logloss: 5.79307e-06\n",
      "[2826]\ttraining's binary_logloss: 5.78914e-06\n",
      "[2827]\ttraining's binary_logloss: 5.78533e-06\n",
      "[2828]\ttraining's binary_logloss: 5.78143e-06\n",
      "[2829]\ttraining's binary_logloss: 5.77808e-06\n",
      "[2830]\ttraining's binary_logloss: 5.77394e-06\n",
      "[2831]\ttraining's binary_logloss: 5.76968e-06\n",
      "[2832]\ttraining's binary_logloss: 5.76576e-06\n",
      "[2833]\ttraining's binary_logloss: 5.76214e-06\n",
      "[2834]\ttraining's binary_logloss: 5.75825e-06\n",
      "[2835]\ttraining's binary_logloss: 5.75426e-06\n",
      "[2836]\ttraining's binary_logloss: 5.75088e-06\n",
      "[2837]\ttraining's binary_logloss: 5.74686e-06\n",
      "[2838]\ttraining's binary_logloss: 5.74294e-06\n",
      "[2839]\ttraining's binary_logloss: 5.7395e-06\n",
      "[2840]\ttraining's binary_logloss: 5.73593e-06\n",
      "[2841]\ttraining's binary_logloss: 5.73196e-06\n",
      "[2842]\ttraining's binary_logloss: 5.72782e-06\n",
      "[2843]\ttraining's binary_logloss: 5.72354e-06\n",
      "[2844]\ttraining's binary_logloss: 5.71944e-06\n",
      "[2845]\ttraining's binary_logloss: 5.71535e-06\n",
      "[2846]\ttraining's binary_logloss: 5.71203e-06\n",
      "[2847]\ttraining's binary_logloss: 5.70775e-06\n",
      "[2848]\ttraining's binary_logloss: 5.70333e-06\n",
      "[2849]\ttraining's binary_logloss: 5.69937e-06\n",
      "[2850]\ttraining's binary_logloss: 5.69502e-06\n",
      "[2851]\ttraining's binary_logloss: 5.69082e-06\n",
      "[2852]\ttraining's binary_logloss: 5.68715e-06\n",
      "[2853]\ttraining's binary_logloss: 5.68341e-06\n",
      "[2854]\ttraining's binary_logloss: 5.67979e-06\n",
      "[2855]\ttraining's binary_logloss: 5.67653e-06\n",
      "[2856]\ttraining's binary_logloss: 5.67257e-06\n",
      "[2857]\ttraining's binary_logloss: 5.66861e-06\n",
      "[2858]\ttraining's binary_logloss: 5.66503e-06\n",
      "[2859]\ttraining's binary_logloss: 5.6617e-06\n",
      "[2860]\ttraining's binary_logloss: 5.65755e-06\n",
      "[2861]\ttraining's binary_logloss: 5.65405e-06\n",
      "[2862]\ttraining's binary_logloss: 5.65e-06\n",
      "[2863]\ttraining's binary_logloss: 5.64625e-06\n",
      "[2864]\ttraining's binary_logloss: 5.64282e-06\n",
      "[2865]\ttraining's binary_logloss: 5.63902e-06\n",
      "[2866]\ttraining's binary_logloss: 5.63547e-06\n",
      "[2867]\ttraining's binary_logloss: 5.63212e-06\n",
      "[2868]\ttraining's binary_logloss: 5.62861e-06\n",
      "[2869]\ttraining's binary_logloss: 5.62424e-06\n",
      "[2870]\ttraining's binary_logloss: 5.6207e-06\n",
      "[2871]\ttraining's binary_logloss: 5.61721e-06\n",
      "[2872]\ttraining's binary_logloss: 5.61294e-06\n",
      "[2873]\ttraining's binary_logloss: 5.60863e-06\n",
      "[2874]\ttraining's binary_logloss: 5.60487e-06\n",
      "[2875]\ttraining's binary_logloss: 5.60039e-06\n",
      "[2876]\ttraining's binary_logloss: 5.59647e-06\n",
      "[2877]\ttraining's binary_logloss: 5.59285e-06\n",
      "[2878]\ttraining's binary_logloss: 5.58954e-06\n",
      "[2879]\ttraining's binary_logloss: 5.58579e-06\n",
      "[2880]\ttraining's binary_logloss: 5.58214e-06\n",
      "[2881]\ttraining's binary_logloss: 5.57911e-06\n",
      "[2882]\ttraining's binary_logloss: 5.57568e-06\n",
      "[2883]\ttraining's binary_logloss: 5.57221e-06\n",
      "[2884]\ttraining's binary_logloss: 5.5688e-06\n",
      "[2885]\ttraining's binary_logloss: 5.56567e-06\n",
      "[2886]\ttraining's binary_logloss: 5.56206e-06\n",
      "[2887]\ttraining's binary_logloss: 5.55861e-06\n",
      "[2888]\ttraining's binary_logloss: 5.55497e-06\n",
      "[2889]\ttraining's binary_logloss: 5.55087e-06\n",
      "[2890]\ttraining's binary_logloss: 5.54735e-06\n",
      "[2891]\ttraining's binary_logloss: 5.54375e-06\n",
      "[2892]\ttraining's binary_logloss: 5.5393e-06\n",
      "[2893]\ttraining's binary_logloss: 5.53571e-06\n",
      "[2894]\ttraining's binary_logloss: 5.53187e-06\n",
      "[2895]\ttraining's binary_logloss: 5.52837e-06\n",
      "[2896]\ttraining's binary_logloss: 5.5244e-06\n",
      "[2897]\ttraining's binary_logloss: 5.52111e-06\n",
      "[2898]\ttraining's binary_logloss: 5.51726e-06\n",
      "[2899]\ttraining's binary_logloss: 5.51281e-06\n",
      "[2900]\ttraining's binary_logloss: 5.50959e-06\n",
      "[2901]\ttraining's binary_logloss: 5.50579e-06\n",
      "[2902]\ttraining's binary_logloss: 5.5027e-06\n",
      "[2903]\ttraining's binary_logloss: 5.49909e-06\n",
      "[2904]\ttraining's binary_logloss: 5.49513e-06\n",
      "[2905]\ttraining's binary_logloss: 5.49192e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2906]\ttraining's binary_logloss: 5.48815e-06\n",
      "[2907]\ttraining's binary_logloss: 5.48496e-06\n",
      "[2908]\ttraining's binary_logloss: 5.48211e-06\n",
      "[2909]\ttraining's binary_logloss: 5.47849e-06\n",
      "[2910]\ttraining's binary_logloss: 5.47447e-06\n",
      "[2911]\ttraining's binary_logloss: 5.47104e-06\n",
      "[2912]\ttraining's binary_logloss: 5.46744e-06\n",
      "[2913]\ttraining's binary_logloss: 5.46402e-06\n",
      "[2914]\ttraining's binary_logloss: 5.46025e-06\n",
      "[2915]\ttraining's binary_logloss: 5.4562e-06\n",
      "[2916]\ttraining's binary_logloss: 5.45284e-06\n",
      "[2917]\ttraining's binary_logloss: 5.44955e-06\n",
      "[2918]\ttraining's binary_logloss: 5.44642e-06\n",
      "[2919]\ttraining's binary_logloss: 5.44341e-06\n",
      "[2920]\ttraining's binary_logloss: 5.43964e-06\n",
      "[2921]\ttraining's binary_logloss: 5.43605e-06\n",
      "[2922]\ttraining's binary_logloss: 5.43296e-06\n",
      "[2923]\ttraining's binary_logloss: 5.42982e-06\n",
      "[2924]\ttraining's binary_logloss: 5.42649e-06\n",
      "[2925]\ttraining's binary_logloss: 5.42295e-06\n",
      "[2926]\ttraining's binary_logloss: 5.41914e-06\n",
      "[2927]\ttraining's binary_logloss: 5.41559e-06\n",
      "[2928]\ttraining's binary_logloss: 5.41219e-06\n",
      "[2929]\ttraining's binary_logloss: 5.40873e-06\n",
      "[2930]\ttraining's binary_logloss: 5.40553e-06\n",
      "[2931]\ttraining's binary_logloss: 5.40237e-06\n",
      "[2932]\ttraining's binary_logloss: 5.3987e-06\n",
      "[2933]\ttraining's binary_logloss: 5.39538e-06\n",
      "[2934]\ttraining's binary_logloss: 5.39241e-06\n",
      "[2935]\ttraining's binary_logloss: 5.38924e-06\n",
      "[2936]\ttraining's binary_logloss: 5.38619e-06\n",
      "[2937]\ttraining's binary_logloss: 5.3823e-06\n",
      "[2938]\ttraining's binary_logloss: 5.37938e-06\n",
      "[2939]\ttraining's binary_logloss: 5.37539e-06\n",
      "[2940]\ttraining's binary_logloss: 5.37234e-06\n",
      "[2941]\ttraining's binary_logloss: 5.36848e-06\n",
      "[2942]\ttraining's binary_logloss: 5.36536e-06\n",
      "[2943]\ttraining's binary_logloss: 5.36236e-06\n",
      "[2944]\ttraining's binary_logloss: 5.35891e-06\n",
      "[2945]\ttraining's binary_logloss: 5.35577e-06\n",
      "[2946]\ttraining's binary_logloss: 5.35203e-06\n",
      "[2947]\ttraining's binary_logloss: 5.34888e-06\n",
      "[2948]\ttraining's binary_logloss: 5.34557e-06\n",
      "[2949]\ttraining's binary_logloss: 5.34228e-06\n",
      "[2950]\ttraining's binary_logloss: 5.3383e-06\n",
      "[2951]\ttraining's binary_logloss: 5.33513e-06\n",
      "[2952]\ttraining's binary_logloss: 5.33188e-06\n",
      "[2953]\ttraining's binary_logloss: 5.32906e-06\n",
      "[2954]\ttraining's binary_logloss: 5.32535e-06\n",
      "[2955]\ttraining's binary_logloss: 5.32195e-06\n",
      "[2956]\ttraining's binary_logloss: 5.31823e-06\n",
      "[2957]\ttraining's binary_logloss: 5.31503e-06\n",
      "[2958]\ttraining's binary_logloss: 5.3123e-06\n",
      "[2959]\ttraining's binary_logloss: 5.30921e-06\n",
      "[2960]\ttraining's binary_logloss: 5.30648e-06\n",
      "[2961]\ttraining's binary_logloss: 5.30294e-06\n",
      "[2962]\ttraining's binary_logloss: 5.29968e-06\n",
      "[2963]\ttraining's binary_logloss: 5.29621e-06\n",
      "[2964]\ttraining's binary_logloss: 5.29319e-06\n",
      "[2965]\ttraining's binary_logloss: 5.29047e-06\n",
      "[2966]\ttraining's binary_logloss: 5.28709e-06\n",
      "[2967]\ttraining's binary_logloss: 5.28386e-06\n",
      "[2968]\ttraining's binary_logloss: 5.28006e-06\n",
      "[2969]\ttraining's binary_logloss: 5.27651e-06\n",
      "[2970]\ttraining's binary_logloss: 5.27356e-06\n",
      "[2971]\ttraining's binary_logloss: 5.27011e-06\n",
      "[2972]\ttraining's binary_logloss: 5.26702e-06\n",
      "[2973]\ttraining's binary_logloss: 5.26366e-06\n",
      "[2974]\ttraining's binary_logloss: 5.26016e-06\n",
      "[2975]\ttraining's binary_logloss: 5.25729e-06\n",
      "[2976]\ttraining's binary_logloss: 5.25467e-06\n",
      "[2977]\ttraining's binary_logloss: 5.25113e-06\n",
      "[2978]\ttraining's binary_logloss: 5.24805e-06\n",
      "[2979]\ttraining's binary_logloss: 5.24517e-06\n",
      "[2980]\ttraining's binary_logloss: 5.24175e-06\n",
      "[2981]\ttraining's binary_logloss: 5.23836e-06\n",
      "[2982]\ttraining's binary_logloss: 5.23545e-06\n",
      "[2983]\ttraining's binary_logloss: 5.23168e-06\n",
      "[2984]\ttraining's binary_logloss: 5.22894e-06\n",
      "[2985]\ttraining's binary_logloss: 5.22595e-06\n",
      "[2986]\ttraining's binary_logloss: 5.22308e-06\n",
      "[2987]\ttraining's binary_logloss: 5.21977e-06\n",
      "[2988]\ttraining's binary_logloss: 5.21695e-06\n",
      "[2989]\ttraining's binary_logloss: 5.21352e-06\n",
      "[2990]\ttraining's binary_logloss: 5.21068e-06\n",
      "[2991]\ttraining's binary_logloss: 5.20697e-06\n",
      "[2992]\ttraining's binary_logloss: 5.20418e-06\n",
      "[2993]\ttraining's binary_logloss: 5.20137e-06\n",
      "[2994]\ttraining's binary_logloss: 5.19882e-06\n",
      "[2995]\ttraining's binary_logloss: 5.1953e-06\n",
      "[2996]\ttraining's binary_logloss: 5.19224e-06\n",
      "[2997]\ttraining's binary_logloss: 5.18904e-06\n",
      "[2998]\ttraining's binary_logloss: 5.18658e-06\n",
      "[2999]\ttraining's binary_logloss: 5.18331e-06\n",
      "[3000]\ttraining's binary_logloss: 5.18045e-06\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = lgb.train(\n",
    "    lgbm_params,\n",
    "    lgtrain,\n",
    "    valid_sets=lgtrain,\n",
    "    num_boost_round=3000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lgb = lgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lgb = np.array([0 if i < 0.5 else 1 for i in predict_lgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7758187952600395"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(predict_lgb, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV based auroc score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(rf, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8463866032226383"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999925617375781"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(predict_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search, tune parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameters to search\n",
    "gridParams = {\n",
    "    'learning_rate': [0.0125, 0.0175, 0.0225],\n",
    "    'n_estimators': [40],\n",
    "    'num_leaves': [170, 220, 270, 320],\n",
    "    #'max_depth': [15, 25, 35],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'feature_fraction': [0.4, 0.5, 0.6]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classifier to use. Note that parameters have to be input manually\n",
    "# not as a dict!\n",
    "mdl = lgb.LGBMClassifier(boosting_type= 'gbdt', objective = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(mdl, gridParams, verbose=0, cv=5, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/data/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "        n_jobs=-1, num_leaves=31, objective='binary', random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=0),\n",
       "       fit_params=None, iid=True, n_jobs=2,\n",
       "       param_grid={'learning_rate': [0.0125, 0.0175, 0.0225], 'n_estimators': [40], 'num_leaves': [170, 220, 270, 320], 'boosting_type': ['gbdt'], 'objective': ['binary'], 'feature_fraction': [0.4, 0.5, 0.6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'gbdt', 'feature_fraction': 0.5, 'learning_rate': 0.0225, 'n_estimators': 40, 'num_leaves': 320, 'objective': 'binary'}\n",
      "0.8844150432336702\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters found\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using parameters already set above, replace in the best from the grid search\n",
    "\n",
    "# params['max_bin'] = grid.best_params_['max_bin']\n",
    "lgbm_params['feature_fraction'] = grid.best_params_['feature_fraction']\n",
    "lgbm_params['learning_rate'] = grid.best_params_['learning_rate']\n",
    "lgbm_params['num_leaves'] = grid.best_params_['num_leaves']\n",
    "#lgbm_params['max_depth'] = grid.best_params_['max_depth']\n",
    "#lgbm_params['reg_alpha'] = grid.best_params_['reg_alpha']\n",
    "#lgbm_params['reg_lambda'] = grid.best_params_['reg_lambda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with params: \n",
      "{'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'binary_logloss', 'num_leaves': 320, 'feature_fraction': 0.5, 'bagging_fraction': 0.75, 'bagging_freq': 2, 'learning_rate': 0.0225, 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "print('Fitting with params: ')\n",
    "print(lgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'binary_logloss', 'num_leaves': 320, 'feature_fraction': 0.5, 'bagging_fraction': 0.75, 'bagging_freq': 2, 'learning_rate': 0.0225, 'verbose': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgtrain = lgb.Dataset(X_train, y_train)\n",
    "lgtest = lgb.Dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.48389\n",
      "[2]\ttraining's binary_logloss: 0.474278\n",
      "[3]\ttraining's binary_logloss: 0.465419\n",
      "[4]\ttraining's binary_logloss: 0.457028\n",
      "[5]\ttraining's binary_logloss: 0.449707\n",
      "[6]\ttraining's binary_logloss: 0.441757\n",
      "[7]\ttraining's binary_logloss: 0.434344\n",
      "[8]\ttraining's binary_logloss: 0.426919\n",
      "[9]\ttraining's binary_logloss: 0.420335\n",
      "[10]\ttraining's binary_logloss: 0.413895\n",
      "[11]\ttraining's binary_logloss: 0.407566\n",
      "[12]\ttraining's binary_logloss: 0.40167\n",
      "[13]\ttraining's binary_logloss: 0.39614\n",
      "[14]\ttraining's binary_logloss: 0.390756\n",
      "[15]\ttraining's binary_logloss: 0.385582\n",
      "[16]\ttraining's binary_logloss: 0.38014\n",
      "[17]\ttraining's binary_logloss: 0.375172\n",
      "[18]\ttraining's binary_logloss: 0.370514\n",
      "[19]\ttraining's binary_logloss: 0.365811\n",
      "[20]\ttraining's binary_logloss: 0.361176\n",
      "[21]\ttraining's binary_logloss: 0.356688\n",
      "[22]\ttraining's binary_logloss: 0.352116\n",
      "[23]\ttraining's binary_logloss: 0.34796\n",
      "[24]\ttraining's binary_logloss: 0.343785\n",
      "[25]\ttraining's binary_logloss: 0.339794\n",
      "[26]\ttraining's binary_logloss: 0.33588\n",
      "[27]\ttraining's binary_logloss: 0.331926\n",
      "[28]\ttraining's binary_logloss: 0.328377\n",
      "[29]\ttraining's binary_logloss: 0.324875\n",
      "[30]\ttraining's binary_logloss: 0.321391\n",
      "[31]\ttraining's binary_logloss: 0.31785\n",
      "[32]\ttraining's binary_logloss: 0.314609\n",
      "[33]\ttraining's binary_logloss: 0.311225\n",
      "[34]\ttraining's binary_logloss: 0.307998\n",
      "[35]\ttraining's binary_logloss: 0.304963\n",
      "[36]\ttraining's binary_logloss: 0.301751\n",
      "[37]\ttraining's binary_logloss: 0.298596\n",
      "[38]\ttraining's binary_logloss: 0.295711\n",
      "[39]\ttraining's binary_logloss: 0.292763\n",
      "[40]\ttraining's binary_logloss: 0.289903\n",
      "[41]\ttraining's binary_logloss: 0.28704\n",
      "[42]\ttraining's binary_logloss: 0.284316\n",
      "[43]\ttraining's binary_logloss: 0.281667\n",
      "[44]\ttraining's binary_logloss: 0.279147\n",
      "[45]\ttraining's binary_logloss: 0.276534\n",
      "[46]\ttraining's binary_logloss: 0.274064\n",
      "[47]\ttraining's binary_logloss: 0.27163\n",
      "[48]\ttraining's binary_logloss: 0.269189\n",
      "[49]\ttraining's binary_logloss: 0.266743\n",
      "[50]\ttraining's binary_logloss: 0.264314\n",
      "[51]\ttraining's binary_logloss: 0.262045\n",
      "[52]\ttraining's binary_logloss: 0.25983\n",
      "[53]\ttraining's binary_logloss: 0.257627\n",
      "[54]\ttraining's binary_logloss: 0.255391\n",
      "[55]\ttraining's binary_logloss: 0.253225\n",
      "[56]\ttraining's binary_logloss: 0.25102\n",
      "[57]\ttraining's binary_logloss: 0.24882\n",
      "[58]\ttraining's binary_logloss: 0.246724\n",
      "[59]\ttraining's binary_logloss: 0.244707\n",
      "[60]\ttraining's binary_logloss: 0.242665\n",
      "[61]\ttraining's binary_logloss: 0.240807\n",
      "[62]\ttraining's binary_logloss: 0.238826\n",
      "[63]\ttraining's binary_logloss: 0.236873\n",
      "[64]\ttraining's binary_logloss: 0.235035\n",
      "[65]\ttraining's binary_logloss: 0.233135\n",
      "[66]\ttraining's binary_logloss: 0.231166\n",
      "[67]\ttraining's binary_logloss: 0.229303\n",
      "[68]\ttraining's binary_logloss: 0.227568\n",
      "[69]\ttraining's binary_logloss: 0.225828\n",
      "[70]\ttraining's binary_logloss: 0.224051\n",
      "[71]\ttraining's binary_logloss: 0.222278\n",
      "[72]\ttraining's binary_logloss: 0.220558\n",
      "[73]\ttraining's binary_logloss: 0.218765\n",
      "[74]\ttraining's binary_logloss: 0.217069\n",
      "[75]\ttraining's binary_logloss: 0.215451\n",
      "[76]\ttraining's binary_logloss: 0.213757\n",
      "[77]\ttraining's binary_logloss: 0.212185\n",
      "[78]\ttraining's binary_logloss: 0.210671\n",
      "[79]\ttraining's binary_logloss: 0.209083\n",
      "[80]\ttraining's binary_logloss: 0.207497\n",
      "[81]\ttraining's binary_logloss: 0.205949\n",
      "[82]\ttraining's binary_logloss: 0.204476\n",
      "[83]\ttraining's binary_logloss: 0.202964\n",
      "[84]\ttraining's binary_logloss: 0.20142\n",
      "[85]\ttraining's binary_logloss: 0.200025\n",
      "[86]\ttraining's binary_logloss: 0.198529\n",
      "[87]\ttraining's binary_logloss: 0.196976\n",
      "[88]\ttraining's binary_logloss: 0.195546\n",
      "[89]\ttraining's binary_logloss: 0.194201\n",
      "[90]\ttraining's binary_logloss: 0.192775\n",
      "[91]\ttraining's binary_logloss: 0.191268\n",
      "[92]\ttraining's binary_logloss: 0.189935\n",
      "[93]\ttraining's binary_logloss: 0.188561\n",
      "[94]\ttraining's binary_logloss: 0.187187\n",
      "[95]\ttraining's binary_logloss: 0.185834\n",
      "[96]\ttraining's binary_logloss: 0.184448\n",
      "[97]\ttraining's binary_logloss: 0.18319\n",
      "[98]\ttraining's binary_logloss: 0.181883\n",
      "[99]\ttraining's binary_logloss: 0.180548\n",
      "[100]\ttraining's binary_logloss: 0.179316\n",
      "[101]\ttraining's binary_logloss: 0.177953\n",
      "[102]\ttraining's binary_logloss: 0.176676\n",
      "[103]\ttraining's binary_logloss: 0.175366\n",
      "[104]\ttraining's binary_logloss: 0.174167\n",
      "[105]\ttraining's binary_logloss: 0.172906\n",
      "[106]\ttraining's binary_logloss: 0.171642\n",
      "[107]\ttraining's binary_logloss: 0.170473\n",
      "[108]\ttraining's binary_logloss: 0.169299\n",
      "[109]\ttraining's binary_logloss: 0.168141\n",
      "[110]\ttraining's binary_logloss: 0.167043\n",
      "[111]\ttraining's binary_logloss: 0.165885\n",
      "[112]\ttraining's binary_logloss: 0.164785\n",
      "[113]\ttraining's binary_logloss: 0.16351\n",
      "[114]\ttraining's binary_logloss: 0.162349\n",
      "[115]\ttraining's binary_logloss: 0.161207\n",
      "[116]\ttraining's binary_logloss: 0.160102\n",
      "[117]\ttraining's binary_logloss: 0.158935\n",
      "[118]\ttraining's binary_logloss: 0.157782\n",
      "[119]\ttraining's binary_logloss: 0.156673\n",
      "[120]\ttraining's binary_logloss: 0.155495\n",
      "[121]\ttraining's binary_logloss: 0.154451\n",
      "[122]\ttraining's binary_logloss: 0.153344\n",
      "[123]\ttraining's binary_logloss: 0.152283\n",
      "[124]\ttraining's binary_logloss: 0.151225\n",
      "[125]\ttraining's binary_logloss: 0.150157\n",
      "[126]\ttraining's binary_logloss: 0.14907\n",
      "[127]\ttraining's binary_logloss: 0.148051\n",
      "[128]\ttraining's binary_logloss: 0.147054\n",
      "[129]\ttraining's binary_logloss: 0.145918\n",
      "[130]\ttraining's binary_logloss: 0.144898\n",
      "[131]\ttraining's binary_logloss: 0.143899\n",
      "[132]\ttraining's binary_logloss: 0.142856\n",
      "[133]\ttraining's binary_logloss: 0.141863\n",
      "[134]\ttraining's binary_logloss: 0.140812\n",
      "[135]\ttraining's binary_logloss: 0.139869\n",
      "[136]\ttraining's binary_logloss: 0.138898\n",
      "[137]\ttraining's binary_logloss: 0.138016\n",
      "[138]\ttraining's binary_logloss: 0.137116\n",
      "[139]\ttraining's binary_logloss: 0.136234\n",
      "[140]\ttraining's binary_logloss: 0.135283\n",
      "[141]\ttraining's binary_logloss: 0.134418\n",
      "[142]\ttraining's binary_logloss: 0.133557\n",
      "[143]\ttraining's binary_logloss: 0.132647\n",
      "[144]\ttraining's binary_logloss: 0.131731\n",
      "[145]\ttraining's binary_logloss: 0.130788\n",
      "[146]\ttraining's binary_logloss: 0.129894\n",
      "[147]\ttraining's binary_logloss: 0.129033\n",
      "[148]\ttraining's binary_logloss: 0.128124\n",
      "[149]\ttraining's binary_logloss: 0.127225\n",
      "[150]\ttraining's binary_logloss: 0.12638\n",
      "[151]\ttraining's binary_logloss: 0.125552\n",
      "[152]\ttraining's binary_logloss: 0.124684\n",
      "[153]\ttraining's binary_logloss: 0.123791\n",
      "[154]\ttraining's binary_logloss: 0.122956\n",
      "[155]\ttraining's binary_logloss: 0.12207\n",
      "[156]\ttraining's binary_logloss: 0.121267\n",
      "[157]\ttraining's binary_logloss: 0.120388\n",
      "[158]\ttraining's binary_logloss: 0.119561\n",
      "[159]\ttraining's binary_logloss: 0.118714\n",
      "[160]\ttraining's binary_logloss: 0.117846\n",
      "[161]\ttraining's binary_logloss: 0.117083\n",
      "[162]\ttraining's binary_logloss: 0.116238\n",
      "[163]\ttraining's binary_logloss: 0.115433\n",
      "[164]\ttraining's binary_logloss: 0.114669\n",
      "[165]\ttraining's binary_logloss: 0.113867\n",
      "[166]\ttraining's binary_logloss: 0.113134\n",
      "[167]\ttraining's binary_logloss: 0.112297\n",
      "[168]\ttraining's binary_logloss: 0.111495\n",
      "[169]\ttraining's binary_logloss: 0.110681\n",
      "[170]\ttraining's binary_logloss: 0.109914\n",
      "[171]\ttraining's binary_logloss: 0.109045\n",
      "[172]\ttraining's binary_logloss: 0.108318\n",
      "[173]\ttraining's binary_logloss: 0.107609\n",
      "[174]\ttraining's binary_logloss: 0.106945\n",
      "[175]\ttraining's binary_logloss: 0.106254\n",
      "[176]\ttraining's binary_logloss: 0.105544\n",
      "[177]\ttraining's binary_logloss: 0.104791\n",
      "[178]\ttraining's binary_logloss: 0.104062\n",
      "[179]\ttraining's binary_logloss: 0.103398\n",
      "[180]\ttraining's binary_logloss: 0.102694\n",
      "[181]\ttraining's binary_logloss: 0.102016\n",
      "[182]\ttraining's binary_logloss: 0.10126\n",
      "[183]\ttraining's binary_logloss: 0.100562\n",
      "[184]\ttraining's binary_logloss: 0.09985\n",
      "[185]\ttraining's binary_logloss: 0.0991335\n",
      "[186]\ttraining's binary_logloss: 0.0984561\n",
      "[187]\ttraining's binary_logloss: 0.097779\n",
      "[188]\ttraining's binary_logloss: 0.0971024\n",
      "[189]\ttraining's binary_logloss: 0.096436\n",
      "[190]\ttraining's binary_logloss: 0.0958268\n",
      "[191]\ttraining's binary_logloss: 0.0951621\n",
      "[192]\ttraining's binary_logloss: 0.0944561\n",
      "[193]\ttraining's binary_logloss: 0.0938171\n",
      "[194]\ttraining's binary_logloss: 0.0932061\n",
      "[195]\ttraining's binary_logloss: 0.0925596\n",
      "[196]\ttraining's binary_logloss: 0.0919416\n",
      "[197]\ttraining's binary_logloss: 0.0912845\n",
      "[198]\ttraining's binary_logloss: 0.0906135\n",
      "[199]\ttraining's binary_logloss: 0.0899927\n",
      "[200]\ttraining's binary_logloss: 0.0893651\n",
      "[201]\ttraining's binary_logloss: 0.0887293\n",
      "[202]\ttraining's binary_logloss: 0.0881344\n",
      "[203]\ttraining's binary_logloss: 0.0875016\n",
      "[204]\ttraining's binary_logloss: 0.0869135\n",
      "[205]\ttraining's binary_logloss: 0.0863496\n",
      "[206]\ttraining's binary_logloss: 0.0857757\n",
      "[207]\ttraining's binary_logloss: 0.0852042\n",
      "[208]\ttraining's binary_logloss: 0.0846026\n",
      "[209]\ttraining's binary_logloss: 0.0840149\n",
      "[210]\ttraining's binary_logloss: 0.0835043\n",
      "[211]\ttraining's binary_logloss: 0.0829857\n",
      "[212]\ttraining's binary_logloss: 0.0824953\n",
      "[213]\ttraining's binary_logloss: 0.0819818\n",
      "[214]\ttraining's binary_logloss: 0.0814433\n",
      "[215]\ttraining's binary_logloss: 0.080919\n",
      "[216]\ttraining's binary_logloss: 0.0803866\n",
      "[217]\ttraining's binary_logloss: 0.07984\n",
      "[218]\ttraining's binary_logloss: 0.0792693\n",
      "[219]\ttraining's binary_logloss: 0.0787457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[220]\ttraining's binary_logloss: 0.078174\n",
      "[221]\ttraining's binary_logloss: 0.0776206\n",
      "[222]\ttraining's binary_logloss: 0.0770574\n",
      "[223]\ttraining's binary_logloss: 0.0765112\n",
      "[224]\ttraining's binary_logloss: 0.0760052\n",
      "[225]\ttraining's binary_logloss: 0.0754996\n",
      "[226]\ttraining's binary_logloss: 0.0749912\n",
      "[227]\ttraining's binary_logloss: 0.0744813\n",
      "[228]\ttraining's binary_logloss: 0.0739605\n",
      "[229]\ttraining's binary_logloss: 0.0735121\n",
      "[230]\ttraining's binary_logloss: 0.0730239\n",
      "[231]\ttraining's binary_logloss: 0.0725395\n",
      "[232]\ttraining's binary_logloss: 0.0720216\n",
      "[233]\ttraining's binary_logloss: 0.0715387\n",
      "[234]\ttraining's binary_logloss: 0.0710778\n",
      "[235]\ttraining's binary_logloss: 0.0706146\n",
      "[236]\ttraining's binary_logloss: 0.0701231\n",
      "[237]\ttraining's binary_logloss: 0.0696934\n",
      "[238]\ttraining's binary_logloss: 0.0691961\n",
      "[239]\ttraining's binary_logloss: 0.0687162\n",
      "[240]\ttraining's binary_logloss: 0.0682545\n",
      "[241]\ttraining's binary_logloss: 0.0678161\n",
      "[242]\ttraining's binary_logloss: 0.0673949\n",
      "[243]\ttraining's binary_logloss: 0.0669676\n",
      "[244]\ttraining's binary_logloss: 0.0665229\n",
      "[245]\ttraining's binary_logloss: 0.0660528\n",
      "[246]\ttraining's binary_logloss: 0.0656062\n",
      "[247]\ttraining's binary_logloss: 0.0651624\n",
      "[248]\ttraining's binary_logloss: 0.0647381\n",
      "[249]\ttraining's binary_logloss: 0.0642847\n",
      "[250]\ttraining's binary_logloss: 0.0638581\n",
      "[251]\ttraining's binary_logloss: 0.06344\n",
      "[252]\ttraining's binary_logloss: 0.0630531\n",
      "[253]\ttraining's binary_logloss: 0.0626722\n",
      "[254]\ttraining's binary_logloss: 0.0622765\n",
      "[255]\ttraining's binary_logloss: 0.0618364\n",
      "[256]\ttraining's binary_logloss: 0.061433\n",
      "[257]\ttraining's binary_logloss: 0.0610247\n",
      "[258]\ttraining's binary_logloss: 0.0606643\n",
      "[259]\ttraining's binary_logloss: 0.0602542\n",
      "[260]\ttraining's binary_logloss: 0.0598294\n",
      "[261]\ttraining's binary_logloss: 0.0594156\n",
      "[262]\ttraining's binary_logloss: 0.059027\n",
      "[263]\ttraining's binary_logloss: 0.0586649\n",
      "[264]\ttraining's binary_logloss: 0.0582875\n",
      "[265]\ttraining's binary_logloss: 0.0579197\n",
      "[266]\ttraining's binary_logloss: 0.0575503\n",
      "[267]\ttraining's binary_logloss: 0.0571957\n",
      "[268]\ttraining's binary_logloss: 0.0567927\n",
      "[269]\ttraining's binary_logloss: 0.0564421\n",
      "[270]\ttraining's binary_logloss: 0.0560656\n",
      "[271]\ttraining's binary_logloss: 0.0557202\n",
      "[272]\ttraining's binary_logloss: 0.0553626\n",
      "[273]\ttraining's binary_logloss: 0.0550011\n",
      "[274]\ttraining's binary_logloss: 0.0546002\n",
      "[275]\ttraining's binary_logloss: 0.0542049\n",
      "[276]\ttraining's binary_logloss: 0.0538394\n",
      "[277]\ttraining's binary_logloss: 0.0535113\n",
      "[278]\ttraining's binary_logloss: 0.053131\n",
      "[279]\ttraining's binary_logloss: 0.0527248\n",
      "[280]\ttraining's binary_logloss: 0.0523538\n",
      "[281]\ttraining's binary_logloss: 0.0520154\n",
      "[282]\ttraining's binary_logloss: 0.0516795\n",
      "[283]\ttraining's binary_logloss: 0.0513235\n",
      "[284]\ttraining's binary_logloss: 0.0510067\n",
      "[285]\ttraining's binary_logloss: 0.0506698\n",
      "[286]\ttraining's binary_logloss: 0.0503272\n",
      "[287]\ttraining's binary_logloss: 0.0500472\n",
      "[288]\ttraining's binary_logloss: 0.0497237\n",
      "[289]\ttraining's binary_logloss: 0.0493868\n",
      "[290]\ttraining's binary_logloss: 0.0490561\n",
      "[291]\ttraining's binary_logloss: 0.048739\n",
      "[292]\ttraining's binary_logloss: 0.048444\n",
      "[293]\ttraining's binary_logloss: 0.0481207\n",
      "[294]\ttraining's binary_logloss: 0.0478126\n",
      "[295]\ttraining's binary_logloss: 0.0475163\n",
      "[296]\ttraining's binary_logloss: 0.0472\n",
      "[297]\ttraining's binary_logloss: 0.0468743\n",
      "[298]\ttraining's binary_logloss: 0.0465651\n",
      "[299]\ttraining's binary_logloss: 0.0462799\n",
      "[300]\ttraining's binary_logloss: 0.0459647\n",
      "[301]\ttraining's binary_logloss: 0.0456547\n",
      "[302]\ttraining's binary_logloss: 0.0453626\n",
      "[303]\ttraining's binary_logloss: 0.045074\n",
      "[304]\ttraining's binary_logloss: 0.044784\n",
      "[305]\ttraining's binary_logloss: 0.0444812\n",
      "[306]\ttraining's binary_logloss: 0.0442042\n",
      "[307]\ttraining's binary_logloss: 0.0439177\n",
      "[308]\ttraining's binary_logloss: 0.0436461\n",
      "[309]\ttraining's binary_logloss: 0.0433738\n",
      "[310]\ttraining's binary_logloss: 0.0430868\n",
      "[311]\ttraining's binary_logloss: 0.0428418\n",
      "[312]\ttraining's binary_logloss: 0.042602\n",
      "[313]\ttraining's binary_logloss: 0.0423211\n",
      "[314]\ttraining's binary_logloss: 0.0420577\n",
      "[315]\ttraining's binary_logloss: 0.0417742\n",
      "[316]\ttraining's binary_logloss: 0.0415067\n",
      "[317]\ttraining's binary_logloss: 0.0412366\n",
      "[318]\ttraining's binary_logloss: 0.0409856\n",
      "[319]\ttraining's binary_logloss: 0.0406892\n",
      "[320]\ttraining's binary_logloss: 0.040435\n",
      "[321]\ttraining's binary_logloss: 0.0401732\n",
      "[322]\ttraining's binary_logloss: 0.0399282\n",
      "[323]\ttraining's binary_logloss: 0.0396797\n",
      "[324]\ttraining's binary_logloss: 0.0394374\n",
      "[325]\ttraining's binary_logloss: 0.039193\n",
      "[326]\ttraining's binary_logloss: 0.0389533\n",
      "[327]\ttraining's binary_logloss: 0.0386968\n",
      "[328]\ttraining's binary_logloss: 0.0384623\n",
      "[329]\ttraining's binary_logloss: 0.0382018\n",
      "[330]\ttraining's binary_logloss: 0.0379537\n",
      "[331]\ttraining's binary_logloss: 0.0377134\n",
      "[332]\ttraining's binary_logloss: 0.0374632\n",
      "[333]\ttraining's binary_logloss: 0.0372184\n",
      "[334]\ttraining's binary_logloss: 0.0369894\n",
      "[335]\ttraining's binary_logloss: 0.0367669\n",
      "[336]\ttraining's binary_logloss: 0.0365556\n",
      "[337]\ttraining's binary_logloss: 0.0363485\n",
      "[338]\ttraining's binary_logloss: 0.0361091\n",
      "[339]\ttraining's binary_logloss: 0.0358931\n",
      "[340]\ttraining's binary_logloss: 0.0356745\n",
      "[341]\ttraining's binary_logloss: 0.0354458\n",
      "[342]\ttraining's binary_logloss: 0.0352084\n",
      "[343]\ttraining's binary_logloss: 0.0349919\n",
      "[344]\ttraining's binary_logloss: 0.0347811\n",
      "[345]\ttraining's binary_logloss: 0.0345737\n",
      "[346]\ttraining's binary_logloss: 0.0343524\n",
      "[347]\ttraining's binary_logloss: 0.0341235\n",
      "[348]\ttraining's binary_logloss: 0.0338945\n",
      "[349]\ttraining's binary_logloss: 0.0336867\n",
      "[350]\ttraining's binary_logloss: 0.0334712\n",
      "[351]\ttraining's binary_logloss: 0.0332554\n",
      "[352]\ttraining's binary_logloss: 0.0330629\n",
      "[353]\ttraining's binary_logloss: 0.0328657\n",
      "[354]\ttraining's binary_logloss: 0.0326491\n",
      "[355]\ttraining's binary_logloss: 0.03245\n",
      "[356]\ttraining's binary_logloss: 0.032234\n",
      "[357]\ttraining's binary_logloss: 0.032023\n",
      "[358]\ttraining's binary_logloss: 0.0318063\n",
      "[359]\ttraining's binary_logloss: 0.0316041\n",
      "[360]\ttraining's binary_logloss: 0.0314165\n",
      "[361]\ttraining's binary_logloss: 0.0312439\n",
      "[362]\ttraining's binary_logloss: 0.0310625\n",
      "[363]\ttraining's binary_logloss: 0.0308718\n",
      "[364]\ttraining's binary_logloss: 0.0306873\n",
      "[365]\ttraining's binary_logloss: 0.0305074\n",
      "[366]\ttraining's binary_logloss: 0.0303409\n",
      "[367]\ttraining's binary_logloss: 0.0301551\n",
      "[368]\ttraining's binary_logloss: 0.0299741\n",
      "[369]\ttraining's binary_logloss: 0.0297747\n",
      "[370]\ttraining's binary_logloss: 0.0295662\n",
      "[371]\ttraining's binary_logloss: 0.0293802\n",
      "[372]\ttraining's binary_logloss: 0.0291886\n",
      "[373]\ttraining's binary_logloss: 0.0289764\n",
      "[374]\ttraining's binary_logloss: 0.0287946\n",
      "[375]\ttraining's binary_logloss: 0.0286268\n",
      "[376]\ttraining's binary_logloss: 0.0284586\n",
      "[377]\ttraining's binary_logloss: 0.0282892\n",
      "[378]\ttraining's binary_logloss: 0.0281189\n",
      "[379]\ttraining's binary_logloss: 0.0279391\n",
      "[380]\ttraining's binary_logloss: 0.0277586\n",
      "[381]\ttraining's binary_logloss: 0.0275879\n",
      "[382]\ttraining's binary_logloss: 0.0274139\n",
      "[383]\ttraining's binary_logloss: 0.0272431\n",
      "[384]\ttraining's binary_logloss: 0.0270786\n",
      "[385]\ttraining's binary_logloss: 0.0269105\n",
      "[386]\ttraining's binary_logloss: 0.0267494\n",
      "[387]\ttraining's binary_logloss: 0.0266015\n",
      "[388]\ttraining's binary_logloss: 0.026459\n",
      "[389]\ttraining's binary_logloss: 0.0263024\n",
      "[390]\ttraining's binary_logloss: 0.026142\n",
      "[391]\ttraining's binary_logloss: 0.0259887\n",
      "[392]\ttraining's binary_logloss: 0.0258404\n",
      "[393]\ttraining's binary_logloss: 0.0256966\n",
      "[394]\ttraining's binary_logloss: 0.0255466\n",
      "[395]\ttraining's binary_logloss: 0.025381\n",
      "[396]\ttraining's binary_logloss: 0.0252384\n",
      "[397]\ttraining's binary_logloss: 0.0250845\n",
      "[398]\ttraining's binary_logloss: 0.0249304\n",
      "[399]\ttraining's binary_logloss: 0.0247907\n",
      "[400]\ttraining's binary_logloss: 0.02464\n",
      "[401]\ttraining's binary_logloss: 0.0245066\n",
      "[402]\ttraining's binary_logloss: 0.0243691\n",
      "[403]\ttraining's binary_logloss: 0.0242169\n",
      "[404]\ttraining's binary_logloss: 0.0240586\n",
      "[405]\ttraining's binary_logloss: 0.0238929\n",
      "[406]\ttraining's binary_logloss: 0.0237509\n",
      "[407]\ttraining's binary_logloss: 0.0236053\n",
      "[408]\ttraining's binary_logloss: 0.0234506\n",
      "[409]\ttraining's binary_logloss: 0.0232926\n",
      "[410]\ttraining's binary_logloss: 0.023143\n",
      "[411]\ttraining's binary_logloss: 0.023\n",
      "[412]\ttraining's binary_logloss: 0.022864\n",
      "[413]\ttraining's binary_logloss: 0.022736\n",
      "[414]\ttraining's binary_logloss: 0.0225937\n",
      "[415]\ttraining's binary_logloss: 0.0224534\n",
      "[416]\ttraining's binary_logloss: 0.0223085\n",
      "[417]\ttraining's binary_logloss: 0.0221728\n",
      "[418]\ttraining's binary_logloss: 0.0220428\n",
      "[419]\ttraining's binary_logloss: 0.0219213\n",
      "[420]\ttraining's binary_logloss: 0.0217951\n",
      "[421]\ttraining's binary_logloss: 0.0216604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[422]\ttraining's binary_logloss: 0.0215401\n",
      "[423]\ttraining's binary_logloss: 0.0214098\n",
      "[424]\ttraining's binary_logloss: 0.0212868\n",
      "[425]\ttraining's binary_logloss: 0.0211618\n",
      "[426]\ttraining's binary_logloss: 0.0210383\n",
      "[427]\ttraining's binary_logloss: 0.0209066\n",
      "[428]\ttraining's binary_logloss: 0.0207839\n",
      "[429]\ttraining's binary_logloss: 0.0206506\n",
      "[430]\ttraining's binary_logloss: 0.0205182\n",
      "[431]\ttraining's binary_logloss: 0.0203889\n",
      "[432]\ttraining's binary_logloss: 0.0202745\n",
      "[433]\ttraining's binary_logloss: 0.020153\n",
      "[434]\ttraining's binary_logloss: 0.020022\n",
      "[435]\ttraining's binary_logloss: 0.0199043\n",
      "[436]\ttraining's binary_logloss: 0.0197824\n",
      "[437]\ttraining's binary_logloss: 0.0196756\n",
      "[438]\ttraining's binary_logloss: 0.0195644\n",
      "[439]\ttraining's binary_logloss: 0.0194422\n",
      "[440]\ttraining's binary_logloss: 0.0193272\n",
      "[441]\ttraining's binary_logloss: 0.0192142\n",
      "[442]\ttraining's binary_logloss: 0.01912\n",
      "[443]\ttraining's binary_logloss: 0.0189857\n",
      "[444]\ttraining's binary_logloss: 0.0188637\n",
      "[445]\ttraining's binary_logloss: 0.018757\n",
      "[446]\ttraining's binary_logloss: 0.0186405\n",
      "[447]\ttraining's binary_logloss: 0.0185085\n",
      "[448]\ttraining's binary_logloss: 0.0183884\n",
      "[449]\ttraining's binary_logloss: 0.0182764\n",
      "[450]\ttraining's binary_logloss: 0.0181661\n",
      "[451]\ttraining's binary_logloss: 0.0180517\n",
      "[452]\ttraining's binary_logloss: 0.0179468\n",
      "[453]\ttraining's binary_logloss: 0.0178401\n",
      "[454]\ttraining's binary_logloss: 0.0177384\n",
      "[455]\ttraining's binary_logloss: 0.0176366\n",
      "[456]\ttraining's binary_logloss: 0.0175342\n",
      "[457]\ttraining's binary_logloss: 0.0174358\n",
      "[458]\ttraining's binary_logloss: 0.0173372\n",
      "[459]\ttraining's binary_logloss: 0.017237\n",
      "[460]\ttraining's binary_logloss: 0.0171436\n",
      "[461]\ttraining's binary_logloss: 0.0170401\n",
      "[462]\ttraining's binary_logloss: 0.0169354\n",
      "[463]\ttraining's binary_logloss: 0.0168398\n",
      "[464]\ttraining's binary_logloss: 0.0167435\n",
      "[465]\ttraining's binary_logloss: 0.0166525\n",
      "[466]\ttraining's binary_logloss: 0.0165558\n",
      "[467]\ttraining's binary_logloss: 0.0164448\n",
      "[468]\ttraining's binary_logloss: 0.0163424\n",
      "[469]\ttraining's binary_logloss: 0.016253\n",
      "[470]\ttraining's binary_logloss: 0.0161583\n",
      "[471]\ttraining's binary_logloss: 0.0160612\n",
      "[472]\ttraining's binary_logloss: 0.0159694\n",
      "[473]\ttraining's binary_logloss: 0.0158733\n",
      "[474]\ttraining's binary_logloss: 0.0157776\n",
      "[475]\ttraining's binary_logloss: 0.0156838\n",
      "[476]\ttraining's binary_logloss: 0.0155926\n",
      "[477]\ttraining's binary_logloss: 0.0154861\n",
      "[478]\ttraining's binary_logloss: 0.0153973\n",
      "[479]\ttraining's binary_logloss: 0.0153137\n",
      "[480]\ttraining's binary_logloss: 0.0152324\n",
      "[481]\ttraining's binary_logloss: 0.0151451\n",
      "[482]\ttraining's binary_logloss: 0.0150568\n",
      "[483]\ttraining's binary_logloss: 0.0149749\n",
      "[484]\ttraining's binary_logloss: 0.0148899\n",
      "[485]\ttraining's binary_logloss: 0.0148076\n",
      "[486]\ttraining's binary_logloss: 0.0147238\n",
      "[487]\ttraining's binary_logloss: 0.0146386\n",
      "[488]\ttraining's binary_logloss: 0.0145584\n",
      "[489]\ttraining's binary_logloss: 0.0144732\n",
      "[490]\ttraining's binary_logloss: 0.0143796\n",
      "[491]\ttraining's binary_logloss: 0.014294\n",
      "[492]\ttraining's binary_logloss: 0.0142034\n",
      "[493]\ttraining's binary_logloss: 0.0141227\n",
      "[494]\ttraining's binary_logloss: 0.0140313\n",
      "[495]\ttraining's binary_logloss: 0.0139496\n",
      "[496]\ttraining's binary_logloss: 0.0138707\n",
      "[497]\ttraining's binary_logloss: 0.0137919\n",
      "[498]\ttraining's binary_logloss: 0.0137107\n",
      "[499]\ttraining's binary_logloss: 0.0136251\n",
      "[500]\ttraining's binary_logloss: 0.0135386\n",
      "[501]\ttraining's binary_logloss: 0.0134539\n",
      "[502]\ttraining's binary_logloss: 0.013378\n",
      "[503]\ttraining's binary_logloss: 0.0132934\n",
      "[504]\ttraining's binary_logloss: 0.0132183\n",
      "[505]\ttraining's binary_logloss: 0.0131398\n",
      "[506]\ttraining's binary_logloss: 0.013066\n",
      "[507]\ttraining's binary_logloss: 0.0129974\n",
      "[508]\ttraining's binary_logloss: 0.0129196\n",
      "[509]\ttraining's binary_logloss: 0.0128348\n",
      "[510]\ttraining's binary_logloss: 0.0127563\n",
      "[511]\ttraining's binary_logloss: 0.0126745\n",
      "[512]\ttraining's binary_logloss: 0.0125998\n",
      "[513]\ttraining's binary_logloss: 0.0125293\n",
      "[514]\ttraining's binary_logloss: 0.0124558\n",
      "[515]\ttraining's binary_logloss: 0.0123793\n",
      "[516]\ttraining's binary_logloss: 0.0123052\n",
      "[517]\ttraining's binary_logloss: 0.0122332\n",
      "[518]\ttraining's binary_logloss: 0.0121666\n",
      "[519]\ttraining's binary_logloss: 0.0120994\n",
      "[520]\ttraining's binary_logloss: 0.0120255\n",
      "[521]\ttraining's binary_logloss: 0.0119536\n",
      "[522]\ttraining's binary_logloss: 0.01188\n",
      "[523]\ttraining's binary_logloss: 0.0118106\n",
      "[524]\ttraining's binary_logloss: 0.011733\n",
      "[525]\ttraining's binary_logloss: 0.011664\n",
      "[526]\ttraining's binary_logloss: 0.0116001\n",
      "[527]\ttraining's binary_logloss: 0.0115152\n",
      "[528]\ttraining's binary_logloss: 0.0114471\n",
      "[529]\ttraining's binary_logloss: 0.0113752\n",
      "[530]\ttraining's binary_logloss: 0.0113124\n",
      "[531]\ttraining's binary_logloss: 0.0112455\n",
      "[532]\ttraining's binary_logloss: 0.0111819\n",
      "[533]\ttraining's binary_logloss: 0.0111134\n",
      "[534]\ttraining's binary_logloss: 0.0110415\n",
      "[535]\ttraining's binary_logloss: 0.0109703\n",
      "[536]\ttraining's binary_logloss: 0.0109048\n",
      "[537]\ttraining's binary_logloss: 0.0108433\n",
      "[538]\ttraining's binary_logloss: 0.0107779\n",
      "[539]\ttraining's binary_logloss: 0.010714\n",
      "[540]\ttraining's binary_logloss: 0.010655\n",
      "[541]\ttraining's binary_logloss: 0.0105869\n",
      "[542]\ttraining's binary_logloss: 0.010521\n",
      "[543]\ttraining's binary_logloss: 0.0104553\n",
      "[544]\ttraining's binary_logloss: 0.0103988\n",
      "[545]\ttraining's binary_logloss: 0.0103386\n",
      "[546]\ttraining's binary_logloss: 0.0102763\n",
      "[547]\ttraining's binary_logloss: 0.0102224\n",
      "[548]\ttraining's binary_logloss: 0.0101652\n",
      "[549]\ttraining's binary_logloss: 0.0100976\n",
      "[550]\ttraining's binary_logloss: 0.0100357\n",
      "[551]\ttraining's binary_logloss: 0.00998089\n",
      "[552]\ttraining's binary_logloss: 0.0099246\n",
      "[553]\ttraining's binary_logloss: 0.00986666\n",
      "[554]\ttraining's binary_logloss: 0.0097993\n",
      "[555]\ttraining's binary_logloss: 0.00974269\n",
      "[556]\ttraining's binary_logloss: 0.00968819\n",
      "[557]\ttraining's binary_logloss: 0.00962888\n",
      "[558]\ttraining's binary_logloss: 0.00957491\n",
      "[559]\ttraining's binary_logloss: 0.00951516\n",
      "[560]\ttraining's binary_logloss: 0.00945512\n",
      "[561]\ttraining's binary_logloss: 0.00940101\n",
      "[562]\ttraining's binary_logloss: 0.00935053\n",
      "[563]\ttraining's binary_logloss: 0.00928465\n",
      "[564]\ttraining's binary_logloss: 0.00922309\n",
      "[565]\ttraining's binary_logloss: 0.00916694\n",
      "[566]\ttraining's binary_logloss: 0.00910942\n",
      "[567]\ttraining's binary_logloss: 0.00906141\n",
      "[568]\ttraining's binary_logloss: 0.00900161\n",
      "[569]\ttraining's binary_logloss: 0.00894004\n",
      "[570]\ttraining's binary_logloss: 0.00888919\n",
      "[571]\ttraining's binary_logloss: 0.00884048\n",
      "[572]\ttraining's binary_logloss: 0.00879289\n",
      "[573]\ttraining's binary_logloss: 0.00874211\n",
      "[574]\ttraining's binary_logloss: 0.00868669\n",
      "[575]\ttraining's binary_logloss: 0.00862984\n",
      "[576]\ttraining's binary_logloss: 0.00858302\n",
      "[577]\ttraining's binary_logloss: 0.00853235\n",
      "[578]\ttraining's binary_logloss: 0.008485\n",
      "[579]\ttraining's binary_logloss: 0.0084384\n",
      "[580]\ttraining's binary_logloss: 0.00839\n",
      "[581]\ttraining's binary_logloss: 0.00834101\n",
      "[582]\ttraining's binary_logloss: 0.00829258\n",
      "[583]\ttraining's binary_logloss: 0.00824672\n",
      "[584]\ttraining's binary_logloss: 0.0081993\n",
      "[585]\ttraining's binary_logloss: 0.00815596\n",
      "[586]\ttraining's binary_logloss: 0.00810477\n",
      "[587]\ttraining's binary_logloss: 0.00804984\n",
      "[588]\ttraining's binary_logloss: 0.0080002\n",
      "[589]\ttraining's binary_logloss: 0.00795332\n",
      "[590]\ttraining's binary_logloss: 0.00790604\n",
      "[591]\ttraining's binary_logloss: 0.00785458\n",
      "[592]\ttraining's binary_logloss: 0.00780569\n",
      "[593]\ttraining's binary_logloss: 0.00776251\n",
      "[594]\ttraining's binary_logloss: 0.00772298\n",
      "[595]\ttraining's binary_logloss: 0.00767792\n",
      "[596]\ttraining's binary_logloss: 0.00763399\n",
      "[597]\ttraining's binary_logloss: 0.00758886\n",
      "[598]\ttraining's binary_logloss: 0.0075415\n",
      "[599]\ttraining's binary_logloss: 0.00750238\n",
      "[600]\ttraining's binary_logloss: 0.00746049\n",
      "[601]\ttraining's binary_logloss: 0.00742256\n",
      "[602]\ttraining's binary_logloss: 0.00737864\n",
      "[603]\ttraining's binary_logloss: 0.00732765\n",
      "[604]\ttraining's binary_logloss: 0.00728671\n",
      "[605]\ttraining's binary_logloss: 0.00724208\n",
      "[606]\ttraining's binary_logloss: 0.00718702\n",
      "[607]\ttraining's binary_logloss: 0.00714582\n",
      "[608]\ttraining's binary_logloss: 0.00709774\n",
      "[609]\ttraining's binary_logloss: 0.00705544\n",
      "[610]\ttraining's binary_logloss: 0.00700973\n",
      "[611]\ttraining's binary_logloss: 0.00696871\n",
      "[612]\ttraining's binary_logloss: 0.00693193\n",
      "[613]\ttraining's binary_logloss: 0.00689096\n",
      "[614]\ttraining's binary_logloss: 0.00685018\n",
      "[615]\ttraining's binary_logloss: 0.00680885\n",
      "[616]\ttraining's binary_logloss: 0.00676603\n",
      "[617]\ttraining's binary_logloss: 0.00672904\n",
      "[618]\ttraining's binary_logloss: 0.00668742\n",
      "[619]\ttraining's binary_logloss: 0.00664826\n",
      "[620]\ttraining's binary_logloss: 0.00660544\n",
      "[621]\ttraining's binary_logloss: 0.00656526\n",
      "[622]\ttraining's binary_logloss: 0.00652171\n",
      "[623]\ttraining's binary_logloss: 0.00648197\n",
      "[624]\ttraining's binary_logloss: 0.00644341\n",
      "[625]\ttraining's binary_logloss: 0.00640762\n",
      "[626]\ttraining's binary_logloss: 0.00637024\n",
      "[627]\ttraining's binary_logloss: 0.00633277\n",
      "[628]\ttraining's binary_logloss: 0.00629658\n",
      "[629]\ttraining's binary_logloss: 0.00625853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[630]\ttraining's binary_logloss: 0.00621669\n",
      "[631]\ttraining's binary_logloss: 0.006182\n",
      "[632]\ttraining's binary_logloss: 0.0061465\n",
      "[633]\ttraining's binary_logloss: 0.00610969\n",
      "[634]\ttraining's binary_logloss: 0.0060752\n",
      "[635]\ttraining's binary_logloss: 0.00603915\n",
      "[636]\ttraining's binary_logloss: 0.00600874\n",
      "[637]\ttraining's binary_logloss: 0.00597243\n",
      "[638]\ttraining's binary_logloss: 0.00593535\n",
      "[639]\ttraining's binary_logloss: 0.00589821\n",
      "[640]\ttraining's binary_logloss: 0.00586767\n",
      "[641]\ttraining's binary_logloss: 0.00583341\n",
      "[642]\ttraining's binary_logloss: 0.00580063\n",
      "[643]\ttraining's binary_logloss: 0.00575977\n",
      "[644]\ttraining's binary_logloss: 0.00572943\n",
      "[645]\ttraining's binary_logloss: 0.00569473\n",
      "[646]\ttraining's binary_logloss: 0.00566273\n",
      "[647]\ttraining's binary_logloss: 0.00562896\n",
      "[648]\ttraining's binary_logloss: 0.00559706\n",
      "[649]\ttraining's binary_logloss: 0.00556078\n",
      "[650]\ttraining's binary_logloss: 0.00553222\n",
      "[651]\ttraining's binary_logloss: 0.00549751\n",
      "[652]\ttraining's binary_logloss: 0.00546792\n",
      "[653]\ttraining's binary_logloss: 0.00543579\n",
      "[654]\ttraining's binary_logloss: 0.00540482\n",
      "[655]\ttraining's binary_logloss: 0.00537413\n",
      "[656]\ttraining's binary_logloss: 0.00534434\n",
      "[657]\ttraining's binary_logloss: 0.00531474\n",
      "[658]\ttraining's binary_logloss: 0.00528351\n",
      "[659]\ttraining's binary_logloss: 0.00525335\n",
      "[660]\ttraining's binary_logloss: 0.00522279\n",
      "[661]\ttraining's binary_logloss: 0.00519154\n",
      "[662]\ttraining's binary_logloss: 0.00516303\n",
      "[663]\ttraining's binary_logloss: 0.00513393\n",
      "[664]\ttraining's binary_logloss: 0.00510195\n",
      "[665]\ttraining's binary_logloss: 0.00507339\n",
      "[666]\ttraining's binary_logloss: 0.00504266\n",
      "[667]\ttraining's binary_logloss: 0.00501335\n",
      "[668]\ttraining's binary_logloss: 0.0049833\n",
      "[669]\ttraining's binary_logloss: 0.0049536\n",
      "[670]\ttraining's binary_logloss: 0.00492427\n",
      "[671]\ttraining's binary_logloss: 0.00489593\n",
      "[672]\ttraining's binary_logloss: 0.00486771\n",
      "[673]\ttraining's binary_logloss: 0.00483536\n",
      "[674]\ttraining's binary_logloss: 0.00480892\n",
      "[675]\ttraining's binary_logloss: 0.00478388\n",
      "[676]\ttraining's binary_logloss: 0.00476057\n",
      "[677]\ttraining's binary_logloss: 0.00473257\n",
      "[678]\ttraining's binary_logloss: 0.00470409\n",
      "[679]\ttraining's binary_logloss: 0.0046727\n",
      "[680]\ttraining's binary_logloss: 0.00464492\n",
      "[681]\ttraining's binary_logloss: 0.00461496\n",
      "[682]\ttraining's binary_logloss: 0.00458669\n",
      "[683]\ttraining's binary_logloss: 0.00455955\n",
      "[684]\ttraining's binary_logloss: 0.00453026\n",
      "[685]\ttraining's binary_logloss: 0.00450101\n",
      "[686]\ttraining's binary_logloss: 0.00447694\n",
      "[687]\ttraining's binary_logloss: 0.00445165\n",
      "[688]\ttraining's binary_logloss: 0.00442697\n",
      "[689]\ttraining's binary_logloss: 0.00440516\n",
      "[690]\ttraining's binary_logloss: 0.00437836\n",
      "[691]\ttraining's binary_logloss: 0.00435432\n",
      "[692]\ttraining's binary_logloss: 0.00432922\n",
      "[693]\ttraining's binary_logloss: 0.00430277\n",
      "[694]\ttraining's binary_logloss: 0.00427691\n",
      "[695]\ttraining's binary_logloss: 0.00424903\n",
      "[696]\ttraining's binary_logloss: 0.00422557\n",
      "[697]\ttraining's binary_logloss: 0.00420417\n",
      "[698]\ttraining's binary_logloss: 0.00418158\n",
      "[699]\ttraining's binary_logloss: 0.00415747\n",
      "[700]\ttraining's binary_logloss: 0.00413277\n",
      "[701]\ttraining's binary_logloss: 0.00410774\n",
      "[702]\ttraining's binary_logloss: 0.00408689\n",
      "[703]\ttraining's binary_logloss: 0.00406125\n",
      "[704]\ttraining's binary_logloss: 0.00403829\n",
      "[705]\ttraining's binary_logloss: 0.0040131\n",
      "[706]\ttraining's binary_logloss: 0.00398678\n",
      "[707]\ttraining's binary_logloss: 0.0039631\n",
      "[708]\ttraining's binary_logloss: 0.00394048\n",
      "[709]\ttraining's binary_logloss: 0.0039185\n",
      "[710]\ttraining's binary_logloss: 0.00389887\n",
      "[711]\ttraining's binary_logloss: 0.00387556\n",
      "[712]\ttraining's binary_logloss: 0.00385425\n",
      "[713]\ttraining's binary_logloss: 0.00383288\n",
      "[714]\ttraining's binary_logloss: 0.00380974\n",
      "[715]\ttraining's binary_logloss: 0.00378667\n",
      "[716]\ttraining's binary_logloss: 0.0037607\n",
      "[717]\ttraining's binary_logloss: 0.00374086\n",
      "[718]\ttraining's binary_logloss: 0.00371987\n",
      "[719]\ttraining's binary_logloss: 0.00369097\n",
      "[720]\ttraining's binary_logloss: 0.00366996\n",
      "[721]\ttraining's binary_logloss: 0.00364757\n",
      "[722]\ttraining's binary_logloss: 0.00362445\n",
      "[723]\ttraining's binary_logloss: 0.00360405\n",
      "[724]\ttraining's binary_logloss: 0.00358483\n",
      "[725]\ttraining's binary_logloss: 0.00356589\n",
      "[726]\ttraining's binary_logloss: 0.00354762\n",
      "[727]\ttraining's binary_logloss: 0.00352757\n",
      "[728]\ttraining's binary_logloss: 0.00350876\n",
      "[729]\ttraining's binary_logloss: 0.00348646\n",
      "[730]\ttraining's binary_logloss: 0.00346993\n",
      "[731]\ttraining's binary_logloss: 0.00344787\n",
      "[732]\ttraining's binary_logloss: 0.00342851\n",
      "[733]\ttraining's binary_logloss: 0.00340733\n",
      "[734]\ttraining's binary_logloss: 0.00338682\n",
      "[735]\ttraining's binary_logloss: 0.00336462\n",
      "[736]\ttraining's binary_logloss: 0.00334368\n",
      "[737]\ttraining's binary_logloss: 0.00332314\n",
      "[738]\ttraining's binary_logloss: 0.00330144\n",
      "[739]\ttraining's binary_logloss: 0.00328375\n",
      "[740]\ttraining's binary_logloss: 0.00326165\n",
      "[741]\ttraining's binary_logloss: 0.00324446\n",
      "[742]\ttraining's binary_logloss: 0.00322613\n",
      "[743]\ttraining's binary_logloss: 0.00320554\n",
      "[744]\ttraining's binary_logloss: 0.00318862\n",
      "[745]\ttraining's binary_logloss: 0.00317019\n",
      "[746]\ttraining's binary_logloss: 0.00315305\n",
      "[747]\ttraining's binary_logloss: 0.00313444\n",
      "[748]\ttraining's binary_logloss: 0.00311666\n",
      "[749]\ttraining's binary_logloss: 0.0031011\n",
      "[750]\ttraining's binary_logloss: 0.00308332\n",
      "[751]\ttraining's binary_logloss: 0.00306554\n",
      "[752]\ttraining's binary_logloss: 0.0030482\n",
      "[753]\ttraining's binary_logloss: 0.00303076\n",
      "[754]\ttraining's binary_logloss: 0.00301252\n",
      "[755]\ttraining's binary_logloss: 0.00299281\n",
      "[756]\ttraining's binary_logloss: 0.00297374\n",
      "[757]\ttraining's binary_logloss: 0.00295739\n",
      "[758]\ttraining's binary_logloss: 0.00293948\n",
      "[759]\ttraining's binary_logloss: 0.00292321\n",
      "[760]\ttraining's binary_logloss: 0.00290786\n",
      "[761]\ttraining's binary_logloss: 0.0028925\n",
      "[762]\ttraining's binary_logloss: 0.0028781\n",
      "[763]\ttraining's binary_logloss: 0.00286125\n",
      "[764]\ttraining's binary_logloss: 0.00284469\n",
      "[765]\ttraining's binary_logloss: 0.0028285\n",
      "[766]\ttraining's binary_logloss: 0.00281226\n",
      "[767]\ttraining's binary_logloss: 0.00279886\n",
      "[768]\ttraining's binary_logloss: 0.00278269\n",
      "[769]\ttraining's binary_logloss: 0.00276728\n",
      "[770]\ttraining's binary_logloss: 0.00275248\n",
      "[771]\ttraining's binary_logloss: 0.00273835\n",
      "[772]\ttraining's binary_logloss: 0.00272387\n",
      "[773]\ttraining's binary_logloss: 0.00271139\n",
      "[774]\ttraining's binary_logloss: 0.0026962\n",
      "[775]\ttraining's binary_logloss: 0.00267829\n",
      "[776]\ttraining's binary_logloss: 0.00266465\n",
      "[777]\ttraining's binary_logloss: 0.00264777\n",
      "[778]\ttraining's binary_logloss: 0.00263212\n",
      "[779]\ttraining's binary_logloss: 0.00261776\n",
      "[780]\ttraining's binary_logloss: 0.00260315\n",
      "[781]\ttraining's binary_logloss: 0.00258838\n",
      "[782]\ttraining's binary_logloss: 0.00257133\n",
      "[783]\ttraining's binary_logloss: 0.00255701\n",
      "[784]\ttraining's binary_logloss: 0.00254377\n",
      "[785]\ttraining's binary_logloss: 0.00252875\n",
      "[786]\ttraining's binary_logloss: 0.00251309\n",
      "[787]\ttraining's binary_logloss: 0.00249936\n",
      "[788]\ttraining's binary_logloss: 0.00248567\n",
      "[789]\ttraining's binary_logloss: 0.00247242\n",
      "[790]\ttraining's binary_logloss: 0.00245918\n",
      "[791]\ttraining's binary_logloss: 0.00244475\n",
      "[792]\ttraining's binary_logloss: 0.00242986\n",
      "[793]\ttraining's binary_logloss: 0.00241744\n",
      "[794]\ttraining's binary_logloss: 0.00240105\n",
      "[795]\ttraining's binary_logloss: 0.00238796\n",
      "[796]\ttraining's binary_logloss: 0.00237072\n",
      "[797]\ttraining's binary_logloss: 0.00235406\n",
      "[798]\ttraining's binary_logloss: 0.00233999\n",
      "[799]\ttraining's binary_logloss: 0.00232592\n",
      "[800]\ttraining's binary_logloss: 0.00230972\n",
      "[801]\ttraining's binary_logloss: 0.00229761\n",
      "[802]\ttraining's binary_logloss: 0.00228528\n",
      "[803]\ttraining's binary_logloss: 0.00227214\n",
      "[804]\ttraining's binary_logloss: 0.00225862\n",
      "[805]\ttraining's binary_logloss: 0.00224349\n",
      "[806]\ttraining's binary_logloss: 0.0022304\n",
      "[807]\ttraining's binary_logloss: 0.00221724\n",
      "[808]\ttraining's binary_logloss: 0.0022038\n",
      "[809]\ttraining's binary_logloss: 0.00219114\n",
      "[810]\ttraining's binary_logloss: 0.00217728\n",
      "[811]\ttraining's binary_logloss: 0.00216528\n",
      "[812]\ttraining's binary_logloss: 0.0021523\n",
      "[813]\ttraining's binary_logloss: 0.00214035\n",
      "[814]\ttraining's binary_logloss: 0.00212822\n",
      "[815]\ttraining's binary_logloss: 0.00211557\n",
      "[816]\ttraining's binary_logloss: 0.00210282\n",
      "[817]\ttraining's binary_logloss: 0.00209307\n",
      "[818]\ttraining's binary_logloss: 0.0020823\n",
      "[819]\ttraining's binary_logloss: 0.00207044\n",
      "[820]\ttraining's binary_logloss: 0.00205872\n",
      "[821]\ttraining's binary_logloss: 0.00204797\n",
      "[822]\ttraining's binary_logloss: 0.00203636\n",
      "[823]\ttraining's binary_logloss: 0.00202429\n",
      "[824]\ttraining's binary_logloss: 0.00201102\n",
      "[825]\ttraining's binary_logloss: 0.00199997\n",
      "[826]\ttraining's binary_logloss: 0.00198726\n",
      "[827]\ttraining's binary_logloss: 0.00197557\n",
      "[828]\ttraining's binary_logloss: 0.00196425\n",
      "[829]\ttraining's binary_logloss: 0.00195201\n",
      "[830]\ttraining's binary_logloss: 0.00194222\n",
      "[831]\ttraining's binary_logloss: 0.00193229\n",
      "[832]\ttraining's binary_logloss: 0.00192082\n",
      "[833]\ttraining's binary_logloss: 0.00190887\n",
      "[834]\ttraining's binary_logloss: 0.00189658\n",
      "[835]\ttraining's binary_logloss: 0.00188615\n",
      "[836]\ttraining's binary_logloss: 0.00187699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[837]\ttraining's binary_logloss: 0.00186615\n",
      "[838]\ttraining's binary_logloss: 0.00185577\n",
      "[839]\ttraining's binary_logloss: 0.00184575\n",
      "[840]\ttraining's binary_logloss: 0.00183529\n",
      "[841]\ttraining's binary_logloss: 0.00182382\n",
      "[842]\ttraining's binary_logloss: 0.00181351\n",
      "[843]\ttraining's binary_logloss: 0.00180279\n",
      "[844]\ttraining's binary_logloss: 0.00179381\n",
      "[845]\ttraining's binary_logloss: 0.00178375\n",
      "[846]\ttraining's binary_logloss: 0.00177296\n",
      "[847]\ttraining's binary_logloss: 0.00176383\n",
      "[848]\ttraining's binary_logloss: 0.00175437\n",
      "[849]\ttraining's binary_logloss: 0.00174424\n",
      "[850]\ttraining's binary_logloss: 0.00173306\n",
      "[851]\ttraining's binary_logloss: 0.00172428\n",
      "[852]\ttraining's binary_logloss: 0.00171539\n",
      "[853]\ttraining's binary_logloss: 0.00170646\n",
      "[854]\ttraining's binary_logloss: 0.0016959\n",
      "[855]\ttraining's binary_logloss: 0.0016873\n",
      "[856]\ttraining's binary_logloss: 0.00167714\n",
      "[857]\ttraining's binary_logloss: 0.00166795\n",
      "[858]\ttraining's binary_logloss: 0.00165821\n",
      "[859]\ttraining's binary_logloss: 0.00164977\n",
      "[860]\ttraining's binary_logloss: 0.00164068\n",
      "[861]\ttraining's binary_logloss: 0.00163252\n",
      "[862]\ttraining's binary_logloss: 0.00162386\n",
      "[863]\ttraining's binary_logloss: 0.00161545\n",
      "[864]\ttraining's binary_logloss: 0.00160617\n",
      "[865]\ttraining's binary_logloss: 0.00159741\n",
      "[866]\ttraining's binary_logloss: 0.00158722\n",
      "[867]\ttraining's binary_logloss: 0.00157851\n",
      "[868]\ttraining's binary_logloss: 0.0015708\n",
      "[869]\ttraining's binary_logloss: 0.00156278\n",
      "[870]\ttraining's binary_logloss: 0.00155305\n",
      "[871]\ttraining's binary_logloss: 0.00154353\n",
      "[872]\ttraining's binary_logloss: 0.00153313\n",
      "[873]\ttraining's binary_logloss: 0.00152426\n",
      "[874]\ttraining's binary_logloss: 0.00151613\n",
      "[875]\ttraining's binary_logloss: 0.00150661\n",
      "[876]\ttraining's binary_logloss: 0.00149786\n",
      "[877]\ttraining's binary_logloss: 0.00148848\n",
      "[878]\ttraining's binary_logloss: 0.00147963\n",
      "[879]\ttraining's binary_logloss: 0.00147263\n",
      "[880]\ttraining's binary_logloss: 0.00146502\n",
      "[881]\ttraining's binary_logloss: 0.00145586\n",
      "[882]\ttraining's binary_logloss: 0.00144821\n",
      "[883]\ttraining's binary_logloss: 0.00144057\n",
      "[884]\ttraining's binary_logloss: 0.00143335\n",
      "[885]\ttraining's binary_logloss: 0.00142698\n",
      "[886]\ttraining's binary_logloss: 0.00141997\n",
      "[887]\ttraining's binary_logloss: 0.00141222\n",
      "[888]\ttraining's binary_logloss: 0.00140416\n",
      "[889]\ttraining's binary_logloss: 0.00139471\n",
      "[890]\ttraining's binary_logloss: 0.00138769\n",
      "[891]\ttraining's binary_logloss: 0.00138192\n",
      "[892]\ttraining's binary_logloss: 0.00137414\n",
      "[893]\ttraining's binary_logloss: 0.00136576\n",
      "[894]\ttraining's binary_logloss: 0.00135887\n",
      "[895]\ttraining's binary_logloss: 0.00135013\n",
      "[896]\ttraining's binary_logloss: 0.00134184\n",
      "[897]\ttraining's binary_logloss: 0.00133421\n",
      "[898]\ttraining's binary_logloss: 0.00132652\n",
      "[899]\ttraining's binary_logloss: 0.00131831\n",
      "[900]\ttraining's binary_logloss: 0.001311\n",
      "[901]\ttraining's binary_logloss: 0.0013039\n",
      "[902]\ttraining's binary_logloss: 0.00129717\n",
      "[903]\ttraining's binary_logloss: 0.00129012\n",
      "[904]\ttraining's binary_logloss: 0.00128325\n",
      "[905]\ttraining's binary_logloss: 0.00127705\n",
      "[906]\ttraining's binary_logloss: 0.00127103\n",
      "[907]\ttraining's binary_logloss: 0.00126205\n",
      "[908]\ttraining's binary_logloss: 0.00125595\n",
      "[909]\ttraining's binary_logloss: 0.0012488\n",
      "[910]\ttraining's binary_logloss: 0.0012423\n",
      "[911]\ttraining's binary_logloss: 0.00123507\n",
      "[912]\ttraining's binary_logloss: 0.00122725\n",
      "[913]\ttraining's binary_logloss: 0.00121937\n",
      "[914]\ttraining's binary_logloss: 0.00121259\n",
      "[915]\ttraining's binary_logloss: 0.00120564\n",
      "[916]\ttraining's binary_logloss: 0.00119967\n",
      "[917]\ttraining's binary_logloss: 0.00119358\n",
      "[918]\ttraining's binary_logloss: 0.00118574\n",
      "[919]\ttraining's binary_logloss: 0.00117977\n",
      "[920]\ttraining's binary_logloss: 0.00117351\n",
      "[921]\ttraining's binary_logloss: 0.00116749\n",
      "[922]\ttraining's binary_logloss: 0.0011606\n",
      "[923]\ttraining's binary_logloss: 0.00115226\n",
      "[924]\ttraining's binary_logloss: 0.00114598\n",
      "[925]\ttraining's binary_logloss: 0.00114014\n",
      "[926]\ttraining's binary_logloss: 0.0011347\n",
      "[927]\ttraining's binary_logloss: 0.00112782\n",
      "[928]\ttraining's binary_logloss: 0.00112168\n",
      "[929]\ttraining's binary_logloss: 0.00111614\n",
      "[930]\ttraining's binary_logloss: 0.00110935\n",
      "[931]\ttraining's binary_logloss: 0.00110347\n",
      "[932]\ttraining's binary_logloss: 0.00109734\n",
      "[933]\ttraining's binary_logloss: 0.00109099\n",
      "[934]\ttraining's binary_logloss: 0.00108494\n",
      "[935]\ttraining's binary_logloss: 0.00107949\n",
      "[936]\ttraining's binary_logloss: 0.00107474\n",
      "[937]\ttraining's binary_logloss: 0.00106814\n",
      "[938]\ttraining's binary_logloss: 0.00106118\n",
      "[939]\ttraining's binary_logloss: 0.0010556\n",
      "[940]\ttraining's binary_logloss: 0.0010504\n",
      "[941]\ttraining's binary_logloss: 0.00104461\n",
      "[942]\ttraining's binary_logloss: 0.00103798\n",
      "[943]\ttraining's binary_logloss: 0.00103162\n",
      "[944]\ttraining's binary_logloss: 0.00102473\n",
      "[945]\ttraining's binary_logloss: 0.00101803\n",
      "[946]\ttraining's binary_logloss: 0.00101246\n",
      "[947]\ttraining's binary_logloss: 0.00100563\n",
      "[948]\ttraining's binary_logloss: 0.000998388\n",
      "[949]\ttraining's binary_logloss: 0.000993008\n",
      "[950]\ttraining's binary_logloss: 0.000988169\n",
      "[951]\ttraining's binary_logloss: 0.000983375\n",
      "[952]\ttraining's binary_logloss: 0.000979387\n",
      "[953]\ttraining's binary_logloss: 0.000973478\n",
      "[954]\ttraining's binary_logloss: 0.000967487\n",
      "[955]\ttraining's binary_logloss: 0.000961604\n",
      "[956]\ttraining's binary_logloss: 0.00095634\n",
      "[957]\ttraining's binary_logloss: 0.000950599\n",
      "[958]\ttraining's binary_logloss: 0.000945394\n",
      "[959]\ttraining's binary_logloss: 0.000940103\n",
      "[960]\ttraining's binary_logloss: 0.000933869\n",
      "[961]\ttraining's binary_logloss: 0.000929993\n",
      "[962]\ttraining's binary_logloss: 0.000925866\n",
      "[963]\ttraining's binary_logloss: 0.000919998\n",
      "[964]\ttraining's binary_logloss: 0.00091493\n",
      "[965]\ttraining's binary_logloss: 0.000909757\n",
      "[966]\ttraining's binary_logloss: 0.000904896\n",
      "[967]\ttraining's binary_logloss: 0.000900722\n",
      "[968]\ttraining's binary_logloss: 0.000896452\n",
      "[969]\ttraining's binary_logloss: 0.000890999\n",
      "[970]\ttraining's binary_logloss: 0.000886925\n",
      "[971]\ttraining's binary_logloss: 0.000881696\n",
      "[972]\ttraining's binary_logloss: 0.000876121\n",
      "[973]\ttraining's binary_logloss: 0.000872156\n",
      "[974]\ttraining's binary_logloss: 0.000867079\n",
      "[975]\ttraining's binary_logloss: 0.000861553\n",
      "[976]\ttraining's binary_logloss: 0.000856163\n",
      "[977]\ttraining's binary_logloss: 0.000851805\n",
      "[978]\ttraining's binary_logloss: 0.000847462\n",
      "[979]\ttraining's binary_logloss: 0.00084281\n",
      "[980]\ttraining's binary_logloss: 0.000838334\n",
      "[981]\ttraining's binary_logloss: 0.000832609\n",
      "[982]\ttraining's binary_logloss: 0.000827639\n",
      "[983]\ttraining's binary_logloss: 0.000821879\n",
      "[984]\ttraining's binary_logloss: 0.000817815\n",
      "[985]\ttraining's binary_logloss: 0.000813452\n",
      "[986]\ttraining's binary_logloss: 0.000809338\n",
      "[987]\ttraining's binary_logloss: 0.000805707\n",
      "[988]\ttraining's binary_logloss: 0.000801872\n",
      "[989]\ttraining's binary_logloss: 0.000796293\n",
      "[990]\ttraining's binary_logloss: 0.000790619\n",
      "[991]\ttraining's binary_logloss: 0.000786566\n",
      "[992]\ttraining's binary_logloss: 0.000782166\n",
      "[993]\ttraining's binary_logloss: 0.000778241\n",
      "[994]\ttraining's binary_logloss: 0.000774679\n",
      "[995]\ttraining's binary_logloss: 0.000770673\n",
      "[996]\ttraining's binary_logloss: 0.000767635\n",
      "[997]\ttraining's binary_logloss: 0.000763584\n",
      "[998]\ttraining's binary_logloss: 0.000759199\n",
      "[999]\ttraining's binary_logloss: 0.000753727\n",
      "[1000]\ttraining's binary_logloss: 0.000748044\n",
      "[1001]\ttraining's binary_logloss: 0.000744527\n",
      "[1002]\ttraining's binary_logloss: 0.000740985\n",
      "[1003]\ttraining's binary_logloss: 0.000735622\n",
      "[1004]\ttraining's binary_logloss: 0.000730677\n",
      "[1005]\ttraining's binary_logloss: 0.000727248\n",
      "[1006]\ttraining's binary_logloss: 0.000724508\n",
      "[1007]\ttraining's binary_logloss: 0.000720189\n",
      "[1008]\ttraining's binary_logloss: 0.000717058\n",
      "[1009]\ttraining's binary_logloss: 0.00071338\n",
      "[1010]\ttraining's binary_logloss: 0.000709093\n",
      "[1011]\ttraining's binary_logloss: 0.000704985\n",
      "[1012]\ttraining's binary_logloss: 0.000701055\n",
      "[1013]\ttraining's binary_logloss: 0.000697853\n",
      "[1014]\ttraining's binary_logloss: 0.000694064\n",
      "[1015]\ttraining's binary_logloss: 0.000690893\n",
      "[1016]\ttraining's binary_logloss: 0.000685861\n",
      "[1017]\ttraining's binary_logloss: 0.000682706\n",
      "[1018]\ttraining's binary_logloss: 0.000679714\n",
      "[1019]\ttraining's binary_logloss: 0.000676225\n",
      "[1020]\ttraining's binary_logloss: 0.000673012\n",
      "[1021]\ttraining's binary_logloss: 0.00066886\n",
      "[1022]\ttraining's binary_logloss: 0.000664222\n",
      "[1023]\ttraining's binary_logloss: 0.000661493\n",
      "[1024]\ttraining's binary_logloss: 0.000658421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1025]\ttraining's binary_logloss: 0.000653633\n",
      "[1026]\ttraining's binary_logloss: 0.000649204\n",
      "[1027]\ttraining's binary_logloss: 0.000645639\n",
      "[1028]\ttraining's binary_logloss: 0.000641737\n",
      "[1029]\ttraining's binary_logloss: 0.000638342\n",
      "[1030]\ttraining's binary_logloss: 0.000635344\n",
      "[1031]\ttraining's binary_logloss: 0.000631368\n",
      "[1032]\ttraining's binary_logloss: 0.00062728\n",
      "[1033]\ttraining's binary_logloss: 0.000624224\n",
      "[1034]\ttraining's binary_logloss: 0.000621362\n",
      "[1035]\ttraining's binary_logloss: 0.000618327\n",
      "[1036]\ttraining's binary_logloss: 0.000615863\n",
      "[1037]\ttraining's binary_logloss: 0.000613209\n",
      "[1038]\ttraining's binary_logloss: 0.000609447\n",
      "[1039]\ttraining's binary_logloss: 0.000605924\n",
      "[1040]\ttraining's binary_logloss: 0.00060314\n",
      "[1041]\ttraining's binary_logloss: 0.000599547\n",
      "[1042]\ttraining's binary_logloss: 0.000597547\n",
      "[1043]\ttraining's binary_logloss: 0.000594629\n",
      "[1044]\ttraining's binary_logloss: 0.000591481\n",
      "[1045]\ttraining's binary_logloss: 0.000588076\n",
      "[1046]\ttraining's binary_logloss: 0.000585245\n",
      "[1047]\ttraining's binary_logloss: 0.000580585\n",
      "[1048]\ttraining's binary_logloss: 0.000575399\n",
      "[1049]\ttraining's binary_logloss: 0.000572962\n",
      "[1050]\ttraining's binary_logloss: 0.000570856\n",
      "[1051]\ttraining's binary_logloss: 0.000566564\n",
      "[1052]\ttraining's binary_logloss: 0.000563683\n",
      "[1053]\ttraining's binary_logloss: 0.000560189\n",
      "[1054]\ttraining's binary_logloss: 0.000557058\n",
      "[1055]\ttraining's binary_logloss: 0.000553728\n",
      "[1056]\ttraining's binary_logloss: 0.000550936\n",
      "[1057]\ttraining's binary_logloss: 0.000547842\n",
      "[1058]\ttraining's binary_logloss: 0.000543964\n",
      "[1059]\ttraining's binary_logloss: 0.000540653\n",
      "[1060]\ttraining's binary_logloss: 0.000536842\n",
      "[1061]\ttraining's binary_logloss: 0.000532255\n",
      "[1062]\ttraining's binary_logloss: 0.0005301\n",
      "[1063]\ttraining's binary_logloss: 0.000525688\n",
      "[1064]\ttraining's binary_logloss: 0.000521039\n",
      "[1065]\ttraining's binary_logloss: 0.000519229\n",
      "[1066]\ttraining's binary_logloss: 0.000516445\n",
      "[1067]\ttraining's binary_logloss: 0.000512538\n",
      "[1068]\ttraining's binary_logloss: 0.000510316\n",
      "[1069]\ttraining's binary_logloss: 0.000508574\n",
      "[1070]\ttraining's binary_logloss: 0.000505506\n",
      "[1071]\ttraining's binary_logloss: 0.000502866\n",
      "[1072]\ttraining's binary_logloss: 0.000499735\n",
      "[1073]\ttraining's binary_logloss: 0.000497133\n",
      "[1074]\ttraining's binary_logloss: 0.000495042\n",
      "[1075]\ttraining's binary_logloss: 0.000490913\n",
      "[1076]\ttraining's binary_logloss: 0.000486603\n",
      "[1077]\ttraining's binary_logloss: 0.000484552\n",
      "[1078]\ttraining's binary_logloss: 0.000481751\n",
      "[1079]\ttraining's binary_logloss: 0.000480038\n",
      "[1080]\ttraining's binary_logloss: 0.000477834\n",
      "[1081]\ttraining's binary_logloss: 0.000475522\n",
      "[1082]\ttraining's binary_logloss: 0.00047235\n",
      "[1083]\ttraining's binary_logloss: 0.000468901\n",
      "[1084]\ttraining's binary_logloss: 0.000466891\n",
      "[1085]\ttraining's binary_logloss: 0.000464901\n",
      "[1086]\ttraining's binary_logloss: 0.000462414\n",
      "[1087]\ttraining's binary_logloss: 0.000460106\n",
      "[1088]\ttraining's binary_logloss: 0.00045793\n",
      "[1089]\ttraining's binary_logloss: 0.000454685\n",
      "[1090]\ttraining's binary_logloss: 0.000451865\n",
      "[1091]\ttraining's binary_logloss: 0.000448754\n",
      "[1092]\ttraining's binary_logloss: 0.000445734\n",
      "[1093]\ttraining's binary_logloss: 0.000443175\n",
      "[1094]\ttraining's binary_logloss: 0.000441089\n",
      "[1095]\ttraining's binary_logloss: 0.000437762\n",
      "[1096]\ttraining's binary_logloss: 0.000433995\n",
      "[1097]\ttraining's binary_logloss: 0.00043114\n",
      "[1098]\ttraining's binary_logloss: 0.000428529\n",
      "[1099]\ttraining's binary_logloss: 0.000425906\n",
      "[1100]\ttraining's binary_logloss: 0.000423757\n",
      "[1101]\ttraining's binary_logloss: 0.000422252\n",
      "[1102]\ttraining's binary_logloss: 0.000420548\n",
      "[1103]\ttraining's binary_logloss: 0.000417495\n",
      "[1104]\ttraining's binary_logloss: 0.000415602\n",
      "[1105]\ttraining's binary_logloss: 0.000414066\n",
      "[1106]\ttraining's binary_logloss: 0.000411517\n",
      "[1107]\ttraining's binary_logloss: 0.000408759\n",
      "[1108]\ttraining's binary_logloss: 0.000406691\n",
      "[1109]\ttraining's binary_logloss: 0.000404984\n",
      "[1110]\ttraining's binary_logloss: 0.00040256\n",
      "[1111]\ttraining's binary_logloss: 0.000400714\n",
      "[1112]\ttraining's binary_logloss: 0.000398156\n",
      "[1113]\ttraining's binary_logloss: 0.000394755\n",
      "[1114]\ttraining's binary_logloss: 0.00039137\n",
      "[1115]\ttraining's binary_logloss: 0.000388214\n",
      "[1116]\ttraining's binary_logloss: 0.000385907\n",
      "[1117]\ttraining's binary_logloss: 0.000384784\n",
      "[1118]\ttraining's binary_logloss: 0.00038316\n",
      "[1119]\ttraining's binary_logloss: 0.000379763\n",
      "[1120]\ttraining's binary_logloss: 0.000376937\n",
      "[1121]\ttraining's binary_logloss: 0.000375448\n",
      "[1122]\ttraining's binary_logloss: 0.000374306\n",
      "[1123]\ttraining's binary_logloss: 0.000372331\n",
      "[1124]\ttraining's binary_logloss: 0.000370837\n",
      "[1125]\ttraining's binary_logloss: 0.000369341\n",
      "[1126]\ttraining's binary_logloss: 0.000367301\n",
      "[1127]\ttraining's binary_logloss: 0.000365845\n",
      "[1128]\ttraining's binary_logloss: 0.000364833\n",
      "[1129]\ttraining's binary_logloss: 0.000363467\n",
      "[1130]\ttraining's binary_logloss: 0.000362098\n",
      "[1131]\ttraining's binary_logloss: 0.000360098\n",
      "[1132]\ttraining's binary_logloss: 0.000357849\n",
      "[1133]\ttraining's binary_logloss: 0.000354849\n",
      "[1134]\ttraining's binary_logloss: 0.000351872\n",
      "[1135]\ttraining's binary_logloss: 0.000349631\n",
      "[1136]\ttraining's binary_logloss: 0.000347763\n",
      "[1137]\ttraining's binary_logloss: 0.000346191\n",
      "[1138]\ttraining's binary_logloss: 0.000343338\n",
      "[1139]\ttraining's binary_logloss: 0.000340906\n",
      "[1140]\ttraining's binary_logloss: 0.000338139\n",
      "[1141]\ttraining's binary_logloss: 0.000337039\n",
      "[1142]\ttraining's binary_logloss: 0.00033612\n",
      "[1143]\ttraining's binary_logloss: 0.000333692\n",
      "[1144]\ttraining's binary_logloss: 0.000331148\n",
      "[1145]\ttraining's binary_logloss: 0.000328962\n",
      "[1146]\ttraining's binary_logloss: 0.000326526\n",
      "[1147]\ttraining's binary_logloss: 0.000323469\n",
      "[1148]\ttraining's binary_logloss: 0.000320563\n",
      "[1149]\ttraining's binary_logloss: 0.00031819\n",
      "[1150]\ttraining's binary_logloss: 0.000315619\n",
      "[1151]\ttraining's binary_logloss: 0.00031307\n",
      "[1152]\ttraining's binary_logloss: 0.000310906\n",
      "[1153]\ttraining's binary_logloss: 0.000308775\n",
      "[1154]\ttraining's binary_logloss: 0.000306315\n",
      "[1155]\ttraining's binary_logloss: 0.000305067\n",
      "[1156]\ttraining's binary_logloss: 0.000303764\n",
      "[1157]\ttraining's binary_logloss: 0.000301514\n",
      "[1158]\ttraining's binary_logloss: 0.000299248\n",
      "[1159]\ttraining's binary_logloss: 0.000297196\n",
      "[1160]\ttraining's binary_logloss: 0.000295029\n",
      "[1161]\ttraining's binary_logloss: 0.000294094\n",
      "[1162]\ttraining's binary_logloss: 0.000292591\n",
      "[1163]\ttraining's binary_logloss: 0.000291629\n",
      "[1164]\ttraining's binary_logloss: 0.000289663\n",
      "[1165]\ttraining's binary_logloss: 0.000287521\n",
      "[1166]\ttraining's binary_logloss: 0.000285765\n",
      "[1167]\ttraining's binary_logloss: 0.000284791\n",
      "[1168]\ttraining's binary_logloss: 0.000283029\n",
      "[1169]\ttraining's binary_logloss: 0.000281765\n",
      "[1170]\ttraining's binary_logloss: 0.000280968\n",
      "[1171]\ttraining's binary_logloss: 0.000280066\n",
      "[1172]\ttraining's binary_logloss: 0.000279283\n",
      "[1173]\ttraining's binary_logloss: 0.000277822\n",
      "[1174]\ttraining's binary_logloss: 0.000276181\n",
      "[1175]\ttraining's binary_logloss: 0.000274259\n",
      "[1176]\ttraining's binary_logloss: 0.000271939\n",
      "[1177]\ttraining's binary_logloss: 0.000269974\n",
      "[1178]\ttraining's binary_logloss: 0.000268273\n",
      "[1179]\ttraining's binary_logloss: 0.000266555\n",
      "[1180]\ttraining's binary_logloss: 0.000265\n",
      "[1181]\ttraining's binary_logloss: 0.000263966\n",
      "[1182]\ttraining's binary_logloss: 0.000262948\n",
      "[1183]\ttraining's binary_logloss: 0.00026125\n",
      "[1184]\ttraining's binary_logloss: 0.000259638\n",
      "[1185]\ttraining's binary_logloss: 0.000257949\n",
      "[1186]\ttraining's binary_logloss: 0.000256503\n",
      "[1187]\ttraining's binary_logloss: 0.000254707\n",
      "[1188]\ttraining's binary_logloss: 0.000252684\n",
      "[1189]\ttraining's binary_logloss: 0.000251996\n",
      "[1190]\ttraining's binary_logloss: 0.000250974\n",
      "[1191]\ttraining's binary_logloss: 0.000248837\n",
      "[1192]\ttraining's binary_logloss: 0.00024682\n",
      "[1193]\ttraining's binary_logloss: 0.000245997\n",
      "[1194]\ttraining's binary_logloss: 0.000245338\n",
      "[1195]\ttraining's binary_logloss: 0.000243362\n",
      "[1196]\ttraining's binary_logloss: 0.000241701\n",
      "[1197]\ttraining's binary_logloss: 0.000239945\n",
      "[1198]\ttraining's binary_logloss: 0.000238111\n",
      "[1199]\ttraining's binary_logloss: 0.000236627\n",
      "[1200]\ttraining's binary_logloss: 0.000235779\n",
      "[1201]\ttraining's binary_logloss: 0.000234313\n",
      "[1202]\ttraining's binary_logloss: 0.000232923\n",
      "[1203]\ttraining's binary_logloss: 0.000232028\n",
      "[1204]\ttraining's binary_logloss: 0.000230638\n",
      "[1205]\ttraining's binary_logloss: 0.000228575\n",
      "[1206]\ttraining's binary_logloss: 0.000226721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1207]\ttraining's binary_logloss: 0.000226022\n",
      "[1208]\ttraining's binary_logloss: 0.000224856\n",
      "[1209]\ttraining's binary_logloss: 0.000223187\n",
      "[1210]\ttraining's binary_logloss: 0.000221392\n",
      "[1211]\ttraining's binary_logloss: 0.000220283\n",
      "[1212]\ttraining's binary_logloss: 0.000219598\n",
      "[1213]\ttraining's binary_logloss: 0.000218094\n",
      "[1214]\ttraining's binary_logloss: 0.000216936\n",
      "[1215]\ttraining's binary_logloss: 0.000214951\n",
      "[1216]\ttraining's binary_logloss: 0.000213478\n",
      "[1217]\ttraining's binary_logloss: 0.000211924\n",
      "[1218]\ttraining's binary_logloss: 0.00021031\n",
      "[1219]\ttraining's binary_logloss: 0.000209056\n",
      "[1220]\ttraining's binary_logloss: 0.000208011\n",
      "[1221]\ttraining's binary_logloss: 0.000207135\n",
      "[1222]\ttraining's binary_logloss: 0.00020636\n",
      "[1223]\ttraining's binary_logloss: 0.000205743\n",
      "[1224]\ttraining's binary_logloss: 0.000204816\n",
      "[1225]\ttraining's binary_logloss: 0.000203463\n",
      "[1226]\ttraining's binary_logloss: 0.000202777\n",
      "[1227]\ttraining's binary_logloss: 0.000201697\n",
      "[1228]\ttraining's binary_logloss: 0.000200791\n",
      "[1229]\ttraining's binary_logloss: 0.000200001\n",
      "[1230]\ttraining's binary_logloss: 0.000198654\n",
      "[1231]\ttraining's binary_logloss: 0.000196927\n",
      "[1232]\ttraining's binary_logloss: 0.000195336\n",
      "[1233]\ttraining's binary_logloss: 0.000193915\n",
      "[1234]\ttraining's binary_logloss: 0.000192529\n",
      "[1235]\ttraining's binary_logloss: 0.000191223\n",
      "[1236]\ttraining's binary_logloss: 0.000189942\n",
      "[1237]\ttraining's binary_logloss: 0.000188611\n",
      "[1238]\ttraining's binary_logloss: 0.000187285\n",
      "[1239]\ttraining's binary_logloss: 0.000186016\n",
      "[1240]\ttraining's binary_logloss: 0.000184609\n",
      "[1241]\ttraining's binary_logloss: 0.000183533\n",
      "[1242]\ttraining's binary_logloss: 0.000182551\n",
      "[1243]\ttraining's binary_logloss: 0.000181111\n",
      "[1244]\ttraining's binary_logloss: 0.000179633\n",
      "[1245]\ttraining's binary_logloss: 0.000178324\n",
      "[1246]\ttraining's binary_logloss: 0.000176872\n",
      "[1247]\ttraining's binary_logloss: 0.00017557\n",
      "[1248]\ttraining's binary_logloss: 0.000174327\n",
      "[1249]\ttraining's binary_logloss: 0.000173035\n",
      "[1250]\ttraining's binary_logloss: 0.000171817\n",
      "[1251]\ttraining's binary_logloss: 0.000170882\n",
      "[1252]\ttraining's binary_logloss: 0.000169899\n",
      "[1253]\ttraining's binary_logloss: 0.00016871\n",
      "[1254]\ttraining's binary_logloss: 0.000167347\n",
      "[1255]\ttraining's binary_logloss: 0.000166034\n",
      "[1256]\ttraining's binary_logloss: 0.000164765\n",
      "[1257]\ttraining's binary_logloss: 0.000163564\n",
      "[1258]\ttraining's binary_logloss: 0.000162262\n",
      "[1259]\ttraining's binary_logloss: 0.00016155\n",
      "[1260]\ttraining's binary_logloss: 0.000160755\n",
      "[1261]\ttraining's binary_logloss: 0.000160118\n",
      "[1262]\ttraining's binary_logloss: 0.000159306\n",
      "[1263]\ttraining's binary_logloss: 0.000158268\n",
      "[1264]\ttraining's binary_logloss: 0.000157175\n",
      "[1265]\ttraining's binary_logloss: 0.000156171\n",
      "[1266]\ttraining's binary_logloss: 0.000155244\n",
      "[1267]\ttraining's binary_logloss: 0.000154054\n",
      "[1268]\ttraining's binary_logloss: 0.000152967\n",
      "[1269]\ttraining's binary_logloss: 0.000152147\n",
      "[1270]\ttraining's binary_logloss: 0.000151536\n",
      "[1271]\ttraining's binary_logloss: 0.00015062\n",
      "[1272]\ttraining's binary_logloss: 0.000149359\n",
      "[1273]\ttraining's binary_logloss: 0.000148334\n",
      "[1274]\ttraining's binary_logloss: 0.000147295\n",
      "[1275]\ttraining's binary_logloss: 0.00014621\n",
      "[1276]\ttraining's binary_logloss: 0.000145162\n",
      "[1277]\ttraining's binary_logloss: 0.000144302\n",
      "[1278]\ttraining's binary_logloss: 0.000143402\n",
      "[1279]\ttraining's binary_logloss: 0.000142383\n",
      "[1280]\ttraining's binary_logloss: 0.000141432\n",
      "[1281]\ttraining's binary_logloss: 0.000140576\n",
      "[1282]\ttraining's binary_logloss: 0.000139596\n",
      "[1283]\ttraining's binary_logloss: 0.000138767\n",
      "[1284]\ttraining's binary_logloss: 0.000137882\n",
      "[1285]\ttraining's binary_logloss: 0.000137246\n",
      "[1286]\ttraining's binary_logloss: 0.000136723\n",
      "[1287]\ttraining's binary_logloss: 0.000136128\n",
      "[1288]\ttraining's binary_logloss: 0.000135504\n",
      "[1289]\ttraining's binary_logloss: 0.000134607\n",
      "[1290]\ttraining's binary_logloss: 0.000133793\n",
      "[1291]\ttraining's binary_logloss: 0.000133198\n",
      "[1292]\ttraining's binary_logloss: 0.000132243\n",
      "[1293]\ttraining's binary_logloss: 0.000131391\n",
      "[1294]\ttraining's binary_logloss: 0.000130462\n",
      "[1295]\ttraining's binary_logloss: 0.000129585\n",
      "[1296]\ttraining's binary_logloss: 0.000128769\n",
      "[1297]\ttraining's binary_logloss: 0.000127899\n",
      "[1298]\ttraining's binary_logloss: 0.000126954\n",
      "[1299]\ttraining's binary_logloss: 0.000126177\n",
      "[1300]\ttraining's binary_logloss: 0.000125382\n",
      "[1301]\ttraining's binary_logloss: 0.000124563\n",
      "[1302]\ttraining's binary_logloss: 0.00012367\n",
      "[1303]\ttraining's binary_logloss: 0.000122898\n",
      "[1304]\ttraining's binary_logloss: 0.000122289\n",
      "[1305]\ttraining's binary_logloss: 0.000121427\n",
      "[1306]\ttraining's binary_logloss: 0.000120608\n",
      "[1307]\ttraining's binary_logloss: 0.000120054\n",
      "[1308]\ttraining's binary_logloss: 0.000119539\n",
      "[1309]\ttraining's binary_logloss: 0.000118822\n",
      "[1310]\ttraining's binary_logloss: 0.00011813\n",
      "[1311]\ttraining's binary_logloss: 0.000117611\n",
      "[1312]\ttraining's binary_logloss: 0.000117004\n",
      "[1313]\ttraining's binary_logloss: 0.000116557\n",
      "[1314]\ttraining's binary_logloss: 0.000116078\n",
      "[1315]\ttraining's binary_logloss: 0.000115356\n",
      "[1316]\ttraining's binary_logloss: 0.000114677\n",
      "[1317]\ttraining's binary_logloss: 0.000113929\n",
      "[1318]\ttraining's binary_logloss: 0.000113287\n",
      "[1319]\ttraining's binary_logloss: 0.0001126\n",
      "[1320]\ttraining's binary_logloss: 0.000111954\n",
      "[1321]\ttraining's binary_logloss: 0.000111256\n",
      "[1322]\ttraining's binary_logloss: 0.000110536\n",
      "[1323]\ttraining's binary_logloss: 0.000109788\n",
      "[1324]\ttraining's binary_logloss: 0.000109104\n",
      "[1325]\ttraining's binary_logloss: 0.000108508\n",
      "[1326]\ttraining's binary_logloss: 0.000107758\n",
      "[1327]\ttraining's binary_logloss: 0.000107194\n",
      "[1328]\ttraining's binary_logloss: 0.000106593\n",
      "[1329]\ttraining's binary_logloss: 0.000105967\n",
      "[1330]\ttraining's binary_logloss: 0.000105383\n",
      "[1331]\ttraining's binary_logloss: 0.00010472\n",
      "[1332]\ttraining's binary_logloss: 0.000104013\n",
      "[1333]\ttraining's binary_logloss: 0.000103428\n",
      "[1334]\ttraining's binary_logloss: 0.000102854\n",
      "[1335]\ttraining's binary_logloss: 0.000102241\n",
      "[1336]\ttraining's binary_logloss: 0.000101603\n",
      "[1337]\ttraining's binary_logloss: 0.000101044\n",
      "[1338]\ttraining's binary_logloss: 0.00010047\n",
      "[1339]\ttraining's binary_logloss: 9.99145e-05\n",
      "[1340]\ttraining's binary_logloss: 9.93875e-05\n",
      "[1341]\ttraining's binary_logloss: 9.88293e-05\n",
      "[1342]\ttraining's binary_logloss: 9.83084e-05\n",
      "[1343]\ttraining's binary_logloss: 9.77974e-05\n",
      "[1344]\ttraining's binary_logloss: 9.71568e-05\n",
      "[1345]\ttraining's binary_logloss: 9.65591e-05\n",
      "[1346]\ttraining's binary_logloss: 9.59038e-05\n",
      "[1347]\ttraining's binary_logloss: 9.53204e-05\n",
      "[1348]\ttraining's binary_logloss: 9.47553e-05\n",
      "[1349]\ttraining's binary_logloss: 9.42204e-05\n",
      "[1350]\ttraining's binary_logloss: 9.3664e-05\n",
      "[1351]\ttraining's binary_logloss: 9.3162e-05\n",
      "[1352]\ttraining's binary_logloss: 9.2633e-05\n",
      "[1353]\ttraining's binary_logloss: 9.21587e-05\n",
      "[1354]\ttraining's binary_logloss: 9.16596e-05\n",
      "[1355]\ttraining's binary_logloss: 9.11439e-05\n",
      "[1356]\ttraining's binary_logloss: 9.06688e-05\n",
      "[1357]\ttraining's binary_logloss: 9.02081e-05\n",
      "[1358]\ttraining's binary_logloss: 8.97343e-05\n",
      "[1359]\ttraining's binary_logloss: 8.92102e-05\n",
      "[1360]\ttraining's binary_logloss: 8.86366e-05\n",
      "[1361]\ttraining's binary_logloss: 8.81848e-05\n",
      "[1362]\ttraining's binary_logloss: 8.76919e-05\n",
      "[1363]\ttraining's binary_logloss: 8.71918e-05\n",
      "[1364]\ttraining's binary_logloss: 8.67071e-05\n",
      "[1365]\ttraining's binary_logloss: 8.62622e-05\n",
      "[1366]\ttraining's binary_logloss: 8.57444e-05\n",
      "[1367]\ttraining's binary_logloss: 8.52515e-05\n",
      "[1368]\ttraining's binary_logloss: 8.47866e-05\n",
      "[1369]\ttraining's binary_logloss: 8.42567e-05\n",
      "[1370]\ttraining's binary_logloss: 8.37778e-05\n",
      "[1371]\ttraining's binary_logloss: 8.33529e-05\n",
      "[1372]\ttraining's binary_logloss: 8.27982e-05\n",
      "[1373]\ttraining's binary_logloss: 8.23405e-05\n",
      "[1374]\ttraining's binary_logloss: 8.19055e-05\n",
      "[1375]\ttraining's binary_logloss: 8.14791e-05\n",
      "[1376]\ttraining's binary_logloss: 8.10332e-05\n",
      "[1377]\ttraining's binary_logloss: 8.05608e-05\n",
      "[1378]\ttraining's binary_logloss: 8.0071e-05\n",
      "[1379]\ttraining's binary_logloss: 7.96379e-05\n",
      "[1380]\ttraining's binary_logloss: 7.92237e-05\n",
      "[1381]\ttraining's binary_logloss: 7.87763e-05\n",
      "[1382]\ttraining's binary_logloss: 7.83383e-05\n",
      "[1383]\ttraining's binary_logloss: 7.79539e-05\n",
      "[1384]\ttraining's binary_logloss: 7.74489e-05\n",
      "[1385]\ttraining's binary_logloss: 7.70374e-05\n",
      "[1386]\ttraining's binary_logloss: 7.65817e-05\n",
      "[1387]\ttraining's binary_logloss: 7.61365e-05\n",
      "[1388]\ttraining's binary_logloss: 7.56995e-05\n",
      "[1389]\ttraining's binary_logloss: 7.53181e-05\n",
      "[1390]\ttraining's binary_logloss: 7.48752e-05\n",
      "[1391]\ttraining's binary_logloss: 7.44297e-05\n",
      "[1392]\ttraining's binary_logloss: 7.40334e-05\n",
      "[1393]\ttraining's binary_logloss: 7.36333e-05\n",
      "[1394]\ttraining's binary_logloss: 7.32469e-05\n",
      "[1395]\ttraining's binary_logloss: 7.28196e-05\n",
      "[1396]\ttraining's binary_logloss: 7.23966e-05\n",
      "[1397]\ttraining's binary_logloss: 7.20332e-05\n",
      "[1398]\ttraining's binary_logloss: 7.16037e-05\n",
      "[1399]\ttraining's binary_logloss: 7.11814e-05\n",
      "[1400]\ttraining's binary_logloss: 7.08333e-05\n",
      "[1401]\ttraining's binary_logloss: 7.04066e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1402]\ttraining's binary_logloss: 6.99636e-05\n",
      "[1403]\ttraining's binary_logloss: 6.95481e-05\n",
      "[1404]\ttraining's binary_logloss: 6.91949e-05\n",
      "[1405]\ttraining's binary_logloss: 6.88043e-05\n",
      "[1406]\ttraining's binary_logloss: 6.8381e-05\n",
      "[1407]\ttraining's binary_logloss: 6.80552e-05\n",
      "[1408]\ttraining's binary_logloss: 6.76914e-05\n",
      "[1409]\ttraining's binary_logloss: 6.7334e-05\n",
      "[1410]\ttraining's binary_logloss: 6.69918e-05\n",
      "[1411]\ttraining's binary_logloss: 6.66696e-05\n",
      "[1412]\ttraining's binary_logloss: 6.629e-05\n",
      "[1413]\ttraining's binary_logloss: 6.59239e-05\n",
      "[1414]\ttraining's binary_logloss: 6.55501e-05\n",
      "[1415]\ttraining's binary_logloss: 6.51702e-05\n",
      "[1416]\ttraining's binary_logloss: 6.48149e-05\n",
      "[1417]\ttraining's binary_logloss: 6.44228e-05\n",
      "[1418]\ttraining's binary_logloss: 6.40813e-05\n",
      "[1419]\ttraining's binary_logloss: 6.37522e-05\n",
      "[1420]\ttraining's binary_logloss: 6.34546e-05\n",
      "[1421]\ttraining's binary_logloss: 6.31226e-05\n",
      "[1422]\ttraining's binary_logloss: 6.28474e-05\n",
      "[1423]\ttraining's binary_logloss: 6.24691e-05\n",
      "[1424]\ttraining's binary_logloss: 6.21473e-05\n",
      "[1425]\ttraining's binary_logloss: 6.17464e-05\n",
      "[1426]\ttraining's binary_logloss: 6.13633e-05\n",
      "[1427]\ttraining's binary_logloss: 6.09814e-05\n",
      "[1428]\ttraining's binary_logloss: 6.07092e-05\n",
      "[1429]\ttraining's binary_logloss: 6.04166e-05\n",
      "[1430]\ttraining's binary_logloss: 6.01354e-05\n",
      "[1431]\ttraining's binary_logloss: 5.98393e-05\n",
      "[1432]\ttraining's binary_logloss: 5.9536e-05\n",
      "[1433]\ttraining's binary_logloss: 5.92245e-05\n",
      "[1434]\ttraining's binary_logloss: 5.89293e-05\n",
      "[1435]\ttraining's binary_logloss: 5.86183e-05\n",
      "[1436]\ttraining's binary_logloss: 5.82814e-05\n",
      "[1437]\ttraining's binary_logloss: 5.79842e-05\n",
      "[1438]\ttraining's binary_logloss: 5.76587e-05\n",
      "[1439]\ttraining's binary_logloss: 5.73654e-05\n",
      "[1440]\ttraining's binary_logloss: 5.71125e-05\n",
      "[1441]\ttraining's binary_logloss: 5.68128e-05\n",
      "[1442]\ttraining's binary_logloss: 5.65696e-05\n",
      "[1443]\ttraining's binary_logloss: 5.62671e-05\n",
      "[1444]\ttraining's binary_logloss: 5.60011e-05\n",
      "[1445]\ttraining's binary_logloss: 5.57232e-05\n",
      "[1446]\ttraining's binary_logloss: 5.54369e-05\n",
      "[1447]\ttraining's binary_logloss: 5.51322e-05\n",
      "[1448]\ttraining's binary_logloss: 5.48218e-05\n",
      "[1449]\ttraining's binary_logloss: 5.45625e-05\n",
      "[1450]\ttraining's binary_logloss: 5.42932e-05\n",
      "[1451]\ttraining's binary_logloss: 5.39589e-05\n",
      "[1452]\ttraining's binary_logloss: 5.36886e-05\n",
      "[1453]\ttraining's binary_logloss: 5.34193e-05\n",
      "[1454]\ttraining's binary_logloss: 5.31631e-05\n",
      "[1455]\ttraining's binary_logloss: 5.2905e-05\n",
      "[1456]\ttraining's binary_logloss: 5.26062e-05\n",
      "[1457]\ttraining's binary_logloss: 5.22907e-05\n",
      "[1458]\ttraining's binary_logloss: 5.20029e-05\n",
      "[1459]\ttraining's binary_logloss: 5.17252e-05\n",
      "[1460]\ttraining's binary_logloss: 5.14618e-05\n",
      "[1461]\ttraining's binary_logloss: 5.1231e-05\n",
      "[1462]\ttraining's binary_logloss: 5.09568e-05\n",
      "[1463]\ttraining's binary_logloss: 5.06942e-05\n",
      "[1464]\ttraining's binary_logloss: 5.04507e-05\n",
      "[1465]\ttraining's binary_logloss: 5.02237e-05\n",
      "[1466]\ttraining's binary_logloss: 4.99726e-05\n",
      "[1467]\ttraining's binary_logloss: 4.97172e-05\n",
      "[1468]\ttraining's binary_logloss: 4.94322e-05\n",
      "[1469]\ttraining's binary_logloss: 4.92017e-05\n",
      "[1470]\ttraining's binary_logloss: 4.89546e-05\n",
      "[1471]\ttraining's binary_logloss: 4.87102e-05\n",
      "[1472]\ttraining's binary_logloss: 4.85057e-05\n",
      "[1473]\ttraining's binary_logloss: 4.82558e-05\n",
      "[1474]\ttraining's binary_logloss: 4.80303e-05\n",
      "[1475]\ttraining's binary_logloss: 4.78035e-05\n",
      "[1476]\ttraining's binary_logloss: 4.75528e-05\n",
      "[1477]\ttraining's binary_logloss: 4.72814e-05\n",
      "[1478]\ttraining's binary_logloss: 4.70007e-05\n",
      "[1479]\ttraining's binary_logloss: 4.67942e-05\n",
      "[1480]\ttraining's binary_logloss: 4.65571e-05\n",
      "[1481]\ttraining's binary_logloss: 4.63469e-05\n",
      "[1482]\ttraining's binary_logloss: 4.60945e-05\n",
      "[1483]\ttraining's binary_logloss: 4.58839e-05\n",
      "[1484]\ttraining's binary_logloss: 4.56566e-05\n",
      "[1485]\ttraining's binary_logloss: 4.54447e-05\n",
      "[1486]\ttraining's binary_logloss: 4.52163e-05\n",
      "[1487]\ttraining's binary_logloss: 4.50111e-05\n",
      "[1488]\ttraining's binary_logloss: 4.4799e-05\n",
      "[1489]\ttraining's binary_logloss: 4.45948e-05\n",
      "[1490]\ttraining's binary_logloss: 4.43662e-05\n",
      "[1491]\ttraining's binary_logloss: 4.41566e-05\n",
      "[1492]\ttraining's binary_logloss: 4.39549e-05\n",
      "[1493]\ttraining's binary_logloss: 4.37619e-05\n",
      "[1494]\ttraining's binary_logloss: 4.35435e-05\n",
      "[1495]\ttraining's binary_logloss: 4.33518e-05\n",
      "[1496]\ttraining's binary_logloss: 4.31532e-05\n",
      "[1497]\ttraining's binary_logloss: 4.29522e-05\n",
      "[1498]\ttraining's binary_logloss: 4.27403e-05\n",
      "[1499]\ttraining's binary_logloss: 4.25373e-05\n",
      "[1500]\ttraining's binary_logloss: 4.23579e-05\n",
      "[1501]\ttraining's binary_logloss: 4.21765e-05\n",
      "[1502]\ttraining's binary_logloss: 4.19881e-05\n",
      "[1503]\ttraining's binary_logloss: 4.17988e-05\n",
      "[1504]\ttraining's binary_logloss: 4.16216e-05\n",
      "[1505]\ttraining's binary_logloss: 4.1408e-05\n",
      "[1506]\ttraining's binary_logloss: 4.12089e-05\n",
      "[1507]\ttraining's binary_logloss: 4.10426e-05\n",
      "[1508]\ttraining's binary_logloss: 4.08219e-05\n",
      "[1509]\ttraining's binary_logloss: 4.06343e-05\n",
      "[1510]\ttraining's binary_logloss: 4.04452e-05\n",
      "[1511]\ttraining's binary_logloss: 4.02543e-05\n",
      "[1512]\ttraining's binary_logloss: 4.0097e-05\n",
      "[1513]\ttraining's binary_logloss: 3.99012e-05\n",
      "[1514]\ttraining's binary_logloss: 3.96886e-05\n",
      "[1515]\ttraining's binary_logloss: 3.94964e-05\n",
      "[1516]\ttraining's binary_logloss: 3.93003e-05\n",
      "[1517]\ttraining's binary_logloss: 3.91054e-05\n",
      "[1518]\ttraining's binary_logloss: 3.89409e-05\n",
      "[1519]\ttraining's binary_logloss: 3.87234e-05\n",
      "[1520]\ttraining's binary_logloss: 3.8558e-05\n",
      "[1521]\ttraining's binary_logloss: 3.83948e-05\n",
      "[1522]\ttraining's binary_logloss: 3.82155e-05\n",
      "[1523]\ttraining's binary_logloss: 3.80288e-05\n",
      "[1524]\ttraining's binary_logloss: 3.78426e-05\n",
      "[1525]\ttraining's binary_logloss: 3.76552e-05\n",
      "[1526]\ttraining's binary_logloss: 3.74662e-05\n",
      "[1527]\ttraining's binary_logloss: 3.72773e-05\n",
      "[1528]\ttraining's binary_logloss: 3.71037e-05\n",
      "[1529]\ttraining's binary_logloss: 3.69276e-05\n",
      "[1530]\ttraining's binary_logloss: 3.67505e-05\n",
      "[1531]\ttraining's binary_logloss: 3.6569e-05\n",
      "[1532]\ttraining's binary_logloss: 3.64103e-05\n",
      "[1533]\ttraining's binary_logloss: 3.62311e-05\n",
      "[1534]\ttraining's binary_logloss: 3.60579e-05\n",
      "[1535]\ttraining's binary_logloss: 3.58982e-05\n",
      "[1536]\ttraining's binary_logloss: 3.57367e-05\n",
      "[1537]\ttraining's binary_logloss: 3.55725e-05\n",
      "[1538]\ttraining's binary_logloss: 3.54014e-05\n",
      "[1539]\ttraining's binary_logloss: 3.52423e-05\n",
      "[1540]\ttraining's binary_logloss: 3.50881e-05\n",
      "[1541]\ttraining's binary_logloss: 3.49189e-05\n",
      "[1542]\ttraining's binary_logloss: 3.47221e-05\n",
      "[1543]\ttraining's binary_logloss: 3.4579e-05\n",
      "[1544]\ttraining's binary_logloss: 3.44216e-05\n",
      "[1545]\ttraining's binary_logloss: 3.42398e-05\n",
      "[1546]\ttraining's binary_logloss: 3.40846e-05\n",
      "[1547]\ttraining's binary_logloss: 3.39189e-05\n",
      "[1548]\ttraining's binary_logloss: 3.3764e-05\n",
      "[1549]\ttraining's binary_logloss: 3.36279e-05\n",
      "[1550]\ttraining's binary_logloss: 3.34789e-05\n",
      "[1551]\ttraining's binary_logloss: 3.33281e-05\n",
      "[1552]\ttraining's binary_logloss: 3.31731e-05\n",
      "[1553]\ttraining's binary_logloss: 3.30345e-05\n",
      "[1554]\ttraining's binary_logloss: 3.29047e-05\n",
      "[1555]\ttraining's binary_logloss: 3.27438e-05\n",
      "[1556]\ttraining's binary_logloss: 3.26066e-05\n",
      "[1557]\ttraining's binary_logloss: 3.24292e-05\n",
      "[1558]\ttraining's binary_logloss: 3.22649e-05\n",
      "[1559]\ttraining's binary_logloss: 3.21199e-05\n",
      "[1560]\ttraining's binary_logloss: 3.1982e-05\n",
      "[1561]\ttraining's binary_logloss: 3.1838e-05\n",
      "[1562]\ttraining's binary_logloss: 3.17001e-05\n",
      "[1563]\ttraining's binary_logloss: 3.15528e-05\n",
      "[1564]\ttraining's binary_logloss: 3.14059e-05\n",
      "[1565]\ttraining's binary_logloss: 3.12657e-05\n",
      "[1566]\ttraining's binary_logloss: 3.11327e-05\n",
      "[1567]\ttraining's binary_logloss: 3.09947e-05\n",
      "[1568]\ttraining's binary_logloss: 3.08364e-05\n",
      "[1569]\ttraining's binary_logloss: 3.06975e-05\n",
      "[1570]\ttraining's binary_logloss: 3.05726e-05\n",
      "[1571]\ttraining's binary_logloss: 3.04542e-05\n",
      "[1572]\ttraining's binary_logloss: 3.03287e-05\n",
      "[1573]\ttraining's binary_logloss: 3.01901e-05\n",
      "[1574]\ttraining's binary_logloss: 3.00605e-05\n",
      "[1575]\ttraining's binary_logloss: 2.99328e-05\n",
      "[1576]\ttraining's binary_logloss: 2.97925e-05\n",
      "[1577]\ttraining's binary_logloss: 2.96445e-05\n",
      "[1578]\ttraining's binary_logloss: 2.95311e-05\n",
      "[1579]\ttraining's binary_logloss: 2.93994e-05\n",
      "[1580]\ttraining's binary_logloss: 2.92869e-05\n",
      "[1581]\ttraining's binary_logloss: 2.91539e-05\n",
      "[1582]\ttraining's binary_logloss: 2.90398e-05\n",
      "[1583]\ttraining's binary_logloss: 2.89232e-05\n",
      "[1584]\ttraining's binary_logloss: 2.88034e-05\n",
      "[1585]\ttraining's binary_logloss: 2.86647e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1586]\ttraining's binary_logloss: 2.85442e-05\n",
      "[1587]\ttraining's binary_logloss: 2.84278e-05\n",
      "[1588]\ttraining's binary_logloss: 2.83204e-05\n",
      "[1589]\ttraining's binary_logloss: 2.82165e-05\n",
      "[1590]\ttraining's binary_logloss: 2.80916e-05\n",
      "[1591]\ttraining's binary_logloss: 2.79647e-05\n",
      "[1592]\ttraining's binary_logloss: 2.78469e-05\n",
      "[1593]\ttraining's binary_logloss: 2.77338e-05\n",
      "[1594]\ttraining's binary_logloss: 2.76058e-05\n",
      "[1595]\ttraining's binary_logloss: 2.74874e-05\n",
      "[1596]\ttraining's binary_logloss: 2.73679e-05\n",
      "[1597]\ttraining's binary_logloss: 2.7242e-05\n",
      "[1598]\ttraining's binary_logloss: 2.71284e-05\n",
      "[1599]\ttraining's binary_logloss: 2.70151e-05\n",
      "[1600]\ttraining's binary_logloss: 2.6904e-05\n",
      "[1601]\ttraining's binary_logloss: 2.67999e-05\n",
      "[1602]\ttraining's binary_logloss: 2.66951e-05\n",
      "[1603]\ttraining's binary_logloss: 2.65822e-05\n",
      "[1604]\ttraining's binary_logloss: 2.64844e-05\n",
      "[1605]\ttraining's binary_logloss: 2.63776e-05\n",
      "[1606]\ttraining's binary_logloss: 2.62792e-05\n",
      "[1607]\ttraining's binary_logloss: 2.61699e-05\n",
      "[1608]\ttraining's binary_logloss: 2.60569e-05\n",
      "[1609]\ttraining's binary_logloss: 2.59504e-05\n",
      "[1610]\ttraining's binary_logloss: 2.58336e-05\n",
      "[1611]\ttraining's binary_logloss: 2.57367e-05\n",
      "[1612]\ttraining's binary_logloss: 2.56377e-05\n",
      "[1613]\ttraining's binary_logloss: 2.55414e-05\n",
      "[1614]\ttraining's binary_logloss: 2.54428e-05\n",
      "[1615]\ttraining's binary_logloss: 2.53455e-05\n",
      "[1616]\ttraining's binary_logloss: 2.52445e-05\n",
      "[1617]\ttraining's binary_logloss: 2.51516e-05\n",
      "[1618]\ttraining's binary_logloss: 2.50492e-05\n",
      "[1619]\ttraining's binary_logloss: 2.49478e-05\n",
      "[1620]\ttraining's binary_logloss: 2.48384e-05\n",
      "[1621]\ttraining's binary_logloss: 2.47334e-05\n",
      "[1622]\ttraining's binary_logloss: 2.46424e-05\n",
      "[1623]\ttraining's binary_logloss: 2.45476e-05\n",
      "[1624]\ttraining's binary_logloss: 2.44413e-05\n",
      "[1625]\ttraining's binary_logloss: 2.43444e-05\n",
      "[1626]\ttraining's binary_logloss: 2.42542e-05\n",
      "[1627]\ttraining's binary_logloss: 2.41673e-05\n",
      "[1628]\ttraining's binary_logloss: 2.40721e-05\n",
      "[1629]\ttraining's binary_logloss: 2.39838e-05\n",
      "[1630]\ttraining's binary_logloss: 2.38869e-05\n",
      "[1631]\ttraining's binary_logloss: 2.38017e-05\n",
      "[1632]\ttraining's binary_logloss: 2.37192e-05\n",
      "[1633]\ttraining's binary_logloss: 2.36331e-05\n",
      "[1634]\ttraining's binary_logloss: 2.35335e-05\n",
      "[1635]\ttraining's binary_logloss: 2.34482e-05\n",
      "[1636]\ttraining's binary_logloss: 2.33533e-05\n",
      "[1637]\ttraining's binary_logloss: 2.32711e-05\n",
      "[1638]\ttraining's binary_logloss: 2.31759e-05\n",
      "[1639]\ttraining's binary_logloss: 2.30861e-05\n",
      "[1640]\ttraining's binary_logloss: 2.29916e-05\n",
      "[1641]\ttraining's binary_logloss: 2.29121e-05\n",
      "[1642]\ttraining's binary_logloss: 2.2823e-05\n",
      "[1643]\ttraining's binary_logloss: 2.27428e-05\n",
      "[1644]\ttraining's binary_logloss: 2.26556e-05\n",
      "[1645]\ttraining's binary_logloss: 2.2565e-05\n",
      "[1646]\ttraining's binary_logloss: 2.24669e-05\n",
      "[1647]\ttraining's binary_logloss: 2.23722e-05\n",
      "[1648]\ttraining's binary_logloss: 2.22915e-05\n",
      "[1649]\ttraining's binary_logloss: 2.22127e-05\n",
      "[1650]\ttraining's binary_logloss: 2.21204e-05\n",
      "[1651]\ttraining's binary_logloss: 2.2036e-05\n",
      "[1652]\ttraining's binary_logloss: 2.19527e-05\n",
      "[1653]\ttraining's binary_logloss: 2.18794e-05\n",
      "[1654]\ttraining's binary_logloss: 2.17979e-05\n",
      "[1655]\ttraining's binary_logloss: 2.17153e-05\n",
      "[1656]\ttraining's binary_logloss: 2.16331e-05\n",
      "[1657]\ttraining's binary_logloss: 2.15499e-05\n",
      "[1658]\ttraining's binary_logloss: 2.14724e-05\n",
      "[1659]\ttraining's binary_logloss: 2.13989e-05\n",
      "[1660]\ttraining's binary_logloss: 2.1326e-05\n",
      "[1661]\ttraining's binary_logloss: 2.12378e-05\n",
      "[1662]\ttraining's binary_logloss: 2.11605e-05\n",
      "[1663]\ttraining's binary_logloss: 2.10803e-05\n",
      "[1664]\ttraining's binary_logloss: 2.10066e-05\n",
      "[1665]\ttraining's binary_logloss: 2.09326e-05\n",
      "[1666]\ttraining's binary_logloss: 2.08511e-05\n",
      "[1667]\ttraining's binary_logloss: 2.07813e-05\n",
      "[1668]\ttraining's binary_logloss: 2.07012e-05\n",
      "[1669]\ttraining's binary_logloss: 2.06335e-05\n",
      "[1670]\ttraining's binary_logloss: 2.05599e-05\n",
      "[1671]\ttraining's binary_logloss: 2.04809e-05\n",
      "[1672]\ttraining's binary_logloss: 2.04072e-05\n",
      "[1673]\ttraining's binary_logloss: 2.03298e-05\n",
      "[1674]\ttraining's binary_logloss: 2.0254e-05\n",
      "[1675]\ttraining's binary_logloss: 2.01854e-05\n",
      "[1676]\ttraining's binary_logloss: 2.01176e-05\n",
      "[1677]\ttraining's binary_logloss: 2.00482e-05\n",
      "[1678]\ttraining's binary_logloss: 1.99751e-05\n",
      "[1679]\ttraining's binary_logloss: 1.99081e-05\n",
      "[1680]\ttraining's binary_logloss: 1.98435e-05\n",
      "[1681]\ttraining's binary_logloss: 1.9777e-05\n",
      "[1682]\ttraining's binary_logloss: 1.97068e-05\n",
      "[1683]\ttraining's binary_logloss: 1.96432e-05\n",
      "[1684]\ttraining's binary_logloss: 1.95765e-05\n",
      "[1685]\ttraining's binary_logloss: 1.95098e-05\n",
      "[1686]\ttraining's binary_logloss: 1.94491e-05\n",
      "[1687]\ttraining's binary_logloss: 1.93818e-05\n",
      "[1688]\ttraining's binary_logloss: 1.93223e-05\n",
      "[1689]\ttraining's binary_logloss: 1.92574e-05\n",
      "[1690]\ttraining's binary_logloss: 1.91979e-05\n",
      "[1691]\ttraining's binary_logloss: 1.91302e-05\n",
      "[1692]\ttraining's binary_logloss: 1.90662e-05\n",
      "[1693]\ttraining's binary_logloss: 1.90043e-05\n",
      "[1694]\ttraining's binary_logloss: 1.89452e-05\n",
      "[1695]\ttraining's binary_logloss: 1.88842e-05\n",
      "[1696]\ttraining's binary_logloss: 1.8828e-05\n",
      "[1697]\ttraining's binary_logloss: 1.8763e-05\n",
      "[1698]\ttraining's binary_logloss: 1.86956e-05\n",
      "[1699]\ttraining's binary_logloss: 1.86314e-05\n",
      "[1700]\ttraining's binary_logloss: 1.85694e-05\n",
      "[1701]\ttraining's binary_logloss: 1.85074e-05\n",
      "[1702]\ttraining's binary_logloss: 1.84468e-05\n",
      "[1703]\ttraining's binary_logloss: 1.83901e-05\n",
      "[1704]\ttraining's binary_logloss: 1.83254e-05\n",
      "[1705]\ttraining's binary_logloss: 1.82658e-05\n",
      "[1706]\ttraining's binary_logloss: 1.82099e-05\n",
      "[1707]\ttraining's binary_logloss: 1.81453e-05\n",
      "[1708]\ttraining's binary_logloss: 1.80804e-05\n",
      "[1709]\ttraining's binary_logloss: 1.80257e-05\n",
      "[1710]\ttraining's binary_logloss: 1.79766e-05\n",
      "[1711]\ttraining's binary_logloss: 1.79118e-05\n",
      "[1712]\ttraining's binary_logloss: 1.78483e-05\n",
      "[1713]\ttraining's binary_logloss: 1.77811e-05\n",
      "[1714]\ttraining's binary_logloss: 1.7727e-05\n",
      "[1715]\ttraining's binary_logloss: 1.76685e-05\n",
      "[1716]\ttraining's binary_logloss: 1.76175e-05\n",
      "[1717]\ttraining's binary_logloss: 1.75615e-05\n",
      "[1718]\ttraining's binary_logloss: 1.75011e-05\n",
      "[1719]\ttraining's binary_logloss: 1.74513e-05\n",
      "[1720]\ttraining's binary_logloss: 1.7397e-05\n",
      "[1721]\ttraining's binary_logloss: 1.73408e-05\n",
      "[1722]\ttraining's binary_logloss: 1.72889e-05\n",
      "[1723]\ttraining's binary_logloss: 1.7233e-05\n",
      "[1724]\ttraining's binary_logloss: 1.71845e-05\n",
      "[1725]\ttraining's binary_logloss: 1.71305e-05\n",
      "[1726]\ttraining's binary_logloss: 1.70847e-05\n",
      "[1727]\ttraining's binary_logloss: 1.70358e-05\n",
      "[1728]\ttraining's binary_logloss: 1.69832e-05\n",
      "[1729]\ttraining's binary_logloss: 1.69271e-05\n",
      "[1730]\ttraining's binary_logloss: 1.68827e-05\n",
      "[1731]\ttraining's binary_logloss: 1.68337e-05\n",
      "[1732]\ttraining's binary_logloss: 1.67835e-05\n",
      "[1733]\ttraining's binary_logloss: 1.67333e-05\n",
      "[1734]\ttraining's binary_logloss: 1.6685e-05\n",
      "[1735]\ttraining's binary_logloss: 1.66381e-05\n",
      "[1736]\ttraining's binary_logloss: 1.65883e-05\n",
      "[1737]\ttraining's binary_logloss: 1.65453e-05\n",
      "[1738]\ttraining's binary_logloss: 1.64934e-05\n",
      "[1739]\ttraining's binary_logloss: 1.64432e-05\n",
      "[1740]\ttraining's binary_logloss: 1.63944e-05\n",
      "[1741]\ttraining's binary_logloss: 1.63474e-05\n",
      "[1742]\ttraining's binary_logloss: 1.63009e-05\n",
      "[1743]\ttraining's binary_logloss: 1.62522e-05\n",
      "[1744]\ttraining's binary_logloss: 1.62084e-05\n",
      "[1745]\ttraining's binary_logloss: 1.6163e-05\n",
      "[1746]\ttraining's binary_logloss: 1.61156e-05\n",
      "[1747]\ttraining's binary_logloss: 1.607e-05\n",
      "[1748]\ttraining's binary_logloss: 1.6027e-05\n",
      "[1749]\ttraining's binary_logloss: 1.59841e-05\n",
      "[1750]\ttraining's binary_logloss: 1.59386e-05\n",
      "[1751]\ttraining's binary_logloss: 1.58897e-05\n",
      "[1752]\ttraining's binary_logloss: 1.58485e-05\n",
      "[1753]\ttraining's binary_logloss: 1.57995e-05\n",
      "[1754]\ttraining's binary_logloss: 1.5753e-05\n",
      "[1755]\ttraining's binary_logloss: 1.57077e-05\n",
      "[1756]\ttraining's binary_logloss: 1.56574e-05\n",
      "[1757]\ttraining's binary_logloss: 1.56092e-05\n",
      "[1758]\ttraining's binary_logloss: 1.55685e-05\n",
      "[1759]\ttraining's binary_logloss: 1.55245e-05\n",
      "[1760]\ttraining's binary_logloss: 1.54765e-05\n",
      "[1761]\ttraining's binary_logloss: 1.54345e-05\n",
      "[1762]\ttraining's binary_logloss: 1.53934e-05\n",
      "[1763]\ttraining's binary_logloss: 1.53541e-05\n",
      "[1764]\ttraining's binary_logloss: 1.5312e-05\n",
      "[1765]\ttraining's binary_logloss: 1.52659e-05\n",
      "[1766]\ttraining's binary_logloss: 1.52288e-05\n",
      "[1767]\ttraining's binary_logloss: 1.51931e-05\n",
      "[1768]\ttraining's binary_logloss: 1.5154e-05\n",
      "[1769]\ttraining's binary_logloss: 1.51138e-05\n",
      "[1770]\ttraining's binary_logloss: 1.50713e-05\n",
      "[1771]\ttraining's binary_logloss: 1.50295e-05\n",
      "[1772]\ttraining's binary_logloss: 1.49944e-05\n",
      "[1773]\ttraining's binary_logloss: 1.49554e-05\n",
      "[1774]\ttraining's binary_logloss: 1.49149e-05\n",
      "[1775]\ttraining's binary_logloss: 1.48734e-05\n",
      "[1776]\ttraining's binary_logloss: 1.4834e-05\n",
      "[1777]\ttraining's binary_logloss: 1.47945e-05\n",
      "[1778]\ttraining's binary_logloss: 1.47553e-05\n",
      "[1779]\ttraining's binary_logloss: 1.47201e-05\n",
      "[1780]\ttraining's binary_logloss: 1.46813e-05\n",
      "[1781]\ttraining's binary_logloss: 1.4647e-05\n",
      "[1782]\ttraining's binary_logloss: 1.4614e-05\n",
      "[1783]\ttraining's binary_logloss: 1.45782e-05\n",
      "[1784]\ttraining's binary_logloss: 1.45397e-05\n",
      "[1785]\ttraining's binary_logloss: 1.45021e-05\n",
      "[1786]\ttraining's binary_logloss: 1.44668e-05\n",
      "[1787]\ttraining's binary_logloss: 1.44261e-05\n",
      "[1788]\ttraining's binary_logloss: 1.43917e-05\n",
      "[1789]\ttraining's binary_logloss: 1.43557e-05\n",
      "[1790]\ttraining's binary_logloss: 1.43176e-05\n",
      "[1791]\ttraining's binary_logloss: 1.42828e-05\n",
      "[1792]\ttraining's binary_logloss: 1.42485e-05\n",
      "[1793]\ttraining's binary_logloss: 1.4217e-05\n",
      "[1794]\ttraining's binary_logloss: 1.41792e-05\n",
      "[1795]\ttraining's binary_logloss: 1.4143e-05\n",
      "[1796]\ttraining's binary_logloss: 1.41098e-05\n",
      "[1797]\ttraining's binary_logloss: 1.40778e-05\n",
      "[1798]\ttraining's binary_logloss: 1.40455e-05\n",
      "[1799]\ttraining's binary_logloss: 1.40095e-05\n",
      "[1800]\ttraining's binary_logloss: 1.39789e-05\n",
      "[1801]\ttraining's binary_logloss: 1.39464e-05\n",
      "[1802]\ttraining's binary_logloss: 1.39089e-05\n",
      "[1803]\ttraining's binary_logloss: 1.38746e-05\n",
      "[1804]\ttraining's binary_logloss: 1.384e-05\n",
      "[1805]\ttraining's binary_logloss: 1.38119e-05\n",
      "[1806]\ttraining's binary_logloss: 1.37772e-05\n",
      "[1807]\ttraining's binary_logloss: 1.37461e-05\n",
      "[1808]\ttraining's binary_logloss: 1.37168e-05\n",
      "[1809]\ttraining's binary_logloss: 1.36847e-05\n",
      "[1810]\ttraining's binary_logloss: 1.36515e-05\n",
      "[1811]\ttraining's binary_logloss: 1.36169e-05\n",
      "[1812]\ttraining's binary_logloss: 1.35857e-05\n",
      "[1813]\ttraining's binary_logloss: 1.35574e-05\n",
      "[1814]\ttraining's binary_logloss: 1.35255e-05\n",
      "[1815]\ttraining's binary_logloss: 1.34913e-05\n",
      "[1816]\ttraining's binary_logloss: 1.34586e-05\n",
      "[1817]\ttraining's binary_logloss: 1.34261e-05\n",
      "[1818]\ttraining's binary_logloss: 1.33929e-05\n",
      "[1819]\ttraining's binary_logloss: 1.33628e-05\n",
      "[1820]\ttraining's binary_logloss: 1.33263e-05\n",
      "[1821]\ttraining's binary_logloss: 1.32986e-05\n",
      "[1822]\ttraining's binary_logloss: 1.32685e-05\n",
      "[1823]\ttraining's binary_logloss: 1.32369e-05\n",
      "[1824]\ttraining's binary_logloss: 1.32042e-05\n",
      "[1825]\ttraining's binary_logloss: 1.31738e-05\n",
      "[1826]\ttraining's binary_logloss: 1.31443e-05\n",
      "[1827]\ttraining's binary_logloss: 1.3111e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1828]\ttraining's binary_logloss: 1.30811e-05\n",
      "[1829]\ttraining's binary_logloss: 1.30507e-05\n",
      "[1830]\ttraining's binary_logloss: 1.30215e-05\n",
      "[1831]\ttraining's binary_logloss: 1.29946e-05\n",
      "[1832]\ttraining's binary_logloss: 1.29687e-05\n",
      "[1833]\ttraining's binary_logloss: 1.29378e-05\n",
      "[1834]\ttraining's binary_logloss: 1.29093e-05\n",
      "[1835]\ttraining's binary_logloss: 1.28829e-05\n",
      "[1836]\ttraining's binary_logloss: 1.28548e-05\n",
      "[1837]\ttraining's binary_logloss: 1.28232e-05\n",
      "[1838]\ttraining's binary_logloss: 1.27929e-05\n",
      "[1839]\ttraining's binary_logloss: 1.27612e-05\n",
      "[1840]\ttraining's binary_logloss: 1.27349e-05\n",
      "[1841]\ttraining's binary_logloss: 1.27091e-05\n",
      "[1842]\ttraining's binary_logloss: 1.26818e-05\n",
      "[1843]\ttraining's binary_logloss: 1.26575e-05\n",
      "[1844]\ttraining's binary_logloss: 1.263e-05\n",
      "[1845]\ttraining's binary_logloss: 1.26017e-05\n",
      "[1846]\ttraining's binary_logloss: 1.25739e-05\n",
      "[1847]\ttraining's binary_logloss: 1.25449e-05\n",
      "[1848]\ttraining's binary_logloss: 1.252e-05\n",
      "[1849]\ttraining's binary_logloss: 1.24941e-05\n",
      "[1850]\ttraining's binary_logloss: 1.24669e-05\n",
      "[1851]\ttraining's binary_logloss: 1.24394e-05\n",
      "[1852]\ttraining's binary_logloss: 1.24142e-05\n",
      "[1853]\ttraining's binary_logloss: 1.23915e-05\n",
      "[1854]\ttraining's binary_logloss: 1.23662e-05\n",
      "[1855]\ttraining's binary_logloss: 1.2342e-05\n",
      "[1856]\ttraining's binary_logloss: 1.23156e-05\n",
      "[1857]\ttraining's binary_logloss: 1.22873e-05\n",
      "[1858]\ttraining's binary_logloss: 1.22628e-05\n",
      "[1859]\ttraining's binary_logloss: 1.22365e-05\n",
      "[1860]\ttraining's binary_logloss: 1.22106e-05\n",
      "[1861]\ttraining's binary_logloss: 1.21822e-05\n",
      "[1862]\ttraining's binary_logloss: 1.2159e-05\n",
      "[1863]\ttraining's binary_logloss: 1.21355e-05\n",
      "[1864]\ttraining's binary_logloss: 1.21095e-05\n",
      "[1865]\ttraining's binary_logloss: 1.20854e-05\n",
      "[1866]\ttraining's binary_logloss: 1.20619e-05\n",
      "[1867]\ttraining's binary_logloss: 1.20344e-05\n",
      "[1868]\ttraining's binary_logloss: 1.20078e-05\n",
      "[1869]\ttraining's binary_logloss: 1.19824e-05\n",
      "[1870]\ttraining's binary_logloss: 1.19568e-05\n",
      "[1871]\ttraining's binary_logloss: 1.19314e-05\n",
      "[1872]\ttraining's binary_logloss: 1.19098e-05\n",
      "[1873]\ttraining's binary_logloss: 1.18837e-05\n",
      "[1874]\ttraining's binary_logloss: 1.18623e-05\n",
      "[1875]\ttraining's binary_logloss: 1.18398e-05\n",
      "[1876]\ttraining's binary_logloss: 1.18154e-05\n",
      "[1877]\ttraining's binary_logloss: 1.17924e-05\n",
      "[1878]\ttraining's binary_logloss: 1.1769e-05\n",
      "[1879]\ttraining's binary_logloss: 1.17468e-05\n",
      "[1880]\ttraining's binary_logloss: 1.17233e-05\n",
      "[1881]\ttraining's binary_logloss: 1.17002e-05\n",
      "[1882]\ttraining's binary_logloss: 1.16754e-05\n",
      "[1883]\ttraining's binary_logloss: 1.16545e-05\n",
      "[1884]\ttraining's binary_logloss: 1.16312e-05\n",
      "[1885]\ttraining's binary_logloss: 1.16075e-05\n",
      "[1886]\ttraining's binary_logloss: 1.15852e-05\n",
      "[1887]\ttraining's binary_logloss: 1.15642e-05\n",
      "[1888]\ttraining's binary_logloss: 1.15397e-05\n",
      "[1889]\ttraining's binary_logloss: 1.1518e-05\n",
      "[1890]\ttraining's binary_logloss: 1.14943e-05\n",
      "[1891]\ttraining's binary_logloss: 1.1471e-05\n",
      "[1892]\ttraining's binary_logloss: 1.14504e-05\n",
      "[1893]\ttraining's binary_logloss: 1.14316e-05\n",
      "[1894]\ttraining's binary_logloss: 1.14097e-05\n",
      "[1895]\ttraining's binary_logloss: 1.13898e-05\n",
      "[1896]\ttraining's binary_logloss: 1.13703e-05\n",
      "[1897]\ttraining's binary_logloss: 1.13475e-05\n",
      "[1898]\ttraining's binary_logloss: 1.13269e-05\n",
      "[1899]\ttraining's binary_logloss: 1.13017e-05\n",
      "[1900]\ttraining's binary_logloss: 1.12818e-05\n",
      "[1901]\ttraining's binary_logloss: 1.12597e-05\n",
      "[1902]\ttraining's binary_logloss: 1.12432e-05\n",
      "[1903]\ttraining's binary_logloss: 1.12212e-05\n",
      "[1904]\ttraining's binary_logloss: 1.12004e-05\n",
      "[1905]\ttraining's binary_logloss: 1.11813e-05\n",
      "[1906]\ttraining's binary_logloss: 1.11605e-05\n",
      "[1907]\ttraining's binary_logloss: 1.11411e-05\n",
      "[1908]\ttraining's binary_logloss: 1.1122e-05\n",
      "[1909]\ttraining's binary_logloss: 1.11027e-05\n",
      "[1910]\ttraining's binary_logloss: 1.10803e-05\n",
      "[1911]\ttraining's binary_logloss: 1.10598e-05\n",
      "[1912]\ttraining's binary_logloss: 1.10367e-05\n",
      "[1913]\ttraining's binary_logloss: 1.10199e-05\n",
      "[1914]\ttraining's binary_logloss: 1.10007e-05\n",
      "[1915]\ttraining's binary_logloss: 1.0982e-05\n",
      "[1916]\ttraining's binary_logloss: 1.09626e-05\n",
      "[1917]\ttraining's binary_logloss: 1.09401e-05\n",
      "[1918]\ttraining's binary_logloss: 1.09195e-05\n",
      "[1919]\ttraining's binary_logloss: 1.08995e-05\n",
      "[1920]\ttraining's binary_logloss: 1.08822e-05\n",
      "[1921]\ttraining's binary_logloss: 1.08626e-05\n",
      "[1922]\ttraining's binary_logloss: 1.08442e-05\n",
      "[1923]\ttraining's binary_logloss: 1.08231e-05\n",
      "[1924]\ttraining's binary_logloss: 1.08044e-05\n",
      "[1925]\ttraining's binary_logloss: 1.07864e-05\n",
      "[1926]\ttraining's binary_logloss: 1.07688e-05\n",
      "[1927]\ttraining's binary_logloss: 1.07497e-05\n",
      "[1928]\ttraining's binary_logloss: 1.07308e-05\n",
      "[1929]\ttraining's binary_logloss: 1.07101e-05\n",
      "[1930]\ttraining's binary_logloss: 1.06904e-05\n",
      "[1931]\ttraining's binary_logloss: 1.06729e-05\n",
      "[1932]\ttraining's binary_logloss: 1.06529e-05\n",
      "[1933]\ttraining's binary_logloss: 1.06347e-05\n",
      "[1934]\ttraining's binary_logloss: 1.06155e-05\n",
      "[1935]\ttraining's binary_logloss: 1.05946e-05\n",
      "[1936]\ttraining's binary_logloss: 1.0577e-05\n",
      "[1937]\ttraining's binary_logloss: 1.05604e-05\n",
      "[1938]\ttraining's binary_logloss: 1.05426e-05\n",
      "[1939]\ttraining's binary_logloss: 1.05229e-05\n",
      "[1940]\ttraining's binary_logloss: 1.05042e-05\n",
      "[1941]\ttraining's binary_logloss: 1.04863e-05\n",
      "[1942]\ttraining's binary_logloss: 1.04687e-05\n",
      "[1943]\ttraining's binary_logloss: 1.04501e-05\n",
      "[1944]\ttraining's binary_logloss: 1.04315e-05\n",
      "[1945]\ttraining's binary_logloss: 1.04115e-05\n",
      "[1946]\ttraining's binary_logloss: 1.03933e-05\n",
      "[1947]\ttraining's binary_logloss: 1.03743e-05\n",
      "[1948]\ttraining's binary_logloss: 1.03572e-05\n",
      "[1949]\ttraining's binary_logloss: 1.03384e-05\n",
      "[1950]\ttraining's binary_logloss: 1.03229e-05\n",
      "[1951]\ttraining's binary_logloss: 1.03045e-05\n",
      "[1952]\ttraining's binary_logloss: 1.02874e-05\n",
      "[1953]\ttraining's binary_logloss: 1.02721e-05\n",
      "[1954]\ttraining's binary_logloss: 1.02537e-05\n",
      "[1955]\ttraining's binary_logloss: 1.02356e-05\n",
      "[1956]\ttraining's binary_logloss: 1.02194e-05\n",
      "[1957]\ttraining's binary_logloss: 1.02038e-05\n",
      "[1958]\ttraining's binary_logloss: 1.01868e-05\n",
      "[1959]\ttraining's binary_logloss: 1.01698e-05\n",
      "[1960]\ttraining's binary_logloss: 1.01537e-05\n",
      "[1961]\ttraining's binary_logloss: 1.01384e-05\n",
      "[1962]\ttraining's binary_logloss: 1.01223e-05\n",
      "[1963]\ttraining's binary_logloss: 1.01059e-05\n",
      "[1964]\ttraining's binary_logloss: 1.00912e-05\n",
      "[1965]\ttraining's binary_logloss: 1.00776e-05\n",
      "[1966]\ttraining's binary_logloss: 1.00609e-05\n",
      "[1967]\ttraining's binary_logloss: 1.00423e-05\n",
      "[1968]\ttraining's binary_logloss: 1.00246e-05\n",
      "[1969]\ttraining's binary_logloss: 1.00109e-05\n",
      "[1970]\ttraining's binary_logloss: 9.99489e-06\n",
      "[1971]\ttraining's binary_logloss: 9.97779e-06\n",
      "[1972]\ttraining's binary_logloss: 9.96215e-06\n",
      "[1973]\ttraining's binary_logloss: 9.94603e-06\n",
      "[1974]\ttraining's binary_logloss: 9.93039e-06\n",
      "[1975]\ttraining's binary_logloss: 9.91178e-06\n",
      "[1976]\ttraining's binary_logloss: 9.89496e-06\n",
      "[1977]\ttraining's binary_logloss: 9.87976e-06\n",
      "[1978]\ttraining's binary_logloss: 9.86329e-06\n",
      "[1979]\ttraining's binary_logloss: 9.84891e-06\n",
      "[1980]\ttraining's binary_logloss: 9.83206e-06\n",
      "[1981]\ttraining's binary_logloss: 9.81815e-06\n",
      "[1982]\ttraining's binary_logloss: 9.80382e-06\n",
      "[1983]\ttraining's binary_logloss: 9.78869e-06\n",
      "[1984]\ttraining's binary_logloss: 9.77414e-06\n",
      "[1985]\ttraining's binary_logloss: 9.75913e-06\n",
      "[1986]\ttraining's binary_logloss: 9.74459e-06\n",
      "[1987]\ttraining's binary_logloss: 9.72944e-06\n",
      "[1988]\ttraining's binary_logloss: 9.7134e-06\n",
      "[1989]\ttraining's binary_logloss: 9.69693e-06\n",
      "[1990]\ttraining's binary_logloss: 9.68363e-06\n",
      "[1991]\ttraining's binary_logloss: 9.67107e-06\n",
      "[1992]\ttraining's binary_logloss: 9.65616e-06\n",
      "[1993]\ttraining's binary_logloss: 9.64273e-06\n",
      "[1994]\ttraining's binary_logloss: 9.62981e-06\n",
      "[1995]\ttraining's binary_logloss: 9.61639e-06\n",
      "[1996]\ttraining's binary_logloss: 9.60349e-06\n",
      "[1997]\ttraining's binary_logloss: 9.58732e-06\n",
      "[1998]\ttraining's binary_logloss: 9.57183e-06\n",
      "[1999]\ttraining's binary_logloss: 9.5589e-06\n",
      "[2000]\ttraining's binary_logloss: 9.5442e-06\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = lgb.train(\n",
    "    lgbm_params,\n",
    "    lgtrain,\n",
    "    valid_sets=lgtrain,\n",
    "    num_boost_round=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7884536364881524"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_lgb = lgb_clf.predict(X_test)\n",
    "predict_lgb = np.array([0 if i < 0.6 else 1 for i in predict_lgb])\n",
    "roc_auc_score(predict_lgb, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf, 'random_forest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.679963\n",
      "[2]\ttraining's binary_logloss: 0.66497\n",
      "[3]\ttraining's binary_logloss: 0.652721\n",
      "[4]\ttraining's binary_logloss: 0.638789\n",
      "[5]\ttraining's binary_logloss: 0.625434\n",
      "[6]\ttraining's binary_logloss: 0.61472\n",
      "[7]\ttraining's binary_logloss: 0.603808\n",
      "[8]\ttraining's binary_logloss: 0.591721\n",
      "[9]\ttraining's binary_logloss: 0.581847\n",
      "[10]\ttraining's binary_logloss: 0.57042\n",
      "[11]\ttraining's binary_logloss: 0.561189\n",
      "[12]\ttraining's binary_logloss: 0.550441\n",
      "[13]\ttraining's binary_logloss: 0.541623\n",
      "[14]\ttraining's binary_logloss: 0.53153\n",
      "[15]\ttraining's binary_logloss: 0.52316\n",
      "[16]\ttraining's binary_logloss: 0.515254\n",
      "[17]\ttraining's binary_logloss: 0.505888\n",
      "[18]\ttraining's binary_logloss: 0.498422\n",
      "[19]\ttraining's binary_logloss: 0.489725\n",
      "[20]\ttraining's binary_logloss: 0.482526\n",
      "[21]\ttraining's binary_logloss: 0.47419\n",
      "[22]\ttraining's binary_logloss: 0.467509\n",
      "[23]\ttraining's binary_logloss: 0.460875\n",
      "[24]\ttraining's binary_logloss: 0.454472\n",
      "[25]\ttraining's binary_logloss: 0.446948\n",
      "[26]\ttraining's binary_logloss: 0.439619\n",
      "[27]\ttraining's binary_logloss: 0.433498\n",
      "[28]\ttraining's binary_logloss: 0.426549\n",
      "[29]\ttraining's binary_logloss: 0.419785\n",
      "[30]\ttraining's binary_logloss: 0.414263\n",
      "[31]\ttraining's binary_logloss: 0.408809\n",
      "[32]\ttraining's binary_logloss: 0.40361\n",
      "[33]\ttraining's binary_logloss: 0.398344\n",
      "[34]\ttraining's binary_logloss: 0.392252\n",
      "[35]\ttraining's binary_logloss: 0.386275\n",
      "[36]\ttraining's binary_logloss: 0.380373\n",
      "[37]\ttraining's binary_logloss: 0.374821\n",
      "[38]\ttraining's binary_logloss: 0.369349\n",
      "[39]\ttraining's binary_logloss: 0.3649\n",
      "[40]\ttraining's binary_logloss: 0.359667\n",
      "[41]\ttraining's binary_logloss: 0.354524\n",
      "[42]\ttraining's binary_logloss: 0.350275\n",
      "[43]\ttraining's binary_logloss: 0.346366\n",
      "[44]\ttraining's binary_logloss: 0.342267\n",
      "[45]\ttraining's binary_logloss: 0.338377\n",
      "[46]\ttraining's binary_logloss: 0.333706\n",
      "[47]\ttraining's binary_logloss: 0.329126\n",
      "[48]\ttraining's binary_logloss: 0.325375\n",
      "[49]\ttraining's binary_logloss: 0.321066\n",
      "[50]\ttraining's binary_logloss: 0.317551\n",
      "[51]\ttraining's binary_logloss: 0.313404\n",
      "[52]\ttraining's binary_logloss: 0.309235\n",
      "[53]\ttraining's binary_logloss: 0.305869\n",
      "[54]\ttraining's binary_logloss: 0.301895\n",
      "[55]\ttraining's binary_logloss: 0.298002\n",
      "[56]\ttraining's binary_logloss: 0.294753\n",
      "[57]\ttraining's binary_logloss: 0.291059\n",
      "[58]\ttraining's binary_logloss: 0.28797\n",
      "[59]\ttraining's binary_logloss: 0.284929\n",
      "[60]\ttraining's binary_logloss: 0.282025\n",
      "[61]\ttraining's binary_logloss: 0.278468\n",
      "[62]\ttraining's binary_logloss: 0.274933\n",
      "[63]\ttraining's binary_logloss: 0.272195\n",
      "[64]\ttraining's binary_logloss: 0.268885\n",
      "[65]\ttraining's binary_logloss: 0.265655\n",
      "[66]\ttraining's binary_logloss: 0.262983\n",
      "[67]\ttraining's binary_logloss: 0.260381\n",
      "[68]\ttraining's binary_logloss: 0.257138\n",
      "[69]\ttraining's binary_logloss: 0.253977\n",
      "[70]\ttraining's binary_logloss: 0.251412\n",
      "[71]\ttraining's binary_logloss: 0.248524\n",
      "[72]\ttraining's binary_logloss: 0.246123\n",
      "[73]\ttraining's binary_logloss: 0.243222\n",
      "[74]\ttraining's binary_logloss: 0.240436\n",
      "[75]\ttraining's binary_logloss: 0.237646\n",
      "[76]\ttraining's binary_logloss: 0.235419\n",
      "[77]\ttraining's binary_logloss: 0.233128\n",
      "[78]\ttraining's binary_logloss: 0.230896\n",
      "[79]\ttraining's binary_logloss: 0.228234\n",
      "[80]\ttraining's binary_logloss: 0.225676\n",
      "[81]\ttraining's binary_logloss: 0.223547\n",
      "[82]\ttraining's binary_logloss: 0.221389\n",
      "[83]\ttraining's binary_logloss: 0.219321\n",
      "[84]\ttraining's binary_logloss: 0.216957\n",
      "[85]\ttraining's binary_logloss: 0.214964\n",
      "[86]\ttraining's binary_logloss: 0.2126\n",
      "[87]\ttraining's binary_logloss: 0.210673\n",
      "[88]\ttraining's binary_logloss: 0.208848\n",
      "[89]\ttraining's binary_logloss: 0.206566\n",
      "[90]\ttraining's binary_logloss: 0.204684\n",
      "[91]\ttraining's binary_logloss: 0.202782\n",
      "[92]\ttraining's binary_logloss: 0.200945\n",
      "[93]\ttraining's binary_logloss: 0.199153\n",
      "[94]\ttraining's binary_logloss: 0.197372\n",
      "[95]\ttraining's binary_logloss: 0.195579\n",
      "[96]\ttraining's binary_logloss: 0.193489\n",
      "[97]\ttraining's binary_logloss: 0.191461\n",
      "[98]\ttraining's binary_logloss: 0.189404\n",
      "[99]\ttraining's binary_logloss: 0.187745\n",
      "[100]\ttraining's binary_logloss: 0.18577\n",
      "[101]\ttraining's binary_logloss: 0.184144\n",
      "[102]\ttraining's binary_logloss: 0.182228\n",
      "[103]\ttraining's binary_logloss: 0.180646\n",
      "[104]\ttraining's binary_logloss: 0.179066\n",
      "[105]\ttraining's binary_logloss: 0.177547\n",
      "[106]\ttraining's binary_logloss: 0.175685\n",
      "[107]\ttraining's binary_logloss: 0.173863\n",
      "[108]\ttraining's binary_logloss: 0.172411\n",
      "[109]\ttraining's binary_logloss: 0.170898\n",
      "[110]\ttraining's binary_logloss: 0.169154\n",
      "[111]\ttraining's binary_logloss: 0.167372\n",
      "[112]\ttraining's binary_logloss: 0.16566\n",
      "[113]\ttraining's binary_logloss: 0.164063\n",
      "[114]\ttraining's binary_logloss: 0.162583\n",
      "[115]\ttraining's binary_logloss: 0.161207\n",
      "[116]\ttraining's binary_logloss: 0.159556\n",
      "[117]\ttraining's binary_logloss: 0.157945\n",
      "[118]\ttraining's binary_logloss: 0.156649\n",
      "[119]\ttraining's binary_logloss: 0.155091\n",
      "[120]\ttraining's binary_logloss: 0.153802\n",
      "[121]\ttraining's binary_logloss: 0.152265\n",
      "[122]\ttraining's binary_logloss: 0.151015\n",
      "[123]\ttraining's binary_logloss: 0.149507\n",
      "[124]\ttraining's binary_logloss: 0.148255\n",
      "[125]\ttraining's binary_logloss: 0.146797\n",
      "[126]\ttraining's binary_logloss: 0.14555\n",
      "[127]\ttraining's binary_logloss: 0.144185\n",
      "[128]\ttraining's binary_logloss: 0.142939\n",
      "[129]\ttraining's binary_logloss: 0.141812\n",
      "[130]\ttraining's binary_logloss: 0.140409\n",
      "[131]\ttraining's binary_logloss: 0.139231\n",
      "[132]\ttraining's binary_logloss: 0.138025\n",
      "[133]\ttraining's binary_logloss: 0.136891\n",
      "[134]\ttraining's binary_logloss: 0.135781\n",
      "[135]\ttraining's binary_logloss: 0.13452\n",
      "[136]\ttraining's binary_logloss: 0.133225\n",
      "[137]\ttraining's binary_logloss: 0.132128\n",
      "[138]\ttraining's binary_logloss: 0.130994\n",
      "[139]\ttraining's binary_logloss: 0.129713\n",
      "[140]\ttraining's binary_logloss: 0.128477\n",
      "[141]\ttraining's binary_logloss: 0.127455\n",
      "[142]\ttraining's binary_logloss: 0.126277\n",
      "[143]\ttraining's binary_logloss: 0.125246\n",
      "[144]\ttraining's binary_logloss: 0.124189\n",
      "[145]\ttraining's binary_logloss: 0.123137\n",
      "[146]\ttraining's binary_logloss: 0.121966\n",
      "[147]\ttraining's binary_logloss: 0.120761\n",
      "[148]\ttraining's binary_logloss: 0.119799\n",
      "[149]\ttraining's binary_logloss: 0.118851\n",
      "[150]\ttraining's binary_logloss: 0.117906\n",
      "[151]\ttraining's binary_logloss: 0.116812\n",
      "[152]\ttraining's binary_logloss: 0.115737\n",
      "[153]\ttraining's binary_logloss: 0.114804\n",
      "[154]\ttraining's binary_logloss: 0.113885\n",
      "[155]\ttraining's binary_logloss: 0.112927\n",
      "[156]\ttraining's binary_logloss: 0.112013\n",
      "[157]\ttraining's binary_logloss: 0.111113\n",
      "[158]\ttraining's binary_logloss: 0.11007\n",
      "[159]\ttraining's binary_logloss: 0.109017\n",
      "[160]\ttraining's binary_logloss: 0.108137\n",
      "[161]\ttraining's binary_logloss: 0.10711\n",
      "[162]\ttraining's binary_logloss: 0.106263\n",
      "[163]\ttraining's binary_logloss: 0.105385\n",
      "[164]\ttraining's binary_logloss: 0.1044\n",
      "[165]\ttraining's binary_logloss: 0.103551\n",
      "[166]\ttraining's binary_logloss: 0.102634\n",
      "[167]\ttraining's binary_logloss: 0.101702\n",
      "[168]\ttraining's binary_logloss: 0.10087\n",
      "[169]\ttraining's binary_logloss: 0.0999508\n",
      "[170]\ttraining's binary_logloss: 0.0990197\n",
      "[171]\ttraining's binary_logloss: 0.098245\n",
      "[172]\ttraining's binary_logloss: 0.0975026\n",
      "[173]\ttraining's binary_logloss: 0.0966415\n",
      "[174]\ttraining's binary_logloss: 0.0957594\n",
      "[175]\ttraining's binary_logloss: 0.0949628\n",
      "[176]\ttraining's binary_logloss: 0.0942145\n",
      "[177]\ttraining's binary_logloss: 0.0933526\n",
      "[178]\ttraining's binary_logloss: 0.092574\n",
      "[179]\ttraining's binary_logloss: 0.0918334\n",
      "[180]\ttraining's binary_logloss: 0.0909988\n",
      "[181]\ttraining's binary_logloss: 0.0901212\n",
      "[182]\ttraining's binary_logloss: 0.0892825\n",
      "[183]\ttraining's binary_logloss: 0.0884927\n",
      "[184]\ttraining's binary_logloss: 0.0877016\n",
      "[185]\ttraining's binary_logloss: 0.0870071\n",
      "[186]\ttraining's binary_logloss: 0.0862312\n",
      "[187]\ttraining's binary_logloss: 0.0855052\n",
      "[188]\ttraining's binary_logloss: 0.0847689\n",
      "[189]\ttraining's binary_logloss: 0.0840466\n",
      "[190]\ttraining's binary_logloss: 0.0834341\n",
      "[191]\ttraining's binary_logloss: 0.0826686\n",
      "[192]\ttraining's binary_logloss: 0.0819852\n",
      "[193]\ttraining's binary_logloss: 0.0812484\n",
      "[194]\ttraining's binary_logloss: 0.0805737\n",
      "[195]\ttraining's binary_logloss: 0.0798818\n",
      "[196]\ttraining's binary_logloss: 0.0791462\n",
      "[197]\ttraining's binary_logloss: 0.0785112\n",
      "[198]\ttraining's binary_logloss: 0.0778671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[199]\ttraining's binary_logloss: 0.0772638\n",
      "[200]\ttraining's binary_logloss: 0.0766379\n",
      "[201]\ttraining's binary_logloss: 0.0759774\n",
      "[202]\ttraining's binary_logloss: 0.0753103\n",
      "[203]\ttraining's binary_logloss: 0.0747256\n",
      "[204]\ttraining's binary_logloss: 0.0741488\n",
      "[205]\ttraining's binary_logloss: 0.0734999\n",
      "[206]\ttraining's binary_logloss: 0.0729097\n",
      "[207]\ttraining's binary_logloss: 0.07227\n",
      "[208]\ttraining's binary_logloss: 0.0715998\n",
      "[209]\ttraining's binary_logloss: 0.0709609\n",
      "[210]\ttraining's binary_logloss: 0.0703132\n",
      "[211]\ttraining's binary_logloss: 0.0697548\n",
      "[212]\ttraining's binary_logloss: 0.0691784\n",
      "[213]\ttraining's binary_logloss: 0.0685933\n",
      "[214]\ttraining's binary_logloss: 0.0680614\n",
      "[215]\ttraining's binary_logloss: 0.0674941\n",
      "[216]\ttraining's binary_logloss: 0.0669178\n",
      "[217]\ttraining's binary_logloss: 0.066328\n",
      "[218]\ttraining's binary_logloss: 0.0658082\n",
      "[219]\ttraining's binary_logloss: 0.0653198\n",
      "[220]\ttraining's binary_logloss: 0.0647656\n",
      "[221]\ttraining's binary_logloss: 0.0642212\n",
      "[222]\ttraining's binary_logloss: 0.0636756\n",
      "[223]\ttraining's binary_logloss: 0.0631491\n",
      "[224]\ttraining's binary_logloss: 0.062638\n",
      "[225]\ttraining's binary_logloss: 0.0621118\n",
      "[226]\ttraining's binary_logloss: 0.0616183\n",
      "[227]\ttraining's binary_logloss: 0.0611019\n",
      "[228]\ttraining's binary_logloss: 0.0606229\n",
      "[229]\ttraining's binary_logloss: 0.0600992\n",
      "[230]\ttraining's binary_logloss: 0.0596143\n",
      "[231]\ttraining's binary_logloss: 0.0591266\n",
      "[232]\ttraining's binary_logloss: 0.0586705\n",
      "[233]\ttraining's binary_logloss: 0.0581841\n",
      "[234]\ttraining's binary_logloss: 0.0577083\n",
      "[235]\ttraining's binary_logloss: 0.0572214\n",
      "[236]\ttraining's binary_logloss: 0.056758\n",
      "[237]\ttraining's binary_logloss: 0.0562983\n",
      "[238]\ttraining's binary_logloss: 0.0558459\n",
      "[239]\ttraining's binary_logloss: 0.0553963\n",
      "[240]\ttraining's binary_logloss: 0.0549271\n",
      "[241]\ttraining's binary_logloss: 0.0544738\n",
      "[242]\ttraining's binary_logloss: 0.0540053\n",
      "[243]\ttraining's binary_logloss: 0.0535628\n",
      "[244]\ttraining's binary_logloss: 0.0531533\n",
      "[245]\ttraining's binary_logloss: 0.0527112\n",
      "[246]\ttraining's binary_logloss: 0.0522844\n",
      "[247]\ttraining's binary_logloss: 0.0518874\n",
      "[248]\ttraining's binary_logloss: 0.0514647\n",
      "[249]\ttraining's binary_logloss: 0.0510556\n",
      "[250]\ttraining's binary_logloss: 0.0506682\n",
      "[251]\ttraining's binary_logloss: 0.0502696\n",
      "[252]\ttraining's binary_logloss: 0.0498742\n",
      "[253]\ttraining's binary_logloss: 0.0494613\n",
      "[254]\ttraining's binary_logloss: 0.0490746\n",
      "[255]\ttraining's binary_logloss: 0.048682\n",
      "[256]\ttraining's binary_logloss: 0.0482955\n",
      "[257]\ttraining's binary_logloss: 0.0479037\n",
      "[258]\ttraining's binary_logloss: 0.0475096\n",
      "[259]\ttraining's binary_logloss: 0.0471576\n",
      "[260]\ttraining's binary_logloss: 0.0467778\n",
      "[261]\ttraining's binary_logloss: 0.0464054\n",
      "[262]\ttraining's binary_logloss: 0.0460471\n",
      "[263]\ttraining's binary_logloss: 0.045672\n",
      "[264]\ttraining's binary_logloss: 0.045319\n",
      "[265]\ttraining's binary_logloss: 0.0449705\n",
      "[266]\ttraining's binary_logloss: 0.0446228\n",
      "[267]\ttraining's binary_logloss: 0.044261\n",
      "[268]\ttraining's binary_logloss: 0.0438791\n",
      "[269]\ttraining's binary_logloss: 0.0435181\n",
      "[270]\ttraining's binary_logloss: 0.0431746\n",
      "[271]\ttraining's binary_logloss: 0.0428168\n",
      "[272]\ttraining's binary_logloss: 0.0424875\n",
      "[273]\ttraining's binary_logloss: 0.0421553\n",
      "[274]\ttraining's binary_logloss: 0.0418083\n",
      "[275]\ttraining's binary_logloss: 0.041475\n",
      "[276]\ttraining's binary_logloss: 0.0411459\n",
      "[277]\ttraining's binary_logloss: 0.0408344\n",
      "[278]\ttraining's binary_logloss: 0.040494\n",
      "[279]\ttraining's binary_logloss: 0.0401883\n",
      "[280]\ttraining's binary_logloss: 0.0398791\n",
      "[281]\ttraining's binary_logloss: 0.0395616\n",
      "[282]\ttraining's binary_logloss: 0.0392493\n",
      "[283]\ttraining's binary_logloss: 0.0389341\n",
      "[284]\ttraining's binary_logloss: 0.0386259\n",
      "[285]\ttraining's binary_logloss: 0.038319\n",
      "[286]\ttraining's binary_logloss: 0.0380191\n",
      "[287]\ttraining's binary_logloss: 0.0377088\n",
      "[288]\ttraining's binary_logloss: 0.0374307\n",
      "[289]\ttraining's binary_logloss: 0.0371431\n",
      "[290]\ttraining's binary_logloss: 0.0368473\n",
      "[291]\ttraining's binary_logloss: 0.0365469\n",
      "[292]\ttraining's binary_logloss: 0.036274\n",
      "[293]\ttraining's binary_logloss: 0.0359971\n",
      "[294]\ttraining's binary_logloss: 0.0357139\n",
      "[295]\ttraining's binary_logloss: 0.0354357\n",
      "[296]\ttraining's binary_logloss: 0.0351663\n",
      "[297]\ttraining's binary_logloss: 0.0348798\n",
      "[298]\ttraining's binary_logloss: 0.0346154\n",
      "[299]\ttraining's binary_logloss: 0.0343329\n",
      "[300]\ttraining's binary_logloss: 0.0340559\n",
      "[301]\ttraining's binary_logloss: 0.0337888\n",
      "[302]\ttraining's binary_logloss: 0.0335231\n",
      "[303]\ttraining's binary_logloss: 0.0332643\n",
      "[304]\ttraining's binary_logloss: 0.0330167\n",
      "[305]\ttraining's binary_logloss: 0.0327656\n",
      "[306]\ttraining's binary_logloss: 0.0325011\n",
      "[307]\ttraining's binary_logloss: 0.0322418\n",
      "[308]\ttraining's binary_logloss: 0.031996\n",
      "[309]\ttraining's binary_logloss: 0.0317577\n",
      "[310]\ttraining's binary_logloss: 0.0315155\n",
      "[311]\ttraining's binary_logloss: 0.0312587\n",
      "[312]\ttraining's binary_logloss: 0.0310052\n",
      "[313]\ttraining's binary_logloss: 0.0307574\n",
      "[314]\ttraining's binary_logloss: 0.0305268\n",
      "[315]\ttraining's binary_logloss: 0.030294\n",
      "[316]\ttraining's binary_logloss: 0.0300643\n",
      "[317]\ttraining's binary_logloss: 0.0298353\n",
      "[318]\ttraining's binary_logloss: 0.0296069\n",
      "[319]\ttraining's binary_logloss: 0.0293748\n",
      "[320]\ttraining's binary_logloss: 0.029155\n",
      "[321]\ttraining's binary_logloss: 0.0289416\n",
      "[322]\ttraining's binary_logloss: 0.0287221\n",
      "[323]\ttraining's binary_logloss: 0.0284949\n",
      "[324]\ttraining's binary_logloss: 0.0282682\n",
      "[325]\ttraining's binary_logloss: 0.0280631\n",
      "[326]\ttraining's binary_logloss: 0.0278447\n",
      "[327]\ttraining's binary_logloss: 0.0276368\n",
      "[328]\ttraining's binary_logloss: 0.027427\n",
      "[329]\ttraining's binary_logloss: 0.0272156\n",
      "[330]\ttraining's binary_logloss: 0.027004\n",
      "[331]\ttraining's binary_logloss: 0.0267961\n",
      "[332]\ttraining's binary_logloss: 0.0265897\n",
      "[333]\ttraining's binary_logloss: 0.0263855\n",
      "[334]\ttraining's binary_logloss: 0.0261838\n",
      "[335]\ttraining's binary_logloss: 0.025981\n",
      "[336]\ttraining's binary_logloss: 0.0257806\n",
      "[337]\ttraining's binary_logloss: 0.0255857\n",
      "[338]\ttraining's binary_logloss: 0.0253861\n",
      "[339]\ttraining's binary_logloss: 0.0251884\n",
      "[340]\ttraining's binary_logloss: 0.0249973\n",
      "[341]\ttraining's binary_logloss: 0.0248062\n",
      "[342]\ttraining's binary_logloss: 0.0246153\n",
      "[343]\ttraining's binary_logloss: 0.0244462\n",
      "[344]\ttraining's binary_logloss: 0.0242738\n",
      "[345]\ttraining's binary_logloss: 0.0240907\n",
      "[346]\ttraining's binary_logloss: 0.0239012\n",
      "[347]\ttraining's binary_logloss: 0.02373\n",
      "[348]\ttraining's binary_logloss: 0.0235527\n",
      "[349]\ttraining's binary_logloss: 0.0233665\n",
      "[350]\ttraining's binary_logloss: 0.0231985\n",
      "[351]\ttraining's binary_logloss: 0.0230255\n",
      "[352]\ttraining's binary_logloss: 0.0228425\n",
      "[353]\ttraining's binary_logloss: 0.0226706\n",
      "[354]\ttraining's binary_logloss: 0.0224954\n",
      "[355]\ttraining's binary_logloss: 0.022318\n",
      "[356]\ttraining's binary_logloss: 0.0221549\n",
      "[357]\ttraining's binary_logloss: 0.0219782\n",
      "[358]\ttraining's binary_logloss: 0.021806\n",
      "[359]\ttraining's binary_logloss: 0.0216314\n",
      "[360]\ttraining's binary_logloss: 0.0214707\n",
      "[361]\ttraining's binary_logloss: 0.0213098\n",
      "[362]\ttraining's binary_logloss: 0.0211541\n",
      "[363]\ttraining's binary_logloss: 0.020992\n",
      "[364]\ttraining's binary_logloss: 0.0208415\n",
      "[365]\ttraining's binary_logloss: 0.02068\n",
      "[366]\ttraining's binary_logloss: 0.0205189\n",
      "[367]\ttraining's binary_logloss: 0.0203626\n",
      "[368]\ttraining's binary_logloss: 0.0202103\n",
      "[369]\ttraining's binary_logloss: 0.0200436\n",
      "[370]\ttraining's binary_logloss: 0.0198875\n",
      "[371]\ttraining's binary_logloss: 0.0197482\n",
      "[372]\ttraining's binary_logloss: 0.0195942\n",
      "[373]\ttraining's binary_logloss: 0.0194506\n",
      "[374]\ttraining's binary_logloss: 0.0193044\n",
      "[375]\ttraining's binary_logloss: 0.019162\n",
      "[376]\ttraining's binary_logloss: 0.0190129\n",
      "[377]\ttraining's binary_logloss: 0.0188638\n",
      "[378]\ttraining's binary_logloss: 0.0187253\n",
      "[379]\ttraining's binary_logloss: 0.0185813\n",
      "[380]\ttraining's binary_logloss: 0.0184323\n",
      "[381]\ttraining's binary_logloss: 0.0182838\n",
      "[382]\ttraining's binary_logloss: 0.0181414\n",
      "[383]\ttraining's binary_logloss: 0.0180054\n",
      "[384]\ttraining's binary_logloss: 0.0178645\n",
      "[385]\ttraining's binary_logloss: 0.0177298\n",
      "[386]\ttraining's binary_logloss: 0.0175903\n",
      "[387]\ttraining's binary_logloss: 0.0174592\n",
      "[388]\ttraining's binary_logloss: 0.0173305\n",
      "[389]\ttraining's binary_logloss: 0.0171948\n",
      "[390]\ttraining's binary_logloss: 0.0170689\n",
      "[391]\ttraining's binary_logloss: 0.016942\n",
      "[392]\ttraining's binary_logloss: 0.0168076\n",
      "[393]\ttraining's binary_logloss: 0.0166851\n",
      "[394]\ttraining's binary_logloss: 0.0165552\n",
      "[395]\ttraining's binary_logloss: 0.0164301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[396]\ttraining's binary_logloss: 0.0163086\n",
      "[397]\ttraining's binary_logloss: 0.0161884\n",
      "[398]\ttraining's binary_logloss: 0.0160625\n",
      "[399]\ttraining's binary_logloss: 0.0159455\n",
      "[400]\ttraining's binary_logloss: 0.0158206\n",
      "[401]\ttraining's binary_logloss: 0.0157\n",
      "[402]\ttraining's binary_logloss: 0.0155789\n",
      "[403]\ttraining's binary_logloss: 0.0154607\n",
      "[404]\ttraining's binary_logloss: 0.0153426\n",
      "[405]\ttraining's binary_logloss: 0.0152259\n",
      "[406]\ttraining's binary_logloss: 0.0151091\n",
      "[407]\ttraining's binary_logloss: 0.0149929\n",
      "[408]\ttraining's binary_logloss: 0.0148796\n",
      "[409]\ttraining's binary_logloss: 0.0147623\n",
      "[410]\ttraining's binary_logloss: 0.0146502\n",
      "[411]\ttraining's binary_logloss: 0.0145413\n",
      "[412]\ttraining's binary_logloss: 0.0144362\n",
      "[413]\ttraining's binary_logloss: 0.0143286\n",
      "[414]\ttraining's binary_logloss: 0.0142198\n",
      "[415]\ttraining's binary_logloss: 0.0141239\n",
      "[416]\ttraining's binary_logloss: 0.0140186\n",
      "[417]\ttraining's binary_logloss: 0.0139128\n",
      "[418]\ttraining's binary_logloss: 0.0138017\n",
      "[419]\ttraining's binary_logloss: 0.0137046\n",
      "[420]\ttraining's binary_logloss: 0.0136069\n",
      "[421]\ttraining's binary_logloss: 0.0135029\n",
      "[422]\ttraining's binary_logloss: 0.0134028\n",
      "[423]\ttraining's binary_logloss: 0.0132999\n",
      "[424]\ttraining's binary_logloss: 0.0131975\n",
      "[425]\ttraining's binary_logloss: 0.0130979\n",
      "[426]\ttraining's binary_logloss: 0.0129995\n",
      "[427]\ttraining's binary_logloss: 0.012904\n",
      "[428]\ttraining's binary_logloss: 0.0128033\n",
      "[429]\ttraining's binary_logloss: 0.0127136\n",
      "[430]\ttraining's binary_logloss: 0.0126146\n",
      "[431]\ttraining's binary_logloss: 0.0125212\n",
      "[432]\ttraining's binary_logloss: 0.0124241\n",
      "[433]\ttraining's binary_logloss: 0.0123305\n",
      "[434]\ttraining's binary_logloss: 0.0122348\n",
      "[435]\ttraining's binary_logloss: 0.0121236\n",
      "[436]\ttraining's binary_logloss: 0.012016\n",
      "[437]\ttraining's binary_logloss: 0.011919\n",
      "[438]\ttraining's binary_logloss: 0.0118206\n",
      "[439]\ttraining's binary_logloss: 0.0117187\n",
      "[440]\ttraining's binary_logloss: 0.0116259\n",
      "[441]\ttraining's binary_logloss: 0.0115359\n",
      "[442]\ttraining's binary_logloss: 0.0114464\n",
      "[443]\ttraining's binary_logloss: 0.0113553\n",
      "[444]\ttraining's binary_logloss: 0.011261\n",
      "[445]\ttraining's binary_logloss: 0.0111769\n",
      "[446]\ttraining's binary_logloss: 0.0110875\n",
      "[447]\ttraining's binary_logloss: 0.0109997\n",
      "[448]\ttraining's binary_logloss: 0.0109131\n",
      "[449]\ttraining's binary_logloss: 0.0108244\n",
      "[450]\ttraining's binary_logloss: 0.0107454\n",
      "[451]\ttraining's binary_logloss: 0.0106594\n",
      "[452]\ttraining's binary_logloss: 0.0105764\n",
      "[453]\ttraining's binary_logloss: 0.010495\n",
      "[454]\ttraining's binary_logloss: 0.010414\n",
      "[455]\ttraining's binary_logloss: 0.0103356\n",
      "[456]\ttraining's binary_logloss: 0.010256\n",
      "[457]\ttraining's binary_logloss: 0.0101826\n",
      "[458]\ttraining's binary_logloss: 0.0101069\n",
      "[459]\ttraining's binary_logloss: 0.0100338\n",
      "[460]\ttraining's binary_logloss: 0.00995369\n",
      "[461]\ttraining's binary_logloss: 0.00987729\n",
      "[462]\ttraining's binary_logloss: 0.00979927\n",
      "[463]\ttraining's binary_logloss: 0.00972719\n",
      "[464]\ttraining's binary_logloss: 0.00965655\n",
      "[465]\ttraining's binary_logloss: 0.00958958\n",
      "[466]\ttraining's binary_logloss: 0.00951833\n",
      "[467]\ttraining's binary_logloss: 0.00944965\n",
      "[468]\ttraining's binary_logloss: 0.0093761\n",
      "[469]\ttraining's binary_logloss: 0.00930542\n",
      "[470]\ttraining's binary_logloss: 0.00923198\n",
      "[471]\ttraining's binary_logloss: 0.00916088\n",
      "[472]\ttraining's binary_logloss: 0.00908771\n",
      "[473]\ttraining's binary_logloss: 0.00901988\n",
      "[474]\ttraining's binary_logloss: 0.00895402\n",
      "[475]\ttraining's binary_logloss: 0.00888605\n",
      "[476]\ttraining's binary_logloss: 0.00881833\n",
      "[477]\ttraining's binary_logloss: 0.00875457\n",
      "[478]\ttraining's binary_logloss: 0.00868633\n",
      "[479]\ttraining's binary_logloss: 0.00862282\n",
      "[480]\ttraining's binary_logloss: 0.0085609\n",
      "[481]\ttraining's binary_logloss: 0.00849696\n",
      "[482]\ttraining's binary_logloss: 0.00843481\n",
      "[483]\ttraining's binary_logloss: 0.00837361\n",
      "[484]\ttraining's binary_logloss: 0.00830722\n",
      "[485]\ttraining's binary_logloss: 0.00824393\n",
      "[486]\ttraining's binary_logloss: 0.0081838\n",
      "[487]\ttraining's binary_logloss: 0.00812343\n",
      "[488]\ttraining's binary_logloss: 0.00806065\n",
      "[489]\ttraining's binary_logloss: 0.00799721\n",
      "[490]\ttraining's binary_logloss: 0.00793789\n",
      "[491]\ttraining's binary_logloss: 0.00787337\n",
      "[492]\ttraining's binary_logloss: 0.00781241\n",
      "[493]\ttraining's binary_logloss: 0.00775038\n",
      "[494]\ttraining's binary_logloss: 0.00769436\n",
      "[495]\ttraining's binary_logloss: 0.00763446\n",
      "[496]\ttraining's binary_logloss: 0.00757692\n",
      "[497]\ttraining's binary_logloss: 0.0075195\n",
      "[498]\ttraining's binary_logloss: 0.00746318\n",
      "[499]\ttraining's binary_logloss: 0.00740737\n",
      "[500]\ttraining's binary_logloss: 0.00735041\n",
      "[501]\ttraining's binary_logloss: 0.00729884\n",
      "[502]\ttraining's binary_logloss: 0.00724389\n",
      "[503]\ttraining's binary_logloss: 0.00719009\n",
      "[504]\ttraining's binary_logloss: 0.00713717\n",
      "[505]\ttraining's binary_logloss: 0.00708024\n",
      "[506]\ttraining's binary_logloss: 0.00702735\n",
      "[507]\ttraining's binary_logloss: 0.00697376\n",
      "[508]\ttraining's binary_logloss: 0.00692056\n",
      "[509]\ttraining's binary_logloss: 0.00686662\n",
      "[510]\ttraining's binary_logloss: 0.00681365\n",
      "[511]\ttraining's binary_logloss: 0.00676248\n",
      "[512]\ttraining's binary_logloss: 0.00671352\n",
      "[513]\ttraining's binary_logloss: 0.00665958\n",
      "[514]\ttraining's binary_logloss: 0.0066081\n",
      "[515]\ttraining's binary_logloss: 0.00656117\n",
      "[516]\ttraining's binary_logloss: 0.00651347\n",
      "[517]\ttraining's binary_logloss: 0.00646572\n",
      "[518]\ttraining's binary_logloss: 0.00641729\n",
      "[519]\ttraining's binary_logloss: 0.00637126\n",
      "[520]\ttraining's binary_logloss: 0.00632733\n",
      "[521]\ttraining's binary_logloss: 0.00628047\n",
      "[522]\ttraining's binary_logloss: 0.00623394\n",
      "[523]\ttraining's binary_logloss: 0.00618545\n",
      "[524]\ttraining's binary_logloss: 0.00614251\n",
      "[525]\ttraining's binary_logloss: 0.00609624\n",
      "[526]\ttraining's binary_logloss: 0.00605199\n",
      "[527]\ttraining's binary_logloss: 0.00600674\n",
      "[528]\ttraining's binary_logloss: 0.00595805\n",
      "[529]\ttraining's binary_logloss: 0.00591459\n",
      "[530]\ttraining's binary_logloss: 0.00587135\n",
      "[531]\ttraining's binary_logloss: 0.0058292\n",
      "[532]\ttraining's binary_logloss: 0.00578771\n",
      "[533]\ttraining's binary_logloss: 0.00574617\n",
      "[534]\ttraining's binary_logloss: 0.00570553\n",
      "[535]\ttraining's binary_logloss: 0.00566361\n",
      "[536]\ttraining's binary_logloss: 0.00562273\n",
      "[537]\ttraining's binary_logloss: 0.00558305\n",
      "[538]\ttraining's binary_logloss: 0.00554141\n",
      "[539]\ttraining's binary_logloss: 0.0055018\n",
      "[540]\ttraining's binary_logloss: 0.00546259\n",
      "[541]\ttraining's binary_logloss: 0.00542238\n",
      "[542]\ttraining's binary_logloss: 0.00538263\n",
      "[543]\ttraining's binary_logloss: 0.00534271\n",
      "[544]\ttraining's binary_logloss: 0.00530291\n",
      "[545]\ttraining's binary_logloss: 0.0052648\n",
      "[546]\ttraining's binary_logloss: 0.00522638\n",
      "[547]\ttraining's binary_logloss: 0.00518853\n",
      "[548]\ttraining's binary_logloss: 0.00515006\n",
      "[549]\ttraining's binary_logloss: 0.00511013\n",
      "[550]\ttraining's binary_logloss: 0.00507613\n",
      "[551]\ttraining's binary_logloss: 0.0050393\n",
      "[552]\ttraining's binary_logloss: 0.00500306\n",
      "[553]\ttraining's binary_logloss: 0.00496487\n",
      "[554]\ttraining's binary_logloss: 0.00492896\n",
      "[555]\ttraining's binary_logloss: 0.00489539\n",
      "[556]\ttraining's binary_logloss: 0.00486115\n",
      "[557]\ttraining's binary_logloss: 0.00482578\n",
      "[558]\ttraining's binary_logloss: 0.00479116\n",
      "[559]\ttraining's binary_logloss: 0.00475699\n",
      "[560]\ttraining's binary_logloss: 0.00472517\n",
      "[561]\ttraining's binary_logloss: 0.00468991\n",
      "[562]\ttraining's binary_logloss: 0.00465603\n",
      "[563]\ttraining's binary_logloss: 0.0046219\n",
      "[564]\ttraining's binary_logloss: 0.00458762\n",
      "[565]\ttraining's binary_logloss: 0.00455125\n",
      "[566]\ttraining's binary_logloss: 0.00451594\n",
      "[567]\ttraining's binary_logloss: 0.00448456\n",
      "[568]\ttraining's binary_logloss: 0.00445117\n",
      "[569]\ttraining's binary_logloss: 0.00441999\n",
      "[570]\ttraining's binary_logloss: 0.00439001\n",
      "[571]\ttraining's binary_logloss: 0.00435911\n",
      "[572]\ttraining's binary_logloss: 0.00432921\n",
      "[573]\ttraining's binary_logloss: 0.00429818\n",
      "[574]\ttraining's binary_logloss: 0.00426774\n",
      "[575]\ttraining's binary_logloss: 0.00423699\n",
      "[576]\ttraining's binary_logloss: 0.00420747\n",
      "[577]\ttraining's binary_logloss: 0.00417603\n",
      "[578]\ttraining's binary_logloss: 0.00414608\n",
      "[579]\ttraining's binary_logloss: 0.00411793\n",
      "[580]\ttraining's binary_logloss: 0.00409056\n",
      "[581]\ttraining's binary_logloss: 0.00406136\n",
      "[582]\ttraining's binary_logloss: 0.00403054\n",
      "[583]\ttraining's binary_logloss: 0.004\n",
      "[584]\ttraining's binary_logloss: 0.00397183\n",
      "[585]\ttraining's binary_logloss: 0.00394187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[586]\ttraining's binary_logloss: 0.00391371\n",
      "[587]\ttraining's binary_logloss: 0.00388607\n",
      "[588]\ttraining's binary_logloss: 0.00385704\n",
      "[589]\ttraining's binary_logloss: 0.00382918\n",
      "[590]\ttraining's binary_logloss: 0.0038032\n",
      "[591]\ttraining's binary_logloss: 0.00377537\n",
      "[592]\ttraining's binary_logloss: 0.00374882\n",
      "[593]\ttraining's binary_logloss: 0.00372338\n",
      "[594]\ttraining's binary_logloss: 0.00369763\n",
      "[595]\ttraining's binary_logloss: 0.00367219\n",
      "[596]\ttraining's binary_logloss: 0.00364397\n",
      "[597]\ttraining's binary_logloss: 0.00361821\n",
      "[598]\ttraining's binary_logloss: 0.00359339\n",
      "[599]\ttraining's binary_logloss: 0.0035683\n",
      "[600]\ttraining's binary_logloss: 0.00354372\n",
      "[601]\ttraining's binary_logloss: 0.00351886\n",
      "[602]\ttraining's binary_logloss: 0.00349407\n",
      "[603]\ttraining's binary_logloss: 0.00346782\n",
      "[604]\ttraining's binary_logloss: 0.00344381\n",
      "[605]\ttraining's binary_logloss: 0.0034181\n",
      "[606]\ttraining's binary_logloss: 0.0033936\n",
      "[607]\ttraining's binary_logloss: 0.00337161\n",
      "[608]\ttraining's binary_logloss: 0.00334883\n",
      "[609]\ttraining's binary_logloss: 0.00332562\n",
      "[610]\ttraining's binary_logloss: 0.00330163\n",
      "[611]\ttraining's binary_logloss: 0.00327795\n",
      "[612]\ttraining's binary_logloss: 0.00325575\n",
      "[613]\ttraining's binary_logloss: 0.00323257\n",
      "[614]\ttraining's binary_logloss: 0.00320936\n",
      "[615]\ttraining's binary_logloss: 0.00318666\n",
      "[616]\ttraining's binary_logloss: 0.00316347\n",
      "[617]\ttraining's binary_logloss: 0.00314352\n",
      "[618]\ttraining's binary_logloss: 0.00312075\n",
      "[619]\ttraining's binary_logloss: 0.00310003\n",
      "[620]\ttraining's binary_logloss: 0.00307929\n",
      "[621]\ttraining's binary_logloss: 0.00305845\n",
      "[622]\ttraining's binary_logloss: 0.00303691\n",
      "[623]\ttraining's binary_logloss: 0.00301574\n",
      "[624]\ttraining's binary_logloss: 0.00299553\n",
      "[625]\ttraining's binary_logloss: 0.00297517\n",
      "[626]\ttraining's binary_logloss: 0.00295558\n",
      "[627]\ttraining's binary_logloss: 0.0029367\n",
      "[628]\ttraining's binary_logloss: 0.00291707\n",
      "[629]\ttraining's binary_logloss: 0.00289714\n",
      "[630]\ttraining's binary_logloss: 0.00287716\n",
      "[631]\ttraining's binary_logloss: 0.00285588\n",
      "[632]\ttraining's binary_logloss: 0.00283613\n",
      "[633]\ttraining's binary_logloss: 0.00281519\n",
      "[634]\ttraining's binary_logloss: 0.00279638\n",
      "[635]\ttraining's binary_logloss: 0.00277866\n",
      "[636]\ttraining's binary_logloss: 0.00276052\n",
      "[637]\ttraining's binary_logloss: 0.00274038\n",
      "[638]\ttraining's binary_logloss: 0.0027219\n",
      "[639]\ttraining's binary_logloss: 0.00270207\n",
      "[640]\ttraining's binary_logloss: 0.00268275\n",
      "[641]\ttraining's binary_logloss: 0.00266509\n",
      "[642]\ttraining's binary_logloss: 0.00264655\n",
      "[643]\ttraining's binary_logloss: 0.00262658\n",
      "[644]\ttraining's binary_logloss: 0.00260756\n",
      "[645]\ttraining's binary_logloss: 0.00258937\n",
      "[646]\ttraining's binary_logloss: 0.00257311\n",
      "[647]\ttraining's binary_logloss: 0.00255476\n",
      "[648]\ttraining's binary_logloss: 0.0025377\n",
      "[649]\ttraining's binary_logloss: 0.00252215\n",
      "[650]\ttraining's binary_logloss: 0.0025045\n",
      "[651]\ttraining's binary_logloss: 0.00248768\n",
      "[652]\ttraining's binary_logloss: 0.00247063\n",
      "[653]\ttraining's binary_logloss: 0.00245304\n",
      "[654]\ttraining's binary_logloss: 0.00243707\n",
      "[655]\ttraining's binary_logloss: 0.00242079\n",
      "[656]\ttraining's binary_logloss: 0.00240528\n",
      "[657]\ttraining's binary_logloss: 0.0023891\n",
      "[658]\ttraining's binary_logloss: 0.00237327\n",
      "[659]\ttraining's binary_logloss: 0.0023567\n",
      "[660]\ttraining's binary_logloss: 0.00234169\n",
      "[661]\ttraining's binary_logloss: 0.00232692\n",
      "[662]\ttraining's binary_logloss: 0.00231262\n",
      "[663]\ttraining's binary_logloss: 0.00229565\n",
      "[664]\ttraining's binary_logloss: 0.00228168\n",
      "[665]\ttraining's binary_logloss: 0.00226674\n",
      "[666]\ttraining's binary_logloss: 0.00225148\n",
      "[667]\ttraining's binary_logloss: 0.00223721\n",
      "[668]\ttraining's binary_logloss: 0.00222364\n",
      "[669]\ttraining's binary_logloss: 0.00220935\n",
      "[670]\ttraining's binary_logloss: 0.00219494\n",
      "[671]\ttraining's binary_logloss: 0.00218134\n",
      "[672]\ttraining's binary_logloss: 0.00216819\n",
      "[673]\ttraining's binary_logloss: 0.00215447\n",
      "[674]\ttraining's binary_logloss: 0.00213859\n",
      "[675]\ttraining's binary_logloss: 0.00212494\n",
      "[676]\ttraining's binary_logloss: 0.00211093\n",
      "[677]\ttraining's binary_logloss: 0.00209729\n",
      "[678]\ttraining's binary_logloss: 0.00208409\n",
      "[679]\ttraining's binary_logloss: 0.00207003\n",
      "[680]\ttraining's binary_logloss: 0.00205742\n",
      "[681]\ttraining's binary_logloss: 0.00204289\n",
      "[682]\ttraining's binary_logloss: 0.0020299\n",
      "[683]\ttraining's binary_logloss: 0.00201553\n",
      "[684]\ttraining's binary_logloss: 0.00200205\n",
      "[685]\ttraining's binary_logloss: 0.00198994\n",
      "[686]\ttraining's binary_logloss: 0.00197767\n",
      "[687]\ttraining's binary_logloss: 0.0019655\n",
      "[688]\ttraining's binary_logloss: 0.00195309\n",
      "[689]\ttraining's binary_logloss: 0.00193957\n",
      "[690]\ttraining's binary_logloss: 0.00192792\n",
      "[691]\ttraining's binary_logloss: 0.00191631\n",
      "[692]\ttraining's binary_logloss: 0.00190319\n",
      "[693]\ttraining's binary_logloss: 0.00189036\n",
      "[694]\ttraining's binary_logloss: 0.00187844\n",
      "[695]\ttraining's binary_logloss: 0.00186557\n",
      "[696]\ttraining's binary_logloss: 0.00185324\n",
      "[697]\ttraining's binary_logloss: 0.00184265\n",
      "[698]\ttraining's binary_logloss: 0.00183193\n",
      "[699]\ttraining's binary_logloss: 0.00182106\n",
      "[700]\ttraining's binary_logloss: 0.00180977\n",
      "[701]\ttraining's binary_logloss: 0.001799\n",
      "[702]\ttraining's binary_logloss: 0.00178826\n",
      "[703]\ttraining's binary_logloss: 0.00177617\n",
      "[704]\ttraining's binary_logloss: 0.0017648\n",
      "[705]\ttraining's binary_logloss: 0.00175166\n",
      "[706]\ttraining's binary_logloss: 0.00174199\n",
      "[707]\ttraining's binary_logloss: 0.00173185\n",
      "[708]\ttraining's binary_logloss: 0.00172026\n",
      "[709]\ttraining's binary_logloss: 0.00171021\n",
      "[710]\ttraining's binary_logloss: 0.00169997\n",
      "[711]\ttraining's binary_logloss: 0.00166088\n",
      "[712]\ttraining's binary_logloss: 0.00162726\n",
      "[713]\ttraining's binary_logloss: 0.00160026\n",
      "[714]\ttraining's binary_logloss: 0.00157917\n",
      "[715]\ttraining's binary_logloss: 0.00155891\n",
      "[716]\ttraining's binary_logloss: 0.00153742\n",
      "[717]\ttraining's binary_logloss: 0.00151925\n",
      "[718]\ttraining's binary_logloss: 0.00150183\n",
      "[719]\ttraining's binary_logloss: 0.0014864\n",
      "[720]\ttraining's binary_logloss: 0.00147098\n",
      "[721]\ttraining's binary_logloss: 0.00145558\n",
      "[722]\ttraining's binary_logloss: 0.001442\n",
      "[723]\ttraining's binary_logloss: 0.00142807\n",
      "[724]\ttraining's binary_logloss: 0.00141392\n",
      "[725]\ttraining's binary_logloss: 0.00140134\n",
      "[726]\ttraining's binary_logloss: 0.00138849\n",
      "[727]\ttraining's binary_logloss: 0.00137657\n",
      "[728]\ttraining's binary_logloss: 0.00136481\n",
      "[729]\ttraining's binary_logloss: 0.00135335\n",
      "[730]\ttraining's binary_logloss: 0.00134117\n",
      "[731]\ttraining's binary_logloss: 0.00132954\n",
      "[732]\ttraining's binary_logloss: 0.00131801\n",
      "[733]\ttraining's binary_logloss: 0.00130696\n",
      "[734]\ttraining's binary_logloss: 0.00129615\n",
      "[735]\ttraining's binary_logloss: 0.00128503\n",
      "[736]\ttraining's binary_logloss: 0.00127396\n",
      "[737]\ttraining's binary_logloss: 0.00126359\n",
      "[738]\ttraining's binary_logloss: 0.00125352\n",
      "[739]\ttraining's binary_logloss: 0.00124338\n",
      "[740]\ttraining's binary_logloss: 0.00123319\n",
      "[741]\ttraining's binary_logloss: 0.00122344\n",
      "[742]\ttraining's binary_logloss: 0.00121384\n",
      "[743]\ttraining's binary_logloss: 0.00120416\n",
      "[744]\ttraining's binary_logloss: 0.00119492\n",
      "[745]\ttraining's binary_logloss: 0.0011856\n",
      "[746]\ttraining's binary_logloss: 0.00117625\n",
      "[747]\ttraining's binary_logloss: 0.00116676\n",
      "[748]\ttraining's binary_logloss: 0.00115759\n",
      "[749]\ttraining's binary_logloss: 0.00114864\n",
      "[750]\ttraining's binary_logloss: 0.00114002\n",
      "[751]\ttraining's binary_logloss: 0.00113149\n",
      "[752]\ttraining's binary_logloss: 0.00112303\n",
      "[753]\ttraining's binary_logloss: 0.00111437\n",
      "[754]\ttraining's binary_logloss: 0.00110509\n",
      "[755]\ttraining's binary_logloss: 0.00109621\n",
      "[756]\ttraining's binary_logloss: 0.00108805\n",
      "[757]\ttraining's binary_logloss: 0.0010797\n",
      "[758]\ttraining's binary_logloss: 0.00107133\n",
      "[759]\ttraining's binary_logloss: 0.00106305\n",
      "[760]\ttraining's binary_logloss: 0.00105497\n",
      "[761]\ttraining's binary_logloss: 0.0010466\n",
      "[762]\ttraining's binary_logloss: 0.0010383\n",
      "[763]\ttraining's binary_logloss: 0.00103005\n",
      "[764]\ttraining's binary_logloss: 0.00102244\n",
      "[765]\ttraining's binary_logloss: 0.00101468\n",
      "[766]\ttraining's binary_logloss: 0.00100691\n",
      "[767]\ttraining's binary_logloss: 0.000999504\n",
      "[768]\ttraining's binary_logloss: 0.000991858\n",
      "[769]\ttraining's binary_logloss: 0.000984214\n",
      "[770]\ttraining's binary_logloss: 0.000976777\n",
      "[771]\ttraining's binary_logloss: 0.000968783\n",
      "[772]\ttraining's binary_logloss: 0.000961577\n",
      "[773]\ttraining's binary_logloss: 0.000954919\n",
      "[774]\ttraining's binary_logloss: 0.000947551\n",
      "[775]\ttraining's binary_logloss: 0.000939862\n",
      "[776]\ttraining's binary_logloss: 0.000932297\n",
      "[777]\ttraining's binary_logloss: 0.000924699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[778]\ttraining's binary_logloss: 0.000917744\n",
      "[779]\ttraining's binary_logloss: 0.000911321\n",
      "[780]\ttraining's binary_logloss: 0.000904474\n",
      "[781]\ttraining's binary_logloss: 0.000897863\n",
      "[782]\ttraining's binary_logloss: 0.000891265\n",
      "[783]\ttraining's binary_logloss: 0.000884333\n",
      "[784]\ttraining's binary_logloss: 0.000877636\n",
      "[785]\ttraining's binary_logloss: 0.000871198\n",
      "[786]\ttraining's binary_logloss: 0.000864699\n",
      "[787]\ttraining's binary_logloss: 0.000857901\n",
      "[788]\ttraining's binary_logloss: 0.000851647\n",
      "[789]\ttraining's binary_logloss: 0.000845216\n",
      "[790]\ttraining's binary_logloss: 0.000838978\n",
      "[791]\ttraining's binary_logloss: 0.000832331\n",
      "[792]\ttraining's binary_logloss: 0.000826494\n",
      "[793]\ttraining's binary_logloss: 0.000820733\n",
      "[794]\ttraining's binary_logloss: 0.000814784\n",
      "[795]\ttraining's binary_logloss: 0.000808437\n",
      "[796]\ttraining's binary_logloss: 0.000802418\n",
      "[797]\ttraining's binary_logloss: 0.000796565\n",
      "[798]\ttraining's binary_logloss: 0.000790911\n",
      "[799]\ttraining's binary_logloss: 0.000784638\n",
      "[800]\ttraining's binary_logloss: 0.000778713\n",
      "[801]\ttraining's binary_logloss: 0.000772973\n",
      "[802]\ttraining's binary_logloss: 0.00076701\n",
      "[803]\ttraining's binary_logloss: 0.000761176\n",
      "[804]\ttraining's binary_logloss: 0.000755599\n",
      "[805]\ttraining's binary_logloss: 0.000749759\n",
      "[806]\ttraining's binary_logloss: 0.000744452\n",
      "[807]\ttraining's binary_logloss: 0.000739323\n",
      "[808]\ttraining's binary_logloss: 0.00073385\n",
      "[809]\ttraining's binary_logloss: 0.000728736\n",
      "[810]\ttraining's binary_logloss: 0.000722985\n",
      "[811]\ttraining's binary_logloss: 0.000718112\n",
      "[812]\ttraining's binary_logloss: 0.00071334\n",
      "[813]\ttraining's binary_logloss: 0.000708243\n",
      "[814]\ttraining's binary_logloss: 0.000702684\n",
      "[815]\ttraining's binary_logloss: 0.000697325\n",
      "[816]\ttraining's binary_logloss: 0.000692405\n",
      "[817]\ttraining's binary_logloss: 0.000687453\n",
      "[818]\ttraining's binary_logloss: 0.000682462\n",
      "[819]\ttraining's binary_logloss: 0.000677327\n",
      "[820]\ttraining's binary_logloss: 0.000672635\n",
      "[821]\ttraining's binary_logloss: 0.000667608\n",
      "[822]\ttraining's binary_logloss: 0.00066288\n",
      "[823]\ttraining's binary_logloss: 0.000658221\n",
      "[824]\ttraining's binary_logloss: 0.00065338\n",
      "[825]\ttraining's binary_logloss: 0.00064861\n",
      "[826]\ttraining's binary_logloss: 0.000644019\n",
      "[827]\ttraining's binary_logloss: 0.000639143\n",
      "[828]\ttraining's binary_logloss: 0.000634421\n",
      "[829]\ttraining's binary_logloss: 0.000630201\n",
      "[830]\ttraining's binary_logloss: 0.000625477\n",
      "[831]\ttraining's binary_logloss: 0.000620447\n",
      "[832]\ttraining's binary_logloss: 0.000616003\n",
      "[833]\ttraining's binary_logloss: 0.000611747\n",
      "[834]\ttraining's binary_logloss: 0.000607026\n",
      "[835]\ttraining's binary_logloss: 0.000602484\n",
      "[836]\ttraining's binary_logloss: 0.000598051\n",
      "[837]\ttraining's binary_logloss: 0.000593345\n",
      "[838]\ttraining's binary_logloss: 0.000589302\n",
      "[839]\ttraining's binary_logloss: 0.000585161\n",
      "[840]\ttraining's binary_logloss: 0.000580567\n",
      "[841]\ttraining's binary_logloss: 0.000576252\n",
      "[842]\ttraining's binary_logloss: 0.000571955\n",
      "[843]\ttraining's binary_logloss: 0.000567972\n",
      "[844]\ttraining's binary_logloss: 0.000564017\n",
      "[845]\ttraining's binary_logloss: 0.00055966\n",
      "[846]\ttraining's binary_logloss: 0.000555725\n",
      "[847]\ttraining's binary_logloss: 0.000551606\n",
      "[848]\ttraining's binary_logloss: 0.000547293\n",
      "[849]\ttraining's binary_logloss: 0.000543114\n",
      "[850]\ttraining's binary_logloss: 0.000539148\n",
      "[851]\ttraining's binary_logloss: 0.000535376\n",
      "[852]\ttraining's binary_logloss: 0.00053135\n",
      "[853]\ttraining's binary_logloss: 0.000527699\n",
      "[854]\ttraining's binary_logloss: 0.000523941\n",
      "[855]\ttraining's binary_logloss: 0.000519949\n",
      "[856]\ttraining's binary_logloss: 0.000515916\n",
      "[857]\ttraining's binary_logloss: 0.000511905\n",
      "[858]\ttraining's binary_logloss: 0.000507825\n",
      "[859]\ttraining's binary_logloss: 0.000504474\n",
      "[860]\ttraining's binary_logloss: 0.0005009\n",
      "[861]\ttraining's binary_logloss: 0.000497022\n",
      "[862]\ttraining's binary_logloss: 0.000493305\n",
      "[863]\ttraining's binary_logloss: 0.000490132\n",
      "[864]\ttraining's binary_logloss: 0.00048681\n",
      "[865]\ttraining's binary_logloss: 0.000483234\n",
      "[866]\ttraining's binary_logloss: 0.00048003\n",
      "[867]\ttraining's binary_logloss: 0.000476749\n",
      "[868]\ttraining's binary_logloss: 0.000473258\n",
      "[869]\ttraining's binary_logloss: 0.000469671\n",
      "[870]\ttraining's binary_logloss: 0.000466161\n",
      "[871]\ttraining's binary_logloss: 0.000462991\n",
      "[872]\ttraining's binary_logloss: 0.00045941\n",
      "[873]\ttraining's binary_logloss: 0.000456185\n",
      "[874]\ttraining's binary_logloss: 0.000452731\n",
      "[875]\ttraining's binary_logloss: 0.000449778\n",
      "[876]\ttraining's binary_logloss: 0.000446368\n",
      "[877]\ttraining's binary_logloss: 0.000443031\n",
      "[878]\ttraining's binary_logloss: 0.000440004\n",
      "[879]\ttraining's binary_logloss: 0.000436703\n",
      "[880]\ttraining's binary_logloss: 0.000433447\n",
      "[881]\ttraining's binary_logloss: 0.000430577\n",
      "[882]\ttraining's binary_logloss: 0.000427592\n",
      "[883]\ttraining's binary_logloss: 0.00042445\n",
      "[884]\ttraining's binary_logloss: 0.000420946\n",
      "[885]\ttraining's binary_logloss: 0.000417693\n",
      "[886]\ttraining's binary_logloss: 0.000414996\n",
      "[887]\ttraining's binary_logloss: 0.000412251\n",
      "[888]\ttraining's binary_logloss: 0.000409453\n",
      "[889]\ttraining's binary_logloss: 0.000406656\n",
      "[890]\ttraining's binary_logloss: 0.000403647\n",
      "[891]\ttraining's binary_logloss: 0.00040048\n",
      "[892]\ttraining's binary_logloss: 0.000397256\n",
      "[893]\ttraining's binary_logloss: 0.00039452\n",
      "[894]\ttraining's binary_logloss: 0.000391409\n",
      "[895]\ttraining's binary_logloss: 0.000388487\n",
      "[896]\ttraining's binary_logloss: 0.000385862\n",
      "[897]\ttraining's binary_logloss: 0.000383004\n",
      "[898]\ttraining's binary_logloss: 0.000380455\n",
      "[899]\ttraining's binary_logloss: 0.000377607\n",
      "[900]\ttraining's binary_logloss: 0.000375149\n",
      "[901]\ttraining's binary_logloss: 0.000372606\n",
      "[902]\ttraining's binary_logloss: 0.000370192\n",
      "[903]\ttraining's binary_logloss: 0.000367834\n",
      "[904]\ttraining's binary_logloss: 0.000365632\n",
      "[905]\ttraining's binary_logloss: 0.000363218\n",
      "[906]\ttraining's binary_logloss: 0.00036048\n",
      "[907]\ttraining's binary_logloss: 0.000358135\n",
      "[908]\ttraining's binary_logloss: 0.000355512\n",
      "[909]\ttraining's binary_logloss: 0.000353182\n",
      "[910]\ttraining's binary_logloss: 0.00035043\n",
      "[911]\ttraining's binary_logloss: 0.000347701\n",
      "[912]\ttraining's binary_logloss: 0.000345516\n",
      "[913]\ttraining's binary_logloss: 0.000342875\n",
      "[914]\ttraining's binary_logloss: 0.000340628\n",
      "[915]\ttraining's binary_logloss: 0.000338504\n",
      "[916]\ttraining's binary_logloss: 0.000336038\n",
      "[917]\ttraining's binary_logloss: 0.000333332\n",
      "[918]\ttraining's binary_logloss: 0.000331141\n",
      "[919]\ttraining's binary_logloss: 0.000329207\n",
      "[920]\ttraining's binary_logloss: 0.000326972\n",
      "[921]\ttraining's binary_logloss: 0.000324642\n",
      "[922]\ttraining's binary_logloss: 0.000322146\n",
      "[923]\ttraining's binary_logloss: 0.000319782\n",
      "[924]\ttraining's binary_logloss: 0.000317598\n",
      "[925]\ttraining's binary_logloss: 0.000315179\n",
      "[926]\ttraining's binary_logloss: 0.000313192\n",
      "[927]\ttraining's binary_logloss: 0.000311033\n",
      "[928]\ttraining's binary_logloss: 0.000308732\n",
      "[929]\ttraining's binary_logloss: 0.000306521\n",
      "[930]\ttraining's binary_logloss: 0.000304546\n",
      "[931]\ttraining's binary_logloss: 0.00030266\n",
      "[932]\ttraining's binary_logloss: 0.000300747\n",
      "[933]\ttraining's binary_logloss: 0.000298449\n",
      "[934]\ttraining's binary_logloss: 0.000296555\n",
      "[935]\ttraining's binary_logloss: 0.000294369\n",
      "[936]\ttraining's binary_logloss: 0.000292591\n",
      "[937]\ttraining's binary_logloss: 0.000290401\n",
      "[938]\ttraining's binary_logloss: 0.000288247\n",
      "[939]\ttraining's binary_logloss: 0.000286485\n",
      "[940]\ttraining's binary_logloss: 0.000284362\n",
      "[941]\ttraining's binary_logloss: 0.000282199\n",
      "[942]\ttraining's binary_logloss: 0.000280158\n",
      "[943]\ttraining's binary_logloss: 0.00027857\n",
      "[944]\ttraining's binary_logloss: 0.000276653\n",
      "[945]\ttraining's binary_logloss: 0.000274936\n",
      "[946]\ttraining's binary_logloss: 0.000272895\n",
      "[947]\ttraining's binary_logloss: 0.00027124\n",
      "[948]\ttraining's binary_logloss: 0.000269126\n",
      "[949]\ttraining's binary_logloss: 0.000267523\n",
      "[950]\ttraining's binary_logloss: 0.000265377\n",
      "[951]\ttraining's binary_logloss: 0.000263492\n",
      "[952]\ttraining's binary_logloss: 0.000261398\n",
      "[953]\ttraining's binary_logloss: 0.000259519\n",
      "[954]\ttraining's binary_logloss: 0.00025756\n",
      "[955]\ttraining's binary_logloss: 0.000255683\n",
      "[956]\ttraining's binary_logloss: 0.000253662\n",
      "[957]\ttraining's binary_logloss: 0.000252104\n",
      "[958]\ttraining's binary_logloss: 0.000250617\n",
      "[959]\ttraining's binary_logloss: 0.000249074\n",
      "[960]\ttraining's binary_logloss: 0.000247431\n",
      "[961]\ttraining's binary_logloss: 0.000245759\n",
      "[962]\ttraining's binary_logloss: 0.000244181\n",
      "[963]\ttraining's binary_logloss: 0.000242473\n",
      "[964]\ttraining's binary_logloss: 0.000240642\n",
      "[965]\ttraining's binary_logloss: 0.000238839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[966]\ttraining's binary_logloss: 0.000237133\n",
      "[967]\ttraining's binary_logloss: 0.000235747\n",
      "[968]\ttraining's binary_logloss: 0.000234227\n",
      "[969]\ttraining's binary_logloss: 0.000232402\n",
      "[970]\ttraining's binary_logloss: 0.000231023\n",
      "[971]\ttraining's binary_logloss: 0.000229196\n",
      "[972]\ttraining's binary_logloss: 0.000227612\n",
      "[973]\ttraining's binary_logloss: 0.00022639\n",
      "[974]\ttraining's binary_logloss: 0.000225063\n",
      "[975]\ttraining's binary_logloss: 0.000223813\n",
      "[976]\ttraining's binary_logloss: 0.000222086\n",
      "[977]\ttraining's binary_logloss: 0.000220834\n",
      "[978]\ttraining's binary_logloss: 0.000219167\n",
      "[979]\ttraining's binary_logloss: 0.000217519\n",
      "[980]\ttraining's binary_logloss: 0.000216224\n",
      "[981]\ttraining's binary_logloss: 0.000214986\n",
      "[982]\ttraining's binary_logloss: 0.000213927\n",
      "[983]\ttraining's binary_logloss: 0.000212762\n",
      "[984]\ttraining's binary_logloss: 0.000211161\n",
      "[985]\ttraining's binary_logloss: 0.000209501\n",
      "[986]\ttraining's binary_logloss: 0.000207771\n",
      "[987]\ttraining's binary_logloss: 0.000206628\n",
      "[988]\ttraining's binary_logloss: 0.000205247\n",
      "[989]\ttraining's binary_logloss: 0.000203633\n",
      "[990]\ttraining's binary_logloss: 0.000202256\n",
      "[991]\ttraining's binary_logloss: 0.000201047\n",
      "[992]\ttraining's binary_logloss: 0.000199609\n",
      "[993]\ttraining's binary_logloss: 0.000198428\n",
      "[994]\ttraining's binary_logloss: 0.000196885\n",
      "[995]\ttraining's binary_logloss: 0.000195703\n",
      "[996]\ttraining's binary_logloss: 0.000194197\n",
      "[997]\ttraining's binary_logloss: 0.000193169\n",
      "[998]\ttraining's binary_logloss: 0.000192135\n",
      "[999]\ttraining's binary_logloss: 0.000191064\n",
      "[1000]\ttraining's binary_logloss: 0.00018982\n",
      "[1001]\ttraining's binary_logloss: 0.000188895\n",
      "[1002]\ttraining's binary_logloss: 0.000187462\n",
      "[1003]\ttraining's binary_logloss: 0.000185962\n",
      "[1004]\ttraining's binary_logloss: 0.000184683\n",
      "[1005]\ttraining's binary_logloss: 0.000183597\n",
      "[1006]\ttraining's binary_logloss: 0.00018222\n",
      "[1007]\ttraining's binary_logloss: 0.000180717\n",
      "[1008]\ttraining's binary_logloss: 0.000179688\n",
      "[1009]\ttraining's binary_logloss: 0.000178289\n",
      "[1010]\ttraining's binary_logloss: 0.000177166\n",
      "[1011]\ttraining's binary_logloss: 0.000176184\n",
      "[1012]\ttraining's binary_logloss: 0.000174946\n",
      "[1013]\ttraining's binary_logloss: 0.000173952\n",
      "[1014]\ttraining's binary_logloss: 0.000172987\n",
      "[1015]\ttraining's binary_logloss: 0.000172078\n",
      "[1016]\ttraining's binary_logloss: 0.000170934\n",
      "[1017]\ttraining's binary_logloss: 0.000169576\n",
      "[1018]\ttraining's binary_logloss: 0.00016877\n",
      "[1019]\ttraining's binary_logloss: 0.000167523\n",
      "[1020]\ttraining's binary_logloss: 0.000166785\n",
      "[1021]\ttraining's binary_logloss: 0.000165559\n",
      "[1022]\ttraining's binary_logloss: 0.000164763\n",
      "[1023]\ttraining's binary_logloss: 0.000163813\n",
      "[1024]\ttraining's binary_logloss: 0.000162712\n",
      "[1025]\ttraining's binary_logloss: 0.000161927\n",
      "[1026]\ttraining's binary_logloss: 0.000161059\n",
      "[1027]\ttraining's binary_logloss: 0.000160241\n",
      "[1028]\ttraining's binary_logloss: 0.000159293\n",
      "[1029]\ttraining's binary_logloss: 0.00015809\n",
      "[1030]\ttraining's binary_logloss: 0.000157465\n",
      "[1031]\ttraining's binary_logloss: 0.000156185\n",
      "[1032]\ttraining's binary_logloss: 0.000155452\n",
      "[1033]\ttraining's binary_logloss: 0.000154567\n",
      "[1034]\ttraining's binary_logloss: 0.000153342\n",
      "[1035]\ttraining's binary_logloss: 0.000152744\n",
      "[1036]\ttraining's binary_logloss: 0.000151865\n",
      "[1037]\ttraining's binary_logloss: 0.000150617\n",
      "[1038]\ttraining's binary_logloss: 0.000149472\n",
      "[1039]\ttraining's binary_logloss: 0.000148805\n",
      "[1040]\ttraining's binary_logloss: 0.000147942\n",
      "[1041]\ttraining's binary_logloss: 0.00014698\n",
      "[1042]\ttraining's binary_logloss: 0.000146404\n",
      "[1043]\ttraining's binary_logloss: 0.000145496\n",
      "[1044]\ttraining's binary_logloss: 0.000144661\n",
      "[1045]\ttraining's binary_logloss: 0.000143821\n",
      "[1046]\ttraining's binary_logloss: 0.000143189\n",
      "[1047]\ttraining's binary_logloss: 0.000142133\n",
      "[1048]\ttraining's binary_logloss: 0.000141208\n",
      "[1049]\ttraining's binary_logloss: 0.000140313\n",
      "[1050]\ttraining's binary_logloss: 0.000139267\n",
      "[1051]\ttraining's binary_logloss: 0.000138726\n",
      "[1052]\ttraining's binary_logloss: 0.000137814\n",
      "[1053]\ttraining's binary_logloss: 0.000137177\n",
      "[1054]\ttraining's binary_logloss: 0.000136201\n",
      "[1055]\ttraining's binary_logloss: 0.000135274\n",
      "[1056]\ttraining's binary_logloss: 0.00013419\n",
      "[1057]\ttraining's binary_logloss: 0.000133687\n",
      "[1058]\ttraining's binary_logloss: 0.000132644\n",
      "[1059]\ttraining's binary_logloss: 0.000131979\n",
      "[1060]\ttraining's binary_logloss: 0.000130848\n",
      "[1061]\ttraining's binary_logloss: 0.000129722\n",
      "[1062]\ttraining's binary_logloss: 0.000129292\n",
      "[1063]\ttraining's binary_logloss: 0.0001285\n",
      "[1064]\ttraining's binary_logloss: 0.000128057\n",
      "[1065]\ttraining's binary_logloss: 0.00012717\n",
      "[1066]\ttraining's binary_logloss: 0.00012671\n",
      "[1067]\ttraining's binary_logloss: 0.000126249\n",
      "[1068]\ttraining's binary_logloss: 0.000125332\n",
      "[1069]\ttraining's binary_logloss: 0.000124886\n",
      "[1070]\ttraining's binary_logloss: 0.000124504\n",
      "[1071]\ttraining's binary_logloss: 0.000124019\n",
      "[1072]\ttraining's binary_logloss: 0.000123596\n",
      "[1073]\ttraining's binary_logloss: 0.000123159\n",
      "[1074]\ttraining's binary_logloss: 0.000122693\n",
      "[1075]\ttraining's binary_logloss: 0.000121662\n",
      "[1076]\ttraining's binary_logloss: 0.000120922\n",
      "[1077]\ttraining's binary_logloss: 0.000120465\n",
      "[1078]\ttraining's binary_logloss: 0.00011936\n",
      "[1079]\ttraining's binary_logloss: 0.00011844\n",
      "[1080]\ttraining's binary_logloss: 0.000117949\n",
      "[1081]\ttraining's binary_logloss: 0.000117229\n",
      "[1082]\ttraining's binary_logloss: 0.000116888\n",
      "[1083]\ttraining's binary_logloss: 0.000115975\n",
      "[1084]\ttraining's binary_logloss: 0.00011557\n",
      "[1085]\ttraining's binary_logloss: 0.000115255\n",
      "[1086]\ttraining's binary_logloss: 0.000114934\n",
      "[1087]\ttraining's binary_logloss: 0.000114685\n",
      "[1088]\ttraining's binary_logloss: 0.000113702\n",
      "[1089]\ttraining's binary_logloss: 0.000112856\n",
      "[1090]\ttraining's binary_logloss: 0.000111809\n",
      "[1091]\ttraining's binary_logloss: 0.000111122\n",
      "[1092]\ttraining's binary_logloss: 0.000110345\n",
      "[1093]\ttraining's binary_logloss: 0.000109413\n",
      "[1094]\ttraining's binary_logloss: 0.000108638\n",
      "[1095]\ttraining's binary_logloss: 0.000107685\n",
      "[1096]\ttraining's binary_logloss: 0.000107159\n",
      "[1097]\ttraining's binary_logloss: 0.000106354\n",
      "[1098]\ttraining's binary_logloss: 0.000105567\n",
      "[1099]\ttraining's binary_logloss: 0.000104773\n",
      "[1100]\ttraining's binary_logloss: 0.000104478\n",
      "[1101]\ttraining's binary_logloss: 0.000103536\n",
      "[1102]\ttraining's binary_logloss: 0.000103195\n",
      "[1103]\ttraining's binary_logloss: 0.000102459\n",
      "[1104]\ttraining's binary_logloss: 0.000101619\n",
      "[1105]\ttraining's binary_logloss: 0.000101226\n",
      "[1106]\ttraining's binary_logloss: 0.000100339\n",
      "[1107]\ttraining's binary_logloss: 0.000100077\n",
      "[1108]\ttraining's binary_logloss: 9.94696e-05\n",
      "[1109]\ttraining's binary_logloss: 9.87492e-05\n",
      "[1110]\ttraining's binary_logloss: 9.78944e-05\n",
      "[1111]\ttraining's binary_logloss: 9.75052e-05\n",
      "[1112]\ttraining's binary_logloss: 9.70236e-05\n",
      "[1113]\ttraining's binary_logloss: 9.61892e-05\n",
      "[1114]\ttraining's binary_logloss: 9.56606e-05\n",
      "[1115]\ttraining's binary_logloss: 9.48396e-05\n",
      "[1116]\ttraining's binary_logloss: 9.40722e-05\n",
      "[1117]\ttraining's binary_logloss: 9.34058e-05\n",
      "[1118]\ttraining's binary_logloss: 9.255e-05\n",
      "[1119]\ttraining's binary_logloss: 9.18932e-05\n",
      "[1120]\ttraining's binary_logloss: 9.14164e-05\n",
      "[1121]\ttraining's binary_logloss: 9.1085e-05\n",
      "[1122]\ttraining's binary_logloss: 9.09619e-05\n",
      "[1123]\ttraining's binary_logloss: 9.08088e-05\n",
      "[1124]\ttraining's binary_logloss: 9.01153e-05\n",
      "[1125]\ttraining's binary_logloss: 8.94244e-05\n",
      "[1126]\ttraining's binary_logloss: 8.87134e-05\n",
      "[1127]\ttraining's binary_logloss: 8.85982e-05\n",
      "[1128]\ttraining's binary_logloss: 8.84456e-05\n",
      "[1129]\ttraining's binary_logloss: 8.76789e-05\n",
      "[1130]\ttraining's binary_logloss: 8.68932e-05\n",
      "[1131]\ttraining's binary_logloss: 8.61358e-05\n",
      "[1132]\ttraining's binary_logloss: 8.53242e-05\n",
      "[1133]\ttraining's binary_logloss: 8.46742e-05\n",
      "[1134]\ttraining's binary_logloss: 8.39233e-05\n",
      "[1135]\ttraining's binary_logloss: 8.34557e-05\n",
      "[1136]\ttraining's binary_logloss: 8.29668e-05\n",
      "[1137]\ttraining's binary_logloss: 8.2726e-05\n",
      "[1138]\ttraining's binary_logloss: 8.19687e-05\n",
      "[1139]\ttraining's binary_logloss: 8.12392e-05\n",
      "[1140]\ttraining's binary_logloss: 8.10243e-05\n",
      "[1141]\ttraining's binary_logloss: 8.07194e-05\n",
      "[1142]\ttraining's binary_logloss: 8.01353e-05\n",
      "[1143]\ttraining's binary_logloss: 7.98742e-05\n",
      "[1144]\ttraining's binary_logloss: 7.90943e-05\n",
      "[1145]\ttraining's binary_logloss: 7.81338e-05\n",
      "[1146]\ttraining's binary_logloss: 7.72333e-05\n",
      "[1147]\ttraining's binary_logloss: 7.62974e-05\n",
      "[1148]\ttraining's binary_logloss: 7.54405e-05\n",
      "[1149]\ttraining's binary_logloss: 7.45554e-05\n",
      "[1150]\ttraining's binary_logloss: 7.3704e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1151]\ttraining's binary_logloss: 7.28559e-05\n",
      "[1152]\ttraining's binary_logloss: 7.2054e-05\n",
      "[1153]\ttraining's binary_logloss: 7.12271e-05\n",
      "[1154]\ttraining's binary_logloss: 7.04427e-05\n",
      "[1155]\ttraining's binary_logloss: 6.96573e-05\n",
      "[1156]\ttraining's binary_logloss: 6.8886e-05\n",
      "[1157]\ttraining's binary_logloss: 6.81261e-05\n",
      "[1158]\ttraining's binary_logloss: 6.74114e-05\n",
      "[1159]\ttraining's binary_logloss: 6.67075e-05\n",
      "[1160]\ttraining's binary_logloss: 6.60037e-05\n",
      "[1161]\ttraining's binary_logloss: 6.53071e-05\n",
      "[1162]\ttraining's binary_logloss: 6.46151e-05\n",
      "[1163]\ttraining's binary_logloss: 6.39462e-05\n",
      "[1164]\ttraining's binary_logloss: 6.32633e-05\n",
      "[1165]\ttraining's binary_logloss: 6.25969e-05\n",
      "[1166]\ttraining's binary_logloss: 6.19462e-05\n",
      "[1167]\ttraining's binary_logloss: 6.13293e-05\n",
      "[1168]\ttraining's binary_logloss: 6.06975e-05\n",
      "[1169]\ttraining's binary_logloss: 6.00733e-05\n",
      "[1170]\ttraining's binary_logloss: 5.94693e-05\n",
      "[1171]\ttraining's binary_logloss: 5.88608e-05\n",
      "[1172]\ttraining's binary_logloss: 5.82693e-05\n",
      "[1173]\ttraining's binary_logloss: 5.76909e-05\n",
      "[1174]\ttraining's binary_logloss: 5.71327e-05\n",
      "[1175]\ttraining's binary_logloss: 5.65633e-05\n",
      "[1176]\ttraining's binary_logloss: 5.60328e-05\n",
      "[1177]\ttraining's binary_logloss: 5.55119e-05\n",
      "[1178]\ttraining's binary_logloss: 5.49711e-05\n",
      "[1179]\ttraining's binary_logloss: 5.44623e-05\n",
      "[1180]\ttraining's binary_logloss: 5.39478e-05\n",
      "[1181]\ttraining's binary_logloss: 5.34326e-05\n",
      "[1182]\ttraining's binary_logloss: 5.29374e-05\n",
      "[1183]\ttraining's binary_logloss: 5.24521e-05\n",
      "[1184]\ttraining's binary_logloss: 5.19486e-05\n",
      "[1185]\ttraining's binary_logloss: 5.14775e-05\n",
      "[1186]\ttraining's binary_logloss: 5.10039e-05\n",
      "[1187]\ttraining's binary_logloss: 5.05449e-05\n",
      "[1188]\ttraining's binary_logloss: 5.00768e-05\n",
      "[1189]\ttraining's binary_logloss: 4.96186e-05\n",
      "[1190]\ttraining's binary_logloss: 4.91684e-05\n",
      "[1191]\ttraining's binary_logloss: 4.87261e-05\n",
      "[1192]\ttraining's binary_logloss: 4.82923e-05\n",
      "[1193]\ttraining's binary_logloss: 4.78685e-05\n",
      "[1194]\ttraining's binary_logloss: 4.74448e-05\n",
      "[1195]\ttraining's binary_logloss: 4.70299e-05\n",
      "[1196]\ttraining's binary_logloss: 4.66172e-05\n",
      "[1197]\ttraining's binary_logloss: 4.6212e-05\n",
      "[1198]\ttraining's binary_logloss: 4.57995e-05\n",
      "[1199]\ttraining's binary_logloss: 4.54102e-05\n",
      "[1200]\ttraining's binary_logloss: 4.50222e-05\n",
      "[1201]\ttraining's binary_logloss: 4.46512e-05\n",
      "[1202]\ttraining's binary_logloss: 4.42796e-05\n",
      "[1203]\ttraining's binary_logloss: 4.39024e-05\n",
      "[1204]\ttraining's binary_logloss: 4.35465e-05\n",
      "[1205]\ttraining's binary_logloss: 4.31735e-05\n",
      "[1206]\ttraining's binary_logloss: 4.28058e-05\n",
      "[1207]\ttraining's binary_logloss: 4.24326e-05\n",
      "[1208]\ttraining's binary_logloss: 4.20718e-05\n",
      "[1209]\ttraining's binary_logloss: 4.17269e-05\n",
      "[1210]\ttraining's binary_logloss: 4.13774e-05\n",
      "[1211]\ttraining's binary_logloss: 4.10528e-05\n",
      "[1212]\ttraining's binary_logloss: 4.07227e-05\n",
      "[1213]\ttraining's binary_logloss: 4.03887e-05\n",
      "[1214]\ttraining's binary_logloss: 4.00509e-05\n",
      "[1215]\ttraining's binary_logloss: 3.97292e-05\n",
      "[1216]\ttraining's binary_logloss: 3.94052e-05\n",
      "[1217]\ttraining's binary_logloss: 3.90771e-05\n",
      "[1218]\ttraining's binary_logloss: 3.876e-05\n",
      "[1219]\ttraining's binary_logloss: 3.84541e-05\n",
      "[1220]\ttraining's binary_logloss: 3.81625e-05\n",
      "[1221]\ttraining's binary_logloss: 3.7872e-05\n",
      "[1222]\ttraining's binary_logloss: 3.75833e-05\n",
      "[1223]\ttraining's binary_logloss: 3.72891e-05\n",
      "[1224]\ttraining's binary_logloss: 3.69994e-05\n",
      "[1225]\ttraining's binary_logloss: 3.67186e-05\n",
      "[1226]\ttraining's binary_logloss: 3.64322e-05\n",
      "[1227]\ttraining's binary_logloss: 3.61573e-05\n",
      "[1228]\ttraining's binary_logloss: 3.58792e-05\n",
      "[1229]\ttraining's binary_logloss: 3.56231e-05\n",
      "[1230]\ttraining's binary_logloss: 3.53477e-05\n",
      "[1231]\ttraining's binary_logloss: 3.50716e-05\n",
      "[1232]\ttraining's binary_logloss: 3.48179e-05\n",
      "[1233]\ttraining's binary_logloss: 3.45483e-05\n",
      "[1234]\ttraining's binary_logloss: 3.42866e-05\n",
      "[1235]\ttraining's binary_logloss: 3.40284e-05\n",
      "[1236]\ttraining's binary_logloss: 3.37778e-05\n",
      "[1237]\ttraining's binary_logloss: 3.35366e-05\n",
      "[1238]\ttraining's binary_logloss: 3.32917e-05\n",
      "[1239]\ttraining's binary_logloss: 3.30542e-05\n",
      "[1240]\ttraining's binary_logloss: 3.2814e-05\n",
      "[1241]\ttraining's binary_logloss: 3.25822e-05\n",
      "[1242]\ttraining's binary_logloss: 3.23505e-05\n",
      "[1243]\ttraining's binary_logloss: 3.21223e-05\n",
      "[1244]\ttraining's binary_logloss: 3.18993e-05\n",
      "[1245]\ttraining's binary_logloss: 3.16738e-05\n",
      "[1246]\ttraining's binary_logloss: 3.14519e-05\n",
      "[1247]\ttraining's binary_logloss: 3.12348e-05\n",
      "[1248]\ttraining's binary_logloss: 3.10037e-05\n",
      "[1249]\ttraining's binary_logloss: 3.07882e-05\n",
      "[1250]\ttraining's binary_logloss: 3.05747e-05\n",
      "[1251]\ttraining's binary_logloss: 3.03741e-05\n",
      "[1252]\ttraining's binary_logloss: 3.01624e-05\n",
      "[1253]\ttraining's binary_logloss: 2.99561e-05\n",
      "[1254]\ttraining's binary_logloss: 2.97473e-05\n",
      "[1255]\ttraining's binary_logloss: 2.95527e-05\n",
      "[1256]\ttraining's binary_logloss: 2.93546e-05\n",
      "[1257]\ttraining's binary_logloss: 2.91539e-05\n",
      "[1258]\ttraining's binary_logloss: 2.89582e-05\n",
      "[1259]\ttraining's binary_logloss: 2.8763e-05\n",
      "[1260]\ttraining's binary_logloss: 2.85671e-05\n",
      "[1261]\ttraining's binary_logloss: 2.83706e-05\n",
      "[1262]\ttraining's binary_logloss: 2.81781e-05\n",
      "[1263]\ttraining's binary_logloss: 2.79929e-05\n",
      "[1264]\ttraining's binary_logloss: 2.78064e-05\n",
      "[1265]\ttraining's binary_logloss: 2.76251e-05\n",
      "[1266]\ttraining's binary_logloss: 2.74473e-05\n",
      "[1267]\ttraining's binary_logloss: 2.72797e-05\n",
      "[1268]\ttraining's binary_logloss: 2.71134e-05\n",
      "[1269]\ttraining's binary_logloss: 2.69423e-05\n",
      "[1270]\ttraining's binary_logloss: 2.67797e-05\n",
      "[1271]\ttraining's binary_logloss: 2.661e-05\n",
      "[1272]\ttraining's binary_logloss: 2.64562e-05\n",
      "[1273]\ttraining's binary_logloss: 2.63018e-05\n",
      "[1274]\ttraining's binary_logloss: 2.61436e-05\n",
      "[1275]\ttraining's binary_logloss: 2.59879e-05\n",
      "[1276]\ttraining's binary_logloss: 2.58372e-05\n",
      "[1277]\ttraining's binary_logloss: 2.56866e-05\n",
      "[1278]\ttraining's binary_logloss: 2.55236e-05\n",
      "[1279]\ttraining's binary_logloss: 2.53639e-05\n",
      "[1280]\ttraining's binary_logloss: 2.52121e-05\n",
      "[1281]\ttraining's binary_logloss: 2.5061e-05\n",
      "[1282]\ttraining's binary_logloss: 2.49033e-05\n",
      "[1283]\ttraining's binary_logloss: 2.47616e-05\n",
      "[1284]\ttraining's binary_logloss: 2.46235e-05\n",
      "[1285]\ttraining's binary_logloss: 2.44777e-05\n",
      "[1286]\ttraining's binary_logloss: 2.43309e-05\n",
      "[1287]\ttraining's binary_logloss: 2.41817e-05\n",
      "[1288]\ttraining's binary_logloss: 2.40528e-05\n",
      "[1289]\ttraining's binary_logloss: 2.39145e-05\n",
      "[1290]\ttraining's binary_logloss: 2.37849e-05\n",
      "[1291]\ttraining's binary_logloss: 2.36493e-05\n",
      "[1292]\ttraining's binary_logloss: 2.3519e-05\n",
      "[1293]\ttraining's binary_logloss: 2.33854e-05\n",
      "[1294]\ttraining's binary_logloss: 2.32665e-05\n",
      "[1295]\ttraining's binary_logloss: 2.31447e-05\n",
      "[1296]\ttraining's binary_logloss: 2.3013e-05\n",
      "[1297]\ttraining's binary_logloss: 2.28851e-05\n",
      "[1298]\ttraining's binary_logloss: 2.27509e-05\n",
      "[1299]\ttraining's binary_logloss: 2.26296e-05\n",
      "[1300]\ttraining's binary_logloss: 2.25037e-05\n",
      "[1301]\ttraining's binary_logloss: 2.23764e-05\n",
      "[1302]\ttraining's binary_logloss: 2.22659e-05\n",
      "[1303]\ttraining's binary_logloss: 2.21418e-05\n",
      "[1304]\ttraining's binary_logloss: 2.20267e-05\n",
      "[1305]\ttraining's binary_logloss: 2.19073e-05\n",
      "[1306]\ttraining's binary_logloss: 2.17926e-05\n",
      "[1307]\ttraining's binary_logloss: 2.16764e-05\n",
      "[1308]\ttraining's binary_logloss: 2.15645e-05\n",
      "[1309]\ttraining's binary_logloss: 2.14488e-05\n",
      "[1310]\ttraining's binary_logloss: 2.13384e-05\n",
      "[1311]\ttraining's binary_logloss: 2.12276e-05\n",
      "[1312]\ttraining's binary_logloss: 2.11203e-05\n",
      "[1313]\ttraining's binary_logloss: 2.10126e-05\n",
      "[1314]\ttraining's binary_logloss: 2.09052e-05\n",
      "[1315]\ttraining's binary_logloss: 2.07993e-05\n",
      "[1316]\ttraining's binary_logloss: 2.06886e-05\n",
      "[1317]\ttraining's binary_logloss: 2.05921e-05\n",
      "[1318]\ttraining's binary_logloss: 2.04903e-05\n",
      "[1319]\ttraining's binary_logloss: 2.03921e-05\n",
      "[1320]\ttraining's binary_logloss: 2.02983e-05\n",
      "[1321]\ttraining's binary_logloss: 2.01997e-05\n",
      "[1322]\ttraining's binary_logloss: 2.0098e-05\n",
      "[1323]\ttraining's binary_logloss: 2.00032e-05\n",
      "[1324]\ttraining's binary_logloss: 1.99097e-05\n",
      "[1325]\ttraining's binary_logloss: 1.98212e-05\n",
      "[1326]\ttraining's binary_logloss: 1.9731e-05\n",
      "[1327]\ttraining's binary_logloss: 1.96319e-05\n",
      "[1328]\ttraining's binary_logloss: 1.95388e-05\n",
      "[1329]\ttraining's binary_logloss: 1.94495e-05\n",
      "[1330]\ttraining's binary_logloss: 1.93583e-05\n",
      "[1331]\ttraining's binary_logloss: 1.92669e-05\n",
      "[1332]\ttraining's binary_logloss: 1.91781e-05\n",
      "[1333]\ttraining's binary_logloss: 1.90877e-05\n",
      "[1334]\ttraining's binary_logloss: 1.89895e-05\n",
      "[1335]\ttraining's binary_logloss: 1.89035e-05\n",
      "[1336]\ttraining's binary_logloss: 1.88156e-05\n",
      "[1337]\ttraining's binary_logloss: 1.87276e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1338]\ttraining's binary_logloss: 1.86435e-05\n",
      "[1339]\ttraining's binary_logloss: 1.85559e-05\n",
      "[1340]\ttraining's binary_logloss: 1.84692e-05\n",
      "[1341]\ttraining's binary_logloss: 1.83826e-05\n",
      "[1342]\ttraining's binary_logloss: 1.83039e-05\n",
      "[1343]\ttraining's binary_logloss: 1.82201e-05\n",
      "[1344]\ttraining's binary_logloss: 1.81407e-05\n",
      "[1345]\ttraining's binary_logloss: 1.80676e-05\n",
      "[1346]\ttraining's binary_logloss: 1.79917e-05\n",
      "[1347]\ttraining's binary_logloss: 1.79126e-05\n",
      "[1348]\ttraining's binary_logloss: 1.7833e-05\n",
      "[1349]\ttraining's binary_logloss: 1.77569e-05\n",
      "[1350]\ttraining's binary_logloss: 1.7679e-05\n",
      "[1351]\ttraining's binary_logloss: 1.75983e-05\n",
      "[1352]\ttraining's binary_logloss: 1.75279e-05\n",
      "[1353]\ttraining's binary_logloss: 1.74535e-05\n",
      "[1354]\ttraining's binary_logloss: 1.73776e-05\n",
      "[1355]\ttraining's binary_logloss: 1.7304e-05\n",
      "[1356]\ttraining's binary_logloss: 1.7228e-05\n",
      "[1357]\ttraining's binary_logloss: 1.71516e-05\n",
      "[1358]\ttraining's binary_logloss: 1.70838e-05\n",
      "[1359]\ttraining's binary_logloss: 1.70124e-05\n",
      "[1360]\ttraining's binary_logloss: 1.69455e-05\n",
      "[1361]\ttraining's binary_logloss: 1.68737e-05\n",
      "[1362]\ttraining's binary_logloss: 1.68054e-05\n",
      "[1363]\ttraining's binary_logloss: 1.67347e-05\n",
      "[1364]\ttraining's binary_logloss: 1.66698e-05\n",
      "[1365]\ttraining's binary_logloss: 1.66012e-05\n",
      "[1366]\ttraining's binary_logloss: 1.6537e-05\n",
      "[1367]\ttraining's binary_logloss: 1.647e-05\n",
      "[1368]\ttraining's binary_logloss: 1.64028e-05\n",
      "[1369]\ttraining's binary_logloss: 1.6338e-05\n",
      "[1370]\ttraining's binary_logloss: 1.62793e-05\n",
      "[1371]\ttraining's binary_logloss: 1.6217e-05\n",
      "[1372]\ttraining's binary_logloss: 1.61536e-05\n",
      "[1373]\ttraining's binary_logloss: 1.6096e-05\n",
      "[1374]\ttraining's binary_logloss: 1.60369e-05\n",
      "[1375]\ttraining's binary_logloss: 1.59726e-05\n",
      "[1376]\ttraining's binary_logloss: 1.59109e-05\n",
      "[1377]\ttraining's binary_logloss: 1.58473e-05\n",
      "[1378]\ttraining's binary_logloss: 1.57877e-05\n",
      "[1379]\ttraining's binary_logloss: 1.57238e-05\n",
      "[1380]\ttraining's binary_logloss: 1.56654e-05\n",
      "[1381]\ttraining's binary_logloss: 1.5609e-05\n",
      "[1382]\ttraining's binary_logloss: 1.55519e-05\n",
      "[1383]\ttraining's binary_logloss: 1.54921e-05\n",
      "[1384]\ttraining's binary_logloss: 1.54309e-05\n",
      "[1385]\ttraining's binary_logloss: 1.53776e-05\n",
      "[1386]\ttraining's binary_logloss: 1.53218e-05\n",
      "[1387]\ttraining's binary_logloss: 1.52696e-05\n",
      "[1388]\ttraining's binary_logloss: 1.52132e-05\n",
      "[1389]\ttraining's binary_logloss: 1.51575e-05\n",
      "[1390]\ttraining's binary_logloss: 1.51024e-05\n",
      "[1391]\ttraining's binary_logloss: 1.50449e-05\n",
      "[1392]\ttraining's binary_logloss: 1.49938e-05\n",
      "[1393]\ttraining's binary_logloss: 1.49397e-05\n",
      "[1394]\ttraining's binary_logloss: 1.48891e-05\n",
      "[1395]\ttraining's binary_logloss: 1.48321e-05\n",
      "[1396]\ttraining's binary_logloss: 1.4779e-05\n",
      "[1397]\ttraining's binary_logloss: 1.47245e-05\n",
      "[1398]\ttraining's binary_logloss: 1.46761e-05\n",
      "[1399]\ttraining's binary_logloss: 1.46259e-05\n",
      "[1400]\ttraining's binary_logloss: 1.45793e-05\n",
      "[1401]\ttraining's binary_logloss: 1.45257e-05\n",
      "[1402]\ttraining's binary_logloss: 1.44805e-05\n",
      "[1403]\ttraining's binary_logloss: 1.44329e-05\n",
      "[1404]\ttraining's binary_logloss: 1.4388e-05\n",
      "[1405]\ttraining's binary_logloss: 1.43355e-05\n",
      "[1406]\ttraining's binary_logloss: 1.42881e-05\n",
      "[1407]\ttraining's binary_logloss: 1.42388e-05\n",
      "[1408]\ttraining's binary_logloss: 1.41909e-05\n",
      "[1409]\ttraining's binary_logloss: 1.41407e-05\n",
      "[1410]\ttraining's binary_logloss: 1.40901e-05\n",
      "[1411]\ttraining's binary_logloss: 1.4044e-05\n",
      "[1412]\ttraining's binary_logloss: 1.39983e-05\n",
      "[1413]\ttraining's binary_logloss: 1.39502e-05\n",
      "[1414]\ttraining's binary_logloss: 1.39024e-05\n",
      "[1415]\ttraining's binary_logloss: 1.38534e-05\n",
      "[1416]\ttraining's binary_logloss: 1.38029e-05\n",
      "[1417]\ttraining's binary_logloss: 1.37555e-05\n",
      "[1418]\ttraining's binary_logloss: 1.3713e-05\n",
      "[1419]\ttraining's binary_logloss: 1.36651e-05\n",
      "[1420]\ttraining's binary_logloss: 1.36224e-05\n",
      "[1421]\ttraining's binary_logloss: 1.35761e-05\n",
      "[1422]\ttraining's binary_logloss: 1.3531e-05\n",
      "[1423]\ttraining's binary_logloss: 1.34861e-05\n",
      "[1424]\ttraining's binary_logloss: 1.34398e-05\n",
      "[1425]\ttraining's binary_logloss: 1.33944e-05\n",
      "[1426]\ttraining's binary_logloss: 1.33511e-05\n",
      "[1427]\ttraining's binary_logloss: 1.33145e-05\n",
      "[1428]\ttraining's binary_logloss: 1.32737e-05\n",
      "[1429]\ttraining's binary_logloss: 1.32291e-05\n",
      "[1430]\ttraining's binary_logloss: 1.31843e-05\n",
      "[1431]\ttraining's binary_logloss: 1.31435e-05\n",
      "[1432]\ttraining's binary_logloss: 1.31031e-05\n",
      "[1433]\ttraining's binary_logloss: 1.30649e-05\n",
      "[1434]\ttraining's binary_logloss: 1.30255e-05\n",
      "[1435]\ttraining's binary_logloss: 1.29857e-05\n",
      "[1436]\ttraining's binary_logloss: 1.29426e-05\n",
      "[1437]\ttraining's binary_logloss: 1.29037e-05\n",
      "[1438]\ttraining's binary_logloss: 1.28671e-05\n",
      "[1439]\ttraining's binary_logloss: 1.28315e-05\n",
      "[1440]\ttraining's binary_logloss: 1.27924e-05\n",
      "[1441]\ttraining's binary_logloss: 1.27492e-05\n",
      "[1442]\ttraining's binary_logloss: 1.27086e-05\n",
      "[1443]\ttraining's binary_logloss: 1.2669e-05\n",
      "[1444]\ttraining's binary_logloss: 1.26303e-05\n",
      "[1445]\ttraining's binary_logloss: 1.25942e-05\n",
      "[1446]\ttraining's binary_logloss: 1.25575e-05\n",
      "[1447]\ttraining's binary_logloss: 1.25217e-05\n",
      "[1448]\ttraining's binary_logloss: 1.24827e-05\n",
      "[1449]\ttraining's binary_logloss: 1.24472e-05\n",
      "[1450]\ttraining's binary_logloss: 1.24043e-05\n",
      "[1451]\ttraining's binary_logloss: 1.23675e-05\n",
      "[1452]\ttraining's binary_logloss: 1.23307e-05\n",
      "[1453]\ttraining's binary_logloss: 1.22912e-05\n",
      "[1454]\ttraining's binary_logloss: 1.22494e-05\n",
      "[1455]\ttraining's binary_logloss: 1.22072e-05\n",
      "[1456]\ttraining's binary_logloss: 1.21707e-05\n",
      "[1457]\ttraining's binary_logloss: 1.21332e-05\n",
      "[1458]\ttraining's binary_logloss: 1.20931e-05\n",
      "[1459]\ttraining's binary_logloss: 1.20585e-05\n",
      "[1460]\ttraining's binary_logloss: 1.20199e-05\n",
      "[1461]\ttraining's binary_logloss: 1.1983e-05\n",
      "[1462]\ttraining's binary_logloss: 1.19463e-05\n",
      "[1463]\ttraining's binary_logloss: 1.19099e-05\n",
      "[1464]\ttraining's binary_logloss: 1.18742e-05\n",
      "[1465]\ttraining's binary_logloss: 1.18408e-05\n",
      "[1466]\ttraining's binary_logloss: 1.18044e-05\n",
      "[1467]\ttraining's binary_logloss: 1.17701e-05\n",
      "[1468]\ttraining's binary_logloss: 1.1734e-05\n",
      "[1469]\ttraining's binary_logloss: 1.16993e-05\n",
      "[1470]\ttraining's binary_logloss: 1.16653e-05\n",
      "[1471]\ttraining's binary_logloss: 1.16315e-05\n",
      "[1472]\ttraining's binary_logloss: 1.15981e-05\n",
      "[1473]\ttraining's binary_logloss: 1.15657e-05\n",
      "[1474]\ttraining's binary_logloss: 1.15332e-05\n",
      "[1475]\ttraining's binary_logloss: 1.15009e-05\n",
      "[1476]\ttraining's binary_logloss: 1.147e-05\n",
      "[1477]\ttraining's binary_logloss: 1.14349e-05\n",
      "[1478]\ttraining's binary_logloss: 1.14017e-05\n",
      "[1479]\ttraining's binary_logloss: 1.13664e-05\n",
      "[1480]\ttraining's binary_logloss: 1.13333e-05\n",
      "[1481]\ttraining's binary_logloss: 1.12997e-05\n",
      "[1482]\ttraining's binary_logloss: 1.12624e-05\n",
      "[1483]\ttraining's binary_logloss: 1.12303e-05\n",
      "[1484]\ttraining's binary_logloss: 1.11964e-05\n",
      "[1485]\ttraining's binary_logloss: 1.11645e-05\n",
      "[1486]\ttraining's binary_logloss: 1.11326e-05\n",
      "[1487]\ttraining's binary_logloss: 1.11021e-05\n",
      "[1488]\ttraining's binary_logloss: 1.10721e-05\n",
      "[1489]\ttraining's binary_logloss: 1.10407e-05\n",
      "[1490]\ttraining's binary_logloss: 1.1012e-05\n",
      "[1491]\ttraining's binary_logloss: 1.09824e-05\n",
      "[1492]\ttraining's binary_logloss: 1.09542e-05\n",
      "[1493]\ttraining's binary_logloss: 1.09251e-05\n",
      "[1494]\ttraining's binary_logloss: 1.08937e-05\n",
      "[1495]\ttraining's binary_logloss: 1.08635e-05\n",
      "[1496]\ttraining's binary_logloss: 1.08351e-05\n",
      "[1497]\ttraining's binary_logloss: 1.08041e-05\n",
      "[1498]\ttraining's binary_logloss: 1.0777e-05\n",
      "[1499]\ttraining's binary_logloss: 1.07495e-05\n",
      "[1500]\ttraining's binary_logloss: 1.07218e-05\n",
      "[1501]\ttraining's binary_logloss: 1.06933e-05\n",
      "[1502]\ttraining's binary_logloss: 1.06666e-05\n",
      "[1503]\ttraining's binary_logloss: 1.0641e-05\n",
      "[1504]\ttraining's binary_logloss: 1.06126e-05\n",
      "[1505]\ttraining's binary_logloss: 1.05858e-05\n",
      "[1506]\ttraining's binary_logloss: 1.05586e-05\n",
      "[1507]\ttraining's binary_logloss: 1.05323e-05\n",
      "[1508]\ttraining's binary_logloss: 1.05065e-05\n",
      "[1509]\ttraining's binary_logloss: 1.04786e-05\n",
      "[1510]\ttraining's binary_logloss: 1.04551e-05\n",
      "[1511]\ttraining's binary_logloss: 1.04279e-05\n",
      "[1512]\ttraining's binary_logloss: 1.04012e-05\n",
      "[1513]\ttraining's binary_logloss: 1.03738e-05\n",
      "[1514]\ttraining's binary_logloss: 1.0347e-05\n",
      "[1515]\ttraining's binary_logloss: 1.03201e-05\n",
      "[1516]\ttraining's binary_logloss: 1.02923e-05\n",
      "[1517]\ttraining's binary_logloss: 1.0265e-05\n",
      "[1518]\ttraining's binary_logloss: 1.02366e-05\n",
      "[1519]\ttraining's binary_logloss: 1.02108e-05\n",
      "[1520]\ttraining's binary_logloss: 1.01859e-05\n",
      "[1521]\ttraining's binary_logloss: 1.01615e-05\n",
      "[1522]\ttraining's binary_logloss: 1.01358e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1523]\ttraining's binary_logloss: 1.01089e-05\n",
      "[1524]\ttraining's binary_logloss: 1.00826e-05\n",
      "[1525]\ttraining's binary_logloss: 1.00551e-05\n",
      "[1526]\ttraining's binary_logloss: 1.0032e-05\n",
      "[1527]\ttraining's binary_logloss: 1.00089e-05\n",
      "[1528]\ttraining's binary_logloss: 9.98494e-06\n",
      "[1529]\ttraining's binary_logloss: 9.961e-06\n",
      "[1530]\ttraining's binary_logloss: 9.93624e-06\n",
      "[1531]\ttraining's binary_logloss: 9.91411e-06\n",
      "[1532]\ttraining's binary_logloss: 9.89048e-06\n",
      "[1533]\ttraining's binary_logloss: 9.86731e-06\n",
      "[1534]\ttraining's binary_logloss: 9.84421e-06\n",
      "[1535]\ttraining's binary_logloss: 9.82192e-06\n",
      "[1536]\ttraining's binary_logloss: 9.79646e-06\n",
      "[1537]\ttraining's binary_logloss: 9.77435e-06\n",
      "[1538]\ttraining's binary_logloss: 9.75123e-06\n",
      "[1539]\ttraining's binary_logloss: 9.72864e-06\n",
      "[1540]\ttraining's binary_logloss: 9.70609e-06\n",
      "[1541]\ttraining's binary_logloss: 9.68156e-06\n",
      "[1542]\ttraining's binary_logloss: 9.65961e-06\n",
      "[1543]\ttraining's binary_logloss: 9.63833e-06\n",
      "[1544]\ttraining's binary_logloss: 9.61808e-06\n",
      "[1545]\ttraining's binary_logloss: 9.59662e-06\n",
      "[1546]\ttraining's binary_logloss: 9.57293e-06\n",
      "[1547]\ttraining's binary_logloss: 9.5495e-06\n",
      "[1548]\ttraining's binary_logloss: 9.52765e-06\n",
      "[1549]\ttraining's binary_logloss: 9.50714e-06\n",
      "[1550]\ttraining's binary_logloss: 9.48744e-06\n",
      "[1551]\ttraining's binary_logloss: 9.46827e-06\n",
      "[1552]\ttraining's binary_logloss: 9.44662e-06\n",
      "[1553]\ttraining's binary_logloss: 9.42582e-06\n",
      "[1554]\ttraining's binary_logloss: 9.40259e-06\n",
      "[1555]\ttraining's binary_logloss: 9.38044e-06\n",
      "[1556]\ttraining's binary_logloss: 9.3574e-06\n",
      "[1557]\ttraining's binary_logloss: 9.33604e-06\n",
      "[1558]\ttraining's binary_logloss: 9.31287e-06\n",
      "[1559]\ttraining's binary_logloss: 9.29365e-06\n",
      "[1560]\ttraining's binary_logloss: 9.27472e-06\n",
      "[1561]\ttraining's binary_logloss: 9.2571e-06\n",
      "[1562]\ttraining's binary_logloss: 9.23868e-06\n",
      "[1563]\ttraining's binary_logloss: 9.2169e-06\n",
      "[1564]\ttraining's binary_logloss: 9.19652e-06\n",
      "[1565]\ttraining's binary_logloss: 9.17515e-06\n",
      "[1566]\ttraining's binary_logloss: 9.15703e-06\n",
      "[1567]\ttraining's binary_logloss: 9.13912e-06\n",
      "[1568]\ttraining's binary_logloss: 9.12025e-06\n",
      "[1569]\ttraining's binary_logloss: 9.10297e-06\n",
      "[1570]\ttraining's binary_logloss: 9.08436e-06\n",
      "[1571]\ttraining's binary_logloss: 9.0654e-06\n",
      "[1572]\ttraining's binary_logloss: 9.04566e-06\n",
      "[1573]\ttraining's binary_logloss: 9.02581e-06\n",
      "[1574]\ttraining's binary_logloss: 9.00657e-06\n",
      "[1575]\ttraining's binary_logloss: 8.98714e-06\n",
      "[1576]\ttraining's binary_logloss: 8.96817e-06\n",
      "[1577]\ttraining's binary_logloss: 8.94909e-06\n",
      "[1578]\ttraining's binary_logloss: 8.92942e-06\n",
      "[1579]\ttraining's binary_logloss: 8.90936e-06\n",
      "[1580]\ttraining's binary_logloss: 8.89107e-06\n",
      "[1581]\ttraining's binary_logloss: 8.87195e-06\n",
      "[1582]\ttraining's binary_logloss: 8.85173e-06\n",
      "[1583]\ttraining's binary_logloss: 8.83328e-06\n",
      "[1584]\ttraining's binary_logloss: 8.81421e-06\n",
      "[1585]\ttraining's binary_logloss: 8.79501e-06\n",
      "[1586]\ttraining's binary_logloss: 8.77643e-06\n",
      "[1587]\ttraining's binary_logloss: 8.75849e-06\n",
      "[1588]\ttraining's binary_logloss: 8.74042e-06\n",
      "[1589]\ttraining's binary_logloss: 8.72356e-06\n",
      "[1590]\ttraining's binary_logloss: 8.70341e-06\n",
      "[1591]\ttraining's binary_logloss: 8.68685e-06\n",
      "[1592]\ttraining's binary_logloss: 8.66925e-06\n",
      "[1593]\ttraining's binary_logloss: 8.65285e-06\n",
      "[1594]\ttraining's binary_logloss: 8.63464e-06\n",
      "[1595]\ttraining's binary_logloss: 8.61848e-06\n",
      "[1596]\ttraining's binary_logloss: 8.59951e-06\n",
      "[1597]\ttraining's binary_logloss: 8.58142e-06\n",
      "[1598]\ttraining's binary_logloss: 8.56457e-06\n",
      "[1599]\ttraining's binary_logloss: 8.54725e-06\n",
      "[1600]\ttraining's binary_logloss: 8.53093e-06\n",
      "[1601]\ttraining's binary_logloss: 8.5148e-06\n",
      "[1602]\ttraining's binary_logloss: 8.49755e-06\n",
      "[1603]\ttraining's binary_logloss: 8.48037e-06\n",
      "[1604]\ttraining's binary_logloss: 8.46246e-06\n",
      "[1605]\ttraining's binary_logloss: 8.44324e-06\n",
      "[1606]\ttraining's binary_logloss: 8.42817e-06\n",
      "[1607]\ttraining's binary_logloss: 8.41263e-06\n",
      "[1608]\ttraining's binary_logloss: 8.39621e-06\n",
      "[1609]\ttraining's binary_logloss: 8.37881e-06\n",
      "[1610]\ttraining's binary_logloss: 8.3642e-06\n",
      "[1611]\ttraining's binary_logloss: 8.34741e-06\n",
      "[1612]\ttraining's binary_logloss: 8.33129e-06\n",
      "[1613]\ttraining's binary_logloss: 8.31666e-06\n",
      "[1614]\ttraining's binary_logloss: 8.29986e-06\n",
      "[1615]\ttraining's binary_logloss: 8.28339e-06\n",
      "[1616]\ttraining's binary_logloss: 8.2688e-06\n",
      "[1617]\ttraining's binary_logloss: 8.25168e-06\n",
      "[1618]\ttraining's binary_logloss: 8.23588e-06\n",
      "[1619]\ttraining's binary_logloss: 8.21992e-06\n",
      "[1620]\ttraining's binary_logloss: 8.20301e-06\n",
      "[1621]\ttraining's binary_logloss: 8.18708e-06\n",
      "[1622]\ttraining's binary_logloss: 8.17177e-06\n",
      "[1623]\ttraining's binary_logloss: 8.15503e-06\n",
      "[1624]\ttraining's binary_logloss: 8.13854e-06\n",
      "[1625]\ttraining's binary_logloss: 8.12256e-06\n",
      "[1626]\ttraining's binary_logloss: 8.1072e-06\n",
      "[1627]\ttraining's binary_logloss: 8.09416e-06\n",
      "[1628]\ttraining's binary_logloss: 8.07898e-06\n",
      "[1629]\ttraining's binary_logloss: 8.06525e-06\n",
      "[1630]\ttraining's binary_logloss: 8.05051e-06\n",
      "[1631]\ttraining's binary_logloss: 8.03322e-06\n",
      "[1632]\ttraining's binary_logloss: 8.01646e-06\n",
      "[1633]\ttraining's binary_logloss: 8.00107e-06\n",
      "[1634]\ttraining's binary_logloss: 7.98582e-06\n",
      "[1635]\ttraining's binary_logloss: 7.9719e-06\n",
      "[1636]\ttraining's binary_logloss: 7.95781e-06\n",
      "[1637]\ttraining's binary_logloss: 7.94379e-06\n",
      "[1638]\ttraining's binary_logloss: 7.92873e-06\n",
      "[1639]\ttraining's binary_logloss: 7.91572e-06\n",
      "[1640]\ttraining's binary_logloss: 7.90109e-06\n",
      "[1641]\ttraining's binary_logloss: 7.88629e-06\n",
      "[1642]\ttraining's binary_logloss: 7.8723e-06\n",
      "[1643]\ttraining's binary_logloss: 7.85922e-06\n",
      "[1644]\ttraining's binary_logloss: 7.8444e-06\n",
      "[1645]\ttraining's binary_logloss: 7.83017e-06\n",
      "[1646]\ttraining's binary_logloss: 7.81588e-06\n",
      "[1647]\ttraining's binary_logloss: 7.80182e-06\n",
      "[1648]\ttraining's binary_logloss: 7.78755e-06\n",
      "[1649]\ttraining's binary_logloss: 7.77367e-06\n",
      "[1650]\ttraining's binary_logloss: 7.75826e-06\n",
      "[1651]\ttraining's binary_logloss: 7.74267e-06\n",
      "[1652]\ttraining's binary_logloss: 7.72907e-06\n",
      "[1653]\ttraining's binary_logloss: 7.71523e-06\n",
      "[1654]\ttraining's binary_logloss: 7.7011e-06\n",
      "[1655]\ttraining's binary_logloss: 7.68684e-06\n",
      "[1656]\ttraining's binary_logloss: 7.67276e-06\n",
      "[1657]\ttraining's binary_logloss: 7.65796e-06\n",
      "[1658]\ttraining's binary_logloss: 7.644e-06\n",
      "[1659]\ttraining's binary_logloss: 7.63152e-06\n",
      "[1660]\ttraining's binary_logloss: 7.61918e-06\n",
      "[1661]\ttraining's binary_logloss: 7.60553e-06\n",
      "[1662]\ttraining's binary_logloss: 7.59404e-06\n",
      "[1663]\ttraining's binary_logloss: 7.58126e-06\n",
      "[1664]\ttraining's binary_logloss: 7.56798e-06\n",
      "[1665]\ttraining's binary_logloss: 7.55492e-06\n",
      "[1666]\ttraining's binary_logloss: 7.54147e-06\n",
      "[1667]\ttraining's binary_logloss: 7.52778e-06\n",
      "[1668]\ttraining's binary_logloss: 7.51541e-06\n",
      "[1669]\ttraining's binary_logloss: 7.50255e-06\n",
      "[1670]\ttraining's binary_logloss: 7.48862e-06\n",
      "[1671]\ttraining's binary_logloss: 7.47625e-06\n",
      "[1672]\ttraining's binary_logloss: 7.46257e-06\n",
      "[1673]\ttraining's binary_logloss: 7.45062e-06\n",
      "[1674]\ttraining's binary_logloss: 7.43809e-06\n",
      "[1675]\ttraining's binary_logloss: 7.42562e-06\n",
      "[1676]\ttraining's binary_logloss: 7.41285e-06\n",
      "[1677]\ttraining's binary_logloss: 7.40046e-06\n",
      "[1678]\ttraining's binary_logloss: 7.38678e-06\n",
      "[1679]\ttraining's binary_logloss: 7.37308e-06\n",
      "[1680]\ttraining's binary_logloss: 7.36098e-06\n",
      "[1681]\ttraining's binary_logloss: 7.34919e-06\n",
      "[1682]\ttraining's binary_logloss: 7.33698e-06\n",
      "[1683]\ttraining's binary_logloss: 7.32545e-06\n",
      "[1684]\ttraining's binary_logloss: 7.31138e-06\n",
      "[1685]\ttraining's binary_logloss: 7.29892e-06\n",
      "[1686]\ttraining's binary_logloss: 7.28662e-06\n",
      "[1687]\ttraining's binary_logloss: 7.27482e-06\n",
      "[1688]\ttraining's binary_logloss: 7.2615e-06\n",
      "[1689]\ttraining's binary_logloss: 7.25017e-06\n",
      "[1690]\ttraining's binary_logloss: 7.23756e-06\n",
      "[1691]\ttraining's binary_logloss: 7.22688e-06\n",
      "[1692]\ttraining's binary_logloss: 7.21594e-06\n",
      "[1693]\ttraining's binary_logloss: 7.20541e-06\n",
      "[1694]\ttraining's binary_logloss: 7.19251e-06\n",
      "[1695]\ttraining's binary_logloss: 7.18094e-06\n",
      "[1696]\ttraining's binary_logloss: 7.16984e-06\n",
      "[1697]\ttraining's binary_logloss: 7.15763e-06\n",
      "[1698]\ttraining's binary_logloss: 7.14585e-06\n",
      "[1699]\ttraining's binary_logloss: 7.13356e-06\n",
      "[1700]\ttraining's binary_logloss: 7.12143e-06\n",
      "[1701]\ttraining's binary_logloss: 7.10916e-06\n",
      "[1702]\ttraining's binary_logloss: 7.09756e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1703]\ttraining's binary_logloss: 7.0865e-06\n",
      "[1704]\ttraining's binary_logloss: 7.07601e-06\n",
      "[1705]\ttraining's binary_logloss: 7.06373e-06\n",
      "[1706]\ttraining's binary_logloss: 7.05289e-06\n",
      "[1707]\ttraining's binary_logloss: 7.04251e-06\n",
      "[1708]\ttraining's binary_logloss: 7.03189e-06\n",
      "[1709]\ttraining's binary_logloss: 7.02024e-06\n",
      "[1710]\ttraining's binary_logloss: 7.00908e-06\n",
      "[1711]\ttraining's binary_logloss: 6.99807e-06\n",
      "[1712]\ttraining's binary_logloss: 6.98759e-06\n",
      "[1713]\ttraining's binary_logloss: 6.97678e-06\n",
      "[1714]\ttraining's binary_logloss: 6.96561e-06\n",
      "[1715]\ttraining's binary_logloss: 6.95475e-06\n",
      "[1716]\ttraining's binary_logloss: 6.94468e-06\n",
      "[1717]\ttraining's binary_logloss: 6.93301e-06\n",
      "[1718]\ttraining's binary_logloss: 6.92261e-06\n",
      "[1719]\ttraining's binary_logloss: 6.91172e-06\n",
      "[1720]\ttraining's binary_logloss: 6.90023e-06\n",
      "[1721]\ttraining's binary_logloss: 6.8906e-06\n",
      "[1722]\ttraining's binary_logloss: 6.88054e-06\n",
      "[1723]\ttraining's binary_logloss: 6.8698e-06\n",
      "[1724]\ttraining's binary_logloss: 6.85886e-06\n",
      "[1725]\ttraining's binary_logloss: 6.84741e-06\n",
      "[1726]\ttraining's binary_logloss: 6.83575e-06\n",
      "[1727]\ttraining's binary_logloss: 6.82454e-06\n",
      "[1728]\ttraining's binary_logloss: 6.8146e-06\n",
      "[1729]\ttraining's binary_logloss: 6.80454e-06\n",
      "[1730]\ttraining's binary_logloss: 6.79422e-06\n",
      "[1731]\ttraining's binary_logloss: 6.78403e-06\n",
      "[1732]\ttraining's binary_logloss: 6.77386e-06\n",
      "[1733]\ttraining's binary_logloss: 6.76284e-06\n",
      "[1734]\ttraining's binary_logloss: 6.75246e-06\n",
      "[1735]\ttraining's binary_logloss: 6.74308e-06\n",
      "[1736]\ttraining's binary_logloss: 6.73361e-06\n",
      "[1737]\ttraining's binary_logloss: 6.7242e-06\n",
      "[1738]\ttraining's binary_logloss: 6.71368e-06\n",
      "[1739]\ttraining's binary_logloss: 6.70389e-06\n",
      "[1740]\ttraining's binary_logloss: 6.69408e-06\n",
      "[1741]\ttraining's binary_logloss: 6.68482e-06\n",
      "[1742]\ttraining's binary_logloss: 6.67537e-06\n",
      "[1743]\ttraining's binary_logloss: 6.66578e-06\n",
      "[1744]\ttraining's binary_logloss: 6.65654e-06\n",
      "[1745]\ttraining's binary_logloss: 6.64629e-06\n",
      "[1746]\ttraining's binary_logloss: 6.638e-06\n",
      "[1747]\ttraining's binary_logloss: 6.62828e-06\n",
      "[1748]\ttraining's binary_logloss: 6.61887e-06\n",
      "[1749]\ttraining's binary_logloss: 6.60843e-06\n",
      "[1750]\ttraining's binary_logloss: 6.59889e-06\n",
      "[1751]\ttraining's binary_logloss: 6.58881e-06\n",
      "[1752]\ttraining's binary_logloss: 6.57878e-06\n",
      "[1753]\ttraining's binary_logloss: 6.5688e-06\n",
      "[1754]\ttraining's binary_logloss: 6.55866e-06\n",
      "[1755]\ttraining's binary_logloss: 6.54962e-06\n",
      "[1756]\ttraining's binary_logloss: 6.53998e-06\n",
      "[1757]\ttraining's binary_logloss: 6.52985e-06\n",
      "[1758]\ttraining's binary_logloss: 6.52068e-06\n",
      "[1759]\ttraining's binary_logloss: 6.51152e-06\n",
      "[1760]\ttraining's binary_logloss: 6.503e-06\n",
      "[1761]\ttraining's binary_logloss: 6.49335e-06\n",
      "[1762]\ttraining's binary_logloss: 6.48393e-06\n",
      "[1763]\ttraining's binary_logloss: 6.4747e-06\n",
      "[1764]\ttraining's binary_logloss: 6.46505e-06\n",
      "[1765]\ttraining's binary_logloss: 6.45512e-06\n",
      "[1766]\ttraining's binary_logloss: 6.44587e-06\n",
      "[1767]\ttraining's binary_logloss: 6.43646e-06\n",
      "[1768]\ttraining's binary_logloss: 6.42635e-06\n",
      "[1769]\ttraining's binary_logloss: 6.41704e-06\n",
      "[1770]\ttraining's binary_logloss: 6.40702e-06\n",
      "[1771]\ttraining's binary_logloss: 6.39819e-06\n",
      "[1772]\ttraining's binary_logloss: 6.38944e-06\n",
      "[1773]\ttraining's binary_logloss: 6.38073e-06\n",
      "[1774]\ttraining's binary_logloss: 6.37071e-06\n",
      "[1775]\ttraining's binary_logloss: 6.36173e-06\n",
      "[1776]\ttraining's binary_logloss: 6.35259e-06\n",
      "[1777]\ttraining's binary_logloss: 6.34316e-06\n",
      "[1778]\ttraining's binary_logloss: 6.33327e-06\n",
      "[1779]\ttraining's binary_logloss: 6.32398e-06\n",
      "[1780]\ttraining's binary_logloss: 6.31455e-06\n",
      "[1781]\ttraining's binary_logloss: 6.30545e-06\n",
      "[1782]\ttraining's binary_logloss: 6.29622e-06\n",
      "[1783]\ttraining's binary_logloss: 6.28821e-06\n",
      "[1784]\ttraining's binary_logloss: 6.28006e-06\n",
      "[1785]\ttraining's binary_logloss: 6.27058e-06\n",
      "[1786]\ttraining's binary_logloss: 6.26233e-06\n",
      "[1787]\ttraining's binary_logloss: 6.25469e-06\n",
      "[1788]\ttraining's binary_logloss: 6.24597e-06\n",
      "[1789]\ttraining's binary_logloss: 6.23619e-06\n",
      "[1790]\ttraining's binary_logloss: 6.22863e-06\n",
      "[1791]\ttraining's binary_logloss: 6.22071e-06\n",
      "[1792]\ttraining's binary_logloss: 6.21224e-06\n",
      "[1793]\ttraining's binary_logloss: 6.20312e-06\n",
      "[1794]\ttraining's binary_logloss: 6.19469e-06\n",
      "[1795]\ttraining's binary_logloss: 6.18594e-06\n",
      "[1796]\ttraining's binary_logloss: 6.17836e-06\n",
      "[1797]\ttraining's binary_logloss: 6.16908e-06\n",
      "[1798]\ttraining's binary_logloss: 6.16211e-06\n",
      "[1799]\ttraining's binary_logloss: 6.15432e-06\n",
      "[1800]\ttraining's binary_logloss: 6.14582e-06\n",
      "[1801]\ttraining's binary_logloss: 6.13757e-06\n",
      "[1802]\ttraining's binary_logloss: 6.12916e-06\n",
      "[1803]\ttraining's binary_logloss: 6.12135e-06\n",
      "[1804]\ttraining's binary_logloss: 6.11381e-06\n",
      "[1805]\ttraining's binary_logloss: 6.10483e-06\n",
      "[1806]\ttraining's binary_logloss: 6.09708e-06\n",
      "[1807]\ttraining's binary_logloss: 6.0887e-06\n",
      "[1808]\ttraining's binary_logloss: 6.08122e-06\n",
      "[1809]\ttraining's binary_logloss: 6.07299e-06\n",
      "[1810]\ttraining's binary_logloss: 6.06526e-06\n",
      "[1811]\ttraining's binary_logloss: 6.05724e-06\n",
      "[1812]\ttraining's binary_logloss: 6.04951e-06\n",
      "[1813]\ttraining's binary_logloss: 6.04165e-06\n",
      "[1814]\ttraining's binary_logloss: 6.03403e-06\n",
      "[1815]\ttraining's binary_logloss: 6.02648e-06\n",
      "[1816]\ttraining's binary_logloss: 6.01869e-06\n",
      "[1817]\ttraining's binary_logloss: 6.01148e-06\n",
      "[1818]\ttraining's binary_logloss: 6.0038e-06\n",
      "[1819]\ttraining's binary_logloss: 5.99748e-06\n",
      "[1820]\ttraining's binary_logloss: 5.98949e-06\n",
      "[1821]\ttraining's binary_logloss: 5.98137e-06\n",
      "[1822]\ttraining's binary_logloss: 5.97379e-06\n",
      "[1823]\ttraining's binary_logloss: 5.96659e-06\n",
      "[1824]\ttraining's binary_logloss: 5.95916e-06\n",
      "[1825]\ttraining's binary_logloss: 5.95171e-06\n",
      "[1826]\ttraining's binary_logloss: 5.94384e-06\n",
      "[1827]\ttraining's binary_logloss: 5.93598e-06\n",
      "[1828]\ttraining's binary_logloss: 5.92839e-06\n",
      "[1829]\ttraining's binary_logloss: 5.9204e-06\n",
      "[1830]\ttraining's binary_logloss: 5.91266e-06\n",
      "[1831]\ttraining's binary_logloss: 5.9055e-06\n",
      "[1832]\ttraining's binary_logloss: 5.898e-06\n",
      "[1833]\ttraining's binary_logloss: 5.88979e-06\n",
      "[1834]\ttraining's binary_logloss: 5.88177e-06\n",
      "[1835]\ttraining's binary_logloss: 5.87418e-06\n",
      "[1836]\ttraining's binary_logloss: 5.86667e-06\n",
      "[1837]\ttraining's binary_logloss: 5.85835e-06\n",
      "[1838]\ttraining's binary_logloss: 5.85056e-06\n",
      "[1839]\ttraining's binary_logloss: 5.84375e-06\n",
      "[1840]\ttraining's binary_logloss: 5.83696e-06\n",
      "[1841]\ttraining's binary_logloss: 5.82892e-06\n",
      "[1842]\ttraining's binary_logloss: 5.82128e-06\n",
      "[1843]\ttraining's binary_logloss: 5.81338e-06\n",
      "[1844]\ttraining's binary_logloss: 5.80591e-06\n",
      "[1845]\ttraining's binary_logloss: 5.7984e-06\n",
      "[1846]\ttraining's binary_logloss: 5.79109e-06\n",
      "[1847]\ttraining's binary_logloss: 5.78436e-06\n",
      "[1848]\ttraining's binary_logloss: 5.77714e-06\n",
      "[1849]\ttraining's binary_logloss: 5.77076e-06\n",
      "[1850]\ttraining's binary_logloss: 5.76374e-06\n",
      "[1851]\ttraining's binary_logloss: 5.7564e-06\n",
      "[1852]\ttraining's binary_logloss: 5.74997e-06\n",
      "[1853]\ttraining's binary_logloss: 5.74345e-06\n",
      "[1854]\ttraining's binary_logloss: 5.73751e-06\n",
      "[1855]\ttraining's binary_logloss: 5.72982e-06\n",
      "[1856]\ttraining's binary_logloss: 5.72254e-06\n",
      "[1857]\ttraining's binary_logloss: 5.71612e-06\n",
      "[1858]\ttraining's binary_logloss: 5.70851e-06\n",
      "[1859]\ttraining's binary_logloss: 5.70109e-06\n",
      "[1860]\ttraining's binary_logloss: 5.69381e-06\n",
      "[1861]\ttraining's binary_logloss: 5.68674e-06\n",
      "[1862]\ttraining's binary_logloss: 5.68029e-06\n",
      "[1863]\ttraining's binary_logloss: 5.67409e-06\n",
      "[1864]\ttraining's binary_logloss: 5.66721e-06\n",
      "[1865]\ttraining's binary_logloss: 5.66045e-06\n",
      "[1866]\ttraining's binary_logloss: 5.65272e-06\n",
      "[1867]\ttraining's binary_logloss: 5.64559e-06\n",
      "[1868]\ttraining's binary_logloss: 5.63835e-06\n",
      "[1869]\ttraining's binary_logloss: 5.6316e-06\n",
      "[1870]\ttraining's binary_logloss: 5.62524e-06\n",
      "[1871]\ttraining's binary_logloss: 5.61919e-06\n",
      "[1872]\ttraining's binary_logloss: 5.61278e-06\n",
      "[1873]\ttraining's binary_logloss: 5.60641e-06\n",
      "[1874]\ttraining's binary_logloss: 5.60006e-06\n",
      "[1875]\ttraining's binary_logloss: 5.59301e-06\n",
      "[1876]\ttraining's binary_logloss: 5.58651e-06\n",
      "[1877]\ttraining's binary_logloss: 5.57962e-06\n",
      "[1878]\ttraining's binary_logloss: 5.57232e-06\n",
      "[1879]\ttraining's binary_logloss: 5.56543e-06\n",
      "[1880]\ttraining's binary_logloss: 5.5586e-06\n",
      "[1881]\ttraining's binary_logloss: 5.55192e-06\n",
      "[1882]\ttraining's binary_logloss: 5.54491e-06\n",
      "[1883]\ttraining's binary_logloss: 5.53811e-06\n",
      "[1884]\ttraining's binary_logloss: 5.53191e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1885]\ttraining's binary_logloss: 5.52485e-06\n",
      "[1886]\ttraining's binary_logloss: 5.51804e-06\n",
      "[1887]\ttraining's binary_logloss: 5.51168e-06\n",
      "[1888]\ttraining's binary_logloss: 5.50587e-06\n",
      "[1889]\ttraining's binary_logloss: 5.49901e-06\n",
      "[1890]\ttraining's binary_logloss: 5.49267e-06\n",
      "[1891]\ttraining's binary_logloss: 5.48657e-06\n",
      "[1892]\ttraining's binary_logloss: 5.47892e-06\n",
      "[1893]\ttraining's binary_logloss: 5.47216e-06\n",
      "[1894]\ttraining's binary_logloss: 5.466e-06\n",
      "[1895]\ttraining's binary_logloss: 5.4598e-06\n",
      "[1896]\ttraining's binary_logloss: 5.45356e-06\n",
      "[1897]\ttraining's binary_logloss: 5.44636e-06\n",
      "[1898]\ttraining's binary_logloss: 5.43952e-06\n",
      "[1899]\ttraining's binary_logloss: 5.43297e-06\n",
      "[1900]\ttraining's binary_logloss: 5.42741e-06\n",
      "[1901]\ttraining's binary_logloss: 5.42125e-06\n",
      "[1902]\ttraining's binary_logloss: 5.4146e-06\n",
      "[1903]\ttraining's binary_logloss: 5.40882e-06\n",
      "[1904]\ttraining's binary_logloss: 5.40225e-06\n",
      "[1905]\ttraining's binary_logloss: 5.39626e-06\n",
      "[1906]\ttraining's binary_logloss: 5.39025e-06\n",
      "[1907]\ttraining's binary_logloss: 5.38434e-06\n",
      "[1908]\ttraining's binary_logloss: 5.37813e-06\n",
      "[1909]\ttraining's binary_logloss: 5.37191e-06\n",
      "[1910]\ttraining's binary_logloss: 5.36511e-06\n",
      "[1911]\ttraining's binary_logloss: 5.35761e-06\n",
      "[1912]\ttraining's binary_logloss: 5.35133e-06\n",
      "[1913]\ttraining's binary_logloss: 5.34519e-06\n",
      "[1914]\ttraining's binary_logloss: 5.33917e-06\n",
      "[1915]\ttraining's binary_logloss: 5.33341e-06\n",
      "[1916]\ttraining's binary_logloss: 5.32793e-06\n",
      "[1917]\ttraining's binary_logloss: 5.32176e-06\n",
      "[1918]\ttraining's binary_logloss: 5.31614e-06\n",
      "[1919]\ttraining's binary_logloss: 5.30983e-06\n",
      "[1920]\ttraining's binary_logloss: 5.30381e-06\n",
      "[1921]\ttraining's binary_logloss: 5.29804e-06\n",
      "[1922]\ttraining's binary_logloss: 5.29266e-06\n",
      "[1923]\ttraining's binary_logloss: 5.28709e-06\n",
      "[1924]\ttraining's binary_logloss: 5.28136e-06\n",
      "[1925]\ttraining's binary_logloss: 5.27549e-06\n",
      "[1926]\ttraining's binary_logloss: 5.26938e-06\n",
      "[1927]\ttraining's binary_logloss: 5.26373e-06\n",
      "[1928]\ttraining's binary_logloss: 5.25777e-06\n",
      "[1929]\ttraining's binary_logloss: 5.25205e-06\n",
      "[1930]\ttraining's binary_logloss: 5.24599e-06\n",
      "[1931]\ttraining's binary_logloss: 5.24066e-06\n",
      "[1932]\ttraining's binary_logloss: 5.23468e-06\n",
      "[1933]\ttraining's binary_logloss: 5.22822e-06\n",
      "[1934]\ttraining's binary_logloss: 5.2224e-06\n",
      "[1935]\ttraining's binary_logloss: 5.21638e-06\n",
      "[1936]\ttraining's binary_logloss: 5.21085e-06\n",
      "[1937]\ttraining's binary_logloss: 5.20547e-06\n",
      "[1938]\ttraining's binary_logloss: 5.19981e-06\n",
      "[1939]\ttraining's binary_logloss: 5.19434e-06\n",
      "[1940]\ttraining's binary_logloss: 5.18847e-06\n",
      "[1941]\ttraining's binary_logloss: 5.18245e-06\n",
      "[1942]\ttraining's binary_logloss: 5.17639e-06\n",
      "[1943]\ttraining's binary_logloss: 5.1712e-06\n",
      "[1944]\ttraining's binary_logloss: 5.16446e-06\n",
      "[1945]\ttraining's binary_logloss: 5.15829e-06\n",
      "[1946]\ttraining's binary_logloss: 5.15281e-06\n",
      "[1947]\ttraining's binary_logloss: 5.14727e-06\n",
      "[1948]\ttraining's binary_logloss: 5.1425e-06\n",
      "[1949]\ttraining's binary_logloss: 5.13792e-06\n",
      "[1950]\ttraining's binary_logloss: 5.13326e-06\n",
      "[1951]\ttraining's binary_logloss: 5.12788e-06\n",
      "[1952]\ttraining's binary_logloss: 5.12316e-06\n",
      "[1953]\ttraining's binary_logloss: 5.11806e-06\n",
      "[1954]\ttraining's binary_logloss: 5.11309e-06\n",
      "[1955]\ttraining's binary_logloss: 5.10749e-06\n",
      "[1956]\ttraining's binary_logloss: 5.10194e-06\n",
      "[1957]\ttraining's binary_logloss: 5.09701e-06\n",
      "[1958]\ttraining's binary_logloss: 5.09173e-06\n",
      "[1959]\ttraining's binary_logloss: 5.08641e-06\n",
      "[1960]\ttraining's binary_logloss: 5.0806e-06\n",
      "[1961]\ttraining's binary_logloss: 5.07532e-06\n",
      "[1962]\ttraining's binary_logloss: 5.06982e-06\n",
      "[1963]\ttraining's binary_logloss: 5.06381e-06\n",
      "[1964]\ttraining's binary_logloss: 5.05772e-06\n",
      "[1965]\ttraining's binary_logloss: 5.05202e-06\n",
      "[1966]\ttraining's binary_logloss: 5.04662e-06\n",
      "[1967]\ttraining's binary_logloss: 5.04113e-06\n",
      "[1968]\ttraining's binary_logloss: 5.03587e-06\n",
      "[1969]\ttraining's binary_logloss: 5.03049e-06\n",
      "[1970]\ttraining's binary_logloss: 5.02537e-06\n",
      "[1971]\ttraining's binary_logloss: 5.01967e-06\n",
      "[1972]\ttraining's binary_logloss: 5.01496e-06\n",
      "[1973]\ttraining's binary_logloss: 5.00959e-06\n",
      "[1974]\ttraining's binary_logloss: 5.00479e-06\n",
      "[1975]\ttraining's binary_logloss: 4.99947e-06\n",
      "[1976]\ttraining's binary_logloss: 4.99412e-06\n",
      "[1977]\ttraining's binary_logloss: 4.98893e-06\n",
      "[1978]\ttraining's binary_logloss: 4.98344e-06\n",
      "[1979]\ttraining's binary_logloss: 4.97827e-06\n",
      "[1980]\ttraining's binary_logloss: 4.9735e-06\n",
      "[1981]\ttraining's binary_logloss: 4.96911e-06\n",
      "[1982]\ttraining's binary_logloss: 4.964e-06\n",
      "[1983]\ttraining's binary_logloss: 4.95876e-06\n",
      "[1984]\ttraining's binary_logloss: 4.95298e-06\n",
      "[1985]\ttraining's binary_logloss: 4.94838e-06\n",
      "[1986]\ttraining's binary_logloss: 4.94294e-06\n",
      "[1987]\ttraining's binary_logloss: 4.93774e-06\n",
      "[1988]\ttraining's binary_logloss: 4.93282e-06\n",
      "[1989]\ttraining's binary_logloss: 4.92834e-06\n",
      "[1990]\ttraining's binary_logloss: 4.92286e-06\n",
      "[1991]\ttraining's binary_logloss: 4.91781e-06\n",
      "[1992]\ttraining's binary_logloss: 4.91314e-06\n",
      "[1993]\ttraining's binary_logloss: 4.90819e-06\n",
      "[1994]\ttraining's binary_logloss: 4.90324e-06\n",
      "[1995]\ttraining's binary_logloss: 4.89736e-06\n",
      "[1996]\ttraining's binary_logloss: 4.89241e-06\n",
      "[1997]\ttraining's binary_logloss: 4.88727e-06\n",
      "[1998]\ttraining's binary_logloss: 4.88254e-06\n",
      "[1999]\ttraining's binary_logloss: 4.87814e-06\n",
      "[2000]\ttraining's binary_logloss: 4.87306e-06\n"
     ]
    }
   ],
   "source": [
    "# deploy model\n",
    "lgtrain = lgb.Dataset(X_res, y_res)\n",
    "\n",
    "final_lgb = lgb.train(\n",
    "    lgbm_params,\n",
    "    lgtrain,\n",
    "    valid_sets=lgtrain,\n",
    "    num_boost_round=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the final model to the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "preprocess = DataPreprocess(label_encoder)\n",
    "processed_payment_test = preprocess.preprocess_payment(payment_test)\n",
    "billing_test = preprocess.initialize_billing(billing_test)\n",
    "processed_billing_test = preprocess.preprocess_billing(billing_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test = preprocess.merge(processed_payment_test, processed_billing_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in transaction_col:\n",
    "    replace_value = processed_test[processed_test[col].notna()][col].mean()\n",
    "    processed_test[col] = processed_test[col].fillna(replace_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test = processed_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_01_month</th>\n",
       "      <th>transaction_02_month</th>\n",
       "      <th>transaction_03_month</th>\n",
       "      <th>transaction_04_month</th>\n",
       "      <th>transaction_05_month</th>\n",
       "      <th>transaction_06_month</th>\n",
       "      <th>transaction_07_month</th>\n",
       "      <th>transaction_08_month</th>\n",
       "      <th>transaction_09_month</th>\n",
       "      <th>transaction_10_month</th>\n",
       "      <th>...</th>\n",
       "      <th>cash_balance_06_month</th>\n",
       "      <th>cash_balance_07_month</th>\n",
       "      <th>cash_balance_08_month</th>\n",
       "      <th>cash_balance_09_month</th>\n",
       "      <th>cash_balance_10_month</th>\n",
       "      <th>cash_balance_11_month</th>\n",
       "      <th>cash_balance_12_month</th>\n",
       "      <th>MaxDelqCycle</th>\n",
       "      <th>AvgDelqCycle</th>\n",
       "      <th>LateCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10074849</th>\n",
       "      <td>411.00</td>\n",
       "      <td>340.26</td>\n",
       "      <td>993.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>906.38</td>\n",
       "      <td>363.00</td>\n",
       "      <td>915.54</td>\n",
       "      <td>609.50</td>\n",
       "      <td>626.85</td>\n",
       "      <td>396.93</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10086539</th>\n",
       "      <td>0.00</td>\n",
       "      <td>556.92</td>\n",
       "      <td>832.00</td>\n",
       "      <td>642.0</td>\n",
       "      <td>661.26</td>\n",
       "      <td>1880.00</td>\n",
       "      <td>950.86</td>\n",
       "      <td>1591.00</td>\n",
       "      <td>1048.60</td>\n",
       "      <td>500.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10140908</th>\n",
       "      <td>214.10</td>\n",
       "      <td>88.36</td>\n",
       "      <td>200.00</td>\n",
       "      <td>206.0</td>\n",
       "      <td>239.99</td>\n",
       "      <td>160.50</td>\n",
       "      <td>418.00</td>\n",
       "      <td>428.72</td>\n",
       "      <td>202.00</td>\n",
       "      <td>163.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10147994</th>\n",
       "      <td>38.11</td>\n",
       "      <td>39.52</td>\n",
       "      <td>218.40</td>\n",
       "      <td>227.9</td>\n",
       "      <td>224.70</td>\n",
       "      <td>229.69</td>\n",
       "      <td>226.00</td>\n",
       "      <td>504.29</td>\n",
       "      <td>4.24</td>\n",
       "      <td>256.20</td>\n",
       "      <td>...</td>\n",
       "      <td>17.85</td>\n",
       "      <td>55.12</td>\n",
       "      <td>28.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10152808</th>\n",
       "      <td>420.00</td>\n",
       "      <td>1030.00</td>\n",
       "      <td>510.00</td>\n",
       "      <td>423.3</td>\n",
       "      <td>877.50</td>\n",
       "      <td>1157.44</td>\n",
       "      <td>709.00</td>\n",
       "      <td>995.00</td>\n",
       "      <td>1015.00</td>\n",
       "      <td>515.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          transaction_01_month  transaction_02_month  transaction_03_month  \\\n",
       "ID_CPTE                                                                      \n",
       "10074849                411.00                340.26                993.92   \n",
       "10086539                  0.00                556.92                832.00   \n",
       "10140908                214.10                 88.36                200.00   \n",
       "10147994                 38.11                 39.52                218.40   \n",
       "10152808                420.00               1030.00                510.00   \n",
       "\n",
       "          transaction_04_month  transaction_05_month  transaction_06_month  \\\n",
       "ID_CPTE                                                                      \n",
       "10074849                   0.0                906.38                363.00   \n",
       "10086539                 642.0                661.26               1880.00   \n",
       "10140908                 206.0                239.99                160.50   \n",
       "10147994                 227.9                224.70                229.69   \n",
       "10152808                 423.3                877.50               1157.44   \n",
       "\n",
       "          transaction_07_month  transaction_08_month  transaction_09_month  \\\n",
       "ID_CPTE                                                                      \n",
       "10074849                915.54                609.50                626.85   \n",
       "10086539                950.86               1591.00               1048.60   \n",
       "10140908                418.00                428.72                202.00   \n",
       "10147994                226.00                504.29                  4.24   \n",
       "10152808                709.00                995.00               1015.00   \n",
       "\n",
       "          transaction_10_month    ...      cash_balance_06_month  \\\n",
       "ID_CPTE                           ...                              \n",
       "10074849                396.93    ...                       0.00   \n",
       "10086539                500.00    ...                       0.00   \n",
       "10140908                163.20    ...                       1.03   \n",
       "10147994                256.20    ...                      17.85   \n",
       "10152808                515.00    ...                       0.00   \n",
       "\n",
       "          cash_balance_07_month  cash_balance_08_month  cash_balance_09_month  \\\n",
       "ID_CPTE                                                                         \n",
       "10074849                   0.00                   0.00                    0.0   \n",
       "10086539                   0.00                   0.00                    0.0   \n",
       "10140908                   0.00                   0.00                    0.0   \n",
       "10147994                  55.12                  28.35                    0.0   \n",
       "10152808                   0.00                   0.00                    0.0   \n",
       "\n",
       "          cash_balance_10_month  cash_balance_11_month  cash_balance_12_month  \\\n",
       "ID_CPTE                                                                         \n",
       "10074849                   0.00                   0.00                    0.0   \n",
       "10086539                   0.00                   0.00                    0.0   \n",
       "10140908                   3.06                   2.04                    0.0   \n",
       "10147994                   0.00                   0.00                    0.0   \n",
       "10152808                   0.00                   0.00                    0.0   \n",
       "\n",
       "          MaxDelqCycle  AvgDelqCycle  LateCount  \n",
       "ID_CPTE                                          \n",
       "10074849             0           0.0          0  \n",
       "10086539             0           0.0          0  \n",
       "10140908             2           1.0         12  \n",
       "10147994             0           0.0         10  \n",
       "10152808             0           0.0         12  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(processed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp = normalize(X_test[:, :-3])\n",
    "X_test = np.hstack((X_tmp, X_test[:, -3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5100, 40)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lgb = rf.predict(X_test)\n",
    "#predict_lgb = np.array([0 if i < 0.6 else 1 for i in predict_lgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test['Default'] = predict_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = processed_test.reset_index()[['ID_CPTE', 'Default']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../raw_data/performance_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71424379</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64887111</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69431075</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31823308</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39407834</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE PERIODID_MY  Default\n",
       "0  71424379  2014-12-01      NaN\n",
       "1  64887111  2015-12-01      NaN\n",
       "2  69431075  2014-12-01      NaN\n",
       "3  31823308  2016-12-01      NaN\n",
       "4  39407834  2012-12-01      NaN"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10074849</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10086539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10140908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10147994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10152808</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  Default\n",
       "0  10074849        0\n",
       "1  10086539        0\n",
       "2  10140908        0\n",
       "3  10147994        0\n",
       "4  10152808        0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission[['ID_CPTE', 'Default']].merge(results, on='ID_CPTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission[['ID_CPTE', 'Default_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission.rename(columns={'Default_y': 'Default'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71424379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64887111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69431075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31823308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39407834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  Default\n",
       "0  71424379        0\n",
       "1  64887111        0\n",
       "2  69431075        0\n",
       "3  31823308        0\n",
       "4  39407834        0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71424379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64887111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69431075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31823308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39407834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE  Default\n",
       "0  71424379        0\n",
       "1  64887111        0\n",
       "2  69431075        0\n",
       "3  31823308        0\n",
       "4  39407834        0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5100"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CPTE</th>\n",
       "      <th>PERIODID_MY</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71424379</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64887111</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69431075</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31823308</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39407834</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CPTE PERIODID_MY  Default\n",
       "0  71424379  2014-12-01      NaN\n",
       "1  64887111  2015-12-01      NaN\n",
       "2  69431075  2014-12-01      NaN\n",
       "3  31823308  2016-12-01      NaN\n",
       "4  39407834  2012-12-01      NaN"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
